<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Soon&#39;s Blog</title>
        <link>https://meme2515.github.io/</link>
        <description>Recent content on Soon&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 19 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://meme2515.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Apache Airflow 개요 및 DAG 작성 베스트 프렉티스</title>
        <link>https://meme2515.github.io/computer_science/airflow_best_practices/</link>
        <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/computer_science/airflow_best_practices/</guid>
        <description>&lt;img src="https://meme2515.github.io/computer_science/images/airflow_best_1.png" alt="Featured image of post Apache Airflow 개요 및 DAG 작성 베스트 프렉티스" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;본 글은 Managed Airflow Server 환경을 사업 모델로 삼은 &lt;a class=&#34;link&#34; href=&#34;https://www.astronomer.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Astronomer&lt;/a&gt; 유튜브 강좌에 기반.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Apache_Airflow&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Airflow&lt;/a&gt; 란 &lt;strong&gt;데이터 파이프라인 관리를 위한 오픈소스 툴&lt;/strong&gt;이다. &amp;lsquo;14년 Airbnb 에서 사내 프로젝트로 시작한 후, 오픈소싱을 통해 &amp;lsquo;19년 Apache Software Foundation 에서 탑레벨 프로젝트로 선정.&lt;/li&gt;
&lt;li&gt;전세계적으로 백만명 이상의 데이터 엔지니어가 데이터 파이프라인 관리를 위해 활용하고 있음.&lt;/li&gt;
&lt;li&gt;2020년 Airflow 2.0 가 공개됨.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ETL/ELT Pipelines&lt;/strong&gt; : Snowflake 등 DW 에 데이터 적재 - &lt;a class=&#34;link&#34; href=&#34;https://docs.astronomer.io/learn/airflow-snowflake&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Orchestrating Snowflake Queries with Airflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt; : Tensorflow 와 MLFlow 를 활용해 MLOps 서비스 구축 - &lt;a class=&#34;link&#34; href=&#34;https://www.astronomer.io/events/webinars/using-airflow-with-tensorflow-mlflow/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Using Airflow with Tensorflow and MLFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Operationalized Analytics&lt;/strong&gt; : 데이터 추출, 가공을 통해 대시보드 전달 - &lt;a class=&#34;link&#34; href=&#34;https://www.astronomer.io/events/webinars/using-airflow-as-a-data-analyst/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Using Airflow as a Data Analyst&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;core-concepts&#34;&gt;Core Concepts&lt;/h3&gt;
&lt;p&gt;Airflow 의 작업 단위는 DAG, Task 로 구분 가능하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DAG&lt;/strong&gt; : Directed Acyclic Graph. 그래프 형태로 표현된 워크플로우이며, 노드 간 디펜던시는 방향성을 가지게 된다 - &lt;a class=&#34;link&#34; href=&#34;https://docs.astronomer.io/learn/dags&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Introduction to Airflow DAGs&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DAG run&lt;/strong&gt; : 시간 특정이 가능한 DAG 실행 건. 스케줄링이나 매뉴얼 트리거가 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt; : DAG 내 개별 작업 단위.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task instance&lt;/strong&gt; : 시간 특정이 가능한 Task 실행 건.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DAG 작성 시 특정 작업을 수행하는 Operator 를 활용하게 되며, Operator 는 파라미터를 받아 실행되는 함수의 형태를 취한다. DAG 내 각 Operator 는 Task 와 같은 단위 - &lt;a class=&#34;link&#34; href=&#34;https://docs.astronomer.io/learn/what-is-an-operator&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Operators 101&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Action Operators&lt;/strong&gt; : 함수 실행. PythonOperator, BashOperator 등.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transfer Operators&lt;/strong&gt; : 소스로 부터 타겟까지 데이터를 이동. S3ToRedshiftOperator 등.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sensors&lt;/strong&gt; : 특정 이벤트가 발생할때까지 대기. ExternalTaskSensor, HttpSensorAsync 등.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operator 간 데이터 전송이 필요한 경우 &lt;strong&gt;XComs&lt;/strong&gt; 를 활용.&lt;/p&gt;
&lt;h3 id=&#34;components&#34;&gt;Components&lt;/h3&gt;
&lt;p&gt;Airflow 의 효율적인 활용을 위해선 인프라 구성에 대한 이해가 필요하다. 이슈 대응 및 DAG 개발 시 구조에 대한 이해가 필요한 상황이 발생할 수 있음.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Webserver&lt;/strong&gt; : Airflow UI 서빙을 위해 Flask 서버가 Gunicorn 을 통해 구동.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scheduler&lt;/strong&gt; : 잡스케줄링을 위한 Daemon.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt; : Task Metadata 저장소. 보통 PostgreSQL 활용.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Executor&lt;/strong&gt; : Task 수행을 위한 연산 자원 배분. Scheduler 내에서 구동된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;high-level-best-practices&#34;&gt;High-Level Best Practices&lt;/h2&gt;
&lt;h3 id=&#34;멱등성-idempotency&#34;&gt;멱등성 (Idempotency)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;멱등성 (Idempotency)&lt;/strong&gt; : 특정 Operation 을 여러번 실행하더라도 최종 결과는 변형되지 않는다.&lt;/li&gt;
&lt;li&gt;예시로 횡단보도를 건너기 위해 누르는 버튼을 들 수 있다 (미국식). 버튼을 여러번 누르더라도, 일정 기간 동안 파란불이 켜지는 결과는 변동하지 않음.&lt;/li&gt;
&lt;li&gt;Idempotent DAG 는 에러 발생 시 빠른 처리를 가능하게 하고, 데이터 유실을 예방하는 효과를 가진다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;airflow-as-an-orchestrator&#34;&gt;Airflow as an Orchestrator&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Airflow 는 본래의 취지에 충실하게 실행 관점이 아닌, &lt;strong&gt;자동화/관리 (orchestration) 관점에서 접근하는 것이 권장&lt;/strong&gt;된다.&lt;/li&gt;
&lt;li&gt;실무적인 관점에서, 다음과 같은 시사점을 가짐 :
&lt;ul&gt;
&lt;li&gt;Airflow 를 활용해 여러 툴을 활용한 job 을 관리할 것&lt;/li&gt;
&lt;li&gt;연산 자원이 많이 필요한 경우 Spark 와 같은 execution framework 로 작업 인계&lt;/li&gt;
&lt;li&gt;가능한 경우 &lt;a class=&#34;link&#34; href=&#34;https://chartio.com/learn/data-warehouses/understanding-etl-and-elt/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ELT 프레임워크&lt;/a&gt; 활용 (Snowflake 와 같이 DW 상의 연산 자원 활용)&lt;/li&gt;
&lt;li&gt;데이터 처리 과정에서 중간 데이터 저장소를 최대한 활용할 것. XCom 등의 기능을 활용해 용량이 큰 데이터프레임을 가공하는 등의 방법은 비권장.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/airflow_best_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Airflow 를 활용한 Data Orchestration 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;keep-tasks-atomic&#34;&gt;Keep Tasks Atomic&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;하나의 Task 는 하나의 작업만을 수행&lt;/strong&gt;해야 하며, 다른 Task 와 무관하게 재실행이 가능해야 한다.&lt;/li&gt;
&lt;li&gt;Atomized Task 의 부분 성공은 즉 전체 Task 의 성공을 의미해야함.&lt;/li&gt;
&lt;li&gt;예를 들어 ETL Pipeline 구축 시 각각 Extract, Transform, Load 에 해당하는 Task 3개를 정의. 각 Task 의 재실행이 가능하기 때문에, idempotence 가 보장된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;incremental-record-filtering&#34;&gt;Incremental Record Filtering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;가능한 경우 ETL, ELT 파이프라인 작성 시 &lt;strong&gt;항상 전체 데이터를 처리하는 것 보다는, 순차적으로 처리&lt;/strong&gt;하는 편이 좋다.
&lt;ul&gt;
&lt;li&gt;예) 시간 마다 배치가 실행되는 경우 전체 데이터셋을 처리하기 보다 마지막 시간에 발생한 데이터만 처리.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;데이터 유실을 방지하거나, 처리 속도를 향상하는데 많은 도움을 줄 수 있음.&lt;/li&gt;
&lt;li&gt;원천 데이터가 항상 변동하는 경우 과거 결과값을 유지할 수 있으며, 이는 Idempotency 와 연계되는 부분.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Last Modified Date vs. Sequence IDs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Incremental loading 을 위해 가장 권장되는 방법은 마지막 수정일자 (Last Modified Date) 필드 활용이다.&lt;/li&gt;
&lt;li&gt;수정일자 필드 활용이 불가능한 경우, 순차적으로 증가하는 ID 필드를 활용하는 것 또한 가능하다. 이 경우 스케줄러가 기존 데이터셋을 업데이트 하지 않고, 새로운 데이터를 붙여넣는 경우가 가장 이상적.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/airflow_best_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Incremental Record Filtering&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;airflow-variables--macros&#34;&gt;Airflow Variables &amp;amp; Macros&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Airflow 는 기본적으로 &lt;a class=&#34;link&#34; href=&#34;https://realpython.com/primer-on-jinja-templating/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;jinja templating&lt;/a&gt; 을 활용한 &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;자체 변수와 매크로&lt;/a&gt;를 제공하며, 작업 효율성을 위해 이를 최대한 이용하는 것이 좋다 - Readability, idempotency, maintainability 등에서 많은 장점 제공.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Airflow Variables 예시&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Variable&lt;/th&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;{{ data_interval_start }}&lt;/td&gt;
&lt;td&gt;pendulum.DateTime&lt;/td&gt;
&lt;td&gt;Start of the data interval. Added in version 2.2.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;{{ data_interval_end }}&lt;/td&gt;
&lt;td&gt;pendulum.DateTime&lt;/td&gt;
&lt;td&gt;End of the data interval. Added in version 2.2.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;{{ ds }}&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;The DAG run’s logical date as YYYY-MM-DD. Same as {{ dag_run.logical_date | ds }}.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;{{ ds_nodash }}&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;Same as {{ dag_run.logical_date | ds_nodash }}.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;{{ ts }}&lt;/td&gt;
&lt;td&gt;str&lt;/td&gt;
&lt;td&gt;Same as {{ dag_run.logical_date | ts }}. Example: 2018-01-01T00:00:00+00:00.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Airflow Macros 예시&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Variable&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;macros.datetime&lt;/td&gt;
&lt;td&gt;The standard lib’s datetime.datetime&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;macros.timedelta&lt;/td&gt;
&lt;td&gt;The standard lib’s datetime.timedelta&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;macros.dateutil&lt;/td&gt;
&lt;td&gt;A reference to the dateutil package&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;macros.time&lt;/td&gt;
&lt;td&gt;The standard lib’s time&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;macros.uuid&lt;/td&gt;
&lt;td&gt;The standard lib’s uuid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;macros.random&lt;/td&gt;
&lt;td&gt;The standard lib’s random.random&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;예시로 다음과 같이 datetime 패키지를 활용하는 경우, Airflow 변수로 기능을 대체할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Bad example - Define today&amp;#39;s and yesterday&amp;#39;s date using datetime module&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;today&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;today&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;yesterday&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;today&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;timedelta&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Good example - Define yesterday&amp;#39;s date with an Airflow variable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;yesterday&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;yesterday_ds_nodash&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;avoid-top-level-code-in-dag&#34;&gt;Avoid Top Level Code in DAG&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Top Level Code 란 &lt;strong&gt;DAG 혹은 Operator 정의 이외 용도의 코드를 의미&lt;/strong&gt;하며, 이러한 코드를 DAG 에 포함시키지 않도록 주의해야 한다 (특히 외부 시스템에 대한 request).&lt;/li&gt;
&lt;li&gt;이러한 부분에 부주의할 시 연산 부담, 코드 가독성 등에서 많이 제약 사항이 발생할 수 있음.&lt;/li&gt;
&lt;li&gt;다음 예시는 다른 DB 에서 수집한 정보를 기반으로 PostgresOperator 를 생성하는 DAG 작성의 Bad Practice 와 Good Practice 를 나열한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bad Practice 의 경우 &lt;strong&gt;Operator 정의 바깥 부분에서 DB 커넥션을 만들었고&lt;/strong&gt;, 이에 따라 실제 DAG 가 수행되지 않더라도 자원을 소모할 여지가 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Bad practice: top-level code in a DAG file&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.decorators&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dag&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.providers.postgres.operators.postgres&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresOperator&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.providers.postgres.hooks.postgres&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresHook&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pendulum&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;hook&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresHook&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;database_conn&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hook&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_records&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;SELECT * FROM grocery_list;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sql_queries&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;grocery&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;amount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sql_query&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;INSERT INTO purchase_order VALUES (&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grocery&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#39;, &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;amount&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;);&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sql_queries&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@dag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;start_date&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2023&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_active_runs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;schedule&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;@daily&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;catchup&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;bad_practices_dag_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;insert_into_purchase_order_postgres&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresOperator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;partial&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;task_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;insert_into_purchase_order_postgres&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;postgres_conn_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;postgres_default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql_queries&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;bad_practices_dag_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;반면 Good Practice 예시에선 &lt;strong&gt;해당 DB 커넥션을 만드는 Task 를 별도 생성&lt;/strong&gt;하였고, 이에 따라 실제 DAG 가 실행되지 않는 이상 자원을 소모하지 않게됨.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Good practice: top-level code in a DAG file&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.decorators&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;task&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.providers.postgres.operators.postgres&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresOperator&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.providers.postgres.hooks.postgres&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresHook&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pendulum&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@dag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;start_date&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2023&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_active_runs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;schedule&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;@daily&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;catchup&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;good_practices_dag_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@task&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_list_of_results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# good practice: wrap database connections into a task&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;hook&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresHook&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;database_conn&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hook&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_records&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;SELECT * FROM grocery_list;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@task&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;create_sql_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;grocery&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;amount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;INSERT INTO purchase_order VALUES (&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grocery&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#39;, &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;amount&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;);&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sql_queries&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;create_sql_query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_list_of_results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;insert_into_purchase_order_postgres&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PostgresOperator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;partial&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;task_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;insert_into_purchase_order_postgres&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;postgres_conn_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;postgres_default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql_queries&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;good_practices_dag_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;이외에도 파이썬 함수, SQL 쿼리문을 외부 파일에 저장하는 등, DAG 파일을 일종의 Config 파일과 같이 깔끔하게 유지해 주어야한다 (향후 유지보수가 훨씬 원활).&lt;/p&gt;
&lt;h3 id=&#34;consistent-method-for-task-dependencies&#34;&gt;Consistent Method for Task Dependencies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Airflow 상에서 Task Dependencies 를 정의하는 방법은 크게 set_upstream(), set_downstream() 함수 활용과 &amp;laquo;, &amp;raquo; 오퍼레이터 활용 방식으로 구분할 수 있다.&lt;/li&gt;
&lt;li&gt;특정 방식이 권장되는 것은 아니나, 정의 방법을 전반적으로 통일해주어야 코드 가독성을 높일 수 있음.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;leverage-airflow-features&#34;&gt;Leverage Airflow Features&lt;/h2&gt;
&lt;h3 id=&#34;provider-packages&#34;&gt;Provider Packages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Airflow 가 사실상 표준 프레임워크로 자리잡았기 때문에, 이외 툴과 연계 활용을 위한 써드파티 &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow-providers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Provider Packages&lt;/a&gt; 가 매우 다양하게 공개되어있다 (GCP, AWS, Databricks 등).&lt;/li&gt;
&lt;li&gt;가능한 경우, 함수를 직접 정의하기 보다는 이러한 provider package 를 최대한 활용하는 편이 유지보수와 공수 최수화 관점에서 권장.&lt;/li&gt;
&lt;li&gt;다양한 provider package 는 다음 링크에서 확인 가능 - &lt;a class=&#34;link&#34; href=&#34;https://registry.astronomer.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Astronomer Provider Packages Registry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;where-to-run-jobs&#34;&gt;Where to Run Jobs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Airflow 는 자체적으로 중소 규모의 data processing task 를 처리할 수 있지만, 연산 자원이 아주 많이 필요한 경우 &lt;a class=&#34;link&#34; href=&#34;https://spark.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Spark&lt;/a&gt; 와 같은 대규모 데이터 처리 프레임워크에 작업을 인계하여야 함 - &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow-providers-apache-spark/stable/operators.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Spark Operators&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;DAG 를 작성하는 과정에서 Airflow 가 자체적으로 데이터를 처리하는 경우, 이에 필요한 연산 자원이 구비되었는지 확인이 반드시 필요하다.&lt;/li&gt;
&lt;li&gt;Task 레벨에서 연산 자원을 유동적으로 활용하기 위해서 Kubernetes Executor 활용이 가능.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;intermediary-data-storage&#34;&gt;Intermediary Data Storage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;소스 -&amp;gt; 타겟으로 직접 데이터를 이동하는 것은 코드 작성이 적기 때문에 괜찮은 방법으로 보일 수 있다. 하지만 ETL 프로세스의 중간 과정을 모니터링 하는 것이 불가능하기 때문에, S3 나 SQL Staging 테이블과 같은 중간 저장소를 활용하는 것이 권장.&lt;/li&gt;
&lt;li&gt;API Limit 이 발생하는 상황에서 유용하게 활용할 수 있음.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-best-practices&#34;&gt;Other Best Practices&lt;/h2&gt;
&lt;h3 id=&#34;consistent-file-structure&#34;&gt;Consistent File Structure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;일정한 파일 구조를 유지하는 것이 유지보수 측면에서 많은 도움이 됨.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── dags/ # Where your DAGs go
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│   └── example-dag.py # An example dag that comes with the initialized project
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── Dockerfile # For Astronomer&amp;#39;s Docker image and runtime overrides
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── include/ # For any other files you&amp;#39;d like to include
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── plugins/ # For any custom or community Airflow plugins
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;├── packages.txt # For OS-level packages
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;└── requirements.txt # For any Python packages&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;dag-name--start-date&#34;&gt;DAG Name &amp;amp; Start Date&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;DAG 의 시작 날짜(start_date)는 static 하게 유지되어야 한다.&lt;/li&gt;
&lt;li&gt;시작 날짜를 변경할 경우 새로운 DAG 이름을 부여해주어야 함. 시작 날짜 변경 시 Airflow database 는 이를 새로운 DAG 로 인식하는데, DAG 이름이 동일하다면 Scheduler 에러 발생 위험이 발생.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;retries&#34;&gt;Retries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Airflow 가 분산처리 시스템과 연계된 경우, 예기치 못하게 task 가 멈추는 현상이 발생할 가능성이 높다 (유지되는 host 수가 많기 때문).&lt;/li&gt;
&lt;li&gt;시스템 에러에 대비해 최소 2회 정도 retry 설정을 하는 것이 권장된다 (분산처리 과정에서 발생하는 대부분의 에러에 대응 가능한 숫자).&lt;/li&gt;
&lt;li&gt;다음과 같은 레벨에서 retry 설정이 가능하다 :
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tasks&lt;/strong&gt; : Operator 의 retries 파라미터 조정&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DAGS&lt;/strong&gt; : DAG 의 default_args 오브젝트에 retries 포함&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deployments&lt;/strong&gt; : AIRFLOW__CORE__DEFAULT_TASK_RETRIES 환경변수 지정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=HvjnLCQygO4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Astronomer - DAG Writing Best Practices in Apache Airflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=zVzBVpbgw1A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Astronomer - DAG Writing Best Practices in Apache Airflow 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.astronomer.io/learn/intro-to-airflow&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Astronomer - An Introduction to Apache Airflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.astronomer.io/learn/dag-best-practices&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Astronomer - Official Site Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>인과추론 (Causal Inference) 개요</title>
        <link>https://meme2515.github.io/machine_learning/causal_inference/</link>
        <pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/machine_learning/causal_inference/</guid>
        <description>&lt;img src="https://meme2515.github.io/machine_learning/images/causal_inference_4.webp" alt="Featured image of post 인과추론 (Causal Inference) 개요" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;인과추론이란 &lt;strong&gt;최종적인 결과값에 영향을 주는 독립변수를 파악해, 이를 조절하는 것에 목적&lt;/strong&gt;을 두며 예측과제와 상반된 목적을 가진다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Prediction vs. Causal Inference, &lt;a class=&#34;link&#34; href=&#34;https://yeong-jin-data-blog.tistory.com/entry/%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0Causal-Inference-%EA%B0%9C%EC%9A%94&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;벌꿀오소리의 공부 일지&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;인과추론과 예측 과제는 다른 목적을 가지지만 경우에 따라 &lt;em&gt;(ex. 모델링을 위한 변수 선정 과정에서 인과추론 방법론 활용 등)&lt;/em&gt; 상호 보완적인 관계를 가질 수 있다.
&lt;ul&gt;
&lt;li&gt;인과추론과 예측 과제는 인풋 -&amp;gt; 모델 -&amp;gt; 아웃풋 이라는 간단한 파이프라인 내에서 최종적인 관심사가 다를뿐, 서로 밀접한 관계를 맺는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;인과추론 모델 또한 한계점을 가지기 때문에 결과를 절대적인 답으로 볼 수는 없다. 다만 &lt;strong&gt;합리적이고 구체적인 증거를 기반으로 주장할 수 있는 근거&lt;/strong&gt;를 제시한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Prediction vs. Causal Inference Approaches, &lt;a class=&#34;link&#34; href=&#34;https://yeong-jin-data-blog.tistory.com/entry/%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0Causal-Inference-%EA%B0%9C%EC%9A%94&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;벌꿀오소리의 공부 일지&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;전통적으로 인과추론은 통계 방법론적 접근이 일반적이었으나, 최근 ML 을 활용한 다양한 방법론이 제시되고 있다.&lt;/li&gt;
&lt;li&gt;회사에서 보통 접하게 되는 A/B 테스팅이란 통계학 기반의 실험적 방법론이며, 이외에도 다양한 접근법이 존재.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;endogeneity-내생성&#34;&gt;Endogeneity (내생성)&lt;/h2&gt;
&lt;h3 id=&#34;문제-정의&#34;&gt;문제 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;변수 간 명확한 인과성을 파악하는데 가장 큰 방해요소는 &lt;strong&gt;내생성 (endogeneity)&lt;/strong&gt; 이다.&lt;/li&gt;
&lt;li&gt;내생성이란 독립 변수가 모델의 오차와 상관성을 가지는 경우를 의미한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
y_i = \alpha + \Beta x_i + \epsilon_i
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;아래와 같은 회귀식에서 유의미한 $\alpha$ 와 $\Beta$ 값을 얻기 위해선 다음 조건이 충족되어야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
E[{\epsilon}_i | x_i] = 0
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;즉, $\alpha$ 와 $\Beta$ 로 설명되는 변수 $y_i$ 와 $x_i$ 간의 관계에서 설명되지 않는 다른 요인이 작용할 경우, 명확한 관계를 판별하는 것이 불가능해지는 것.&lt;/li&gt;
&lt;li&gt;오차값에 의해 영향을 받는 변수 $x_i$ 는 &lt;strong&gt;내생변수 (endogenuous variable)&lt;/strong&gt; 로 분류된다. 이와 다르게 모델 내 다른 어떤 값으로 부터도 영향을 받지 않는 변수는 &lt;strong&gt;외생변수 (exogenuous variable)&lt;/strong&gt; 로 분류.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;발생-원인&#34;&gt;발생 원인&lt;/h3&gt;
&lt;p&gt;내생성의 주요 발생 원인은 다음과 같이 크게 세종류로 구분이 가능하다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1) Omitted Variables&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_5.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. &lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/causal-inference-with-linear-regression-endogeneity-9d9492663bac&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Casual Inference with Linear Regression&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;모델 내 존재하지 않는 변수 $Z$가 독립변수, 종속변수와 상관성을 가지게 될 경우 이를 &lt;strong&gt;교란변수 (Confounding Variable)&lt;/strong&gt; 라 칭한다.&lt;/li&gt;
&lt;li&gt;이러한 교란변수가 회귀식 내에 존재하지 않을 경우 (omitted), 이에 영향을 받는 독립변수는 오차값과 상관성을 가지기 때문에 내생변수가 되어버림.&lt;/li&gt;
&lt;li&gt;회귀식에 교란변수를 더하면, 내생성이 사라지고 기존 독립변수의 상관계수가 올바른 값으로 수정됨.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;(2) Simultaneity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;내생성의 또 다른 원인은 종속변수가 독립변수에 영향을 미치는 경우이다. 이 경우 X -&amp;gt; Y 와 Y -&amp;gt; X 의 인과성이 모두 합당하기 때문에 실제 상관계수 산출에 어려움을 겪을 수 있다.
&lt;ul&gt;
&lt;li&gt;예) 높은 교육 수준이 평균 소득을 높이는 것은 사실이나, 평균 소득이 높은 가구는 교육에 더욱 많은 지출을 하는 것 또한 사실이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;이러한 관계는 &lt;strong&gt;Simultaneity Bias&lt;/strong&gt; 를 발생시키며, 관계에서 정확한 인과성을 파악하는 것이 불가능.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;(3) Measurement Error&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;회귀식의 기본 전제는 모든 데이터가 정확하게 측정되었다는 것이나, 실제 측정 환경에서 오류가 발생했을 가능성이 있다.&lt;/li&gt;
&lt;li&gt;이렇듯 오류가 발생한 측정값과 실제값 간의 차이를 &lt;strong&gt;측정 오차 (Measurement Error)&lt;/strong&gt; 라고 칭한다.&lt;/li&gt;
&lt;li&gt;종속변수 $Y$ 내 측정 오차가 존재하는 경우, 내생성이 발생하지 않는다. 반면 독립변수 $X$ 내 측정 오차가 존재하는 경우 내생성 발생.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;simpsons-paradox&#34;&gt;Simpson&amp;rsquo;s Paradox&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;인과추론 과정에서 발생 가능한 대표적인 내생성 문제의 예시가 &lt;strong&gt;심슨의 역설 (Simpson&amp;rsquo;s Paradox)&lt;/strong&gt; 이다.&lt;/li&gt;
&lt;li&gt;간단히 설명해, &lt;strong&gt;여러 그룹의 자료를 합했을 때의 결과가 각 그룹을 구분했을 때의 결과와 다른 때&lt;/strong&gt;를 의미한다.&lt;/li&gt;
&lt;li&gt;예시로 백신 A와 B 중 특정 질병을 치료하는데 더 나은 효과를 보이는 백신을 선택해야 한다고 가정해보자.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_7.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. &lt;a class=&#34;link&#34; href=&#34;https://medium.com/bondata/simpsons-paradox-and-confounding-190a26f9e039&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Simpson&amp;rsquo;s Paradox and Confounding&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;아래와 같이, 그룹을 단순하게 백신 A, B 를 맞았을 경우로 분리할 경우 다음과 같은 테이블을 얻을 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_8.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. &lt;a class=&#34;link&#34; href=&#34;https://medium.com/bondata/simpsons-paradox-and-confounding-190a26f9e039&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Simpson&amp;rsquo;s Paradox and Confounding&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;당연히 상단의 수치만으로 비교하였을 경우, 사망률이 16% 로 더 낮은 백신 A를 선택하는 것이 타당하다.&lt;/li&gt;
&lt;li&gt;하지만 데이터를 세분화해, 환자가 백신을 맞기 전 상태로 나누어 확인하게되면 다음과 같이 반대의 결과값이 도출된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_9.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 6. &lt;a class=&#34;link&#34; href=&#34;https://medium.com/bondata/simpsons-paradox-and-confounding-190a26f9e039&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Simpson&amp;rsquo;s Paradox and Confounding&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;이와 같이 비직관적인 결과가 도출되는 이유는 Treatment A 를 처방받은 환자는 대부분 Mild 한 상태에 있었으며, Treatment B 를 처방받은 환자는 대부분 Severe 한 상태에 있었다는 점에 기인한다. 즉, 가중치에 차이가 존재.&lt;/li&gt;
&lt;li&gt;이러한 상황에서 백신을 선택하기 위한 의사결정을 수행하기 위해서는, 문제의 인과 모형 (Causal Structure) 을 감안해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Case A : 환자의 상태가 백신을 결정하는 경우&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_10.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 7. &lt;a class=&#34;link&#34; href=&#34;https://medium.com/bondata/simpsons-paradox-and-confounding-190a26f9e039&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Simpson&amp;rsquo;s Paradox and Confounding&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;공급량의 차이로 인해 Treatment A 는 비교적 상태가 양호한 환자에게 투약하고, Treatment B 는 상태가 안좋은 환자에게 투약한 경우이다.&lt;/li&gt;
&lt;li&gt;선별 방식의 차이로 다음과 같은 샘플 불균형이 발생한다.
&lt;ul&gt;
&lt;li&gt;백신 A를 투약 받은 그룹은 불균형적으로 사망할 확률이 낮은 환자가 다수를 구성.&lt;/li&gt;
&lt;li&gt;백신 B를 투약 받은 그룹은 불균형적으로 사망할 확률이 높은 환자가 다수를 구성.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;선별 방식이 구조적으로 불균형하기 때문에, 세분화된 분석결과를 참고하는 것이 타당하다 (백신 B 선정).&lt;/li&gt;
&lt;li&gt;이 경우 내생성의 발생 원인은 &lt;strong&gt;백신 배분 방식이라는 교란변수이다&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Case B : 백신이 환자의 상태를 결정하는 경우&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_11.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 8. &lt;a class=&#34;link&#34; href=&#34;https://medium.com/bondata/simpsons-paradox-and-confounding-190a26f9e039&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Simpson&amp;rsquo;s Paradox and Confounding&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;공급량의 차이로 인해 대기시간의 차이가 발생하였으며, 상대적으로 오래 기다린 Treatment B 환자의 상태가 더욱 악화된 경우이다.
&lt;ul&gt;
&lt;li&gt;백신 B를 투약 받은 그룹은 투약을 위해 대기하는 시간동안 사망할 확률이 높아지게 된다.&lt;/li&gt;
&lt;li&gt;백신 A를 투약 받은 그룹은 투약을 위해 대기하는 시간이 없어 사망할 확률이 높아지지 않게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;이러한 경우 선별 방식의 불균형성이 없고, 대기 시간 또한 Treatment 의 특성으로 볼 수 있기 때문에 합산된 분석결과를 참고하는 것이 타당하다 (백신 A 선정).&lt;/li&gt;
&lt;li&gt;이 경우 &lt;strong&gt;인과관계의 복잡성은 증가했지만, 내생성이 발생했다고 볼 수 없다&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;해결-방법&#34;&gt;해결 방법&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/causal_inference_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 9. &lt;a class=&#34;link&#34; href=&#34;https://yeong-jin-data-blog.tistory.com/entry/%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0Causal-Inference-%EA%B0%9C%EC%9A%94&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;벌꿀오소리의 공부 일지&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;인과추론 과정에서 발생 가능한 내생성을 통제하기 위해 일반적으로 다음과 같은 3가지 방법을 사용할 수 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Research Design&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Randomized Controlled Trial&lt;/strong&gt; : 샘플 수집 과정을 디자인해 내생성을 통제하는 방식. 가장 효과적이지만 현실적인 한계가 존재한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quasi-Experiment&lt;/strong&gt; : 실험과 관계 없이 발생한 데이터를 기반으로 실험 환경을 모방.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/bondata/instrumental-variable-2-e4ff9ae9ca09&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Local Average Treatment Effect (LATE)&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=dGLXUwGCu4A&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Selection Model&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/use-causal-graphs-4e3af630cf64&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Causal Graph&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Od6oAz1Op2k&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CodeEmporium - Causal Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=MFnOYNU5sbk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CodeEmporium - Causal Inference w/ ML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://yeong-jin-data-blog.tistory.com/entry/%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0Causal-Inference-%EA%B0%9C%EC%9A%94&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;벌꿀오소리의 공부 일지&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/causal-inference-with-linear-regression-endogeneity-9d9492663bac&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Casual Inference with Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=lLI-0pK9MD8&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ben Lambert - Endogeneity and Instrumental Variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/bondata/simpsons-paradox-and-confounding-190a26f9e039&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Medium - Simpson&amp;rsquo;s Paradox and Confounding&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>로그 데이터의 개념과 활용 방식</title>
        <link>https://meme2515.github.io/computer_science/log_analysis/</link>
        <pubDate>Thu, 13 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/computer_science/log_analysis/</guid>
        <description>&lt;img src="https://meme2515.github.io/computer_science/images/log_2.png" alt="Featured image of post 로그 데이터의 개념과 활용 방식" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;로그란&#34;&gt;로그란?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;시스템 내에서 발생한 모든 이벤트를 시간순으로 기록한 데이터.&lt;/li&gt;
&lt;li&gt;카카오톡 등 일상생활에서 쓰이는 앱 부터 IoT 장비 까지 다양한 접목 예시가 존재한다.&lt;/li&gt;
&lt;li&gt;가장 대표적인 예시로 유저 행동 로그가 있으며, 추가 분석을 통해 사용자의 행동 패턴을 확인하거나, 머신러닝 기반의 유저 클러스터링을 수행하는 등 다양한 활용이 가능.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;체계적인-로그-관리가-필요한-이유&#34;&gt;체계적인 로그 관리가 필요한 이유&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;로그가 없으면 당연히 기록된 이벤트 데이터를 확인할 수 없고, 시스템 활용 현황에 대한 분석이 불가능하다.&lt;/li&gt;
&lt;li&gt;부주의한 로깅은 추후 회사에서 성과 데이터를 분석하고자 할때 과거 데이터가 활용 불가능한 난감한 상황을 연출할 수 있다.&lt;/li&gt;
&lt;li&gt;이러한 상황을 사전에 방지하기 위해는 &lt;strong&gt;잘 설계된 로그 및 주기적인 QA 가 필수적.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;데이터-로그-설계-주체&#34;&gt;데이터 로그 설계 주체&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;회사에 따라 상황이 다를 수 있으나 일반적으로 (1) 해당 기능을 만든 기획자 또는 PM (2) 데이터 분석가 또는 엔지니어로 구분될 수 있음.&lt;/li&gt;
&lt;li&gt;기획자는 보고 싶은 데이터와 추가된 기능에 대한 명확한 이해가 있고, 분석가는 분석에 용이한 형태에 대한 피드백을 줄 수 있음으로 협업해 진행하는 편이 좋음.&lt;/li&gt;
&lt;li&gt;로그 설계 방법론은 변성윤 님의 &lt;a class=&#34;link&#34; href=&#34;https://zzsza.github.io/data/2021/06/13/data-event-log-definition/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;어쩐지 오늘은&lt;/a&gt; 블로그 참조 (존경&amp;hellip;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;로그의-형태&#34;&gt;로그의 형태&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;크게 DB 와 파일 형태로 구분이 가능하다.&lt;/li&gt;
&lt;li&gt;단순 파일로 로그 관리를 진행할 경우, 분석을 위해 DW 로 옮기는 파이프라인 필요.&lt;/li&gt;
&lt;li&gt;일반적인 비즈니스 환경에선 크게 다음과 같은 용도로 구분하는 것이 가능 :
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;시스템 로그&lt;/strong&gt; : OS, RDBMS 와 같은 미들웨어에서 문제가 발생했을때 장애 원인 파악 용도&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;어플리케이션 로그&lt;/strong&gt; : 개발자가 어플리케이션의 장애 원인을 파악하기 위한 용도&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;비즈니스 로그&lt;/strong&gt; : 향후 분석을 위해 수집하는 사용자의 서비스 사용 형태, 거래 기록 등&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;로그-시스템&#34;&gt;로그 시스템&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/log_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 로그 시스템 다이어그램 - &lt;a class=&#34;link&#34; href=&#34;https://spidyweb.tistory.com/484&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spidy Web 블로그&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;Solution&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;API Server&lt;/td&gt;
&lt;td&gt;로그를 클라이언트로 부터 수집하고 데이터를 정제&lt;/td&gt;
&lt;td&gt;웹 서버&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Message Q&lt;/td&gt;
&lt;td&gt;로그 저장소가 순간적으로 많은 트래픽을 감당할 수 없는 경우가 많기 때문에, 중간에 MQ 를 넣어서 들어오는 로그를 저장하며 완충&lt;/td&gt;
&lt;td&gt;Kafka (대량 큐) AWS SQS or 구글Pub/Sub (클라우드 큐) Rabbit MQ (일반적인 큐)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Message Consumer&lt;/td&gt;
&lt;td&gt;MQ 로 부터 로그를 Message Consumer 가 순차적으로 읽어서 Log Storage에 저장&lt;/td&gt;
&lt;td&gt;Multi Thread(or Process) + Timer 를 조합하여 메시지를 폴링 방식으로 읽어오는 어플리케이션&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Log Storage&lt;/td&gt;
&lt;td&gt;로그 저장소&lt;/td&gt;
&lt;td&gt;Elastic Search, Hadoop(HDFS), HBase (하둡) Drill, Druid (SQL 기반 빅데이터 플랫폼)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reporting&lt;/td&gt;
&lt;td&gt;저장된 로그는 Reporting 툴을 이용하여 시각화&lt;/td&gt;
&lt;td&gt;Kibana, Zeppelin, Jupyter&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;tracking-plan&#34;&gt;Tracking Plan&lt;/h2&gt;
&lt;h3 id=&#34;tracking-plan-이란&#34;&gt;Tracking Plan 이란?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;로그 설계/분석에서 높은 품질의 데이터 만큼 중요한 것은 잘 정돈된 로그 설계 문서 (Tracking Plan) 이다.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;이러한 설계 과정이 잘 정리되어야 추후 분석 시 어떤 이벤트를 확인해야 하는지, 확인된 데이터가 정상적인지 등을 확인할 수 있다.&lt;/li&gt;
&lt;li&gt;Tracking Plan 을 잘 활용하면 이벤트가 어떤 방식으로 기록되는지 한눈에 확인할 수 있다. 또한 중복 수집을 사전에 예방하고, 일관성을 유지할 수 있음.&lt;/li&gt;
&lt;li&gt;Tracking Plan 내에 다음과 같은 정보를 포함 :
&lt;ul&gt;
&lt;li&gt;이벤트 이름&lt;/li&gt;
&lt;li&gt;이벤트 설명&lt;/li&gt;
&lt;li&gt;이벤트 카테고리 (추상화 또는 도메인)&lt;/li&gt;
&lt;li&gt;어느 시점에 실행되는지&lt;/li&gt;
&lt;li&gt;어떤 파라미터를 가지는지 (타입, 설명, 필수 여부)&lt;/li&gt;
&lt;li&gt;어느 플랫폼에서 남기는지&lt;/li&gt;
&lt;li&gt;언제부터 수집했는지&lt;/li&gt;
&lt;li&gt;언제 수집을 중지했는지&lt;/li&gt;
&lt;li&gt;설계, 개발 완료 여부&lt;/li&gt;
&lt;li&gt;QA 개발 여부&lt;/li&gt;
&lt;li&gt;배포 여부&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;참조-template&#34;&gt;참조 Template&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1oEbMAWQt7lFXVJtM8sMdTaqjoeVQvZok24o_lOtxCyI/edit?pli=1#gid=854230389&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Avo - Analytics Tracking Plan Template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1-6rXRomzq05YDQ9A6QG9A2i-jez72amPw-Johhd-heQ/edit#gid=45524225&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Amplitude - Basic Event Tracking Plan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1b_uHvFbXAuKxFNFwNjRj4-_6sSrhlgHoizeJLSp1Grw/edit#gid=465273655&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Practico Analytics - Analytics Tracking Plan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mixpanel.app.box.com/s/4qhbozhmsrzvzpakan6hqif0t3036qui&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Mixpanel - Retail &amp;amp; eCommerce Tracking Plan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.google.com/spreadsheets/d/10PV5mC_iT98mtIBbYMyVCxkYtTbCitHJ1DH2qAEQI-4/edit#gid=1162516317&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Data-led - Tracking Plan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;분석-활용&#34;&gt;분석 활용&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;별도 파싱이 필요한 경우 ETL 파이프를 통해 데이터베이스에 적재.&lt;/li&gt;
&lt;li&gt;바로 활용 가능한 경우 Storm/Spark 등 분산처리 기술을 이용하여 실시간 분석.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;우아한형제들-로그-매니지먼트-예시&#34;&gt;우아한형제들 로그 매니지먼트 예시&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://techblog.woowahan.com/2536/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;우아한기술블로그 - 로그 데이터로 유저 이해하기&lt;/a&gt; 에 관련 담당자님이 올려주신 로그 분석 사례이다.&lt;/p&gt;
&lt;h3 id=&#34;서비스-이해&#34;&gt;서비스 이해&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;클라이언트 로그 설계를 위해 앱의 모든 화면과 이벤트 (클릭, 배너 노출 등) 를 상세히 파악.&lt;/li&gt;
&lt;li&gt;실제 유저가 앱을 사용하듯 모든 기능과 화면에 대한 이해가 필수적.&lt;/li&gt;
&lt;li&gt;모든 분석가가 로그 설계 과정을 거치는 것은 아니나, 분석 방향과 프레임 설정에 매우 큰 도움을 줄 수 있음.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;로그-수집&#34;&gt;로그 수집&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;엔지니어 및 개발자 협업을 통한 실제 로그 수집 진행.&lt;/li&gt;
&lt;li&gt;저장소 내 JSON 파일로 적재되었으며, 실시간으로 데이터 추출/분석이 가능한 Spark, Zeppelin 환경 구성.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/log_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 수집 로그 예시 - &lt;a class=&#34;link&#34; href=&#34;https://techblog.woowahan.com/2536/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;우아한기술블로그 - 로그 데이터로 유저 이해하기&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;품질-확보&#34;&gt;품질 확보&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;로그 수집이 처음 진행된 경우 데이터 품질 확보가 특히 중요함.&lt;/li&gt;
&lt;li&gt;의도한 바와 같이 각 필드에 적절한 데이터가 쌓이고 있는지, 누락 혹은 이상치는 존재하지 않는지 확인 진행.&lt;/li&gt;
&lt;li&gt;품질 확보에 꽤나 많은 시간이 소요되며, 문제 발생 시 담당자와 협업을 통해 해결.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/log_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. 수집 오류 예시 - &lt;a class=&#34;link&#34; href=&#34;https://techblog.woowahan.com/2536/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;우아한기술블로그 - 로그 데이터로 유저 이해하기&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;분석-프레임-설정&#34;&gt;분석 프레임 설정&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;로그 데이터는 특성상 단시간 내 몇 백만 건의 데이터가 순식간에 쌓이고, 정의 항목이 수백건에 달하기 때문에 무작정 분석을 시작하는 경우 허우적 거리는 경험을 하게 될 수 있음.&lt;/li&gt;
&lt;li&gt;이를 방지하기 위해 목적을 명확히 설정하고 적절한 질문을 사전에 작성.&lt;/li&gt;
&lt;li&gt;로그 설계 경험을 바탕으로 대략적인 프레임을 구축하여, 분석 및 인사이트 도출 과정에서 참조.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;프레임 예시 :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;목적 1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;앱 내 시나리오 및 기능을 개선할 수 있는 방안을 찾자 (궁극적으로 사용성 및 UX 개선)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;질문&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;구간 별 Conversion Rate 는? 어떠한 기준으로 계산할 것인가? 세션의 기준?&lt;/li&gt;
&lt;li&gt;퍼널 별 이탈율은 얼마나 되는지? 주요 bottleneck 구간은?&lt;/li&gt;
&lt;li&gt;각 단계 별 주요 행동 패턴은? 주로 활용되는 기능은? 세부적인 개선점은?&lt;/li&gt;
&lt;li&gt;재구매율 혹은 재방문율은 어떠한가?&lt;/li&gt;
&lt;li&gt;지표 계산 방식은? 평균 재구매 시간? 시간이 오래 걸릴수록 패널티가 있는지?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;목적 2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;전체 유저 세분화하여 행동 패턴의 차이 확인 &amp;raquo; 핵심 그룹 타겟팅&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;질문&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;지역별에 따른 유저 행동 패턴의 차이는?&lt;/li&gt;
&lt;li&gt;주간 방문수 기준으로 구분하면?&lt;/li&gt;
&lt;li&gt;주문 경험 유 vs 무 여부로 구분&lt;/li&gt;
&lt;li&gt;신규 유저 vs 기존 가입 유저의 행동 패턴의 차이는?&lt;/li&gt;
&lt;li&gt;타 플랫폼 이용 경험 유 vs 무 (디바이스 크로스)가 결제에 미치는 영향은?&lt;/li&gt;
&lt;li&gt;주문한 카테고리 (예, 시킨 것만 시키는 그룹, 바꾸는 그룹)별로 구분하면?&lt;/li&gt;
&lt;li&gt;결제시 주문 방식별 세분화? 주문 방식별로 특이한 패턴은?&lt;/li&gt;
&lt;li&gt;클릭한 배너에 따른 결제율 차이는?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;디테일에-목숨걸지-말-것&#34;&gt;디테일에 목숨걸지 말 것&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;업데이트된 서비스를 로그 설계에 반영하지 못했거나, 기타 유사한 이유로 해석 불가능한 결과가 나오는 경우가 있다.&lt;/li&gt;
&lt;li&gt;예시적으로 유저가 특정 화면을 3초 동안 5번 확인한 것으로 조회되는 경우, 다소 자의적으로 느껴지더라도 보다 인간의 행동을 효과적으로 설명하기 위해 5개 행을 하나의 행으로 축약.&lt;/li&gt;
&lt;li&gt;유사한 데이터 발생할 경우 무엇을 기준으로 중복을 제거하는 것이 적절한가? 에 대한 자문.&lt;/li&gt;
&lt;li&gt;결국, 분석의 초기 목적과 논리를 기반으로한 접근 방식이 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;분석-결과&#34;&gt;분석 결과&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;업무의 절반은 분석 결과를 유관자에게 전달하고, 설득을 통해 실질적인 변화와 성과를 이끌도록 지원하는 것.&lt;/li&gt;
&lt;li&gt;따라서 &lt;strong&gt;분석 결과를 명확하고 간결하게 전달하는 것은 매우, 매우 중요하다&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;고급 방법론이 아닌 실질적인 변화를 이끌어 낼 수 있는 방식을 택할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://spidyweb.tistory.com/484&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spidy Web 블로그&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zzsza.github.io/data/2021/06/13/data-event-log-definition/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;어쩐지 오늘은&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://techblog.woowahan.com/2536/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;우아한기술블로그 - 로그 데이터로 유저 이해하기&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>PySpark 란?</title>
        <link>https://meme2515.github.io/computer_science/pyspark/</link>
        <pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/computer_science/pyspark/</guid>
        <description>&lt;img src="https://meme2515.github.io/computer_science/images/pyspark_1.jpeg" alt="Featured image of post PySpark 란?" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apache Spark 는 제한된 공간의 로컬 환경에서 처리하기 어려운 대규모 데이터를, 여러대의 서버를 활용해 분산처리할 수 있도록 돕는 오픈소스 툴이다.&lt;/li&gt;
&lt;li&gt;Hadoop 생태계의 &lt;a class=&#34;link&#34; href=&#34;https://12bme.tistory.com/154&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MapReduce&lt;/a&gt; 와 상응하는 개념이나, Map, Reduce 단계를 순차적으로 정의해야 하는 것이 아니라 사전 정의된 operation 을 통해 전처리가 가능하다 (예. join operation).&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/pyspark_4.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. MapReduce vs. Spark&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Spark 는 기본적으로 연산 결과를 메모리상에서 처리하기 때문에 디스크 처리 위주인 MapReduce 방식에 비해 처리 속도가 월등히 빠르다.&lt;/li&gt;
&lt;li&gt;Spark 는 Scala 로 작성된 프로그램이며, Python 으로 다루기 위해서는 PySpark 라는 파이썬 API 활용이 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;concepts&#34;&gt;Concepts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Distributed Computing&lt;/strong&gt; : 하나의 작업을 여러대의 서버로 분산하여 소요 시간을 단축하는 연산 방식&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cluster&lt;/strong&gt; : 유저의 요청에 따라 상호 작용하고, 결과값을 구하는 과정에서 활용되는 서버 군집&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resilient Distributed Dataset (RDD)&lt;/strong&gt; : 하둡 HDFS 와 유사한 분산 저장 환경이며, 정형 데이터 구조를 가지지 않음. 최근엔 널리 사용되지 않는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-architecture--theory&#34;&gt;Spark Architecture &amp;amp; Theory&lt;/h2&gt;
&lt;h3 id=&#34;architecture&#34;&gt;Architecture&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/pyspark_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Spark Architecture&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Spark 클러스터로 명령을 전달하고, 결과값을 전달 받기 위해선 우선 Spark 세션을 정의해주어야 한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.sql&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SparkSession&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SparkSession&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;builder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;appName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getOrCreate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;이렇게 정의된 세션은 Spark 클러스터의 마스터 노드인 SparkContext 와 소통한다. 반면 실제 분산 작업을 수행하는 노드는 Worker Node 라 지칭하며, SparkContext 는 Cluster Manager 를 통해 Worker Node 의 연산 자원을 부여받고, 업무를 분배한다.&lt;/p&gt;
&lt;p&gt;각 Worker Node 안에는 작업을 수행하는 Executer 프로그램이 있으며, 여러 Task 를 동시에 저장하고 중간 결과를 캐시에 저장하는 기능을 제공한다.&lt;/p&gt;
&lt;h3 id=&#34;directed-acyclic-graph-dag&#34;&gt;Directed Acyclic Graph (DAG)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow&lt;/a&gt; 와 같은 단방향성 태스크 그래프를 의미한다.&lt;/li&gt;
&lt;li&gt;Spark 는 데이터 가공과 관련된 커맨드를 받은 후 이에 상응하는 DAG 연산 그래프를 생성한다.&lt;/li&gt;
&lt;li&gt;DAG 내 모든 작업을 작업 수행 이전에 파악하는 것이 가능하기 때문에, 이에 따른 최적화가 수반.&lt;/li&gt;
&lt;li&gt;가공된 데이터는 새로운 데이터프레임 오브젝트 내 저장된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/pyspark_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Dag Overview&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;PySpark 에는 (1) Transformation, (2) Action 두 종류의 커맨드가 존재한다.&lt;/li&gt;
&lt;li&gt;가장 대표적인 차이점은 Transformation 커맨드는 새로운 데이터프레임을 생성하지만, Action 커맨드는 실행 결과를 곧바로 출력한다는 점.&lt;/li&gt;
&lt;li&gt;또한 Transformation 커맨드는 DAG 를 생성할 뿐 추후 실제 산출된 데이터가 필요할때까지 해당 DAG 를 수행하지 않는다. 반면 Action 커맨드는 코드 호출 시 곧바로 모든 가공 작업을 수행한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/pyspark_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. Transformations &amp;amp; Actions&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;데이터 가공 중간 과정의 산출 결과를 캐싱하는 기능이 제공된다.&lt;/li&gt;
&lt;li&gt;캐싱된 데이터는 Worker Node 의 메모리상에 존재하므로, 가용 공간에 비해 너무 큰 규모의 데이터가 캐싱되지 않도록 유의할 필요가 있다.&lt;/li&gt;
&lt;li&gt;캐싱된 데이터를 취합해 Master Node 에 저장하기 위해선 콜렉션 기능을 활용한다.&lt;/li&gt;
&lt;li&gt;캐싱 과정과 유사하게 Master Node 가용 공간을 감안하여 콜렉션을 수행할 필요가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/pyspark_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Caching&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;pyspark-dataframe&#34;&gt;PySpark DataFrame&lt;/h2&gt;
&lt;h3 id=&#34;전처리-코드-예시&#34;&gt;전처리 코드 예시&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터 로딩&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 기본 csv 파일 로딩 (모든 데이터 타입은 String 으로 자동 지정)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;option&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;header&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;true&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shk/heart.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 데이터 타입 정의&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Age INTEGER, Sex STRING, ChestPainType STRING&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shk/heart.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;header&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 데이터 타입 추정&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shk/heart.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inferSchema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;header&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Null Replace&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shk/heart.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nullValue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;NA&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;데이터 저장&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 기본 csv 파일 저장&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;save&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shk/heart.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Overwrite&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;overwrite&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;save&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/Users/shk/heart.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Count, Show &amp;amp; Column Select&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Count Rows&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 첫 5개 로우 보기&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 컬럼 선택&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Sex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;데이터 타입 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 데이터 타입 확인&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;printSchema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtypes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 데이터 타입 변경&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.sql.types&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;FloatType&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;withColumn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Age&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Age&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;FloatType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;컬럼 삭제 및 이름 바꾸기&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 컬럼 삭제&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;AgeFixed&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 컬럼 이름 변경&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;withColumnRenamed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;통계치 산출&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;RestingBP&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;describe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Drop NA&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Drop NA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;na&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 전체 로우가 NA 인 경우만 삭제&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;na&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;how&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;all&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# NA 삭제 기준 컬럼 수 정의&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;na&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;thresh&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# NA 삭제 기준 컬럼 정의&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;na&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;how&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;any&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Replace 값 정의&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;na&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fill&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;?&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Imputer 활용 (평균치)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.ml.feature&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Imputer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;imptr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Imputer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;inputCols&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;RestingBP&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;outputCols&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;RestingBP&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setStrategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mean&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imptr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;필터링&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 필터링&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age &amp;gt; 18&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age &amp;gt; 18&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 필터링 (복수조건)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ChestPainType&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;ATA&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ChestPainType&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;ATA&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 필터링 (반대조건)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;ChestPainType&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;ATA&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;수식 활용&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.sql.functions&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;expr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;age + 0.2 * AgeFixed&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;withColumn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;new_col&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;expr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Group By&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 평균치 산정&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;avg(HeartDisease)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Sorting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.sql.functions&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;desc&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;disease_by_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;avg(HeartDisease)&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;disease_by_age&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orderBy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;desc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;age&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Functions&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pyspark.sql&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;functions&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;F&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupby&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;HeartDisease&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;pandas-와의-비교&#34;&gt;Pandas 와의 비교&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/pyspark_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 6. Pandas vs Spark 데이터 처리 속도 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Row, Column, Schema 를 제공하는 유사한 데이터프레임 환경이나, 사용법이 동일하지 않고 싱글노드 기반의 Pandas 와 활용 목적에서 차이가 존재한다. 하지만, 파이썬 기반의 데이터프레임 환경인 만큼 상당히 유사한 부분들이 존재하고, Pandas 활용에 익숙한 사용자에게 PySpark 의 진입장벽은 낮은 편.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Pandas 로 변환&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pd_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toPandas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Pandas 에서 변환&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;spark_df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;createDataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pd_df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=cZS5xYYIPzk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Moran Reznik - The Only PySpark Tutorial You Will Ever Need&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=tDVPcqGpEnM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Computerphile - Apache Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=2PVzOHA3ktE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Simplilearn - Hadoop vs Spark&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>모델링을 위한 특성 선별 방법 (Feature Selection)</title>
        <link>https://meme2515.github.io/machine_learning/feature_selection/</link>
        <pubDate>Sun, 09 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/machine_learning/feature_selection/</guid>
        <description>&lt;img src="https://meme2515.github.io/machine_learning/images/feature_1.webp" alt="Featured image of post 모델링을 위한 특성 선별 방법 (Feature Selection)" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;운영되는 서비스에서 파생되는 데이터의 종류는 매우 다양하고, 이 중 모델링에 유용한 데이터를 추려내 활용하는 변수 선별 과정은 어렵지만 필수적인 일이다. 정돈된 방식으로, 유의미한 데이터를 선별해 모델링을 진행하지 않을 경우 발생할 수 있는 문제점은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;지나친 노이즈로 인해 오버피팅이 발생할 수 있다.&lt;/li&gt;
&lt;li&gt;모델 성능이 저하될 수 있다.&lt;/li&gt;
&lt;li&gt;불필요한 학습 시간이 발생할 수 있다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;실무적인 feature selection 과정에선 문제 환경에 기반한 적절한 가설 설정과 테크니컬한 검증 과정이 병행되어야 한다. 아무리 feature 의 유용성이 수치화된다고 하더라도, 조직이 보유하고 있는 모든 데이터를 활용하는 것은 불가능하기 때문이다.&lt;/p&gt;
&lt;p&gt;다음 글은 비즈니스 적인 가설 설정보다는, 이를 검증하기 위한 테크니컬 방법론을 크게 Filtering, Wrapping, Embedding 세 분류로 정리한다.&lt;/p&gt;
&lt;h2 id=&#34;filter-기반-방법&#34;&gt;Filter 기반 방법&lt;/h2&gt;
&lt;p&gt;변수 간 관계성에 기반해 모델 활용에 유용한 feature 를 선정하는 방식이다. 선택 과정에서 실제 모델링을 진행하지는 않으며, 연산처리가 빠른 대신 실제 모델 적용 시 예기치 못한 결과가 발생할 수 있다는 단점을 가진다. 특성상 통계적 방법론이 주를 이룬다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/feature_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;mutual-information&#34;&gt;Mutual Information&lt;/h3&gt;
&lt;p&gt;정보이론에서 두 개 변수에 대한 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Mutual_information&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Mutual information&lt;/a&gt; 이란, 하나의 변수를 통해 다른 변수에 대해 얻을 수 있는 정보의 양을 설명하며, 보편적인 Correlation Coefficient 와 달리 변수 간 선형관계나, 연속성을 요하지 않는다.&lt;/p&gt;
&lt;p&gt;$$
\text{Mutual Information} = \sum_{x\in X}\sum_{y\in Y} p(x,y) \text{log}[\frac{p(x,y)}{p(x)p(y)}]
$$&lt;/p&gt;
&lt;p&gt;위 방정식에서 $p(x,y)$ 는 $x, y$ 변수의 결합확률을, $p(x)$ 와 $p(y)$ 는 각각 $x, y$ 변수의 주변확률을 의미한다. 두 변수 중 하나의 값이 변동하지 않는 경우 Mutual Information 은 $0$ 에 근접한 값을 가지며, 변수 간 정보성이 커질수록 (예. 두 변수가 항상 같은 값을 가지는 경우) Mutual Information 은 큰 값을 가지게 된다.&lt;/p&gt;
&lt;p&gt;변수값이 연속성을 가지는 경우, binning 을 통한 카테고리화가 필요하다. 즉, Mutual Information 은 카테고리 변수 활용을 위한 Feature Selection 방법론으로 생각할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt;  &lt;span class=&#34;nn&#34;&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mutual_info_classif&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;importances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mutual_info_classif&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;feat_importances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;importances&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dataframe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataframe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;feat_importances&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;barh&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;teal&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/feature_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;chi-square-test&#34;&gt;Chi-square Test&lt;/h3&gt;
&lt;p&gt;카이제곱검정이란 특정 변수에 대해 가설적으로 설정한 분포와 실제 관측된 분포 간 차이에 대해 통계적 유의성을 구하는 과정을 뜻한다 (예. 동전을 100번 던졌을때 해당 동전이 fair coin 인지 검증).&lt;/p&gt;
&lt;p&gt;데이터가 주어졌을때 분석가는 인풋 변수와 타겟 변수가 독립적이라는 가설 하에 다음 방정식을 활용해 인풋 변수의 모든 값에 대한 expected frequency 를 구할 수 있다.&lt;/p&gt;
&lt;p&gt;$$
P(AB) = P(A) \cdot P(B)
$$&lt;/p&gt;
&lt;p&gt;하지만 이렇게 도출된 값은 실제 데이터를 가공해 구한 $P(AB)$ 와 차이를 가질 것이다. 이렇게 구한 expected frequency 와 실제 관측된 frequency 간 차이가 클때, 해당 변수는 타겟 변수에 대해 높은 종속성을 가지며, 유용한 feature 라고 판단할 수 있게 되는 것.&lt;/p&gt;
&lt;p&gt;(분포를 직접 비교하는 것이 아니다. 변수 간 독립성 가설이 기각되는지 여부에 따라 종속성을 판단하는 과정이라고 생각하는 것이 보다 정확하다)&lt;/p&gt;
&lt;p&gt;$$
\Chi_c^2 = \sum \frac{(O_i - E_i)^2}{E_i}
$$&lt;/p&gt;
&lt;p&gt;위 방정식에서 $O_i$ 은 observed value, $E_i$ 은 expected value 를 의미한다.&lt;/p&gt;
&lt;p&gt;카이제곱검정 활용에는 다음과 같은 제약 사항이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모든 변수가 카테고리 변수일 것&lt;/li&gt;
&lt;li&gt;독립적으로 샘플링 되었을 것&lt;/li&gt;
&lt;li&gt;모든 값에 대한 expected frequency 가 5 이상일 것&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SelectKBest&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chi2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#convert to categorical data by converting data to integers&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_cat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;astype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#three features with highest chi-squared stats selected&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;chi2_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SelectKBest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chi2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_kbest_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chi2_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;fishers-score&#34;&gt;Fisher&amp;rsquo;s Score&lt;/h3&gt;
&lt;p&gt;전통적인 Feature Extraction 방법론이다. ANOVA 와 유사하게 타겟 카테고리 별 분산과, 전체 데이터의 분산을 비교해 통계치를 산출하는 방법 - &lt;a class=&#34;link&#34; href=&#34;https://stats.stackexchange.com/questions/277123/fisher-score-feature-selection-implementation#:~:text=The%20score%20of%20the%20i,of%20the%20i%2Dth%20feature.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;참고 글&lt;/a&gt;. 산정된 통계치를 나열해 가장 &amp;ldquo;유의미한&amp;rdquo; feature 를 특정하는 것이 가능하다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;skfeature.function.similarity_based&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fisher_score&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#calculating scores&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ranks&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fisher_score&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fisher_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#plotting ranks&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;feat_importances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Series&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;importances&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dataframe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataframe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;feat_importances&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;barh&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;teal&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/feature_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;correlation-coefficient&#34;&gt;Correlation Coefficient&lt;/h3&gt;
&lt;p&gt;변수 간 선형 관계를 측정해 상관성이 높은 feature 를 추리는 방법이다. 타겟 변수와의 상관성을 파악하는 것은 물론, feature 간 상관성 또한 파악할 수 있기 때문에 다중공신성 문제를 사전에 인지하는데에 도움을 줄 수 있다.&lt;/p&gt;
&lt;p&gt;하지만 해당 방법론 또한 분명한 단점들이 존재한다. 대표적으로 비선형 관계성을 파악하지 못한다는 점을 들 수 있는데, 실무적 환경에서 구축하는 모델이 대부분 비선형성 관계를 전제한다는 점을 생각했을때 실제 모델 적용에 부적합한 방법일 가능성이 높다.&lt;/p&gt;
&lt;p&gt;(다만 $R^2$ 와 같은 결정계수를 활용한다면 실제 선형 관계를 가지는 feature 를 특정하는데 도움을 줄 수 있다)&lt;/p&gt;
&lt;p&gt;또 다른 단점은 선형관계 파악에 지표의 연속성이 전제된다는 점이다. 따라서 타겟 변수가 카테고리 변수인 경우, 상관성을 활용한 특성 선별은 다소 부적합할 수 있다. 문제 특성과 변수의 종류에 따라 여러 방법을 혼용해서 사용하는 것이 필요할 수 있고, 이렇듯 여러가지 접근법으로 동일한 변수가 반복적으로 선별되는 경우 해당 변수는 모델 성능에 기여할 확률이 높을 것이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;seaborn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sns&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#correlation matrix&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cor&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dataframe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;corr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#plotting heatmap&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;heatmap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;annot&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/feature_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;wrapper-기반-방법&#34;&gt;Wrapper 기반 방법&lt;/h2&gt;
&lt;p&gt;실제 데이터의 subset 을 활용해 모델링을 진행하고, 성능 지표에 기반해 가장 높은 성능을 보이는 feature 집합을 특정하는 방식이다. 당연한 이야기이지만, 모델 적용 환경에서 검증된 feature set 을 특정할 수 있는 대신 연산속도가 느리다는 단점을 가진다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/feature_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;forward-feature-selection&#34;&gt;Forward Feature Selection&lt;/h3&gt;
&lt;p&gt;성능 기여도가 가장 높은 feature 를 시작으로, feature set 을 순차적으로 늘려가는 방식이다. 마치 greedy algorithm 과 같이 주어진 단계에서, 개별 변수의 기여도를 기반으로 의사결정을 내리는 만큼 변수 조합의 시너지 효과가 충분히 반영되지 않을 수 있다.&lt;/p&gt;
&lt;p&gt;또한 모델 정의가 선행되기 때문에 파라미터 튜닝과 병렬로 진행될 경우 많은 자원이 소모될 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;mlxtend.feature_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SequentialFeatureSelector&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LogisticRegression&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;class_weight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;balanced&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;solver&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;lbfgs&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_jobs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ffs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SequentialFeatureSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;best&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_jobs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ffs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ffs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k_feature_names_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;backward-feature-elimination&#34;&gt;Backward Feature Elimination&lt;/h3&gt;
&lt;p&gt;모든 feature set 을 대상으로 모델링을 진행한 후, 순차적으로 기여도가 낮은 feature 를 제외하는 방식이다. 기본적으로 forward feature selection 과 유사한 장단점을 가진다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;mlxtend.feature_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SequentialFeatureSelector&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LogisticRegression&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;class_weight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;balanced&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;solver&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;lbfgs&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_jobs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ffs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SequentialFeatureSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;best&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_jobs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ffs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ffs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k_feature_names_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;exhuastive-feature-selection&#34;&gt;Exhuastive Feature Selection&lt;/h3&gt;
&lt;p&gt;가능한 모든 feature 조합을 비교해 가장 성능이 좋은 feature set 을 추리는 방식이며, 관점에 따라 가장 신뢰도가 높은 방법일 수 있으나 연산 과정에 비효율적인 측면이 존재한다. 데이터 규모에 따라 많은 자원이 소모될 수 있기때문에 문제 적용에 적합한지에 대한 충분한 고민이 필요하다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;mlxtend.feature_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ExhaustiveFeatureSelector&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.ensemble&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RandomForestClassifier&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#create the ExhaustiveFeatureSelector object&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;efs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ExhaustiveFeatureSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;RandomForestClassifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;min_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;max_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;scoring&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;roc_auc&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#fit the object to the training data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;efs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;efs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#print the selected features&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;selected_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;efs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;best_idx_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;selected_features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;recursive-feature-elimination&#34;&gt;Recursive Feature Elimination&lt;/h3&gt;
&lt;p&gt;우선 전체 feature set 을 대상으로 모델링을 진행한 후, correlation coefficient 와 같은 특정한 지표를 기반으로 일정 비중의 feature 를 제외하는 방법을 재귀적으로 반복하게 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RFE&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rfe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RFE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_features_to_select&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rfe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rfe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;embedded-방법&#34;&gt;Embedded 방법&lt;/h2&gt;
&lt;p&gt;모델 구조 내 내장된 변수 채택 기법을 뜻한다. 모델이 &amp;ldquo;알아서&amp;rdquo; feature selection 을 수행하는 것 처럼 비춰질 수 있으나, 사실 정석적인 feature selection 으로 얻는 이점을 곱씹어본다면 (예. 학습 시간 단축 등) 모델링 결과에 기반한 별도 feature selection 과정이 동반되어야 한다는 점은 유사하다고 볼 수 있을 것 같다.&lt;/p&gt;
&lt;p&gt;결국 방식에 차이가 있을뿐, 어떠한 feature 가 가장 모델 성능에 기여하는지를 판별하고, 이를 기반으로 데이터를 전처리 하는 과정은 필수적이다! 라고 볼 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;regularization&#34;&gt;Regularization&lt;/h3&gt;
&lt;p&gt;흔히 알려진 Ridge (L2), Lasso (L1), Elastic Net (L1 &amp;amp; L2) 과 같은 회귀식 기반의 regularization 기법이다. 모델 파라미터의 합산값을 손실 함수에 더해, 최소한의 feature 만을 사용한다는 개념이며, 각각 방법론에 따른 행동양식의 차이가 존재한다 - &lt;a class=&#34;link&#34; href=&#34;https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;참고 글&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;random-forest-importance&#34;&gt;Random Forest Importance&lt;/h3&gt;
&lt;p&gt;랜덤 포레스트 모델링 시, feature 별 성능 기여도를 판단할 수 있는 importance 지수 산정이 가능하다. 이 중 가장 대표적인 것이 MDI (Mean Decrease in Impurity) Importance 지수인데, 해당되는 feature 를 기반으로 데이터가 나뉘어질때 감소하는 impurity 의 평균치라고 이해할 수 있다 - &lt;a class=&#34;link&#34; href=&#34;https://velog.io/@vvakki_/%EB%9E%9C%EB%8D%A4-%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8%EC%97%90%EC%84%9C%EC%9D%98-%EB%B3%80%EC%88%98-%EC%A4%91%EC%9A%94%EB%8F%84Variable-Importance-3%EA%B0%80%EC%A7%80#:~:text=%EB%9E%9C%EB%8D%A4%20%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8%EB%9E%80%2C%20%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95,%EB%AA%A8%ED%98%95%28Ensemble%20Model%29%EC%9E%85%EB%8B%88%EB%8B%A4.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;참고 글&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;source&#34;&gt;Source&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=eJIp_mgVLwE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=eJIp_mgVLwE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=wjsNqBmjBuw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=wjsNqBmjBuw&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>개인 프로젝트 - 모기 활동 지수 예측기</title>
        <link>https://meme2515.github.io/projects/mosquito/</link>
        <pubDate>Mon, 27 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/projects/mosquito/</guid>
        <description>&lt;img src="https://meme2515.github.io/projects/images/mosquito_title.jpeg" alt="Featured image of post 개인 프로젝트 - 모기 활동 지수 예측기" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/projects/images/mosquito_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 어플리케이션 화면 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/meme2515/mosquito_app&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub 링크&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;위 화면과 같이 관심 지역을 읍면동 단위까지 선택하면 조회 당일의 모기 활동 지수를 예측하는 웹 어플리케이션 입니다.&lt;/p&gt;
&lt;p&gt;구축된 ML 모델을 노트북 환경이 아닌 실제 어플리케이션에 적용하려면 어떤 작업이 필요할까에 대한 궁금증으로 개인적으로 진행한 프로젝트이며, 프로젝트 진행 내용은 대략적으로 다음과 같습니다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;오픈 데이터셋을 활용한 사이킷런 회귀 모델 구축&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Flask 어플리케이션과 모델 연동 및 기본적인 html 페이지 구축&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;기상청 단기 예보 API 를 활용한 날씨 데이터 조회 기능 구현&lt;/li&gt;
&lt;li&gt;지역 별 경위도와 기상청 API 좌표 체계 간 변환 함수 구현&lt;/li&gt;
&lt;li&gt;기본적인 JavaScript 를 활용해 지역 선택 기능 구현&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;WSGI, NGINX 를 활용한 배포 서버 구축&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;도커를 활용한 프로젝트 컨테이너 생성&lt;/li&gt;
&lt;li&gt;Digital Ocean 클라우드 서버 배포&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;모기-활동-지수&#34;&gt;모기 활동 지수?&lt;/h2&gt;
&lt;p&gt;모기 활동 지수라는 개념이 생소하실텐데요, 기상청에서 운영 중인 모기 활동 예측 기술을 먼저 소개 드립니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://news.seoul.go.kr/welfare/archives/511985&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;홍보 자료&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://koreascience.kr/article/JAKO201867551547852.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;방재저널&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://patentimages.storage.googleapis.com/c0/15/61/0ea5a1509636d0/KR20180060730A.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;특허청 자료&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/projects/images/mosquito_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 데이터 수집 경로&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;일반적인 인식과는 다르게 우리나라 또한 모기와 관련된 질병으로 부터 안전지역이라 할 수 없는데, 90년대 이후 북한 접경 지역에선 말라리아 환자가 지속적으로 발생하고 있고 인천국제공항 주변 지역 또한 해외여행객의 영향으로 지키바이러스, 뎅기열 등 매개감염병을 유발하는 많은 외래종 모기가 유입된 상황입니다.&lt;/p&gt;
&lt;p&gt;이에 대해 수도권 기상청은 국민 건강 보호를 목적으로 2018년 모기 예측 기술 개발 사업을 추진했습니다. 수도권, 특히 인천광역시에 많이 분포한 수백 개 모기 관측망의 데이터를 기온, 토지이용 상황 등과 함께 분석해 랜덤 포레스트 모델을 구축했는데요. 주요 인사이트는 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;개채 수 증가는 7월 초, 9월 중순 2번의 정점을 이루는데, 이는 여름철 집중호우의 영향으로 추정.&lt;/li&gt;
&lt;li&gt;일최저기온이 10도를 넘으면 모기개채수는 증가하기 시작함.&lt;/li&gt;
&lt;li&gt;10월 최저기온이 급격히 낮아지면 모기개채수도 급감함.&lt;/li&gt;
&lt;li&gt;도심과 농촌, 해안 간 우세하게 나타나는 모기의 종류에서 많은 차이를 보임.&lt;/li&gt;
&lt;li&gt;서울시의 경우 기온이 1도 상승하면 모기 발생 위험이 약 10.8% 씩 증가.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/projects/images/mosquito_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 빨간집모기 개체 수와 기온의 시계열 분포&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;회귀-모델&#34;&gt;회귀 모델&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://news.seoul.go.kr/welfare/mosquito&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;데이터 소스 - 서울시&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;프로젝트의 중점이 모델 서빙이기 때문에, 특별한 feature engineering 이나 model selection 과정 없이 간단한 회귀 모델로 모기 출현 지수를 예측하는 모델을 구축했습니다&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(사실 활용한 데이터셋 자체가 서울시가 제공한 예측치의 시계열 자료이기에, 적당히만 세팅한다면 100% 에 가까운 정확도가 나올 것으로 생각됩니다)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;우선 데이터셋은 1,342 건의 일 별 (1) 모기 지수, (2) 강수량, (3) 최저 기온, (4) 최대 기온으로 구성되어 있습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;mosquito_Indicator&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;rain(mm)&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;min_T(℃)&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;max_T(℃)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;count&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1342.000000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1342.000000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1342.000000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1342.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;mean&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;251.991803&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.539866&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;10.005663&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;19.096870&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;std&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;295.871336&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;13.868106&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;11.109489&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;11.063394&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;min&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.000000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.000000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-17.800000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-10.700000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;max&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1000.000000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;144.500000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;30.300000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;39.600000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;여기서 mosquito_indicator 로 표기된 모기 활동 지수는 특정한 범위 내에서 채집된 모기 개채수를 정규화시킨 지표라고 이해하시면 됩니다.&lt;/p&gt;
&lt;p&gt;원본 데이터에는 이외에도 관측 날짜가 포함되어 있습니다. 이는 타깃 변수가 계절성을 가지기 때문에 핵심 feature 로 활용될 수 있지만, 모델링 과정을 최대한 간단하게 유지하기 위해 아래 내용에선 생략되었습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/projects/images/mosquito_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. 변수 별 Pair Plot&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;변수 별 관계를 시각적으로 살펴봤을때, 최저/최고 기온이 모기 개채수와 전반적으로 큰 상관성을 나타내는 것을 확인할 수 있습니다. 강수량의 경우 이상치로 인해 관계성을 시각적으로 판단하기가 어려웠고, 따라서 아래와 같이 강수량의 로그 값과 모기 활동 지수 간의 관계를 월 별로 시각화 하였습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/projects/images/mosquito_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. 월 별 로그 강수량과 모기 활동 지수&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;생각과 달리 10월을 제외하면 모기 개채수와 강수량 간에는 큰 상관성이 관찰되지는 않았습니다. 저널에 기재된 것과 같이 7월 초, 9월 말 집중 호우로 개채수가 급감된다는 가설과 다소 상반되는 결과였는데, 하지만 월 별 모기 활동 지수의 분포에 차이가 있다는 점을 확인할 수 있었어요.&lt;/p&gt;
&lt;p&gt;모델링은 사이킷런의 회귀 모델을 기반으로 진행했으며, Validation Set 에 대해 약 155 의 Mean Absolute Error 를 기록했습니다.&lt;/p&gt;
&lt;h2 id=&#34;flask-어플리케이션&#34;&gt;Flask 어플리케이션&lt;/h2&gt;
&lt;p&gt;학습이 완료된 모델은 별도 pkl 파일로 저장하여, flask 앱에서 바로 활용할 수 있도록 구성했습니다. 이후 유저의 위치 정보를 기상 정보로 변환하려고 보니 다음과 같은 데이터 변환 과정이 필요했습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;읍면동 까지의 위치 정보를 경위도 좌표로 변환&lt;/li&gt;
&lt;li&gt;변환된 경위도 좌표를 기상청 격자정보로 변환&lt;/li&gt;
&lt;li&gt;격자정보를 통해 기상청 API 에서 강수량, 기온 정보 가져오기&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;읍면동 위치에 따른 경위도 정보는 국내 모든 행정구역에 대한 데이터를 &lt;a class=&#34;link&#34; href=&#34;https://skyseven73.tistory.com/23&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;해당 블로그&lt;/a&gt; 에서 다운받아 사용했습니다. csv 형태로 서버에 저장 후, 필요시 pandas 데이터프레임으로 불러와 해당되는 경위도를 변수에 저장하게 되는데 추후 성능 개선을 위해선 데이터베이스 활용 또한 고려가 가능합니다.&lt;/p&gt;
&lt;p&gt;기상청 API 에서 필요로 하는 위치 정보는 경위도가 아닌 별도의 &lt;a class=&#34;link&#34; href=&#34;https://fronteer.kr/service/kmaxy&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;격자정보&lt;/a&gt;이기 때문에 별도의 변환 로직을 구현하는 과정 또한 필요했습니다. 로직은 &lt;a class=&#34;link&#34; href=&#34;https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;amp;blogId=javaking75&amp;amp;logNo=220089575454&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;해당 블로그&lt;/a&gt; 를 참고했습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/projects/images/mosquito_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. 기상청 격자정보 - 위경도 변환 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;이렇게 추출된 기상청 격자정보 등의 값을 기반으로 &lt;a class=&#34;link&#34; href=&#34;https://www.data.go.kr/data/15043494/fileData.do&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;기상청 단기예보 API&lt;/a&gt; 에서 최신 기상 정보를 가져오는 파이프라인을 구축했습니다. 예측하고자 하는 날짜의 바로 전날 오후 11시에 발표된 예보값을 가져오게 되며, API 코드는 위 링크에 첨부되어 있는 API 가이드를 참고했습니다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/projects/images/mosquito_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. 기상청 단기 예보 API 출력값 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;프론트엔드 구성 단계에선 브라우저 내에서 읍면동 단위 까지의 위치 정보를 기입할 수 있도록 구성하는 작업이 필요했는데, html 페이지 내에서 선택된 &amp;ldquo;시도&amp;rdquo; 값에 따라 &amp;ldquo;시군구&amp;rdquo; 의 선택값 등을 변동하는 과정에서 약간의 jQuery를 활용했습니다 (&lt;a class=&#34;link&#34; href=&#34;https://chichi-story.tistory.com/18&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;참고 블로그&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;wsgi--nginx--도커&#34;&gt;WSGI + NGINX + 도커&lt;/h2&gt;
&lt;p&gt;가능한 배포 환경에 가까운 경험을 위해서 flask 앱을 WSGI 서버인 gunicorn 으로 래핑 후, gunicorn 을 구동하는 3개의 도커 컨테이너를 대상으로 로드 밸런싱을 수행하는 nginx 서버를 구축했습니다. 관련해 공부한 내용은 &lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/computer_science/wsgi/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;웹서버와 WAS&lt;/a&gt; 에 자세히 기록해 두었습니다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>웹 어플리케이션 배포 - WSGI 와 NGINX 서버란</title>
        <link>https://meme2515.github.io/computer_science/wsgi/</link>
        <pubDate>Sun, 26 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/computer_science/wsgi/</guid>
        <description>&lt;img src="https://meme2515.github.io/computer_science/images/wsgi_1.png" alt="Featured image of post 웹 어플리케이션 배포 - WSGI 와 NGINX 서버란" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;이번 글에서는 웹 개발에서 자주 등장하는 단어인 wsgi, nginx, werkzeug 등을 설명한다.&lt;/p&gt;
&lt;h2 id=&#34;web-server-vs-was&#34;&gt;Web Server vs. WAS&lt;/h2&gt;
&lt;p&gt;먼저 Web Server 와 Web Application Server (WAS) 의 개념을 살펴볼 필요가 있다.&lt;/p&gt;
&lt;p&gt;현대적인 웹페이지엔 &lt;strong&gt;정적 요소&lt;/strong&gt; (Static Pages - image, html, css, javascript) 와 &lt;strong&gt;동적 요소&lt;/strong&gt; (Dynamic Pages - python, database) 가 혼재되어 있다. 보통 이러한 정적인 요소를 클라이언트 사이드에서 처리되는 프론트엔드, 동적인 요소를 서버 사이드에서 처리되는 백엔드로 지칭한다.&lt;/p&gt;
&lt;p&gt;하지만 클라이언트 사이드에서 처리되는 html, css 또한 결국 웹 서버에서 관련된 파일을 내려받는 과정이 필요한데, 이러한 정적인 요소를 담당하는 서버를 &lt;strong&gt;Web Server&lt;/strong&gt;, 그리고 동적인 요소를 담당하는 서버를 &lt;strong&gt;WAS&lt;/strong&gt; 로 설정하는 것이다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/wsgi_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 웹서버와 WAS 의 구성&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;WSGI 는 이와 같은 구조에서 동적인 요소를 담당하는 WAS 를 구축하는데 활용된다. 반면 NGINX 는 Web Server 의 한 종류로서, 웹사이트의 정적인 요소를 담당하고 필요 시 WSGI 서버와 통신하여 동적인 결과값을 클라이언트에서 서빙하는 역할 또한 수행하는 것.&lt;/p&gt;
&lt;h2 id=&#34;wsgi&#34;&gt;WSGI&lt;/h2&gt;
&lt;p&gt;로컬 환경에서 서버를 구동해본 경험이 있다면 다음과 같은 메시지에 익숙할 것이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-zsh&#34; data-lang=&#34;zsh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WARNING: This is a development server. Do not use it in a production deployment.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Use a production WSGI server instead
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* Restarting with stat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* Debugger is active!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* Debugger PIN: 123-456-789
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* Running on http://127.0.0.1:5000/&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;이와 같은 메시지가 뜨는 이유는, Flask 나 Django 같은 백엔드 프레임워크에서 기본적으로 구동되는 서버는 실제 배포를 염두하고 제작된 서버 구조가 아니기 때문이다. 이와 같은 서버는 Werkzeug (벨저크) 패키지에서 제공하는 개발 서버인데, HTTP 기능이 제한되어 있고, 효율성, 안정성, 보안성에서 많은 취약점이 존재한다 &lt;em&gt;(하지만 속도가 빠르고, 개발에 용이한 기능들을 제공)&lt;/em&gt;. 따라서 배포 환경에 알맞은 WSGI HTTP 서버를 활용할 필요가 발생한다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/wsgi_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. WSGI 서버 활용 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;WSGI (Web Server Gateway Interface) 란 유저로 부터 전송받은 HTTP Request 를 Django 와 같은 백엔드 프레임워크가 이해할 수 있는 Python 오브젝트로 변환하는 역할을 수행한다. 앞서 언급한 벨저크 서버 또한 사실 이러한 기능을 수행하고 있지만, 개발 환경에 맞는 WSGI 서버란 다수의 워커를 구성해 분산 처리가 가능하고, 개발 서버의 취약점을 보완한 버전이라고 생각할 수 있다.&lt;/p&gt;
&lt;p&gt;프레임워크와 WSGI 서버를 구분하는 또 다른 장점은 백엔드 프레임워크가 클라이언트 연결을 유지하는 작업을 수행할 필요 없이, 주어진 Request 에 대한 Response 값을 반환하는 작업에만 집중할 수 있다는 점이다. Django 와 같은 백엔드 프레임워크는 애초에 이러한 목적으로 설계된 패키지이기 때문에, 가능한 모든 상황에서 WSGI 래퍼를 활용해야 한다.&lt;/p&gt;
&lt;h3 id=&#34;wsgi-standard&#34;&gt;WSGI Standard&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/wsgi_4.jpeg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Gunicorn 로고&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;WSGI 스탠다드란 모든 WSGI 서버와 프레임워크가 서로 호환할 수 있도록 약속된 통신 프로토콜이다. 대표적인 WSGI 서버인 Gunicorn, uWSGI 등은 이러한 스탠다드를 따르기 때문에 WSGI 프레임워크인 Django, Flask, Pyramid, Falcon 등과 모두 호환이 가능하다.&lt;/p&gt;
&lt;h2 id=&#34;nginx&#34;&gt;NGINX&lt;/h2&gt;
&lt;p&gt;언급했듯 NGINX 는 웹사이트의 정적인 요소를 담당하는 Web Server 이다. 클라이언트가 웹서버에 html, css 등의 파일을 요청하면, 이를 빠르게 서빙하여 WAS 가 동작할 필요가 없게끔 만들어준다.&lt;/p&gt;
&lt;h3 id=&#34;reverse-proxy&#34;&gt;Reverse Proxy&lt;/h3&gt;
&lt;p&gt;NGINX 와 WSGI 서버는 Reverse Proxy 방식을 통해 연결된다. 여기서 Reverse Proxy 란 사용자가 흔히 활용하는 Proxy 서버와 반대되는 개념인데, 클라이언트가 서버로 보내는 HTTP 정보가 우회될때 이를 &lt;strong&gt;Forward Proxy&lt;/strong&gt;, 서버가 클라이언트에게 보내는 HTTP 정보가 우회될때 이를 &lt;strong&gt;Reverse Proxy&lt;/strong&gt; 라고 구분지어 부르는 것.&lt;/p&gt;
&lt;h3 id=&#34;web-server-가-반드시-구분되어야-할까&#34;&gt;Web Server 가 반드시 구분되어야 할까?&lt;/h3&gt;
&lt;p&gt;결론만 놓고 보면 Django, WSGI 서버만 있어도 웹사이트는 정상적으로 작동한다. 현대적인 WSGI 서버는 정적인 요소까지 모두 서빙하는 기능을 제공하기 때문이다.&lt;/p&gt;
&lt;p&gt;하지만 대부분의 경우 별도 웹서버를 구축하는 것이 권장되는 가장 큰 이유는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;서버 부하 방지
&lt;ul&gt;
&lt;li&gt;WAS 는 데이터베이스 조회와 다양한 연산 처리로 이미 많은 연산 자원을 활용하는 상태이다. 때문에 단순한 정적 컨텐츠는 Web Server 에서 빠르게 전달하는 것이 유저의 체감 속도도 높이고, 서버 부하 또한 줄일 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;여러 대의 WAS 를 활용한 로드 밸런싱
&lt;ul&gt;
&lt;li&gt;많은 트래픽이 발생할 경우 WAS 의 수를 늘려, 이를 하나의 Web Server 와 연동하는 것이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/wsgi_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. NGINX 서버 활용 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;정리하자면 Django, Flask 등의 백엔드 서버 배포 시 동적인 요소와 정적인 요소를 구분하기 위해 NGINX 서버를 구축하고, NGINX 서버와 Django 에서 개발된 백엔드와의 소통을 위해 WSGI 서버가 구축된다. 경우에 따라 일부 요소들이 생략되는 경우가 발생할 수 있지만 &lt;em&gt;(Jekyll, Hugo 와 같은 Static Site 는 구조상 백엔드를 필요로하지 않는다. 또한 트래픽이 작다면 웹서버 없이 프로토타이핑이 가능하다)&lt;/em&gt;, 일반적인 형태의 웹사이트는 보통 이러한 구조를 따라 구축되는 것이 강하게 권장된다고 볼 수 있다.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wayhome25.github.io/django/2018/03/03/django-deploy-02-nginx-wsgi/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wayhome25.github.io/django/2018/03/03/django-deploy-02-nginx-wsgi/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=66xlIunxWYQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=66xlIunxWYQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://binux.tistory.com/32&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://binux.tistory.com/32&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>ELMo (Embeddings from Language Model)</title>
        <link>https://meme2515.github.io/neural_network/elmo/</link>
        <pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/elmo/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/elmo_title2.png" alt="Featured image of post ELMo (Embeddings from Language Model)" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ELMo 는 2018년 공개된 워드 임베딩 방법론이며, GloVe, Word2Vec 등 기존 여러 임베딩 방식이 문맥을 파악하지 못하는 단점을 보완하고자 설계되었다.&lt;/li&gt;
&lt;li&gt;예시로 River Bank (강둑) 와 Bank Account (은행 계좌) 라는 단어에서 Bank 는 전혀 다른 의미를 가지지만, 문맥을 파악하지 못하는 임베딩 기법은 Bank 에 동일한 벡터를 부여함으로 NLP 성능이 떨어질 수 밖에 없음.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;word2vec&#34;&gt;Word2Vec&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ELMo 의 등장 배경을 이해하기 위해선 2014년 공개 후 한동안 널리 사용되었던 Word2Vec 모델을 이해할 필요가 있다.&lt;/li&gt;
&lt;li&gt;하단의 예시는 몇 가지의 Word2Vec 알고리즘 중 가장 널리 활용된 방식인 Skipgram 버전에 대한 소개.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Word2Vec 피처 설계&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;임의로 설정된 컨텍스트 사이즈 (상단 예시의 경우 5) 를 활용해, 특정 단어 $X$ 가 가운데에 위치해 있을때 함께 등장한 단어 $Y$ 를 피처로 설계한다.&lt;/li&gt;
&lt;li&gt;문장 별로 한개의 $X$ 에 대해 복수의 $Y$ 가 추출되고, 문장이 여러개 활용되기 때문에 $X$ 와 $Y$ 의 관계에 대한 통계 정보를 얻을 수 있다. (예. $X$ 값 &amp;ldquo;the&amp;rdquo; 에 대한 $Y$ 값 &amp;ldquo;quick&amp;rdquo;, &amp;ldquo;brown&amp;rdquo;)&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Word2Vec 신경망 모델&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;이렇게 추출된 데이터셋은 1개의 hidden layer 를 가진 작은 신경망 모델에 학습된다. 모델 구조는 10,000 사이즈의 벡터로 one-hot encode 된 인풋 $X$ 에 대해 동일한 사이즈로 one-hot encode 된 아웃풋 $Y$ 에 확률값을 부여하는 것.&lt;/li&gt;
&lt;li&gt;모델의 hidden layer 는 300개의 뉴런으로 구성되어 있으며, 학습이 끝난 hidden layer 는 그대로 단어의 피처로 활용된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo3.jpeg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Word2Vec 임베딩의 의미론적 (semantic), 구문론적 (syntactic) 관계&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;이렇게 추출된 임베딩이 실제 단어의 의미와 연관성을 가진다는 근거는 임베딩 벡터 간의 관계와 실제 단어 간의 관계가 유사성을 가진다는 점. 대표적인 예시로 &amp;ldquo;Queen&amp;rdquo; 과 &amp;ldquo;King&amp;rdquo; 이라는 단어 간 벡터의 차이값은 &amp;ldquo;Woman&amp;rdquo; 과 &amp;ldquo;Man&amp;rdquo; 이라는 단어 간 벡터의 차이값과 유사하다.&lt;/li&gt;
&lt;li&gt;Word2Vec 모델이 특히 널리 활용된 이유는 이와같이 추출된 단어 임베딩이 LSTM 과 같은 Sequence 모델의 인풋으로 활용될 수 있었다는 점. 이로 인해 Sequence 모델은 단어의 의미를 유추하기 보다, 문장 내 단어 간 관계를 파악하는 것으로 활용 목적을 좁힐 수 있었다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contextual-word-embedding&#34;&gt;Contextual Word Embedding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;이렇듯 발전되어 온 워드 임베딩 기법에 ELMo 가 기여한 부분은 문맥에 기반한 단어 임베딩을 가능하게 했다는 점이다. 상기된 예시인 River Bank (강둑) 와 Bank Account (은행 계좌) 를 생각하면 됨.&lt;/li&gt;
&lt;li&gt;문장에 기반한 단어의 임베딩은 Word2Vec 의 예시와 같이 사전에 생성될 수 없으며, 사전 학습된 모델을 통해 생성되어야 한다. 이러한 기법은 CoVe, ULMFit 등 ELMo 등장 이전에 시도되었지만, ELMo 가 중요한 이유는 State-of-the-Art 성능을 기록했기 때문.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;elmo&#34;&gt;ELMo&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ELMo 를 구성하는 주요 요소는 크게 (1) 캐릭터 단위의 단어 representation (2) 양방향 LSTM 네트워크 (3) 언어 모델 학습 과정을 들 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;character-based-word-representations&#34;&gt;Character-based word representations&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. Character CNN Architecture&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;우선 문장의 개별적인 단어는 (sat) 더 작은 단위인 character 로 분할된다 (s, a, t). 이후 각 character 는 고유한 임베딩 벡터로 변환. 따라서 한 개의 단어는 character 레벨 임베딩 벡터로 구성된 매트릭스로 변형되며, 이는 다양한 kernel width 를 가진 CNN 레이어를 통해 처리된다.&lt;/li&gt;
&lt;li&gt;각 CNN 레이어의 아웃을 하나의 채널로 합친 후 maxpooling 적용.&lt;/li&gt;
&lt;li&gt;Maxpooling 아웃풋은 두 개의 linear layer 에 연결되며, 각 linear layer 는 residual connection 과 유사한 highway connection 을 통해 연결되어 있다 (차이점은 highway connection 은 모수를 가진다는 점).&lt;/li&gt;
&lt;li&gt;최종 linear layer 의 아웃풋은 1차적인 word representation 의 기능을 수행하며, 512 사이즈를 가짐.&lt;/li&gt;
&lt;li&gt;Character representation 의 장점은 오타와 같이 실제 상황에서 발생 가능한 단어를 유연하게 다룰 수 있다는 점.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bidirectional-lstm-structure&#34;&gt;Bidirectional LSTM structure&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Bidirectional LSTM Architecture&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;문맥을 파악하기 위해 ELMo 는 RNN 기법을 활용하며, 서로 다른 진행 방향을 가진 두개의 LSTM 모델을 적용.&lt;/li&gt;
&lt;li&gt;진행 방향이 다르기 때문에 하나의 임베딩은 단어의 왼편에 속한 문맥을, 또 하나의 임베딩은 단어의 오른편에 속한 문맥을 파악하는 역할을 수행한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pre-trained-as-a-language-model&#34;&gt;Pre-trained as a language model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;언어 모델이란 특정 단어나, character 배열에 확률값을 부여하는 통계 모델이다. 예를 들자면 “Congratulations you have won a prize” 라는 영문장이 발생할 확률을 각 단어들의 조합이라는 관점에서 계산하는 것.&lt;/li&gt;
&lt;li&gt;이를 수식으로는 다음과 같이 표현할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$P(W_1 = Congratulations, W_2 = you, W_3 = have, W_4 = won, W_5 = a, W_6 = prize)$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;하지만 단어의 조합이란 무한의 영역이며, 실제 데이터를 기반으로 이와 같은 통계치를 직접적으로 얻는 것은 불가능한 작업이다. 때문에 다음과 같은 조건부 확률의 규칙를 활용하게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$P(x, y) = P(x|y)P(y)$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4개의 단어가 등장하는 문장에 대한 확률값 $P(W_1, W_2, W_3, W_4)$ 는 조건부 확률을 규칙을 적용해 다음과 같이 확장하는 것이 가능.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$P(W_1, W_2, W_3, W_4)$$&lt;/p&gt;
&lt;p&gt;$$= P(W_1, W_2, W_3 | W_4)P(W_4)$$&lt;/p&gt;
&lt;p&gt;$$= P(W_1, W_2 | W_3, W_4)P(W_3 | W_4)P(W_4)$$&lt;/p&gt;
&lt;p&gt;$$= P(W_1 | W_2, W_3, W_4)P(W_2 | W_3, W_4)P(W_3 | W_4)P(W_4)$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;위와 같은 문제의 재정의에 따라, 이제 우리가 계산하고자 하는 값은 이전에 등장한 모든 단어에 비추었을때 특정한 단어가 발생할 확률로 정의할 수 있다. 이러한 조건부 확률을 계산할 수 있다면, 각 단어의 조건부 확률을 곱해줌으로 전체 문장의 확률값을 계산하는 것이 가능해지는 것.&lt;/li&gt;
&lt;li&gt;이를 로그로 치환할 시, 조건부 확률의 곱을 단순한 합계로 변형하는 것이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$\text{log} P(\text{sentence}) = \Sigma_{\text{word}} log P(\text{word} | \text{all words that came before})$$&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 6. Language Modeling in LSTM&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;따라서 위와 같이 다음 단어를 예측하는 시퀀스 모델은 언어 모델의 조건부 확률을 구하는 작업을 수행한다고 볼 수 있으며, 최종 레이어 내 확률 부여를 위해서 softmax 함수가 적용된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 7. Language Modeling As a Task&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;이론적인 부분을 간단하게 짚고 넘어갔지만, 위와 같은 상황에서 단어 별로 알맞은 확률값을 부여하기 위해서는 상당한 수준의 사전 지식을 요구한다.&lt;/li&gt;
&lt;li&gt;등장하는 4개 단어 중 cyclcing 을 제외한 단어는 모두 문법적으로 적법할 수 있지만, window &amp;gt; aquarium &amp;gt; pool 순서의 확률값을 부여한다는 것은 각각 단어에 대한 특성을 이해한다는 것을 의미.&lt;/li&gt;
&lt;li&gt;이러한 상황에서 완벽히 확률값을 부여하는 모델을 AI Complete 라 지칭할 수 있으며, 이를 위해서는 common sense, context 에 대한 인간 수준의 이해를 필요로 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;elmo-architecture&#34;&gt;ELMo Architecture&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/elmo8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 8. ELMo Architecture&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;상기된 컴포넌트를 바탕으로 구축된 ELMo 모델 구조의 다이어그램이다. Char-CNN 모델이 생성한 최초 단어 임베딩을 기준으로 2개의 LSTM 모델을 언어 모델로서 학습시키는 것.&lt;/li&gt;
&lt;li&gt;최종 단어 임베딩은 다음과 같이 정의된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
e_k = \gamma i h_K^{init} + \gamma \sum_{j=0}^{L} f_j h_{k,j}^{forward} + \gamma \sum_{j=0}^{L} b_j h_{k,j}^{backward}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;위 방정식에서 등장하는 $h^{init}$, $h^{forward}$, $h^{backward}$ 는 각각 Char-CNN, Forward LSTM, Backward LSTM 의 아웃풋이며, 이외 변수를 통해 finetuning 을 지원하는 것.&lt;/li&gt;
&lt;li&gt;특히 $\gamma$ 는 Weight 파라미터로 부여된 태스크에 따라 서로 다른 가중치를 부여하게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=csAlW9HmwAQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=csAlW9HmwAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wikidocs.net/33930&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wikidocs.net/33930&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://reniew.github.io/22/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://reniew.github.io/22/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>(논문 리뷰) RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
        <link>https://meme2515.github.io/neural_network/roberta/</link>
        <pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/roberta/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/roberta_1.gif" alt="Featured image of post (논문 리뷰) RoBERTa: A Robustly Optimized BERT Pretraining Approach" /&gt;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;언어 모델 간의 직접적인 비교는 (1) 연산 자원 (2) 서로 다른 데이터 (3) 하이퍼파라미터 민감도 문제로 많은 어려움이 있다.&lt;/li&gt;
&lt;li&gt;본 논문에서는 BERT 논문의 선행 학습 과정을 재현하며, 특히 하이퍼파라미터와 데이터 규모에 따른 성능 차이를 탐구.&lt;/li&gt;
&lt;li&gt;처음 공개된 버전의 BERT 는 매우 undertrain 되어 있었으며, 적합한 학습 과정을 통해 이후 등장한 모든 언어 모델을 상회하는 성능을 기록 (GLUE, RACE, SQuAD).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;자기지도 학습 방법인 &lt;strong&gt;ELMo, GPT, BERT, XLM, XLNet&lt;/strong&gt; 등은 많은 성능 발전을 이루어냈지만, 이러한 모델들의 어떠한 요소가 성능에 직접적인 영향을 끼쳤는지 판별하기 어려운 측면이 존재.&lt;/li&gt;
&lt;li&gt;상기된 문제들로 인해 이러한 모델 간 직접적인 비교는 난이도가 높은 편.&lt;/li&gt;
&lt;li&gt;본 논문에서는 하이퍼파리미터와 데이터 규모에 의한 BERT 성능의 변화를 면밀히 관찰하여 개선된 학습 방법을 제시. 구체적인 방법은 다음과 같다.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;더 많은 데이터로, 더 큰 배치를 구성하여, 더 긴 기간 동안 학습을 진행&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;NSP (Next Sentence Prediction) 과제 제거&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;학습 시 더욱 긴 문장 활용&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;정적인 (static) 마스킹 패턴을 동적으로 (dynamic) 변경&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;연구진은 또한 &lt;strong&gt;CC-News&lt;/strong&gt; 라는 새로운 데이터셋을 활용해 여타 모델의 데이터셋과 유사한 규모를 구축함.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experimental-setup&#34;&gt;Experimental Setup&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;기존 BERT 와 동일한 하이퍼파라미터 세팅을 가져가나, peak lr 과 warmup steps 는 별도 튜닝을 거침. Adam Optimizer 의 epsilon, beta 2 값 또한 일부 변경하였다.&lt;/li&gt;
&lt;li&gt;특히 학습 성능은 Adam epsilon 값에 크게 민감하게 반응.&lt;/li&gt;
&lt;li&gt;기존 방식과 다르게 학습 과정에서 최대 sequence length 를 변경시키지 않았으며, 512 로 고정.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BookCorpus + Wikipedia 데이터셋 (약 16 GB) 에 CC-News (76 GB), OpenWebText (38 GB), Stories (31 GB) 등의 데이터셋을 추가하였다.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;training-procedure-analysis&#34;&gt;Training Procedure Analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;고정된 BERT 모델을 기반으로, 연구진은 다음과 같은 실험을 진행.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;static-vs-dynamic-masking&#34;&gt;Static vs. Dynamic Masking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;BERT 는 최초 데이터 전처리 과정에서 마스킹 위치를 선정한 후, 적용된 마스크를 학습 과정에서 정적으로 활용한다.&lt;/li&gt;
&lt;li&gt;기존 방식에서는 epoch 간 동일한 마스크 활용을 방지하기 위해, 각 문장에 대한 마스킹을 10 번씩 개별적으로 진행. 40 epoch 간 학습을 진행했기 때문에 모델이 완벽히 동일한 마스킹에 노출된 횟수는 총 4회 이다.&lt;/li&gt;
&lt;li&gt;연구진은 이러한 방식을 sequence 가 모델에 학습될 때마다 마스킹을 진행하는 동적 방식과 비교하였으며, 이는 데이터셋이 커질수록 성능을 결정하는 핵심 요소가 될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Masking&lt;/th&gt;
&lt;th&gt;SQuAD 2.0&lt;/th&gt;
&lt;th&gt;MNLI-m&lt;/th&gt;
&lt;th&gt;SST-2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;reference&lt;/td&gt;
&lt;td&gt;76.3&lt;/td&gt;
&lt;td&gt;84.3&lt;/td&gt;
&lt;td&gt;92.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RoBERTa Implementation:&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;static&lt;/td&gt;
&lt;td&gt;78.3&lt;/td&gt;
&lt;td&gt;84.3&lt;/td&gt;
&lt;td&gt;92.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dynamic&lt;/td&gt;
&lt;td&gt;78.7&lt;/td&gt;
&lt;td&gt;84.0&lt;/td&gt;
&lt;td&gt;92.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;테이블에 따르면, 동적 마스킹은 정적 마스킹 방식에 비해 아주 약간의 성능 개선을 제공.&lt;/li&gt;
&lt;li&gt;(개인적인 생각이나, 알려진 바에 의해 그렇게 유효한 차이인지는 잘 모르겠다. 마치 AlexNet 의 Local Response Normalization 을 보는 것 같음)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-input-format-and-next-sentence-prediction&#34;&gt;Model Input Format and Next Sentence Prediction&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;기존 BERT 의 인풋은 두 개의 문장으로 구성되어 있으며, 50% 의 확률로 실제 연속적으로 등장하는 문장이거나, 나머지 50% 의 확률로 서로 다른 문서에서 추출된 문장.&lt;/li&gt;
&lt;li&gt;모델은 이러한 두 문장이 실제로 연속적으로 등장하는 문장인지 여부를 학습하게 되며, 이를 NSP 과제라 지칭함 (NSP 손실 함수 활용).&lt;/li&gt;
&lt;li&gt;기존 연구에서는 이러한 NSP 학습 과제를 배제할 경우, 성능이 대폭 하락하는 결과를 확인하였지만, 최근 연구들은 NSP 학습의 필요성에 의문을 제기함.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Segment Pair + NSP :&lt;/strong&gt; 기존 BERT 의 인풋 포맷과 동일한 형태. 인풋 토큰은 두 개의 Segment Pair 를 기반으로 하며, 하나의 Segment 는 다수의 Sentence 를 포함할 수 있다. 여기서 Segment 의 최대 길이는 512 로 한정 되어 있음.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Sentence Pair + NSP :&lt;/strong&gt; 인풋은 두 개의 Sentence 를 기반으로 함. 두 문장의 합이 최대 길이인 512 에 한참 못 미치기 때문에 연구진은 배치 사이즈를 키우는 방식을 선택.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Full Sentences :&lt;/strong&gt; NSP Loss 가 배제되며, 512 사이즈에 맞게 한 개, 또는 복수의 문서에서 텍스트를 추출한다. 하나의 문서에 끝에 도달한 경우 (SEP) 토큰을 삽입한 후, 이후 문서로 넘어가게 됨.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Doc Sentences :&lt;/strong&gt; Full Setences 방식과 동일하나, 하나의 문서에서만 텍스트를 추출한다. 512 사이즈에 미치지 못하는 경우 동적으로 배치 사이즈를 조정함.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;SQuAD 1.1/2.0&lt;/th&gt;
&lt;th&gt;MNLI-m&lt;/th&gt;
&lt;th&gt;SST-2&lt;/th&gt;
&lt;th&gt;RACE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Reimplementation with NSP loss&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Segment Pair&lt;/td&gt;
&lt;td&gt;90.4/78.7&lt;/td&gt;
&lt;td&gt;84.0&lt;/td&gt;
&lt;td&gt;92.9&lt;/td&gt;
&lt;td&gt;64.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sentence Pair&lt;/td&gt;
&lt;td&gt;88.7/76.2&lt;/td&gt;
&lt;td&gt;82.9&lt;/td&gt;
&lt;td&gt;92.1&lt;/td&gt;
&lt;td&gt;63.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reimplementation without NSP loss&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Full Sentences&lt;/td&gt;
&lt;td&gt;90.4/79.1&lt;/td&gt;
&lt;td&gt;84.7&lt;/td&gt;
&lt;td&gt;92.5&lt;/td&gt;
&lt;td&gt;64.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Doc Sentences&lt;/td&gt;
&lt;td&gt;90.6/79.7&lt;/td&gt;
&lt;td&gt;84.7&lt;/td&gt;
&lt;td&gt;92.7&lt;/td&gt;
&lt;td&gt;65.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reference&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bert Base&lt;/td&gt;
&lt;td&gt;88.5/76.3&lt;/td&gt;
&lt;td&gt;84.3&lt;/td&gt;
&lt;td&gt;92.8&lt;/td&gt;
&lt;td&gt;64.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;XLNet Base (K = 7)&lt;/td&gt;
&lt;td&gt;_/81.3&lt;/td&gt;
&lt;td&gt;85.8&lt;/td&gt;
&lt;td&gt;92.7&lt;/td&gt;
&lt;td&gt;66.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;XLNet Base (K = 6)&lt;/td&gt;
&lt;td&gt;_/81.0&lt;/td&gt;
&lt;td&gt;85.6&lt;/td&gt;
&lt;td&gt;93.4&lt;/td&gt;
&lt;td&gt;66.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Sentence Pair 는 Segment Pair 에 비해 Downstream Task (전이 학습 영역) 에서 낮은 성능을 보였으며, 이는 모델이 거리가 먼 단어 간 dependency 를 학습하지 못해서 일 것이라 추측.&lt;/li&gt;
&lt;li&gt;NSP loss 를 제거한 후 성능이 소폭 상승하였으며, 이는 기존 방법이 Segment Pair 방식을 그대로 유지했기 때문이라 추측할 수 있다.&lt;/li&gt;
&lt;li&gt;Doc Sentences 가 Full Sentences 에 비해 나은 성능을 보였지만, 변동적인 배치 사이즈로 인해 RoBERTa 모델은 Full Sentences 방식을 사용 (다른 모델과 비교 조건을 통일하기 위함).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;training-with-large-batches&#34;&gt;Training with Large Batches&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Learning Rate 만 적합하게 조정된다면, mini-batch 사이즈를 키우는 것은 학습 속도와 최종 과제 수행 능력에 긍정적인 영향을 끼친다.&lt;/li&gt;
&lt;li&gt;기존 BERT 모델은 256 Batch Size/1M Steps 세팅 값으로 학습을 진행. 이는 연산 비용 차원에서 (1) 2K Batch Size/125K Steps, (2) 8K Batch Size/31K Steps 와 동일하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;batch size&lt;/th&gt;
&lt;th&gt;steps&lt;/th&gt;
&lt;th&gt;learning rate&lt;/th&gt;
&lt;th&gt;perplexity&lt;/th&gt;
&lt;th&gt;MNLI-m&lt;/th&gt;
&lt;th&gt;SST-2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;1M&lt;/td&gt;
&lt;td&gt;1e-4&lt;/td&gt;
&lt;td&gt;3.99&lt;/td&gt;
&lt;td&gt;84.7&lt;/td&gt;
&lt;td&gt;92.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2K&lt;/td&gt;
&lt;td&gt;125K&lt;/td&gt;
&lt;td&gt;7e-4&lt;/td&gt;
&lt;td&gt;3.68&lt;/td&gt;
&lt;td&gt;85.2&lt;/td&gt;
&lt;td&gt;92.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8K&lt;/td&gt;
&lt;td&gt;31K&lt;/td&gt;
&lt;td&gt;1e-3&lt;/td&gt;
&lt;td&gt;3.77&lt;/td&gt;
&lt;td&gt;84.6&lt;/td&gt;
&lt;td&gt;92.8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;연구진은 배치 사이즈를 키울 경우, 모델의 perplexity (cross-entropy 기반 loss metric) 가 감소한다는 점을 발견. 또한 end-task 의 정확도 또한 향상된다는 점을 발견한다.&lt;/li&gt;
&lt;li&gt;배치 사이즈가 큰 경우 병렬 처리가 쉬워진다는 장점 또한 있다. 이후 연구진은 RoBERTa 학습에 8K Batch Size 를 적용함.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;text-encoding&#34;&gt;Text Encoding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Byte-Pair Encoding (BPE)&lt;/strong&gt; 란 캐릭터와 단어 레벨 representation 의 중간에 있는 인코딩 방식. 실제 단어가 아닌 단어의 부분들을 기반으로 인코딩을 수행한다.&lt;/li&gt;
&lt;li&gt;보통의 BPE 단어 사전은 10K~100K 정도의 규모를 가지는데, 이 중 대부분은 유니코드 캐릭터에 의한 것이며, 이를 바이트 기반으로 변경하여 unknown token 을 필요로 하지 않는 50K 규모의 단어 사전을 구축할 수 있다.&lt;/li&gt;
&lt;li&gt;기존 BERT 논문은 캐릭터 레벨의 30K 규모 BPE 사전을 활용하였으나, 연구진은 이를 바이트 기반의 50K BPE 사전으로 변경. 때문에 기존 방식에 적용된 데이터 전처리를 필요로 하지 않는다.&lt;/li&gt;
&lt;li&gt;이로 인해 BERT Base 는 파라미터 수가 약 15M, BERT Large 는 약 20M 개 상승.&lt;/li&gt;
&lt;li&gt;성능 평가 면에서는 바이트 기반 BPE 가 약간 낮은 성능을 보이나, 연구진은 바이트 기반 BPE 의 장점이 단점을 상쇄한다고 판단, 이를 RoBERTa 에 적용한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;roberta&#34;&gt;RoBERTa&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;동적 마스킹, Full Setences w/o NSP loss, 증가한 mini-batch 사이즈, 바이트 레벨 BPE 등을 적용한 BERT 모델을 연구진은 Robustly optimized BERT approach (RoBERTa) 라 명명.&lt;/li&gt;
&lt;li&gt;또한 RoBERTa 는 (1) 데이터 크기와 성질 (2) 학습의 정도가 모델 성능에 끼치는 영향을 탐구한다.&lt;/li&gt;
&lt;li&gt;XLNet 의 경우 기존 BERT 모델에 비해 10배 많은 데이터를 활용해 학습되었으며, 배치 사이즈의 경우 8배가 컸던 반면 학습 step 은 1/2 정도의 규모였음으로 BERT 에 비해 약 4배 정도의 시퀀스에 노출된 것.&lt;/li&gt;
&lt;li&gt;보다 직접적인 비교를 위해 연구진은 규모가 유사한 데이터를 활용해 다음 세개의 모델을 테스트했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;data&lt;/th&gt;
&lt;th&gt;batch size&lt;/th&gt;
&lt;th&gt;steps&lt;/th&gt;
&lt;th&gt;SQuAD&lt;/th&gt;
&lt;th&gt;MNLI-m&lt;/th&gt;
&lt;th&gt;SST-2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;RoBERTa&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;with BOOKS + WIKI&lt;/td&gt;
&lt;td&gt;16GB&lt;/td&gt;
&lt;td&gt;8K&lt;/td&gt;
&lt;td&gt;100K&lt;/td&gt;
&lt;td&gt;93.6/87.3&lt;/td&gt;
&lt;td&gt;89.0&lt;/td&gt;
&lt;td&gt;95.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+ additional data&lt;/td&gt;
&lt;td&gt;160GB&lt;/td&gt;
&lt;td&gt;8K&lt;/td&gt;
&lt;td&gt;100K&lt;/td&gt;
&lt;td&gt;94.0/87.7&lt;/td&gt;
&lt;td&gt;89.3&lt;/td&gt;
&lt;td&gt;95.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+ pretrain longer&lt;/td&gt;
&lt;td&gt;160GB&lt;/td&gt;
&lt;td&gt;8K&lt;/td&gt;
&lt;td&gt;300K&lt;/td&gt;
&lt;td&gt;94.4/88.7&lt;/td&gt;
&lt;td&gt;90.0&lt;/td&gt;
&lt;td&gt;96.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+ pretrain even longer&lt;/td&gt;
&lt;td&gt;160GB&lt;/td&gt;
&lt;td&gt;8K&lt;/td&gt;
&lt;td&gt;500K&lt;/td&gt;
&lt;td&gt;94.6/89.4&lt;/td&gt;
&lt;td&gt;90.2&lt;/td&gt;
&lt;td&gt;96.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BERT Large&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;with BOOKS + WIKI&lt;/td&gt;
&lt;td&gt;13GB&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;1M&lt;/td&gt;
&lt;td&gt;90.9/81.8&lt;/td&gt;
&lt;td&gt;86.6&lt;/td&gt;
&lt;td&gt;93.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;XLNet Large&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;with BOOKS + WIKI&lt;/td&gt;
&lt;td&gt;13GB&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;1M&lt;/td&gt;
&lt;td&gt;94.0/87.8&lt;/td&gt;
&lt;td&gt;88.4&lt;/td&gt;
&lt;td&gt;94.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+ additional data&lt;/td&gt;
&lt;td&gt;126GB&lt;/td&gt;
&lt;td&gt;2K&lt;/td&gt;
&lt;td&gt;500K&lt;/td&gt;
&lt;td&gt;94.5/88.8&lt;/td&gt;
&lt;td&gt;89.8&lt;/td&gt;
&lt;td&gt;95.6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;이외에도 RoBERTa 모델은 GLUE, SQuAD, RACE 등의 벤치마크 과제에서 state-of-the-art 성능을 기록. 주로 XLNet 과 비교되었는데, 성능 차이가 아주 큰 편은 아님.&lt;/li&gt;
&lt;li&gt;특히 GLUE 벤치마크의 경우, train set 을 활용한 환경에서 9개 과제 모두 가장 높은 성능을 기록했지만 test set 기반의 리더보드에서는 4개 과제에서만 가장 높은 성능을 기록했다. 하지만 리더보드의 대부분 모델과 다르게 RoBERTa 는 복수과제를 활용한 fine-tuning 을 진행하지 않음.&lt;/li&gt;
&lt;li&gt;SQuAD 또한 비슷한 양상을 보이는데, 리더보드에서 XLNet + SG-Net Verifier 에 비해 약간 낮은 성능을 기록했다 (외부 데이터를 활용하지 않았기 때문이라고 하는데, 뭔가 자꾸 사족이 붙는 느낌).&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>T5 (Text-To-Text Transfer Tranformer) 구조 소개</title>
        <link>https://meme2515.github.io/neural_network/t5/</link>
        <pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/t5/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/t5_1.gif" alt="Featured image of post T5 (Text-To-Text Transfer Tranformer) 구조 소개" /&gt;&lt;ul&gt;
&lt;li&gt;본 글은 T5 구조에 대한 Google AI 의 공식적인 &lt;a class=&#34;link&#34; href=&#34;https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;소개글&lt;/a&gt;을 번역한 것이며, 실제 논문은 &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1910.10683&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;본 링크&lt;/a&gt;를 참조할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;최근 NLP 분야의 성장은 웹에서 확보할 수 있는 수많은 unlabeled 텍스트를 활용한 전이 학습의 효율성에 기인.&lt;/li&gt;
&lt;li&gt;이러한 학습은 주로 self-supervised 형식으로 이루어지며, 빈칸 채우기 등의 태스크를 수행하는 것을 1차적인 과제로 삼음.&lt;/li&gt;
&lt;li&gt;방대한 데이터를 기반으로 사전 학습을 마친 모델은 별도 데이터를 활용해 finetune 될 수 있으며, 이는 보유한 데이터만으로 모델을 학습하는 것 보다 월등히 나은 성능을 보임.&lt;/li&gt;
&lt;li&gt;2018 년 부터 &lt;strong&gt;GPT, ULMFit, ELMo, BERT&lt;/strong&gt; 등 다양한 전이학습의 성공 사례가 보고되었으며, 2019 년도에는 &lt;strong&gt;XLNet, RoBERTa, ALBERT, Reformer, MT-DNN&lt;/strong&gt; 등 보다 개선된 방식이 개발.&lt;/li&gt;
&lt;li&gt;발전 속도가 워낙 빠르기 때문에, 어떠한 개선점이 유효하고, 어떠한 모델의 조합이 효과적인지를 판단하기 어려운 면이 존재한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;t5&#34;&gt;T5&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;본 논문에서는 가장 효과적인 전이 학습 방식을 평가하기 위한 비교 실험을 진행하였으며, 결과를 기반으로 T5 모델을 구축.&lt;/li&gt;
&lt;li&gt;또한 새로운 사전 학습 데이터셋인 &lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/datasets/catalog/c4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Colossal Clean Crawled Corpus (C4)&lt;/a&gt; 를 공개했다.&lt;/li&gt;
&lt;li&gt;C4 데이터를 기반으로 학습된 T5 모델은 공개 당시 state-of-the-art 성능을 기록했으며, 또한 다양한 태스크에 접목될 수 있는 유연성을 가지고 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/google-research/text-to-text-transfer-transformer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;코드&lt;/a&gt;. &lt;a class=&#34;link&#34; href=&#34;https://github.com/google-research/text-to-text-transfer-transformer#released-model-checkpoints&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;사전 학습 모델&lt;/a&gt;. &lt;a class=&#34;link&#34; href=&#34;https://colab.research.google.com/github/google-research/text-to-text-transfer-transformer/blob/main/notebooks/t5-trivia.ipynb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Colab Notebook&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;a-shared-text-to-text-framework&#34;&gt;A Shared Text-To-Text Framework&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;T5 를 정의하는 핵심적인 요소는 모든 NLP 태스크를 text-to-text 포맷으로 통일시켰다는 점. 이는 BERT 처럼 클래스 레이블 등으로 한정된 아웃풋을 출력하는 모델과 차별되는 포인트이다.&lt;/li&gt;
&lt;li&gt;text-to-text 프레임워크는 동일한 모델, 손실 함수, 하이퍼파라미터를 활용해 모든 NLP 태스크 수행이 가능하며, 이는 기계 번역, 문서 요약, 질답, 분류, 회귀 (출력값을 텍스트로 변환) 등의 태스크를 포함한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/t5_1.gif&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Diagram of text-to-text framework&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;a-large-pre-training-dataset-c4&#34;&gt;A Large Pre-training Dataset (C4)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;전이 학습의 핵심적인 요소는 사전 학습에 사용되는 unlabeled 데이터셋이다.&lt;/li&gt;
&lt;li&gt;사전 학습 수준에 따른 성능 편차를 정확하게 측정하기 위해서는 질이 높고, 다양성이 높으며, 규모가 큰 데이터를 필요로 하는데 연구진은 이러한 조건을 모두 충족하는 데이터셋이 존재하지 않는다고 판단.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.wikipedia.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;위키피디아&lt;/a&gt; 데이터셋은 품질이 높지만, 규모가 크지 않으며 스타일이 획일적. &lt;a class=&#34;link&#34; href=&#34;https://commoncrawl.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Common Crawl&lt;/a&gt; 데이터셋은 규모는 크지만 데이터의 품질이 낮다.&lt;/li&gt;
&lt;li&gt;이러한 조건을 모두 충족하는 데이터셋을 구축하기 위해 연구진은 기존 Common Crawl 데이터셋을 정제한 C4 데이터셋을 구축하였으며, 이는 위키피디아 데이터셋에 비해 약 100배의 규모를 가지고 있다.&lt;/li&gt;
&lt;li&gt;적용된 정제 과정은 완성되지 않은 문장 제외, 중복 데이터 제외, offensive 혹은 noisy 한 데이터 제외 등.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;a-systematic-study-of-transfer-learning-methodology&#34;&gt;A Systematic Study of Transfer Learning Methodology&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;연구진은 상기된 T5 프레임워크와 C4 데이터셋을 활용해 알려진 다양한 NLP 전이 학습 방법을 비교했다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Model Architectures&lt;/strong&gt; : Encoder-Decoder 모델 구조는 대체로 Decoder-Only 구조에 비해 높은 성능을 보임.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pre-training Objectives&lt;/strong&gt; : Fill-in-the-blank 스타일의 학습 목표가 가장 유연한 모델을 생성.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unlabeled Datasets&lt;/strong&gt; : 최종 목적과 부합한 in-domain 데이터의 사전 학습은 도움이 되었으나, 사전 학습 데이터셋이 너무 작은 경우 over-fitting 문제 발생.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Training Strategies&lt;/strong&gt; : 멀티태스트 러닝은 사전 학습 후 전이 학습을 진행하는 방식과 유사한 성능을 낼 수 있지만, 각 태스크에 따른 학습 주기를 세밀하게 조정해야 함.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scale&lt;/strong&gt; : 한정된 연산 자원 배분을 위해 적합한 모델 사이즈, 학습 시간, 앙상블 모델 수 등을 탐색.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;insights--scale--state-of-the-art&#34;&gt;Insights + Scale = State-of-the-Art&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;비교 분석을 통해 얻은 인사이트를 기반으로, TPU 를 활용한 모델 스케일링을 진행. 최종 모델은 약 11 billion (110 억) 개의 파라미터를 가지고 있다.&lt;/li&gt;
&lt;li&gt;GLUE, SuperGLUE, SQuAD, CNN/Daily Mail 벤치마크 등에서 당시 가장 높은 성능을 기록.&lt;/li&gt;
&lt;li&gt;특히 주목할 점은 SuperGLUE 에서 인간과 유사한 점수를 기록했다는 것인데, 해당 데이터셋은 고의적으로 머신러닝으로 해결하기 어려운 데이터를 주로 포함.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;extensions&#34;&gt;Extensions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;T5 는 논문에 언급된 것 이외에도 많은 태스크에 쉽게 적용할 수 있다는 장점을 가지고 있다.&lt;/li&gt;
&lt;li&gt;다음 섹션에서는 Closed-Book Question Answering 과 변측적인 blank-size 에 대한 fill-in-the-blank 과제 적용 사례를 설명.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;closed-book-question-answering&#34;&gt;Closed-Book Question Answering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;지문과 질문을 인풋으로 받았을 때, 질문에 대한 적절한 답변을 생성하는 과제.&lt;/li&gt;
&lt;li&gt;예시적으로 Hurricane Connie 에 대한 위키피디아 지문과 Hurricane Connie 는 언제 발생했는가? 라는 질문을 받았을때 모델은 &amp;ldquo;August 3rd, 1955&amp;rdquo; 와 같이 적절한 답변을 아웃풋해야 한다.&lt;/li&gt;
&lt;li&gt;이러한 과제를 위해 설계된 Stanford Question Answering Dataset (SQuAD) 에서 T5 는 당시 가장 높은 성능을 기록.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/t5_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. T5 learns to fill in dropped-out spans of text&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Colab 데모와 논문에서 연구진은 컨텍스트 없이 모델이 적절한 답변을 할 수 있는지를 테스트 하였으며, TriviaQA, WebQuestions, Natural Questions 데이터셋에서 원문 그대로의 답변을 제시한 비율이 각각 50.1%, 37.4%, 34.5% 를 기록했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/t5_3.gif&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Question answering UI&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;fill-in-the-blank-text-generation&#34;&gt;Fill-in-the-Blank Text Generation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GPT-2 와 같은 LLM 은 실제 사람이 작성한 것과 유사한 텍스트를 생성하는 작업에 매우 탁월한 성능을 보인다. 이는 &lt;a class=&#34;link&#34; href=&#34;https://app.inferkit.com/demo&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Talk To Transformer&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://aidungeon.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI Dungeon&lt;/a&gt; 과 같은 적용 사례로 까지 이어짐.&lt;/li&gt;
&lt;li&gt;이는 fill-in-the-blank 과제에서 빈칸이 가장 뒷편에 있는 경우라고 해석할 수 있으며, 해당 과제는 T5 의 사전 학습 과제와 일치함.&lt;/li&gt;
&lt;li&gt;연구진은 빈칸에 들어갈 단어 수를 제시하고, 모델이 이를 채워넣는 과제를 실험하였으며 사실적으로 생성된 텍스트를 확인함.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Singular Value Decomposition 의 개념 소개</title>
        <link>https://meme2515.github.io/machine_learning/svd/</link>
        <pubDate>Fri, 30 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/machine_learning/svd/</guid>
        <description>&lt;img src="https://meme2515.github.io/machine_learning/images/svd_1.jpg" alt="Featured image of post Singular Value Decomposition 의 개념 소개" /&gt;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://angeloyeo.github.io/2019/08/01/SVD.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;strong&gt;공돌이의 수학정리노트&lt;/strong&gt;&lt;/a&gt; 블로그를 인용하자면, 특이값 분해가 설명하고자 하는 바는 &lt;strong&gt;&amp;ldquo;직교하는 벡터 집합에 대하여, 선형 변환 후에 그 크기는 변하지만 여전히 직교할 수 있게 되는 그 직교 집합은 무엇인가? 그리고 선형 변환 후의 결과는 무엇인가?&amp;rdquo;&lt;/strong&gt; 로 정리할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;시각적인 설명은 덧붙이자면, 왼편의 직교하는 벡터 집합 $V$ 에 대한 $A$ 매트릭스 선형 변환 결과를 오른편의 벡터 집합 $U\Sigma$ 라고 가정.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 직교성 조건을 만족하지 못하는 경우&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;시각화를 돕기 위해 오른편의 벡터 크기를 의미하는 $\Sigma$ 매트릭스를 제외한 후, 다음과 같은 결과를 만족하는 크기 1 의 벡터 집합 $U$ 을 찾는 과정이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 직교성 조건을 만족하는 경우&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;즉, 각자 직교하는 벡터 집합 $U, V$ 는 다음과 같은 관계를 가진다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
AV = U\Sigma
$$&lt;/p&gt;
&lt;h2 id=&#34;특이값-분해의-정의&#34;&gt;특이값 분해의 정의&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;임의의 $m \times n$ 차원 행렬 $A$ 를 다음과 같이 분해하는 행렬 분해 방법 중 하나이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
A = U\Sigma V^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;네 행렬 ($A, U, \Sigma, V$) 의 크기와 성질은 다음과 같이 정리할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
A: m \times n \text{ regular matrix} \newline
U: m \times m \text{ orthogonal matrix} \newline
\Sigma: m \times n \text{ diagonal matrix} \newline
V: n \times n \text{ orthogonal matrix}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Orthogonality 란 &lt;strong&gt;컬럼 별 벡터가 모두 서로 직교하는 성질&lt;/strong&gt;을 칭하는데, 소개 섹션에서 언급했듯 이는 매트릭스 $A$ 에 의해 변환되는 두 개 벡터 집합 $U$ 와 $V$ 의 기본 전제이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 Orthogonal 매트릭스는 또한 다음과 같은 성질을 가진다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
UU^T = U^T U = I
$$&lt;/p&gt;
&lt;p&gt;$$
U^{-1} = U^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;따라서 다음과 같은 유도가 가능한 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
AV = U\Sigma \newline
= AVV^T = U\Sigma V^T \newline
= A = U\Sigma V^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Diagonality 란 &lt;strong&gt;행렬의 대각성분을 제외한 나머지 원소의 값이 모두 $0$ 인 경우&lt;/strong&gt;를 뜻한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Diagonal Matrix 를 $m \times n$ 모양으로 가정했을 때 행렬 크기가 맞지 않는 애매한 경우가 발생할 수 있다. 이럴때 $m &amp;gt; n$ 인 경우 $n \times n$ 행렬 하단에 모든 원소가 $0$ 인 $m - n \times n$ 행렬이 붙어있게 되거나, $m &amp;lt; n$ 인 경우 $m \times m$ 행렬 오른쪽에 모든 원소가 $0$ 인 $n \times n - m$ 행렬이 붙어있는 식.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. 특이값 분해 방정식 내 행렬 도식화&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;u-와-v-를-어떻게-찾을까&#34;&gt;U 와 V 를 어떻게 찾을까?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;우선 다음과 같이 행렬 $A$ 와 $A^T$ 를 정의하자.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
A = U\Sigma V^T \newline
$$&lt;/p&gt;
&lt;p&gt;$$
A^T = (U\Sigma V^T)^T = V\Sigma^T U^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이를 활용해 다음과 같은 수식 관계를 찾을 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
AA^T = U\Sigma V^TV\Sigma^T U^T = U\Sigma^2 U^T
$$&lt;/p&gt;
&lt;p&gt;$$
A^T A = V \Sigma^T U^T U\Sigma V^T = V \Sigma^2 V^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;즉, 벡터 집합 $U$ 와 $V$ 는 각각 $AA^T, A^TA$ 행렬에 대한 eigenvector 이며, 이는 eigendecomposition 테크닉을 활용해 풀이가 가능하다. 관련한 컨텐츠는 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=PFDu9oVAE-g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;3blue1brown&lt;/a&gt; 과 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=KTKAp9Q3yWg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ritvikmath&lt;/a&gt; 비디오 참고.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_6.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. 고유값 분해 (Eigen-decomposition) 방정식&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;특이값-분해의-목적과-활용&#34;&gt;특이값 분해의 목적과 활용&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;특이값 분해의 공식은 다음과 같이 풀어쓰는 것이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
A = U\Sigma V^T
$$&lt;/p&gt;
&lt;p&gt;$$
= {
\begin{pmatrix}
| &amp;amp; | &amp;amp; &amp;amp; |  \newline
u_1 &amp;amp; u_2 &amp;amp; \cdots &amp;amp; u_m  \newline
| &amp;amp; | &amp;amp; &amp;amp; |
\end{pmatrix}
\begin{pmatrix}
\sigma_1 &amp;amp; &amp;amp; &amp;amp; &amp;amp; 0  \newline
&amp;amp; \sigma_2 &amp;amp; &amp;amp; &amp;amp; 0  \newline
&amp;amp; &amp;amp; \ddots &amp;amp; &amp;amp; 0  \newline
&amp;amp; &amp;amp; &amp;amp; \sigma_m &amp;amp; 0  \newline
\end{pmatrix}
\begin{pmatrix}
- &amp;amp; v_1^T &amp;amp; -  \newline
- &amp;amp; v_2^T &amp;amp; -  \newline
&amp;amp; \vdots &amp;amp;   \newline
- &amp;amp; v_n^T &amp;amp; -  \newline
\end{pmatrix}
}
$$&lt;/p&gt;
&lt;p&gt;$$
= \sigma_1 u_1 v_1^T + \sigma_2 u_2 v_2^T + &amp;hellip; + \sigma_m u_m v_m^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$u_1 v_1^T$ 등의 결과값은 $m \times n$ 행렬이며, &lt;strong&gt;합산을 통해 최종 행렬인 $A$ 에 다다르기 위한 하나의 레이어&lt;/strong&gt; 정도로 생각할 수 있다. $u$ 와 $v$ 는 정규화된 벡터이기 때문에 $u_1 v_1^T$ 의 값은 1 과 -1 사이에 위치한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 $u_1 v_1^T$ 에 의해 특정된 레이어의 정보량은 $\sigma_1$ 에 의해 정해지며, 이를 특이값이라 부른다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이어 별 정보량은 특이값의 크기에 의해 결정되기 때문에, 특이값 $p$ 개 만을 이용해 행렬 $A$ 를 부분 복원하는 작업이 가능해진다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. 행렬 $A$ 의 부분 복원 과정 도식화&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;이를 가장 직관적으로 설명하는 방법은 이미지의 SVD 복원 과정을 시각화하는 것이다. 하단의 예시는 이미지를 다수의 레이어로 분할 후, 레이어의 누적 합을 단계적으로 시각화 한 것이다. &lt;strong&gt;초반 몇개의 레이어에 주요 정보들이 집중되어 있고, 후반 레이어로 갈수록 마이너한 정보를 담고 있다.&lt;/strong&gt; 이는 $\Sigma$ 행렬에서 특이값 $\sigma_x$ 이 계속해 작아지며, 이에 상응하는 $u_x v_x^T$ 레이어가 가진 정보량이 감소하는 것과 같은 원리.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 6. 공돌이의 수학정리노트 블로그에 소개된 SVD 복원 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;차원축소-기법과의-연계점&#34;&gt;차원축소 기법과의 연계점&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$A$ 행렬에서 분해된 $U, \Sigma, V$ 행렬 중, &lt;strong&gt;$V$ 행렬의 각 row vector 는 projection axis, 즉 차원 축소를 수행할 축을 특정하며, 이에 상응하는 $\Sigma$ 행렬의 원소는 해당 projection axis 의 정보량을 특정한다&lt;/strong&gt;. 하단 예시에서 파란색으로 표기된 $v_1$ axis 의 정보량은 $\sigma_1 = 12.4$ 와 같은 식.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 7. $v_1$ 벡터는 $\sigma_1$ 만큼의 정보량을 가지는 projection axis 를 특정한다&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Projection axis 가 특정 되었다면, 해당 &lt;strong&gt;projection axis 에 데이터를 투영했을때 각 데이터가 가지는 값은 행렬곱 $U\Sigma$ 에 의해 결정&lt;/strong&gt;되게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 8. 차원 축소 후 데이터의 위치는 $U\Sigma$ 에 의해 결정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;본격적인 차원 축소를 수행하기 위해서는 먼저 축소 차원 수 $n$ 을 결정한 후, $\Sigma$ 행렬에서 가장 큰 특이값 $n$ 개를 제외한 나머지 값을 $0$ 으로 바꿔주어야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/svd_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 9. 차원 축소 수행을 위해서는 가장 작은 특이값 n 개를 0 으로 설정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://angeloyeo.github.io/2019/08/01/SVD.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://angeloyeo.github.io/2019/08/01/SVD.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=UyAfmAZU_WI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=UyAfmAZU_WI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=PFDu9oVAE-g&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=PFDu9oVAE-g&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=CpD9XlTu3ys&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=CpD9XlTu3ys&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 8</title>
        <link>https://meme2515.github.io/mlops/fsdl_8/</link>
        <pubDate>Thu, 08 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_8/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_8_title.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 8" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=a54xH6nT4Sw&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-8-teams-and-pm/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1o2x8ywivp555__AEbLLI28BsiQmHobOh/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-is-this-hard&#34;&gt;Why is this hard?&lt;/h2&gt;
&lt;p&gt;제품을 만드는 과정은 다음과 같은 이유로 어렵고 험난하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;좋은 인력을 채용해야 한다.&lt;/li&gt;
&lt;li&gt;채용된 인력을 관리하고, 성장시켜야 한다.&lt;/li&gt;
&lt;li&gt;팀의 결과물들을 관리하고, 방향성을 맞춰야 한다.&lt;/li&gt;
&lt;li&gt;장기간 제품에 영향을 끼칠 기술적인 요소들을 적절히 선택해야 한다.&lt;/li&gt;
&lt;li&gt;리더십의 기대치를 관리해야 한다.&lt;/li&gt;
&lt;li&gt;필요 조건을 정의하고, 관련 인력에게 커뮤니케이션 해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;머신러닝은 이와 같은 과정을 더욱 어렵게 만든다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 관련 인력은 아직 시장에 많지 않고, 채용 비용이 비싼 편이다.&lt;/li&gt;
&lt;li&gt;ML 팀에는 상대적으로 다양한 롤 (role) 이 존재한다.&lt;/li&gt;
&lt;li&gt;대부분 프로젝트의 타임라인이 불명확하고, 실패 확률이 높다.&lt;/li&gt;
&lt;li&gt;분야가 빠르게 발전하고 있으며, ML 제품 관리는 어렵고 아직 체계가 확립되지 않았다.&lt;/li&gt;
&lt;li&gt;리더십은 대게 ML 기술을 깊게 이해하지 못한다.&lt;/li&gt;
&lt;li&gt;비전문 인력이 ML 제품의 실패 원인을 파악하기 어렵다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;8주차 강의는 다음과 같은 내용을 담고있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 분야의 롤 (role) 과 롤 별 필요 전문성&lt;/li&gt;
&lt;li&gt;ML 엔지니어 채용 방식 (그리고 취업 방식)&lt;/li&gt;
&lt;li&gt;ML 팀의 구성 방식과 전체 조직과 협업하는 법&lt;/li&gt;
&lt;li&gt;ML 팀과 ML 제품을 운영하는 법&lt;/li&gt;
&lt;li&gt;ML 제품 기획 시 고려 요소&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;roles&#34;&gt;Roles&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;대표적인 롤&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Product Manager&lt;/strong&gt; : ML Product Manager 는 ML 팀, 비즈니스 영역, 제품 유저, 데이터 오너 간 협업하여 도큐먼트를 작성하고, 제품의 뼈대를 세우고, 계획을 수립하고, 그 중 작업의 우선순위를 정해 ML 프로젝트를 진행하는 역할을 맡는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MLOps/ML Platform Engineer&lt;/strong&gt; : 모델 배포 과정을 보다 쉽고 스케일링이 가능하도록 인프라를 설계하는 역할을 맡는다. 이후 AWS, GCP, Kafka, 혹은 다른 ML 툴을 활용해 배포된 제품의 인프라를 관리하는 역할을 수행.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Engineer&lt;/strong&gt; : 모델을 학습하고 배포하는 역할. TensorFlow, Docker 등의 툴을 활용해 예측 시스템을 실제 데이터에 적용한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Researcher&lt;/strong&gt; : 예측 모델을 학습하는 역할을 맡지만, 주로 최신 모델을 실험적인 환경에서 사용해보거나 이외 제품 적용이 시급하지 않은 문제를 다룬다. TensorFlow, PyTorch 등의 라이브러리를 노트북 환경에서 다루며, 실험 결과를 공유하는 역할을 맡는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Scientist&lt;/strong&gt; : 위에 설명된 모든 역할을 포괄하는 단어. 조직에 따라 비즈니스 문제에 대한 해결을 구하는 분석가 역할을 수행할 수도 있으며, SQL, Excel, Pandas, Sklearn 등의 다양한 툴을 다룬다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;필요한 스킬&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;이러한 롤들을 수행하기 위해선 어떤 스킬셋이 필요할까? 하단 차트는 이러한 롤들이 필요로 하는 스킬셋을 도식화 한다 - &lt;em&gt;수평축은 ML 전문성을, 동그라미 크기는 커뮤니케이션과 기술 문서 작성에 대한 스킬을 뜻함&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MLOps&lt;/strong&gt; 란 기본적으로 소프트웨어 엔지리어링 롤이며, 기존의 소프트웨어 엔지니어링 파이프라인에 대한 이해가 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Engineer&lt;/strong&gt; 는 ML 과 소프트웨어 개발 기술에 대한 지식을 모두 요구한다. 이러한 요구조건은 시장에 흔하지 않으며, 상당한 self-study 를 거친 엔지니어, 혹은 소프트웨어 엔지니어로 근무하는 과학/엔지니어링 분야 박사 학위자가 적합.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Researcher&lt;/strong&gt; 는 컴퓨터 공학, 통계학 등의 석/박사 학위를 소지하고 있는 ML 전문가가 적합하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Product Manager&lt;/strong&gt; 는 기존의 Product Manager 의 역할과 크게 다르지 않지만, ML 제품 개발 과정과 관련 지식에 능통해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Scientist&lt;/strong&gt; 란 학사 학위자 부터 박사 학위자 까지 다양한 배경을 가질 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;버클리 EECS 박사 과정을 밟고 있는 &lt;a class=&#34;link&#34; href=&#34;https://www.shreya-shankar.com/phd-year-one/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Shreya Shankar 가 게시한 글&lt;/a&gt;에 따르면, &lt;strong&gt;ML 엔지니어는 Task ML 엔지니어, Platform ML 엔지니어&lt;/strong&gt;로 세분화해 구분할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Task ML Engineer&lt;/strong&gt; 는 구체적인 ML 파이프라인을 관리하는 역할을 맡는다. 이러한 ML 파이프라인이 정상적으로 작동하는지, 주기적인 업데이트가 이루어지는지 등을 확인하며, 대체로 업무량이 많은 편.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Platform ML Engineer&lt;/strong&gt; 는 다른 ML Engineer 들이 수행하는 반복적인 작업들을 자동화 하는 업무를 맡는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hiring&#34;&gt;Hiring&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI 역량 갭&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;FSDL 이 처음 시작된 2018 년의 경우 채용시장에서 AI 기술을 이해하는 인력을 찾기는 어려운 일이었다. 따라서 기업 내 AI 활용의 가장 큰 걸림돌은 인력 확보 문제였다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2022년 현재, 이러한 채용시장 내 AI 역량에 대한 수요/공급 간 불균형은 여전히 존재하지만, 4년간 이루어진 관련 인력들의 커리어 전환, 이미 ML 수업을 수강한 학부생들의 시장 유입으로 어느 정도 해소된 면이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 아직 시장에는 ML 이 어떻게 실패하고, ML 제품을 성공적으로 배포하는 방법을 아는 인력이 부족하다. 특히 &lt;strong&gt;제품 배포 경험&lt;/strong&gt;을 가진 인력에 대한 품귀 현상이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;채용 소스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이렇듯 작은 인력 풀과 급성장하는 수요로 인해 ML 직군 채용은 어려운 편이다. MLOps, Data Engineer, Product Manager 와 같은 롤은 많은 ML 지식을 요구하지 않기 때문에, 본 섹션에서는 코어 ML 직군에 대한 채용 방법을 설명한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위와 같은 완벽한, 그리고 비현실적인 JD 를 통한 채용은 잘못된 방식이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이보다는 소프트 엔지니어링 스킬셋을 갖춘 후보 중 ML 분야에 대한 관심이 있고, 배우고자 하는 인력을 추리는 편이 낫다. 기본적인 개발 역량이 있다면 ML 은 충분히 학습 가능한 영역이다.&lt;/li&gt;
&lt;li&gt;주니어 레벨의 채용 또한 고려해 볼 수 있다. 최근 졸업생등은 ML 지식을 상당 수준 가지고 있는 편.&lt;/li&gt;
&lt;li&gt;필요한 시킬셋이 무엇인지 가능한 자세히 기술하는 편이 좋다. DevOps 부터 알고리즘 개발까지 모든 ML 개발 과정에 능통한 인력을 찾기란 불가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML Researcher 를 채용하기 위해 강사진은 다음과 같은 팁을 제시한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;논문의 양보다는 질을 검토할 것. 아이디어의 독창성, 수행 방식 또한 면밀히 검증.&lt;/li&gt;
&lt;li&gt;트렌디한 문제보다 본질적인 문제에 집중하는 연구자를 우선 채용할 것.&lt;/li&gt;
&lt;li&gt;학계 밖에서의 경험은 비즈니스 환경 적응에 도움이 되기 때문에 이 또한 중요하다.&lt;/li&gt;
&lt;li&gt;박사 학위가 없거나, 유사 분야인 물리학, 통계학 등을 공부한 인력 또한 진중하게 검토할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 지원자를 찾기 위해서는 다음과 같은 경로를 시도할 것.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LinkedIn, 리크루터, 캠퍼스 방문 등 기존 채용 경로 검토.&lt;/li&gt;
&lt;li&gt;ArXiv, 유명 컨퍼런스 등을 모니터링하고, 마음에 드는 논문의 1 저자 플래그.&lt;/li&gt;
&lt;li&gt;좋아하는 논문을 누군가 수준있게 구현한 경우 플래그.&lt;/li&gt;
&lt;li&gt;NeurIPS, ICML, ICLR 등 ML 컨퍼런스 참석.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;리크루팅을 진행하면서 지원자들이 회사에 바라는 바를 파악하고, 이에 맞춰 회사를 포지셔닝 하는 과정이 필요하다. ML 전문가들은 흥미로운 데이터를 기반으로 영향력있는 일을 하고 싶어하기 때문에 배움과 영향력을 지향하는 문화를 만들고, 이를 통해 좋은 인력이 지원할 동기를 만들어 주어야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 지원자를 모으기 위해선 채용을 진행중인 팀이 어떻게 우수하고, 미션이 어떻게 의미있는지에 대한 적극적이고 구체적인 설명이 곁들여져야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;인터뷰&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지원자를 인터뷰 할 때는, &lt;strong&gt;지원자의 강점은 재확인하고, 약점은 최소 기준점을 충족하는지 확인&lt;/strong&gt;하자. ML Researcher 의 경우 새로운 ML 프로젝트에 대해 창의적으로 생각할 수 있는지 검증이 필요하지만, 코드 퀄리티의 경우 최소한의 요건만 충족하면 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 인터뷰는 기존 소프트웨어 엔지니어링 인터뷰에 비해 덜 성숙한 분야이다. Chip Huyen 의 &lt;a class=&#34;link&#34; href=&#34;https://huyenchip.com/ml-interviews-book/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;strong&gt;Introduction to ML Inteviews Book&lt;/strong&gt;&lt;/a&gt; 과 같은 레퍼런스를 참조.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;organizations&#34;&gt;Organizations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ML 팀의 구성이란 아직 정답이 존재하지 않는 영역이다. 하지만 조직 내 ML 활용 특성과 성숙도에 따라 존재하는 best practice 는 다음과 같이 정리할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 1 - 초기단계 혹은 Ad-Hoc 성 ML&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;사실상 조직 내 ML 활용이 없으며, 필요시 단발성 프로젝트가 진행되는 경우. 인하우스 ML 전문성은 매우 낮은 편이다.&lt;/li&gt;
&lt;li&gt;중소규모의 비즈니스이거나, 교육, 물류 등 상대적으로 IT 중요도가 낮은 분야일 것.&lt;/li&gt;
&lt;li&gt;ML 적용으로 인한 단기적 이점이 상당히 적은 편.&lt;/li&gt;
&lt;li&gt;ML 프로젝트에 대한 지원이 적으며, 좋은 인력을 채용하고 유지하는 것에 상당한 어려움이 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 2 - ML R&amp;amp;D&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;조직 내 대부분의 ML 관련 업무가 R&amp;amp;D 에 치중되어 있는 경우. 대부분의 채용이 논문 작성 경험이 있는 ML Researcher, 박사 학위자를 대상으로 한다.&lt;/li&gt;
&lt;li&gt;에너지, 제조, 통신 등의 분야에서 규모가 큰 회사일 가능성이 높다.&lt;/li&gt;
&lt;li&gt;경험이 많은 연구 인력 채용을 통해 long-term 비즈니스 문제를 해결할 역량을 가지고 있다.&lt;/li&gt;
&lt;li&gt;하지만 질좋은 데이터 확보가 어려우며, 연구에서 실제 비즈니스 가치를 가진 제품 개발까지의 과정이 잘 이루어지지 않는다. 따라서 투자 규모 또한 작은 편.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 3 - 비즈니스 &amp;amp; 제품 팀 내 적극적인 활용&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;특정한 제품이나, 사업 영역에 속한 소프트웨어, 분석 인력이 이미 ML 전문성을 확보하고 있는 경우이다. 이러한 ML 인력은 소속된 팀의 엔지니어링/기술 담당자에게 보고하는 구조를 가진다.&lt;/li&gt;
&lt;li&gt;IT 회사이거나, 금융 회사일 가능성이 높다.&lt;/li&gt;
&lt;li&gt;이러한 경우 ML 제품 개선은 직접적인 비즈니스 가치를 준다. 또한 아이디어 제시와 제품 개선 간 밀접한 피드백 사이클 또한 존재.&lt;/li&gt;
&lt;li&gt;하지만 높은 수준의 인력을 채용하는 것은 여전히 어렵고, 연산 자원이나 데이터 등을 확보하는 것에 많이 시간이 소요될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 4 - 독립적인 ML 기능&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 부서가 별도 조직으로 구성되어, senior management 에게 직접 보고하는 경우. ML Product Manager 가 연구자, 엔지니어와 협업해 클라이언트가 사용하는 제품을 개발하며, 장기적인 연구 또한 진행한다.&lt;/li&gt;
&lt;li&gt;규모가 큰 금융 회사일 가능성이 높음.&lt;/li&gt;
&lt;li&gt;수준높은 인력을 보유하고 있기 때문에 추가적인 인력 소싱이 쉬운 편이다. 데이터와 연산 자원이 수월하게 배분되며, ML 개발과 관련된 여러 문화와 규율을 형성할 조건이 마련된다.&lt;/li&gt;
&lt;li&gt;하지만 사업 영역에 따라 ML 활용에 대한 이점을 설득하거나, 모델에 대한 기초적인 내용을 교육하는 것에 많은 노력이 들 수 있다. 또 피드백 사이클 또한 빠르게 전개되지 못할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 5 - ML 우선주의&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CEO 의 직접적인 투자가 이루어지며, 비즈니스 전반에서 관련 전문 인력이 빠른 성과를 내기위해 노력한다. 별도의 ML 조직은 난이도가 높고, 호흡이 긴 프로젝트를 주로 전담.&lt;/li&gt;
&lt;li&gt;규모가 큰 IT 회사, 또는 ML 분야 스타트업이 이에 해당한다.&lt;/li&gt;
&lt;li&gt;데이터 접근이 쉽고, ML 전문가가 선호할만한 문화/환경을 가지고 있다. 개발직군 또한 ML 에 대한 이해가 높기 때문에 개발 과정이 수월한 편.&lt;/li&gt;
&lt;li&gt;하지만 ML 관점의 생각을 비즈니스 전반에서 가지기는 어려우며, 현실적으로 구성되기 어려운 조직 환경.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;조직 구성 전략&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;자신의 조직의 상단의 5개 타입 중 어느 타입에 가장 가까운지에 따라 적절한 조직 구성 전략을 선택하는 과정이 필요하다. 강사진이 정리한 조직 구성 전략은 크게 다음과 같은 영역에서 정의된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Software Engineer vs. Research&lt;/strong&gt; : 소프트웨어와의 연동성을 위해 ML 팀이 어느 정도까지 관여하는가? 팀 내 소프트웨어 엔지니어링 역량은 어느 정도의 중요성을 가지는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Ownership&lt;/strong&gt; : 데이터 수집, 웨어하우징, 레이블링, 파이프라이닝 과정에서 ML 팀은 어느 정도의 권한을 가지는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model Ownership&lt;/strong&gt; : ML 팀은 개발된 모델의 배포까지를 담당하는가? 이렇게 배포된 모델은 누가 관리하는가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음 섹션은 조직 특성에 따른 구성 전략을 간단히 설명한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;조직이 &lt;strong&gt;ML R&amp;amp;D&lt;/strong&gt; 에 집중하는 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;개발 보다는 연구 역량이 더욱 중요시되기 때문에, 두 담당 영역간 협업 능력이 다소 저하될 수 있다.&lt;/li&gt;
&lt;li&gt;ML 팀은 데이터에 대한 권한을 가지지 않으며 데이터 엔지니어의 지원을 받지 않는다.&lt;/li&gt;
&lt;li&gt;사실상의 ML 제품화는 발생하지 않는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이미 &lt;strong&gt;제품 내 ML 활용&lt;/strong&gt;이 이루어지는 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;연구 보다는 개발 역량이 중요시되며, 연구직 또한 적절한 엔지니어링 역량을 보유해 연구 단계 이후 제품화를 감안해야 한다.&lt;/li&gt;
&lt;li&gt;데이터 관리와 생성에 대한 권한을 가지지 않는다. 데이터 엔지니어의 지원을 통해 데이터 파이프라인 구축.&lt;/li&gt;
&lt;li&gt;ML Engineer 들은 배포되는 모델에 대한 모든 권한을 가지게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;별도의 ML 조직&lt;/strong&gt;이 구성된 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모든 팀은 연구 &amp;amp; 개발 인력을 보유할 수 있으며, 팀 내 협업이 긴밀하게 이루어진다.&lt;/li&gt;
&lt;li&gt;데이터 거버넌스, 엔지니어링 관련 논의에서 보다 힘이 실린 의견표출이 가능하다.&lt;/li&gt;
&lt;li&gt;모델은 유저에게 배포되지만, 이를 관리하는 책임은 유지된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML 우선주의&lt;/strong&gt;가 존재하는 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;연구 분야에 중점이 있지만, 연구자들 또한 개발 인력과 긴밀히 협업한다.&lt;/li&gt;
&lt;li&gt;전사 데이터 인프라에 대한 권한을 소유하게 된다.&lt;/li&gt;
&lt;li&gt;배포된 모델에 대한 관리/운영 책임은 유저에게 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;managing&#34;&gt;Managing&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Managing ML teams is challenging&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 팀 운영이 어려운 이유로는 다음과 같은 4가지를 들 수 있다.
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;공수 예측&lt;/strong&gt; : ML 프로젝트란 착수 전 난이도를 측정하기 애매한 측면이 존재한다. 데이터를 조회하고, 여러 모델을 적용해보며 새로 습득해야 하는 정보가 무궁무진하며, 이는 프로젝트 타임라인 설정에 차질을 줄 여지가 많다. 또한 어떠한 모델이 잘 작동할지 사전에 파악하는 것은 불가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;비선형적인 업무 진전도&lt;/strong&gt; : Weights and Biases 의 CEO 인 Lukas Biewald 가 쓴 &lt;a class=&#34;link&#34; href=&#34;https://medium.com/@l2k/why-are-machine-learning-projects-so-hard-to-manage-8e9b9cf49641&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 블로그 포스트&lt;/a&gt;에 의하면, ML 프로젝트의 진전 상황과 무관하게 앞으로의 상황을 예측하기 어려운 경우가 많다 &lt;em&gt;(상단 그래프 참조)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;문화 차이&lt;/strong&gt; : 엔지니어링과 연구 분야는 서로 크게 다른 문화를 형성하고 있다. 연구 분야는 새롭고, 독창적인 생각을 선호하는 반면, 엔지니어링 분야는 검증된 방법을 선호하기 때문. 이로 인해 ML 조직은 빈번하게 문화 충돌로 인한 갈등을 경험하며, 이와 같은 갈등은 제대로 다뤄지지 않을 시 조직 운영에 치명적인 결과를 초래할 수 있다. 따라서 ML 조직 운영의 주요 과제 중 하나는 ML, 소프트웨어 엔지니어링 분야 간 협업을 이끌어 내는 부분이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;리더십의 도메인 이해 결여&lt;/strong&gt; : 조직의 리더십이 ML 기술을 구체적으로 이해하고 있는 경우는 흔치않다. 따라서 기술을 한계를 명확하게 전달하고, 올바른 기대치를 심어주는 과정에 어려움이 따를 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How to manage ML teams better&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 조직의 관리는 아직 체계가 확립되지 않은 분야지만, 다음과 같은 노력을 통해 개선이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;확률적 계획 수립&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;대부분의 ML 프로젝트는 단계적인 태스크를 명확하게 정의한 후 시작한다. 하지만 이와 같은 엔지니어링적 접근 보다는, 각 태스크에 대한 성공 확률을 부여해 ML 프로젝트는 근본적인 실험성을 동반한다는 점을 사전에 인지하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;다양한 접근 방법 구비&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;제품 개발 계획을 세우는 단계에서 한 개 방법의 성공에 의존하는 것은 위험하기 때문에, 가능한 많은 아이디어와 접근 방법을 포용해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;아웃풋 보다는 인풋을 기반으로한 업무 평가&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;여러 방법을 수행하면서, 성공 여부를 기반으로 팀원의 기여도를 측정하는 것은 적절치 않다. 이와 같은 방법의 평가는 안전하고, 검증된 접근법만을 독려해 전반적인 팀의 상상력, 독창성을 저해할 수 있기 때문. ML 제품의 성공을 위해서는 새로운 아이디어를 높은 수준으로 검증하는 과정이 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;연구자, 엔지니어 간 협업&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;엔지니어링과 연구 부서 간 협업은 수준있는 ML 제품 개발을 위해 필수적이다. 따라서 이들 그룹 간 협업을 독려하고, 이끌 필요가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;빠른 성과 추구&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이와 같은 방법은 리더십에게 프로젝트의 진전도를 보다 효과적이고, 명료하게 전달할 수 있도록 하며, 장기적으로 ML 프로젝트가 성공하는데 도움을 준다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;불확실성에 대한 리더십의 충분한 이해&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;조직의 리더는 타임라인 상 위험요소에 대해 명확하게 이해하고 (understanding timeline risk), 불확실성을 해소할 책임이 있기 때문에 (addressing blind spots) ML 개발의 본질적인 불확실성을 전달하는 과정에서 어려움이 따를 수 있다. 하지만 다음과 같은 접근을 통해 리더십의 ML 이해도를 높이는 것이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 영역에 한정된 KPI 를 지나치게 강조하는 것은 좋지 않은 방법이다 (예. F1 스코어를 0.2 개선해 모델 성능이 상당 부분 개선되었다 등의 코멘트).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대신, 조직 구성원 대부분이 이해할 수 있는 리스크/임팩트 설명을 곁들이는 편이 좋다 (예. 모델 개선으로 인해 약 10% 전환율 상승이 예상되나, 추가적인 demographic 요소를 참조해 지속적으로 성능을 평가하는 과정이 필요).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://a16z.com/2016/06/10/ai-deep-learning-machines/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this a16z primer&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://executive.berkeley.edu/programs/artificial-intelligence&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this class from Prof. Pieter Abbeel&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://pair.withgoogle.com/guidebook&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this Google&amp;rsquo;s People + AI guidebook&lt;/a&gt;&lt;/strong&gt; 등의 리소스 공유를 통해 리더십의 ML 관련 이해도 제고.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ML PMs are well-positioned to educate the organization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML Product Manager 직군은 크게 두 개 타입으로 구분 가능하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Task PM :&lt;/strong&gt; 보다 일반적인 ML PM 모습에 가깝다. 특정 분야에 전문성을 가지고 있고 (예. 안전 정책) 관련해 세부적인 유즈케이스에 많은 경험을 가지고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Platform PM :&lt;/strong&gt; 최근 등장한 PM 직군 형태. Task PM 보다 넓은 영역에서 (우선순위 설정, 워크플로우 관리 등) ML 팀을 지원할 책임을 가지고 있다. ML 에 대한 보다 넓은 이해를 가지고 있고, 조직 전반에 걸쳐 ML 이해도를 높이고, 모델의 아웃풋을 신뢰할 수 있도록 돕는다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 제품의 성공을 위해서는 두 개 타입의 PM 모두 중요한 역할을 수행하며, 특히 Platform PM 은 조직 전반에서 ML 제품 영향력을 키우는 역할을 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What is &amp;ldquo;Agile&amp;rdquo; for ML?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Agile, 소프트웨어 간 관계는 다음 두가지 옵션과 ML 간 관계와 유사하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CRISP-DM, TDSP 모두 구조적이고, 데이터 사이언스 분야에 특화된 프로젝트 관리 방법론이다. 이들 모델을 활용해 프로젝트의 단계, 역할, 산출물 등을 통용/약속된 방식으로 정의할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TDSP&lt;/strong&gt; 는 보다 구조적이며, Agile 방법론에 대한 직접적인 대체제이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CRISP-DM&lt;/strong&gt; 은 보다 상위 레벨의 개념들을 다루며, 프로젝트 관리 체계의 정의가 약한 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;스케일이 큰 프로젝트 진행 시 이러한 프레임워크 적용을 고려해 볼 수 있지만, 그렇지 않은 경우 이를 강제할 필요는 없다. 이들 프레임워크가 머신러닝 보다는 전통적인 데이터 사이언스 문제를 기반으로 하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;design&#34;&gt;Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;대부분의 경우, ML 제품 기획에서 가장 어려운 부분은 제품 구현이 아닌 &lt;strong&gt;유저의 기대치와 실현 가능한 제품의 수준 간 격차를 좁히는 일&lt;/strong&gt;이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 시스템을 접한 유저는 대게 고도로 개발된, 실제 가능한 것보다 더 많은 문제를 풀 수 있는 시스템을 기대하기 마련이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;하지만 현실 세계의 ML 시스템이란 특정 작업을 위해 훈련된 강아지와 같다. 집중력에 한계가 존재하고, 학습 받지 않은 작업을 수행하기 어려워 하는 경우가 대부분이기 때문.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_title.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Keys to Good ML Product Design&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;유저는 제품 사용으로 얻을 수 있는 장점과 한계를 명확히 이해했을때 더 높은 만족도를 보인다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;AI-powered&amp;rdquo; 라는 캐치 프레이스를 사용하기 보다는, 실제 모델이 해결하는 문제에 집중할 것.&lt;/li&gt;
&lt;li&gt;시스템 설계를 사람과 같이 느껴지도록 구성하였다면, 유저가 이를 실제 사람과 같이 다룰 것으로 기대할 것.&lt;/li&gt;
&lt;li&gt;Amazon Alexa 와 같이 특정 상황에 ML 이 어떻게 대처할 것인지를 사전에 정의하는 것 또한 검토.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모델이 실행에 실패했을때를 대비한 백업 플랜을 준비할 것.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;지나친 자동화는 오히려 유저 경험의 질을 떨어트릴 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;피드백 룹 구축을 통한 지속적인 모델 개선으로 유저 경험을 개선할 것.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;실패 관리는 ML 시스템 유저의 만족도 제고를 위한 핵심적인 요소이다. 유저가 직접 잘못된 아웃풋을 수정하는 기능을 추가하거나, 특정 임계점을 넘은 경우에만 결과값을 보여주는 등의 Quality Assurance 체계가 필요하다 &lt;em&gt;(예. 페이스북이 사진에 포함된 얼굴을 기반으로 친구 태깅을 추천하지만, 직접적으로 수행하지는 않는 것과 같은 경우)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Types of User Feedback&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 문제 해결을 위해 &lt;strong&gt;유저의 피드백을 깊게 살필 필요&lt;/strong&gt;가 있으며, 피드백은 다음과 같이 구분 가능하다 &lt;em&gt;(x축이 모델 개선 과제 내 유용성, y축이 유저 난이도)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;간접적, 암시적 피드백 (indirect implicit feedback)&lt;/strong&gt; : 유저가 제품 구매 과정에서 이탈했는지 등의 정보.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;직접적, 암시적 피드백 (direct implicit feedback)&lt;/strong&gt; : 유저가 제품 구매 과정의 다음 단계로 이동했는지 등의 정보.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;이항적, 명시적 피드백 (binary explicit feedback)&lt;/strong&gt; : 좋아요/싫어요 등 제품 만족도를 두 개 옵션 중 하나로 특정하는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;범주적, 명시적 피드백 (categorical explicit feedback)&lt;/strong&gt; : 별점 등 제품 만족도를 여러개의 옵션 중 하나로 특정하는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;자유적 피드백 (free text feedback)&lt;/strong&gt; : 유저의 자유로운 텍스트 피드백.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델 보정 (model corrections)&lt;/strong&gt; : 유저의 직접적인 데이터 레이블링.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;이러한 피드백 체계를 구축할 때에는 유저의 이타심에 기대는 것 보다는, 피드백을 제공하는 것이 유저에게 어떤 가치를 제공하는지 적극적으로 설명하는 편이 낫다. 또한, 유저 피드백에 따른 모델 개선이 실제로 빠르고 직접적으로 작동할 수 있도록 구성되어야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 7</title>
        <link>https://meme2515.github.io/mlops/fsdl_7/</link>
        <pubDate>Wed, 07 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_7/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_7_title.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 7" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Rm11UeGwGgk&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-7-foundation-models/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/17ZAj6izyYhV-SXA_UKNWjYo0adbL2E8n/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;기초 모델 (foundation model) 이란 방대한 양의 데이터를 학습한 큰 규모의 모델을 뜻하며, 다양한 task 에 응용될 수 있다.&lt;/li&gt;
&lt;li&gt;본 주차에서는 Fine-Tuning, Transformers, LLM, Prompt Engineering, CLIP 등의 주제를 다룰 예정.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;fine-tuning&#34;&gt;Fine-Tuning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;전통적인 ML 은 규모가 큰 모델에 방대한 양의 데이터를 학습하지만, 보유한 데이터가 제한적일 때에는 &lt;strong&gt;전이 학습&lt;/strong&gt;을 통해 성능을 향상 시킬 수 있다.&lt;/li&gt;
&lt;li&gt;전이 학습 (transfer training) 의 기본적인 방법론은 pre-train 된 동일한 모델에 레이어를 덧붙인 후, 일부 가중치를 학습하는 것.&lt;/li&gt;
&lt;li&gt;비전 분야에서는 2014년 부터 적용되어왔던 방식이며, Model Zoo 상에서 사전 학습이 이루어진 AlexNet, ResNet 과 같은 모델을 쉽게 찾을 수 있다.&lt;/li&gt;
&lt;li&gt;NLP 분야의 경우, 사전 학습은 word embedding 영역에 한정되어왔다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://jalammar.github.io/illustrated-word2vec/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Word2Vec&lt;/a&gt;&lt;/strong&gt; 은 2013년도 자주 함께 등장하는 단어 간 cosine similarity 를 최소화하는 모델을 학습 시켰다. 결과적으로 얻은 벡터를 활용해 연산 작업을 하는 등 다양한 적용 예시를 보임.&lt;/li&gt;
&lt;li&gt;단순한 단어의 의미 뿐 아니라 맥락에 대한 이해 또한 embedding 작업에 중요한 역할을 수행한다. 2018 년도 등장한 &lt;strong&gt;ELMO, ULMFit&lt;/strong&gt; 등이 이에 속하며, 이들 모델은 사전 학습이 완료된 LSTM 모델을 공개했다.&lt;/li&gt;
&lt;li&gt;하지만 최근 Model Zoo 를 살피면 LSTM 모델은 자취를 감춘 모양새이다. 최근 더욱 활발히 연구되고 있는 모델 구조는 트랜스포머 이기 때문.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;transformers&#34;&gt;Transformers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;트랜스포머는 2017년 유명한 논문 “Attention Is All You Need” 에서 처음 등장했으며, 기존 NLP 와는 확연히 다른 구조로 번역 등의 분야에서 독보적인 성능을 보였다.&lt;/li&gt;
&lt;li&gt;블로그 주인이 별도로 작성한 트랜스포머 소개글이 이미 있으니 대신 참고하면 좋을 듯 하다 - &lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/neural_network/transformer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Transformer 네트워크 개념 소개&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;large-language-models&#34;&gt;Large Language Models&lt;/h2&gt;
&lt;h3 id=&#34;models&#34;&gt;Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GPT 와 GPT-2 는 각각 2018 년과 2019 년에 공개되었다. 기존 트랜스포머 구조에서 Decoder 만을 활용해 구축된 모델이며, Masked Self-Attention 을 차용했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 모델들은 약 800 만 개의 웹페이지로 학습되었으며, 가장 큰 모델은 약 15억 개의 파라미터를 가지고 있다.&lt;/li&gt;
&lt;li&gt;GPT-2 가 학습된 방식은 웹 데이터를 기반으로 다음 단어를 예측하는 작업이다. 이러한 작업은 파라미터 수가 증가할 수록 더욱 자연스러워 진다는 특징을 가지고 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BERT 는 유사한 시점에 공개되었다. 트랜스포머 구조의 인코더만을 활용해 만들어졌으며, Attention Masking 을 적용하지 않았다.&lt;/li&gt;
&lt;li&gt;약 1억 천만 개의 파라미터를 가지고 있으며, 학습 과정에서 BERT 는 random 한 단어를 마스킹 처리한 후, 해당 단어가 어떤 단어인지 예측하는 task 를 수행한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;T5&lt;/a&gt;&lt;/strong&gt; (Text-to-Text Transformer) 은 2020 년 공개된 모델이다. 인풋과 아웃풋 모두 텍스트이기 떄문에 모델이 어떤 작업을 수행해야 하는지 특정하는 것이 가능.&lt;/li&gt;
&lt;li&gt;T5 는 Encoder-Decoder 구조를 가지고 있고, 위키피디아 보다 약 100배 큰 C4 데이터를 기반으로 학습되었다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/gpt-3-apps/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GPT-3&lt;/a&gt;&lt;/strong&gt; 는 2020년에 공개된 모델이며 기존 GPT/GPT-2 보다 약 100배의 크기를 가지고 있다. 엄청난 규모로 인해 few-shot learning, zero-shot learning 등의 작업에 이전에 달성하지 못한 정확도를 기록했다.&lt;/li&gt;
&lt;li&gt;하단 그래프에서 보이듯, 데이터 수가 증가할수록 모델의 성능이 linear 하게 증가하는 것을 확인할 수 있다. 또한, 파라미터가 많을 수록 모델 성능이 증가한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI 는 또한 2022 년 초 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/instruction-following/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Instruct-GPT&lt;/a&gt;&lt;/strong&gt; 를 공개했다. GPT-3 의 아웃풋에 대해 사람이 순위를 매기도록 하여, 파인튜닝을 진행하는 방식.&lt;/li&gt;
&lt;li&gt;Instruct-GPT 는 특정한 지시를 따르는데 개선된 성능을 보이며 (하기 이미지 참고), API 상 ‘text-davinci-002’ 라는 이름으로 공개되어 있는 상태이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DeepMind 는 2021년 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2112.04426.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RETRO (Retrieval-Enhanced Transformers)&lt;/a&gt;&lt;/strong&gt; 라는 모델을 공개했다. 단순히 파라미터에 정보를 담는 것이 아니라, 별도 데이터베이스에 이에 대한 정보를 저장하는 방식.&lt;/li&gt;
&lt;li&gt;BERT 를 활용해 여러 문장을 인코딩 후, 약 1조 개의 토큰을 가진 데이터베이스에 저장하게 된다. 예측 시 매칭되는 문장을 조회해 정보를 추출하게 되며, 항상 최신 정보를 조회할 수 있다는 장점을 가진다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DeepMind 는 또한 2022 년 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://gpt3demo.com/apps/chinchilla-deepmind&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Chinchilla&lt;/a&gt;&lt;/strong&gt; 라는 모델을 공개했으며, 언어 모델의 크기와 성능에 대한 상관 관계를 관찰했다는 점에 의의가 있다.&lt;/li&gt;
&lt;li&gt;DeepMind 팀은 약 7천만 ~ 160억 개의 파라미터를 가진 &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2203.15556.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;400 개의 언어 모델&lt;/a&gt;을, 50억 에서 5000억 개 까지의 토큰을 활용해 학습했으며, 최적의 파라미터와 데이터 셋 사이즈를 유추하는 수식을 통해 대부분의 언어 모델이 undertrain 되었다는 결론을 내렸다 (더 큰 데이터 셋이 필요).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이를 증명하기 위해 DeepMind 팀은 약 2800 억 개의 파라미터를 가진 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://gpt3demo.com/apps/deepmind-gopher&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gopher&lt;/a&gt;&lt;/strong&gt; 라는 모델을 3000 개의 토큰으로 학습하였으며, Gopher 의 학습 결과를 Chinchilla (약 700 억 개의 파라미터, 1조 4천 개의) 의 것과 비교해 Chinchilla 의 성능이 더욱 우수하다는 점을 도출.&lt;/li&gt;
&lt;li&gt;즉 파라미터 수가 적더라도 데이터가 많다면 모델은 더 우수한 성능을 내는 것이 가능하다는 결론을 내렸다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vendors&#34;&gt;Vendors&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI 는 다음과 같은 모델 사이즈 옵션을 제공 : Ada3 (3억 5천만 파라미터), Babbage (13억 파라미터), Curie (67억 파라미터), Davinci (1750억 파라미터). &lt;a class=&#34;link&#34; href=&#34;https://openai.com/api/pricing/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;각 옵션은 서로 다른 가격 정책과 기능을 제공한다&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;GPT-3 의 눈에 띄는 결과들은 대부분 Davinci 를 기반으로 하며, 추가 비용을 들인다면 모델의 fine-tuning 또한 진행할 수 있다.&lt;/li&gt;
&lt;li&gt;OpenAI 의 대안은 다음과 같다:
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://cohere.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cohere AI&lt;/a&gt; 는 유사한 모델을 유사한 가격으로 제공&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ai21.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AI21&lt;/a&gt; 는 보다 큰 규모의 모델을 제공&lt;/li&gt;
&lt;li&gt;오픈소스 언어 모델 또한 존재하며 대표적으로 Eleuther GPT-NeoX (200억 파라미터), Facebook OPT-175B (1750억 파라미터), BLOOM from BigScience (1760억 파라미터) 가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prompt-engineering&#34;&gt;Prompt Engineering&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GPT-3 와 유사한 언어 모델들은 외계 기술에 가깝다 - 정확히 어떻게 작동되는지가 명확하지 않으며, 이에 대한 인사이트를 위해서는 모델과 상호작용을 해보는 수 밖에는 없다.&lt;/li&gt;
&lt;li&gt;tokenization 으로 인해 GPT-3 는 단어의 순서를 뒤집는 작업, 길이가 긴 문장을 다루는 작업 등에 다소 아쉬운 성능을 보인다.&lt;/li&gt;
&lt;li&gt;GPT-3 가 잘 수행하지 못하는 다른 예시는 캐릭터를 조합하는 작업인데, 이를 수행하기 위해서는 GPT-3 에게 &lt;a class=&#34;link&#34; href=&#34;https://twitter.com/npew/status/1525900849888866307&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;단계적 수행을 위한 알고리즘&lt;/a&gt;을 학습시켜야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;또 다른 prompt engineering 의 예시는 “Let’s Think Step by Step”. &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2205.11916.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Large Language Models are Zero-Shot Reasoners&lt;/a&gt;&lt;/strong&gt; 라는 논문에서 처음 등장했으며, GPT-3 모델에 “Let’s Think Step by Step” 이라는 내용을 추가하는 것 만으로 수학 문제에 대한 정답율을 17% 에서 78% 로 향상하는 것을 관찰한 내용을 담고있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT 는 또한 긴 문맥을 파악하는 작업을 잘 수행할 수 있으며, csv 파일을 생성하거나 Python 코드 등을 작성하는 &lt;a class=&#34;link&#34; href=&#34;https://twitter.com/goodside/status/1557381916109701120&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;예시&lt;/a&gt;를 쉽게 찾을 수 있다.&lt;/li&gt;
&lt;li&gt;GPT 는 문맥에 따라 원하는 작업을 수행하지 않을 수 있기 때문에 주의가 필요하다. GPT-3 를 기반으로 제작된 어플리케이션에서 또한 발생하는 문제이니 사전 조치가 필요할 수 있는 영역 (&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://simonwillison.net/2022/Sep/12/prompt-injection/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;prompt injection attacks&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://twitter.com/goodside/status/1564112369806151680&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;possess your AI&lt;/a&gt;&lt;/strong&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PromptSource, OpenPrompt 등의 prompt engineering 툴이 존재하지만, 실제 배포 모델 개발을 위해서는 커뮤니티 내 더욱 개선된 툴셋이 필요한 상황.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-applications&#34;&gt;Other Applications&lt;/h2&gt;
&lt;h3 id=&#34;code&#34;&gt;Code&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;대규모 모델의 주요 활용 예시 중 하나는 &lt;strong&gt;코드 생성&lt;/strong&gt; 영역. DeepMind 팀은 약 400 억 개의 파라미터를 가진 트랜스포머 모델 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.deepmind.com/blog/competitive-programming-with-alphacode&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Alphacode&lt;/a&gt;&lt;/strong&gt; 를 통해 Codeforce 대회에서 평균 이상의 성적을 기록한 적이 있으며, 이를 위해 코드를 생성하는 모델과 생성된 코드를 검증하는 모델을 개발.&lt;/li&gt;
&lt;li&gt;모델의 아웃풋을 필터링 하는 작업을 실제 성능 향상에 상당한 도움을 줄 수 있다. OpenAI 또한 수학 문제를 풀기 위해 유사한 프로세스를 적용한 적이 있으니 &lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/grade-school-math/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;관련 자료&lt;/a&gt;를 참고하면 좋을 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;코드 생성 모델은 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github Copilot&lt;/a&gt;&lt;/strong&gt; 과 같은 실제 제품으로도 개발 되었으며, 유사한 제품으로는 &lt;a class=&#34;link&#34; href=&#34;https://blog.replit.com/ai&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;replit&lt;/a&gt; 이 존재한다.&lt;/li&gt;
&lt;li&gt;프로그래밍 환경에 ML 모델을 적용하는 것은 이제 시작 단계에 있는 상태이며, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2207.14502.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;A recent paper&lt;/a&gt;&lt;/strong&gt; 에서는 자체적으로 생성한 문제를 기반으로 코딩 능력을 향상시키는 모델 또한 공개한 바가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;semantic-search&#34;&gt;Semantic Search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Semantic Search (의미 기반 검색)&lt;/strong&gt; 는 또 다른 유망한 적용 영역이다. 하나의 문서를 기반으로 생성한 embedding vector 를 활용해 유사성을 탐색하는 기능인데, cosine similarity 를 기반으로 해당 vector 간 의미가 얼마나 유사한지를 명확하게 판별할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;정보가 많은, float type 의 벡터 연산에는 많은 자원이 필요한데, Google 과 Facebook 같은 회사는 이러한 문제를 해결하기 위해 &lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/using-faiss-to-search-in-multidimensional-spaces-ccc80fcbf949&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FAISS&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ScaNN&lt;/a&gt; 과 같은 라이브러리를 개발.&lt;/li&gt;
&lt;li&gt;오픈소스로는 &lt;a class=&#34;link&#34; href=&#34;https://www.deepset.ai/haystack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Haystack from DeepSet&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;http://Jina.AI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Jina.AI&lt;/a&gt; 등을 참고할 것. Pinecone, Weaviate, Milvus, Qdrant, Qdrant, Google Vector AI Matching Engine 또한 관련 서비스를 제공한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;going-cross-modal&#34;&gt;Going Cross-Modal&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;새로운 모델들은 비전, 텍스트 간 서로 다른 형태의 데이터를 취합하는 기능을 제공한다. 예시로 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/tackling-multiple-tasks-with-a-single-visual-language-model/flamingo.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Flamingo model&lt;/a&gt;&lt;/strong&gt; 을 들 수 있는데, perceiver resampler 라는 구조를 활용해 이미지를 규격화된 토큰으로 전환할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;최근 공개된 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://socraticmodels.github.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Socratic Model&lt;/a&gt;&lt;/strong&gt; 은 각자 별도의 학습 과정을 거친 비전, 언어, 오디오 모델이 하나의 인터페이스로 통합되어, 자연어 prompt 를 통해 새로운 task 를 수행하는 구조를 가지고 있다.&lt;/li&gt;
&lt;li&gt;Foundation 모델이란 Stanford 에서 공개한 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2108.07258&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;On the Opportunities and Risks of Foundation Models&lt;/a&gt;&lt;/strong&gt; 에서 처음 알려진 개념이다. 강사진은 Large Language Model, 또는 Large Neural Network 가 더욱 적합한 단어라고 생각.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;clip-and-image-generation&#34;&gt;CLIP and Image Generation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;해당 섹션에서는 비전 분야를 주제로 다룸.&lt;/li&gt;
&lt;li&gt;2021 년 OpenAI 은 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2103.00020&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CLIP (Contrastive Language-Image Pre-Training)&lt;/a&gt;&lt;/strong&gt; 을 공개했다. 트랜스포머를 활용해 인코딩 된 텍스트, ResNet 과 Visual Transformer 를 활용해 인코딩 된 이미지를 기반으로 대조 학습 (cosine similarity 기반 이미지, 텍스트 페어 매칭) 을 진행하는 구조.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_18.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI 팀은 이러한 간단한 구조를 활용해 학습되지 않은 경우에 대해서도 이미지와 텍스트 임베딩을 매칭할 수 있는 모델을 구축한다.&lt;/li&gt;
&lt;li&gt;새로운 데이터를 예측하는 방법은 크게 linear probe (로지스틱 회귀), zero-shot learning 으로 나뉘어지며, 주로 zero-shot learning 방법론이 더 나은 성능을 보임.&lt;/li&gt;
&lt;li&gt;모델의 주요한 점은 이미지와 텍스트가 직접 연계되는 것이 아니라, 임베딩 공간에서 매칭 된다는 점. 다른 포맷의 데이터를 페어링 할 때 유용하게 쓰이는 테크닉이다.&lt;/li&gt;
&lt;li&gt;예시적으로 image-to-text 과제의 경우, CLIP 모델을 활용해 추출된 이미지 임베딩을 기반으로 GPT 모델이 텍스트를 생성하는 방식.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_19.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이미지 생성 영역에서 가장 널리 알려진 모델은 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://cdn.openai.com/papers/dall-e-2.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DALL-E (unCLIP)&lt;/a&gt;&lt;/strong&gt; 이다.&lt;/li&gt;
&lt;li&gt;구조적으로 기존 CLIP 시스템 대비 (1) 텍스트 임베딩을 이미지 임베딩과 맵핑하는 Prior 영역 (2) 이미지 임베딩을 실제 이미지로 전환하는 Decoder 영역을 추가적으로 가지고 있다.&lt;/li&gt;
&lt;li&gt;Prior 영역은 수많은 텍스트 임베딩이 모두 한개의 이미지에 적합할 수 있다는 문제를 해결한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DALL-E 2 의 경우 이러한 Prior 구조로 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/diffusion-models-made-easy-8414298ce4da&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Diffusion Model&lt;/a&gt;&lt;/strong&gt; 을 차용. Diffusion Model 이란 Noisy 한 데이터에 단계적으로 학습함으로서 효과적인 Data Denoising 을 가능하게 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diffusion 시스템은 인코딩된 텍스트, CLIP 텍스트 임베딩, Diffusion Timestamp, Noised CLIP Embedding 에 순차적으로 Denoising 을 적용, 노이즈가 제거된 CLIP 이미지 예측을 가능하게 한다.&lt;/li&gt;
&lt;li&gt;이러한 방법을 통해 실제 텍스트와 모델, CLIP 이미지 임베딩 공간 간 간극을 좁히는 효과를 가짐.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_22.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decoder 는 Prior 의 아웃풋인 이미지 임베딩을 실제 이미지로 변환하는 역할을 수행한다. U-Net 구조를 차용해 인풋 이미지 임베딩에서 점차 노이즈를 제거하는 방식.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_23.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;결과적으로 CLIP 임베딩만을 활용해 이미지를 생성하거나, 복수의 CLIP 임베딩을 활용해 이미지를 합치는 것 또한 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_24.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;유사한 모델로는 Parti 와 StableDiffusion 이 있다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://parti.research.google/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Parti&lt;/a&gt;&lt;/strong&gt; : DALL-E 2 공개 이후 구글이 공개한 모델이며, Diffusion 모델이 아닌 VQGAN 구조를 활용, 이미지를 고차원의 토큰으로 변환하는 과정을 거친다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://stability.ai/blog/stable-diffusion-public-release&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;StableDiffusion&lt;/a&gt;&lt;/strong&gt; : 비교적 최근 &lt;a class=&#34;link&#34; href=&#34;https://github.com/CompVis/latent-diffusion&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공개&lt;/a&gt;된 모델이며, latent diffusion 모델을 활용해 이미지를 저차원의 latent 공간으로 치환 후, 이미지를 픽셀 공간에 재생성하는 구조를 가진다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7_25.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;image-to-image, video generation, photoshop plugin 등 다양한 분야에서 활용.&lt;/li&gt;
&lt;li&gt;이러한 모델을 구동하는 것은 꽤 많은 작업을 필요로 할 수 있으며, 툴셋이나 코드베이스로 바뀔 가능성 또한 있다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 5</title>
        <link>https://meme2515.github.io/mlops/fsdl_5/</link>
        <pubDate>Mon, 05 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_5/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_5_9.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 5" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=W3hKjXg7fXM&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-5-deployment/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1ABdEgVHvOIBtJhfmzy5ps_dMrwFKlgwd/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배포 과정은 좋은 모델 개발에 있어 필수적인 요소이다. &lt;strong&gt;오프라인으로 모든 평가를 진행하면 모델의 작은 실수들을 놓치기 쉽고, 사용자가 정말 필요로 하는 문제 해결 능력이 부재할 수 있기 때문.&lt;/strong&gt; 이러한 요소는 모델 배포를 통해서만 검증이 가능한 경우가 많다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다른 ML 개발 단계와 같이 &lt;strong&gt;최소한의 기능만을 구현한 후, 복잡한 부분들을 순차적으로 추가&lt;/strong&gt;하는 과정을 거치는 편이 좋다. 과정은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프로토타입 설계&lt;/li&gt;
&lt;li&gt;모델/UI 분리&lt;/li&gt;
&lt;li&gt;스케일 문제 해결&lt;/li&gt;
&lt;li&gt;속도 이슈 발생 시, 엣지 디바이스 활용 검토&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;build-a-prototype-to-interact-with&#34;&gt;Build A Prototype To Interact With&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;프로토타입 설계를 위한 툴로는 최근 HuggingFace 가 인수한 &lt;a class=&#34;link&#34; href=&#34;https://gradio.app/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradio&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://streamlit.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Streamlit&lt;/a&gt; 등이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 프로토타입 설계를 위해서는 다음과 같은 기본적인 규칙을 지키자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;심플한 UI&lt;/strong&gt; : 프로토타입의 주된 목적은 실사용 환경에서 모델을 테스트해보고, 타인의 피드백을 얻는 것이다. Gradio, Streamlit 과 같은 앱을 활용하면 많은 코드를 쓰지 않더라도 기본적인 인터페이스 구축이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Web URL 활용&lt;/strong&gt; : URL 은 공유하기 쉬우며, 이를 기준점으로 삼아 더욱 복잡한 배포 방식을 택하면서 발생할 장단점을 생각할 수 있다. Streamlit, HuggingFace 모두 클라우드 배포 기능을 제공.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;공수 최소화&lt;/strong&gt; : 강사진은 프로토타입 설계에 하루 이상을 소비하지 않을 것을 권장.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 프로토타입은 최종 솔루션의 형태가 아니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프론트엔드 구현에 있어 분명한 한계점이 존재한다. 완성된 형태의 서비스 제공을 위해서는 커스텀 UI 제작이 필요.&lt;/li&gt;
&lt;li&gt;스케일링 문제를 안고있다. 유저 수가 증가하게 된다면 스케일업을 위해 백엔드 구축이 필요.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;상단 장표는 일반적인 어플리케이션의 구조를 보여준다. Client 란 유저가 상호작용하는 기기, 즉 브라우저, 차량, 스마트폰 등이며, 이러한 기기는 네트워킹을 통해 서버와 소통한다. 서버는 데이터베이스와의 상호 작용을 통해 어플리케이션을 구동.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이러한 기본적인 어플리케이션 구조에 ML 모델을 배포하는 여러가지 방법이 존재한다. 언급된 프로토타입 접근법은 &lt;strong&gt;model-in-service&lt;/strong&gt; 방식에 해당하며, 웹서버가 패키징된 모델을 품고있는 경우이다 &lt;em&gt;(인스타 등 이미 성숙도가 올라간 서비스에 ML 기능을 추가하는 형태로 생각하면 됨)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 방식의 가장 큰 장점은 모델의 복잡성과 무관하게 기존의 인프라를 사용할 수 있다는 점이다. 하지만 이러한 방식에는 여러가지 단점 또한 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;웹서버가 다른 언어로 작성.&lt;/strong&gt; 파이썬 기반이 아니라면, 이미 구축된 모델을 서버에 통합하는 과정이 까다로울 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델이 서버 코드보다 자주 업데이트 될 수 있음.&lt;/strong&gt; 어플리케이션이 이미 성숙 단계에 접어들었으나 모델이 초기 단계에 있다면, 모델 업데이트 마다 재배포 과정을 겪어야 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;웹서버에 비해 모델의 크기가 지나치게 클 수 있음.&lt;/strong&gt; 이러한 경우 모델을 직접적으로 사용하지 않더라도 전반적인 어플리케이션 사용 경험에 부정적인 영향이 미칠 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;서버 하드웨어는 ML 작업에 최적화되지 않음.&lt;/strong&gt; 이러한 서버 장비에 GPU 가 내장되어 있는 경우는 굉장히 드물다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링 속성의 차이가 발생할 수 있음.&lt;/strong&gt; 따라서 모델과 기존 어플리케이션 간 스케일링 규칙의 차등을 두어야 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;separate-your-model-from-your-ui&#34;&gt;Separate Your Model From Your UI&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;모델을 UI 에서 완전히 분리하는 방법은 크게 &lt;strong&gt;(1) Batch Prediction&lt;/strong&gt;, &lt;strong&gt;(2) Model-as-Service&lt;/strong&gt; 방식으로 나뉜다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 이란 모든 데이터 포인트에 대한 예측치를 사전에 구한 후, 결과값을 데이터베이스에 저장하는 방식&lt;/strong&gt;이다. 경우에 따라 가장 적절한 방식일 수 있는데, 인풋값이 제한된 경우 주기적으로 예측치를 구하는 것만으로 충분히 최신 정보가 반영된 예측치를 사용자에게 전달할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 방식이 적절한 예시는 초기단계의 추천 시스템, 내부 활용을 위한 마케팅 자동화 시스템 등.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주기적으로 예측값을 구하기 위해서는 데이터 처리 자동화 파이프라인 활용이 필요하다. (1) 데이터 처리, (2) 모델 로딩, (3) 예측, (4) 예측값 저장 순의 작업이 필요한데, Dagster, Airflow 등의 DAG 시스템이 처리하기에 적절한 문제이다. 유사한 ML 전용 툴인 &lt;a class=&#34;link&#34; href=&#34;https://metaflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Metaflow&lt;/a&gt; 또한 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;구현이 간단하다.&lt;/strong&gt; 이미 학습에 배치 처리 툴을 활용하고 있다면 이러한 구조를 재사용 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링이 쉽다.&lt;/strong&gt; 데이터베이스는 기본적으로 스케일링에 최적화 되어있는 시스템이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;대형 시스템에서 수년간 검증된 구조.&lt;/strong&gt; 이미 많은 기업들이 이와 같은 예측 파이프라인을 활용해왔고, 예상하지 못한 문제가 발생할 확률이 상대적으로 적다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치 전달이 빠름.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;경우의 수가 많은 인풋을 처리할 수 없음.&lt;/strong&gt; 모든 경우의 수에 대한 모든 예측치를 구하는 것에는 분명한 한계가 존재한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치가 가장 최신의 정보를 반영하지 못함.&lt;/strong&gt; 이러한 정보가 매분, 매초 의미있는 변화를 가진다면, 유저가 보는 예측치는 이미 유의미한 정보를 제공하지 못할 확률이 높다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batch Job 실행 실패를 감지하기 어려움.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 란 모델을 별도의 온라인 서비스로서 운영하는 방식이다.&lt;/strong&gt; 모델은 백엔드, 또는 클라이언트에서 송출한 request 에 대해 response 를 보내는 방식으로 소통하게된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;신뢰성.&lt;/strong&gt; 모델에서 발생한 버그가 전체 웹 어플리케이션을 다운시킬 확률이 감소하게 된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링.&lt;/strong&gt; 목적에 최적화된 하드웨어를 선택하고, 알맞은 방식으로 스케일링을 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;유연성.&lt;/strong&gt; 여러 어플리케이션이 모델 인프라를 공유할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;레이턴시.&lt;/strong&gt; 별도의 서비스인 만큼, 서버/클라이턴트가 모델을 사용할 때 시간적 비용이 발생.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;복잡한 인프라.&lt;/strong&gt; 구축/운영에 대한 새로운 비용이 발생함.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 단점들은 감안하더라도 &lt;strong&gt;model-as-service 구조는 대부분의 ML 제품 배포에 적합한 방식이다&lt;/strong&gt;. 복잡한 어플리케이션의 구조에서 모델 서비스를 개별적으로 스케일링 할 수 있다는 점은 중요하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5주차 강의에선 이러한 모델 서비스를 구축하기 위한 부분들을 설명한다. 이는 &lt;strong&gt;(1) Rest API, (2) 디펜던시 관리, (3) 성능 최적화, (4) 수평 스케일링, (5) 롤아웃&lt;/strong&gt; 등의 개념을 포함한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Rest APIs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 제품의 &lt;strong&gt;Rest API&lt;/strong&gt; 란 약속된 형태의 HTTP 요청에 따라 예측값을 반환하는 형태를 칭한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인프라에 호스팅된 대안적인 프로토콜은 &lt;a class=&#34;link&#34; href=&#34;https://grpc.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gRPC&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://graphql.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GraphQL&lt;/a&gt; &lt;em&gt;(모델 서비스에 적합하지 않을 수 있음)&lt;/em&gt; 이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;아직 모델 서비스 분야에선 Rest API 문법이 통일되지 않은 상태.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google Cloud 는 key, value 페어를 가진 리스트를 인풋으로 정의&lt;/li&gt;
&lt;li&gt;Azure 는 모델 구조에 따라 변동하는 데이터 오브젝트를 다룸&lt;/li&gt;
&lt;li&gt;AWS Sagemaker 는 Google Cloud 와 유사한 형태의 인풋을 기대하지만, 세부적인 형태의 차이 존재.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dependency Management (디펜던시 관리)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;예측값은 코드, 모델 가중치, 그리고 디펜던시에 따라 결정된다.&lt;/strong&gt; 따라서 기대하는 예측값을 얻기 위해서는 웹서버에 개발 환경과 동일한 디펜던시가 세팅되어야 하지만, 이를 항상 보장하는 것은 어려운 작업이다 &lt;em&gt;(개발 환경에서 혹여나 패키지 업데이트가 이루어진다면 서버에서 동일한 업데이트를 매번 진행해야 함, 개발자가 많아지면 관리가 어려워진다)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 디펜던시를 관리하는 방법은 크게 두가지가 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;디펜던시에 무관하게 실행 가능한, &lt;strong&gt;표준화된 모델 개발&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컨테이너 활용&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 모델 표준화&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;모델 표준화는 ONNX (Open Neural Network Exchange) 라이브러리를 활용해 이루어진다. 라이브러리는 &lt;strong&gt;환경에 무관하게 실행 가능한 ML 모델&lt;/strong&gt;을 개발할 수 있도록 돕는데, 언어, 패키지 버전 등과 무관하게 동일한 기능을 제공하는 것을 목표로 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 실사용 환경에선 많은 라이브러리들이 지나치게 빠른 속도로 업데이트되기 때문에 변환 과정에서 버그가 자주 발생하고, 이를 해결하기 위해 오히려 ONNX 를 사용하지 않는 것 보다 더 많은 작업이 발생하는 경우가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;또 torchvision 과 같은 주변 라이브러리는 아예 지원이 안되는 경우가 많다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 컨테이너&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;컨테이너를 설명하기 전, 우선 도커와 가상머신의 개념을 구분해 정리할 필요가 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;가상머신 (VM)&lt;/strong&gt; : &lt;strong&gt;라이브러리, 어플리케이션은 물론 운영체계 (OS) 까지를 하나의 패키지로 묶는 방식&lt;/strong&gt;이다. 용량은 물론 실행에 필요한 자원 소모가 큰 편.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;도커&lt;/strong&gt; : &lt;strong&gt;OS 를 적은 용량/자원으로 가상화하여, 필요한 라이브러리와 어플리케이션 만을 구동&lt;/strong&gt;하는 방식.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇듯 실행이 가벼운 도커는 일반적으로 구분 가능한 작업 마다 개별적으로 생성된다. 예시로 웹앱은 (1) 웹서버, (2) 데이터베이스, (3) Job 관리, (4) Worker 총 4개의 컨테이너가 함께 동작하는 방식으로 운영.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Job 관리 (Job Queue)&lt;/strong&gt; : Airflow, Rundeck 등의 Job Scheduler 에서 유지하는, 앞으로 실행할 Job 에 대한 데이터 구조.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Worker&lt;/strong&gt; : 요청한 태스크를 수행하는 자원 &lt;em&gt;(예. 주문 내역을 파싱 및 데이터베이스로 이동)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;도커 컨테이너는 &lt;strong&gt;도커 파일&lt;/strong&gt;을 통해 생성된다. 각 컨테이너는 서로 다른 도커 파일을 통해 환경을 생성하며, 클라우드나 별도 서버에 저장된 도커 허브를 통해 컨테이너를 공유하는 것 또한 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;도커는 다음과 같은 3가지 요소로 구성되어 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;클라이언트&lt;/strong&gt; : 도커 이미지 구성. 로컬 환경에서 여러 커맨드를 통해 조작이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;도커 호스트&lt;/strong&gt; : 클라이언트에서 입력된 커맨드 실행 및 이미지/컨테이너 생성. 서버 혹은 로컬 환경 모두 구성이 가능함.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;레지스트리&lt;/strong&gt; : 여러 개의 컨테이너 저장. 도커 호스트와 직접 소통.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이와 같은 태스크 분리를 통해 노트북 등의 로컬 자원, 도커 호스트에 저장된 이미지에 등에 의해 도커 활용에 제약이 가해지지 않는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;공개된 여러 퍼블릭 도커 허브엔 다양한 이미지가 호스팅 되어 있으며, 프라이빗 이미지를 저장할 수 있는 기능 또한 제공하고 있다. 최근엔 그 인기가 급상승해 이렇나 도커 허브 활용을 기본 전제로 하는 경우가 잦은 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;도커는 입문 난이도가 다소 높은 편이다. &lt;a class=&#34;link&#34; href=&#34;https://github.com/replicate/cog&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cog&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/bentoml/BentoML&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BentoML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/trussworks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Truss&lt;/a&gt; 와 같은 서비스는 이러한 과정을 간소화 해주며 지정된 모델 호스트 활용, 모델 패키징 등 다양한 기능을 제공한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance Optimization (성능 최적화)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;예측 연산을 효율화하기 위해선 &lt;strong&gt;GPU, concurrency (여러 모델 활용), model distillation (모델 간소화), quantization (파라미터 용량 제한), caching (캐싱), batching (배치 관리), GPU sharing, 관련 라이브러리들&lt;/strong&gt;을 논할 필요가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. GPU&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;호스트 서버에 GPU 자원을 포함시키는 것에서 얻는 장점은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학습이 이루어진 것과 같은 환경에서 예측이 이루어진다면 &lt;strong&gt;환경 관련 이슈가 발생할 염려가 없다&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;많은 트래픽을 더욱 빨리 처리할 수 있다&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 &lt;strong&gt;GPU 자원은 세팅이 보다 어렵고, 트래픽에 의한 비용폭이 크기 때문에 CPU 만을 활용한 초기 모델 서비스 또한 고려해봄직 하다&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하기 테크닉을 통해 보다 적은 비용으로 CPU 자원에서 연산 속도를 개선하는 것 또한 가능함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Concurrency&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;여러개의 CPU, 또는 CPU 코어에서 복수의 모델을 실행하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Thread Tuning&lt;/strong&gt; 과정이 필요하며, 이와 같은 테크닉을 통해 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Nw77sEAn_Js&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;로블록스&lt;/a&gt;는 일일 10억 리퀘스트에 대한 BERT 서비스를 CPU 자원만으로 해결.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. Model Distillation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;학습된 모델의 행동을 모방하는 작은 규모의 모델을 생성하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://heartbeat.comet.ml/research-guide-model-distillation-techniques-for-deep-learning-4a100801c0eb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 글&lt;/a&gt; 에서 관련된 테크닉을 소개하고 있으며, 직접 구현시 성능이 다소 떨어질 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;서비스 환경에서 자주 활용되지는 않지만, &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/transformers/model_doc/distilbert&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistilBERT&lt;/a&gt; 와 같은 예외 경우 또한 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4. Quantization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;모델 전체, 또는 일부분을 보다 작은 용량의 number representation 을 활용해 실행하는 방식이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대게 활용되는 representation 으로는 16-bit floating point, 8-bit integer 가 있으며, 모델 정확도에 부정적인 영향을 끼치게 된다. 속도 개선이 정확도 보다 중요하다고 판단되면 고려할 수 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PyTorch, Tensorflow 등의 패키지는 자체 quantization 라이브러리를 포함하고 있으며, Huggingface 의 사전학습 모델 활용 시 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/optimum/index&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huggingface Optimum&lt;/a&gt; 또한 활용이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습 시 quantization 과정을 감안한 &lt;strong&gt;quantization-aware training&lt;/strong&gt; 이라는 테크닉이 존재하고, 적은 용량으로 representation 변경 시 보다 개선된 정확도를 보인다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5. Caching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;자주 처리되는 인풋을 캐시에 미리 저장해둠으로 처리 속도를 개선시키는 방식. 자원 활용이 큰 연산을 수행하기 전에 인풋이 캐시에 존재하는지 먼저 확인한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;캐싱에는 다양한 방식이 존재하지만, &lt;a class=&#34;link&#34; href=&#34;https://docs.python.org/3/library/functools.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python functools 라이브러리&lt;/a&gt;를 활용하는 것을 추천.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. Batching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배치 처리 시 연산 속도가 개선된다는 점을 활용해 (특히 GPU 활용 시) 일정 수만큼의 인풋을 저장 후 처리하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인풋을 모으는 기간 동안 유저가 레이턴시를 경험할 수 있기 때문에 배치 사이즈 조절이 필요하다. 레이턴시가 너무 길어진다면 이를 별도로 처리해야하며, 구현이 복잡하기 때문에 라이브러리 등을 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;7. GPU Sharing&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;단일 GPU 에 여러개의 모델을 구동시키는 것 또한 가능하다. GPU sharing 기능을 지원하는 패키지 활용.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;8. 라이브러리&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyTorch, Tensorflow, NVIDIA, Ray Serve 등의 옵션이 있다. NVIDIA 쪽이 가장 좋은 성능을 보여주지만 입문장벽이 있는 편이고, &lt;a class=&#34;link&#34; href=&#34;https://docs.ray.io/en/latest/serve/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ray Serve&lt;/a&gt; 의 경우 비교적 난이도가 쉬운 편.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Horizontal Scaling (수평 스케일링)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;트래픽이 증가할 수록 단일 서버보다는 여러대의 서버에서 복제된 모델을 운영할 필요가 생긴다. 이를 &lt;strong&gt;수평 스케일링&lt;/strong&gt;이라 부르며, 한대의 서버에서 처리했을 트래픽을 여러개의 서버로 분산하는 작업을 필요로한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;각 서버엔 서비스되는 모델의 복제본이 저장 되어있으며, &lt;a class=&#34;link&#34; href=&#34;https://www.nginx.com/resources/glossary/nginx/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;nginx&lt;/a&gt; 와 같은 load balancer 라는 툴을 이용해 분산된 트래픽을 처리한다. 모델 서비스의 경우 이를 구현하는 방식으로는 크게 &lt;strong&gt;container orchestration 와 serverless&lt;/strong&gt; 가 존재한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. Container Orchestration&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes&lt;/a&gt; 를 활용해 다수의 도커 컨테이너를 여러대의 서버에서 분산처리 할 수 있도록 돕는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단순히 모델 배포가 목적이라면 굳이 Kubernetes 를 활용할 필요는 없다. &lt;a class=&#34;link&#34; href=&#34;https://www.kubeflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubeflow&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.seldon.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Seldon&lt;/a&gt; 등 관련 작업을 간소화 하는 옵션이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Serverless&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;어플리케이션을 구성하는 코드와 환경을 zip 파일, 또는 도커 컨테이너로 압축한 후 하나의 함수 (model.predict() 등) 를 통해 예측치를 연산하도록 구성.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이와 같이 패키징 된 모델은 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/lambda/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Lambda&lt;/a&gt; 와 같은 서비스를 통해 배포되며, 인프라와 관련된 모든 작업은 클라우드에서 자동적으로 처리된다 &lt;em&gt;(증가한 트래픽에 따른 스케일링 등)&lt;/em&gt;. 유저 입장에서는 제때 비용만 정산하면 됨.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;구체적인 이유로 Kubernetes 를 활용하는 것이 아니라면, Serverless 로 배포를 시작하는 편이 좋다. 단점은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;배포 패키지의 사이즈 제한이 존재한다.&lt;/strong&gt; 용량이 큰 모델은 이와 같은 방식으로 배포가 어려운 편.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;트래픽 미발생으로 서버가 닫혀있는 상태에서 다시 예측치를 내기 까지의 시간 소요가 길다.&lt;/strong&gt; 이를 cold start 문제라 부르며, 초단위에서 분단위 까지의 시간을 필요로 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;파이프라인 등 복잡한 소프트웨어 기능 구현이 어렵다.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;서버 상태 모니터링과 별도 배포 툴 적용이 어렵다.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Serverless 환경은 대체로 GPU 를 포함하지 않으며, 실행 시간에 제한을 둔다.&lt;/strong&gt; 보다 작은 규모의 &lt;a class=&#34;link&#34; href=&#34;https://www.banana.dev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Banana&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.pipeline.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Piepeline&lt;/a&gt; 과 같은 스타트업들은 GPU 를 활용한 서버리스를 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model Rollouts (롤아웃)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이미 배포된 상태의 모델을 업데이트하고, 관리하는 과정을 의미한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;새로운 모델을 효율적으로 배포 하기 위해서는 다음과 같은 배포 방식이 모두 가능해야 한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;점진적 배포&lt;/strong&gt; : 기존 배포 버전에서 새로운 배포 버전으로 트래픽 양을 점진적으로 증가.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;즉각적 배포&lt;/strong&gt; : 문제가 발생한 배포 버전에서 새로운 배포 버전으로 즉각적인 변경.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;배포 버전 관리&lt;/strong&gt; : 두 개의 배포 버전을 두고 트래픽 배분.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;파이프라인 배포&lt;/strong&gt; : 개발된 파이프라인 플로우를 모델과 함께 배포.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 기능들은 직접 구현이 어려우며, 일반적으로 managed service 를 통해 모델 배포에 적용하게 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Managed Options&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_18.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;클라우드 3사 모두 배포 과정을 간소화하는 managed service option 기능을 제공하며, BentoML, Banana 등의 스타트업 또한 관련 기능을 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;가장 인지도 있는 서비스는 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/sagemaker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Sagemaker&lt;/a&gt; 이다. Huggingface class, SciKit-Learn model 등 일반적인 형태의 모델의 경우 적용이 쉬운 편이다. 하지만 일반적인 EC2 인스턴스에 비해 50~100% 가량 비용이 비쌈.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;move-to-the-edge&#34;&gt;Move To The Edge?&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_19.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;웹에서 벗어나 클라이언트 기기 (엣지 디바이스) 내에서 모델 예측을 구현하는 방식 또한 고려해 볼 수 있다. 인터넷 액세스가 불안정한 환경이거나, 민감한 개인정보를 다룰 경우 엣지 디바이스 활용은 필수적.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;엣지 디바이스 활용을 필수적으로 요구하는 환경이 아니라면, 모델의 정확도와 레이턴시 간 유저 경험에 더 중요한 요소를 선택해야한다. &lt;strong&gt;레이턴시를 줄일 수 있는 모든 옵션이 이미 적용되었다면, 엣지 디바이스 활용을 고려할 것&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;엣지 디바이스 inference 는 구현이 복잡하기 때문에 반드시 필요한 경우에만 적용해야 한다. 서버에서 학습된 모델 가중치를 엣지 기기에 불러온 후, 이후 모든 예측 과정을 엣지 기기에서 수행하는 방식으로 진행.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대표적인 장점은 레이턴시 감소이다. 네트워크를 사용할 필요가 없으며, 트래픽에 의한 비용이 발생하지 않는다. 이에 반한 단점은 하드웨어와 소프트웨어의 제약이다. 모델 업데이트 또한 과정이 보다 복잡해지는 문제가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Frameworks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;엣지 배포에 필요한 적절한 프레임워크는 학습 과정과 엣지 기기에 따라 달라질 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developer.nvidia.com/tensorrt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorRT&lt;/a&gt;&lt;/strong&gt; : 엣지 기기가 NVIDIA 하드웨어라면 가장 적절&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developers.google.com/ml-kit&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLKit&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developer.apple.com/documentation/coreml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CoreML&lt;/a&gt;&lt;/strong&gt; : Android, 혹은 iPhone 을 대상으로 한다면 공식 프레임워크 검토&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/mobile/home/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Mobile&lt;/a&gt;&lt;/strong&gt; : iOS 와 Android 환경을 모두 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/lite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TFLite&lt;/a&gt;&lt;/strong&gt; : 핸드폰과 같은 일반적인 기기가 아닌 경우 또한 TF 사용 환경을 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/js&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorFlow JS&lt;/a&gt;&lt;/strong&gt; : 브라우저 배포 전용 프레임워크&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://tvm.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache TVM&lt;/a&gt;&lt;/strong&gt; : 라이브러리, 타깃 기기와 무관하게 활용 가능. 가능한 많은 환경을 지원하고자 한다면 적절함&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외에도 &lt;a class=&#34;link&#34; href=&#34;https://mlir.llvm.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLIR&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://octoml.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OctoML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.tinyml.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TinyML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.modular.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Modular&lt;/a&gt; 과 같은 제품군이 존재함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;엣지 기기의 하드웨어 제약을 뛰어넘는 용량을 가진 모델의 경우, 프레임워크와 무관하게 배포는 불가능하다고 보아야한다. 때문에 가능한 적은 용량과 연산 자원을 사용하면서 최대의 성능을 이끌어내는 모델 구조가 중요.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Quantization, Distillation 등의 기법 또한 활용 가능하나, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MobileNets&lt;/a&gt;&lt;/strong&gt; 와 같이 엣지 기기를 사전에 염두한 모델 구조 또한 존재한다. 모델 성능이 감소하나 많은 경우 실사용에 지장이 없다. 이와 결이 유사한 모델로는 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/huggingface/distilbert-8cf3380435b5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistilBERT&lt;/a&gt;&lt;/strong&gt; 가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mindsets&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;엣지 배포를 검토할 시 다음과 같은 사항을 고려하는 편이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;모델 구조가 아닌 엣지 기기의 환경에 집중할 것.&lt;/strong&gt; 성능이 좋은 모델 구조를 학습 후, 엣지 기기에서 구동이 어렵다면 모델링 과정을 처음부터 다시 시작해야 할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;실행 가능한 모델이 구현되었다면, 계속적으로 엣지 기기를 활용할 것이 아니라 로컬 환경에서 모델을 고도화 할 것.&lt;/strong&gt; 이 경우 모델 용량 등을 Experiment Tracking Metric 으로 추가하는 것이 좋다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;모델 튜닝 과정을 추가적인 리스크로 다룰 것.&lt;/strong&gt; 관련 프레임워크는 아직 성숙하지 못했기 때문에, 작은 하이퍼파라미터 변동으로도 모델이 작동하지 않을 리스크가 존재한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;버저닝을 통한 회귀점을 구비할 것.&lt;/strong&gt; 엣지 배포의 경우 특히 모델을 작동하던 마지막 상태로 복구할 수 있는 시스템이 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 4</title>
        <link>https://meme2515.github.io/mlops/fsdl_4/</link>
        <pubDate>Sun, 04 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_4/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_4_3.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 4" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=Jlm4oqW41vY&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-4-data-management/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/17Ak9mxNBIAv_FHUZsneqSWSud9Dh7F3i/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 분야가 발전되기 시작한 초기 단계에 업계가 잘 이해하지 못했던 부분은 데이터와의 접점이다. 데이터셋을 만들고, 분석하고, 전처리하는 등의 과정은 ML 프로젝트 전반에 걸쳐 필수적이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4주차 강의의 핵심 내용은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;초도 분석에 원하는 것보다 10배 많은 시간을 할애해야 한다.&lt;/li&gt;
&lt;li&gt;데이터를 고치고, 추가하고, 증강하는 것이 대체로 성능 향상에 가장 크게 기여한다.&lt;/li&gt;
&lt;li&gt;데이터를 다루는 과정을 가능한 간단하게 유지할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-sources&#34;&gt;Data Sources&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;이미지, 텍스트, 로그, 데이터베이스&lt;/strong&gt; 등 데이터 원천의 종류는 다양하다. 딥러닝을 위해서는 GPU 자원이 있는 로컬 파일 시스템에 데이터를 옮겨와야하며, 이렇게 학습 데이터를 옮기는 방식은 다루는 데이터 마다 차이가 생긴다.
&lt;ul&gt;
&lt;li&gt;이미지의 경우 S3 등의 &lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;에서 직접 다운로드 받을 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 분산 처리를 통해 데이터를 분석하고, 일부분을 발췌해 로컬 환경으로 옮겨주는 등의 과정이 필요하다 &lt;em&gt;(원문 전달 내용이 조금 불확실함)&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;로그와 데이터베이스의 경우 &lt;strong&gt;데이터 레이크&lt;/strong&gt;를 활용해 데이터를 모으고, 처리할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;파일시스템&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;파일시스템이란 &lt;strong&gt;“파일” 이라는 기초 단위에 기반한 추상화 개념&lt;/strong&gt;이다. 파일이란 흔히 생각하듯 텍스트, 바이너리 등 다양한 형태를 취할 수 있으며, 버전의 개념을 가지지 않는다.&lt;/li&gt;
&lt;li&gt;파일시스템은 보통 사용하는 기기에 연결된 디스크에 저장되며, 연결의 개념은 물리적일 수도, 온프레미스, 클라우드, 혹은 분산시스템에 기반한 원격 연결을 의미할 수도 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;디스크 성능을 평가하는데 가장 중요한 요소는 속도와 대역폭&lt;/strong&gt;이다. 저장장치 포맷은 주로 HDD 와 SSD 로 나뉘어지며, 동일한 SSD 이더라도 SATA 와 NVMe 연결방식 간 약 100배의 속도차이가 발생한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;오브젝트 스토리지란 &lt;strong&gt;파일시스템 활용을 위한 API&lt;/strong&gt; 를 뜻하며, 가장 기본이 되는 단위는 이미지, 오디오, 텍스트 등의 바이너리 형태 “오브젝트” 이다.&lt;/li&gt;
&lt;li&gt;버저닝, 중복 저장 개념이 존재하며, 로컬 파일시스템에 비해서는 속도가 느리지만 클라우드 활용을 위해서는 충분.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터베이스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;지속적이고, 빠르고, 스케일링이 가능한 정형데이터 저장소이다.&lt;/li&gt;
&lt;li&gt;이미지와 같은 바이너리 데이터를 저장하기 보다는 오브젝트 스토리지에 상응하는 URL 을 저장.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.postgresql.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Postgres&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.sqlite.org/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SQLite&lt;/a&gt; 등의 오픈소스가 널리 활용된다.&lt;/li&gt;
&lt;li&gt;프로젝트가 상호 reference 를 같는 객체를 다룬다면 데이터베이스의 도입이 불가피하기 때문에 처음부터 사용하는 편이 개발 시간을 단축시킬 가능성이 높다.&lt;/li&gt;
&lt;li&gt;W&amp;amp;B, HuggingFace Hub, Label Studio 등의 MLOps 툴을 사실 이러한 데이터베이스의 역할을 수행.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 웨어하우스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스가 &lt;strong&gt;온라인 트랜잭션 처리 (OLTP)&lt;/strong&gt; 를 위해 설계되었다면, 데이터 웨어하우스를 &lt;strong&gt;온라인 분석 처리 (OLAP)&lt;/strong&gt; 을 위해 설계된 데이터 처장 체계이다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OLTP&lt;/strong&gt; : &lt;em&gt;네트워크 상의 여러 이용자가 실시간으로 DB 의 데이터를 갱신하거나 조회하는 등의 단위작업 처리 방식. Row-oriented, 즉 개별적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OLAP&lt;/strong&gt; : &lt;em&gt;데이터를 분석하고 유의미한 정보로 치환하거나, 복잡한 모델링을 가능하게끔 하는 분석 방법. Column-oriented, 즉 통계적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;데이터 웨어하우스로 여러 데이터를 끌어오는 작업을 &lt;strong&gt;ETL (Extract-Transform-Load)&lt;/strong&gt; 이라 칭하며, 비즈니스 관점의 의사결정을 위한 정보를 웨어하우스에서 끌어오게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 레이크&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 웨어하우스와 유사하나, 데이터를 사전에 가공하는 ETL 방식과 달리 일단 데이터를 모으고, 사용시 가공하는 &lt;strong&gt;ELT (Extract-Load-Transform)&lt;/strong&gt; 방식을 사용한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;최근 트렌드는 데이터 웨어하우스와 데이터 레이크를 통합하는 솔루션들이다. 정형 데이터와 비정형 데이터가 같은 저장소에서 다뤄질 수 있으며, &lt;a class=&#34;link&#34; href=&#34;https://www.snowflake.com/?lang=ko&amp;amp;utm_source=google&amp;amp;utm_medium=paidsearch&amp;amp;utm_campaign=ap-kr-ko-brand-core-exact&amp;amp;utm_content=go-eta-evg-ss-free-trial&amp;amp;utm_term=c-g-snowflake-e&amp;amp;_bt=579103397662&amp;amp;_bk=snowflake&amp;amp;_bm=e&amp;amp;_bn=g&amp;amp;_bg=128328467463&amp;amp;gclsrc=aw.ds&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUubkoz7BoatiURcPHbxVDF3FAWwLuPcV1hSkAOItZfeqaTMTbDpzxQaAnZXEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snowflake&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://www.databricks.com/p/ebook/the-data-lakehouse-platform-for-dummies?utm_medium=paid&amp;#43;search&amp;amp;utm_source=google&amp;amp;utm_campaign=15849074529&amp;amp;utm_adgroup=130486333845&amp;amp;utm_content=ebook&amp;amp;utm_offer=the-data-lakehouse-platform-for-dummies&amp;amp;utm_ad=587394793834&amp;amp;utm_term=databricks&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUsOVwmdjpvZBvMSSWc1Z-5P83Uc0Y8k7hBQYQjbHZIEF_5Vb0p_3fMaArshEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Databricks&lt;/a&gt; 등의 업체가 분야를 선도하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;분야에 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://dataintensive.net/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Designing Data-Intensive Applications&lt;/a&gt; 라는 책을 추천.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 탐색은 주로 &lt;strong&gt;SQL&lt;/strong&gt; 과 &lt;strong&gt;DataFrame&lt;/strong&gt; 을 활용해 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt; 은 정형 데이터를 다루는 기본적인 인터페이스이며, 수십년간 사용되고 발전되어왔다. RDBMS 등의 트랜잭션 기반 데이터베이스에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pandas&lt;/strong&gt; 는 Python 생태계에서 사용되는 주된 DataFrame 이며 SQL 과 유사한 작업을 수행할 수 있다. OLAP 등의 분석 기반 환경에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://examples.dask.org/dataframe.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DASK DataFrame&lt;/a&gt; 은 Pandas 작업을 여러개의 CPU 코어에서 분산 처리 할 수 있도록 돕는다. &lt;a class=&#34;link&#34; href=&#34;https://rapids.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RAPIDS&lt;/a&gt; 는 동일한 분산 처리 작업을 GPU 에서 수행.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-processing&#34;&gt;Data Processing&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리는 예시와 함께 설명하는 편이 좋다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SNS 플랫폼에 업로드되는 사진을 기반으로, 사진의 인기도를 예측하는 모델을 매일 학습하는 상황이라고 가정하자. 모델러는 다음과 같은 데이터를 활용하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스 내 메타데이터 (업로드 시간, 제목, 장소 등)&lt;/li&gt;
&lt;li&gt;로그 데이터 기반 유저 정보 (로그인 횟수 등)&lt;/li&gt;
&lt;li&gt;별도 분류 모델 기반 사진 정보 (컨텐츠, 스타일 등)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 최종적인 모델 학습이 진행되기 전, 데이터베이스 쿼리 작업, 로그 처리 작업, 모델 예측 작업 등 많은 데이터 처리 작업이 수행되어야 하며, 이러한 &lt;strong&gt;사전 작업을 정해진 순서대로 처리&lt;/strong&gt;해야 할 필요가 생긴다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow&lt;/a&gt; 는 언급된 기능을 수행하는 Python 생태계의 기본 스케줄러 툴이다. &lt;strong&gt;DAG (Directed Acyclic Graph)&lt;/strong&gt; 라는 개념을 활용해 순차적인 작업 설정이 가능하며, 이러한 작업이란 SQL 쿼리, Python 함수 등 다양한 종류가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.prefect.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Prefect&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://dagster.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dagster&lt;/a&gt; 또한 유사한 기능을 수행하는 경쟁 제품이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;feature-store&#34;&gt;Feature Store&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리 과정이 모델 학습과 병렬로 진행될 떄, 모델은 이후 학습에서 어떤 데이터가 신규로 생성되었는지, 어떤 데이터가 이미 학습에 활용되었는지 등을 파악할 필요가 발생할 수 있다 (필수적인 요소는 아님).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 경우 &lt;strong&gt;Feature Store&lt;/strong&gt; 기능을 활용한 데이터 관리가 필요해지게 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feature Store 라는 개념은 Uber 의 ML 플랫폼 &lt;strong&gt;Michalengelo&lt;/strong&gt; 를 소개하는 &lt;a class=&#34;link&#34; href=&#34;https://www.uber.com/en-KR/blog/michelangelo-machine-learning-platform/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 글&lt;/a&gt;에서 처음 등장했다. Uber 의 시스템 특성상 학습은 오프라인, 예측은 온라인으로 진행되기에 두 과정의 싱크를 맞춰줄 필요가 생겼고, 이를 해결하기 위한 수단으로 Feature Store 개념을 사용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;tecton.ai&#34; &gt;Tecton&lt;/a&gt; 은 해당 분야에서 가장 널리 사용되는 SaaS 솔루션이며, 이외에도 &lt;a class=&#34;link&#34; href=&#34;https://feast.dev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Feast&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.featureform.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Featureform&lt;/a&gt; 등의 옵션이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/datasets/index&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HuggingFace Datasets&lt;/a&gt; 는 ML 학습에 특화된 8000+ 데이터셋을 제공하며, 비전, NLP 등 분야가 다양한 편이다. 호스트된 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/datasets/codeparrot/github-code&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github-Code&lt;/a&gt; 데이터를 예시로 들자면 데이터 핸들링을 돕기 위해 Aparche Parquet 형태로 스트림 할 수 있기 떄문에 1TB+ 용량의 전체 데이터를 다운로드 할 필요가 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;또다른 훌륭한 데이터셋의 예시로는 RedCaps 를 들 수 있다. Reddit 에서 수집된 12M 의 이미지-텍스트 페어를 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HuggingFace Datasets 와 유사한 서비스로는 &lt;a class=&#34;link&#34; href=&#34;https://www.activeloop.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Activeloop&lt;/a&gt; 이 있는데, 데이터 다운로드 없이 분석과 기타 데이터 활용이 가능하도록 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-labeling&#34;&gt;Data Labeling&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 레이블링 작업을 시작하기 전, 정말 레이블링이 필요한지를 스스로에게 물어볼 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;자기지도학습 (self-supervised learning)&lt;/strong&gt; 이란 직접적인 레이블링 작업 없이 데이터의 일부분을 레이블로 활용하는 학습 방식을 뜻하며, NLP 과제에서 중요한 요소로 자리매김하고 있다. 마스킹 등의 기법을 통해 데이터의 한 부분을 예측하는 과제이며, &lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/clip/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenAI CLIP&lt;/a&gt; 과 같이 cross-modality 과제에서 (이미지-텍스트 등) 또한 활용이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;이미지 데이터 증강&lt;/strong&gt;은 비전 모델에서 사실상 필수적인 요소이다. &lt;a class=&#34;link&#34; href=&#34;https://github.com/pytorch/vision&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;torchvision&lt;/a&gt; 과 같은 라이브러리를 활용하여 간단하게 구현할 수 있으며, &lt;strong&gt;이미지의 &amp;ldquo;의미&amp;quot;를 변질시키지 않는 선에서 데이터에 변형을 주는 것&lt;/strong&gt;을 목표로 삼는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외 데이터 형태에 대한 증강 방식은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;정형 데이터의 경우 랜덤하게 선택된 셀 정보를 삭제함으로 미입수 데이터를 모방할 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 증강 기법이 상대적으로 부족한 편. 단어의 순서를 변경하거나, 부분적으로 삭제하는 방식이 존재한다.&lt;/li&gt;
&lt;li&gt;오디오 데이터는 속도를 조절하거나, 빈 오디오를 중간에 삽입하는 방식 등이 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Synthetic Data (합성 데이터)&lt;/strong&gt; 또한 고려해볼 필요가 있다. 레이블에 대한 사전 지식을 통해 기존에 존재하지 않는 데이터를 생성할 수 있으며, 적용 예시로는 영수증, 손글씨 이미지 등이 있다. 많은 공수가 필요하기 때문에 다른 방법은 없는지 충분히 검토 후 도입.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;보다 창의성을 발휘해 유저에게 레이블링 작업을 맞기는 것 또한 가능하다. 위 이미지와 같이 Google Photos 는 유저에게 이미지 레이블링 작업을 요구.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;유저의 직접적인 레이블링은 언급된 data flywheel 개념의 적용 예시이다. 유저는 모델 성능 향상에 기여하고, 이로 인해 유저의 제품 경험 또한 개선된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇듯 데이터 레이블링을 우회하는 다양한 방법이 존재하지만, 결국 &lt;strong&gt;모델링 작업을 시작하기 위해서는 어느정도의 레이블링 작업은 불가피&lt;/strong&gt;하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링이란 bounding box 와 같이 &lt;strong&gt;표준적인 형태의 주석을 기록하는 작업&lt;/strong&gt;이다. 주석의 형태보다는 레이블러가 올바른 교육을 받는 것이 가장 중요하며, &lt;strong&gt;이들이 레이블링 표준을 준수하도록 하는 것은 어렵지만 가장 핵심적인 요소&lt;/strong&gt;이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블러 고용 시 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 레이블링을 전문적으로 수행하는 업체.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;레이블러의 &lt;strong&gt;직접적인 고용&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.mturk.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Mechanical Turk&lt;/a&gt; 와 같은 &lt;strong&gt;크라우드 소싱&lt;/strong&gt;. 레이블링 품질을 위해 가능한 피하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링 전문 업체들은 소프트웨어 개발, 인력 관리, 품질 관리 까지의 다양한 작업을 수행한다. 업체 활용이 필요하다면 데잍러를 충분히 이해한 후, 샘플 레이블 등을 통해 여러 경쟁 업체를 비교한 후 의사결정을 내리는 편이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://scale.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Scale AI&lt;/a&gt; 는 업계에서 가장 규모가 큰 데이터 레이블링 솔루션이다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://labelbox.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Labelbox&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://supervise.ly/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Supervisely&lt;/a&gt; 가 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://labelstud.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LabelStudio&lt;/a&gt; 는 가장 널리 알려진 오픈소스 솔루션이며, 직접 레이블링을 수행할 때 활용하게 된다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://diffgram.com/main/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Diffgram&lt;/a&gt; 이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://snorkel.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snorkel&lt;/a&gt; 은 weak supervision 기반 레이블링 툴이며, &amp;ldquo;amazing&amp;rdquo; 이라는 단어가 들어간 모든 문장을 &amp;ldquo;긍정&amp;rdquo; 카테고리로 구분하는 등의 빠른 레이블링 작업을 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-versioning&#34;&gt;Data Versioning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 버전 관리는 단계적으로 구분이 가능하다.
&lt;ul&gt;
&lt;li&gt;Level 0 : &lt;strong&gt;단순한 파일시스템 관리로, 버전 관리가 이루어 지지 않는다.&lt;/strong&gt; 모델이란 코드와 데이터가 합쳐져 만들어진 결과물이기 때문에, 데이터가 바뀌면 동일한 모델을 구현하지 못하게 된다.&lt;/li&gt;
&lt;li&gt;Level 1 : &lt;strong&gt;학습시 데이터에 대한 스냅샷을 저장&lt;/strong&gt;하는 방식. 모델에 활용된 데이터가 특정 가능하지만, 이상적인 방식이라고 보기엔 어렵다.&lt;/li&gt;
&lt;li&gt;Level 2 : &lt;strong&gt;코드 버전 관리와 같은 개념을 도입&lt;/strong&gt;. &lt;a class=&#34;link&#34; href=&#34;https://git-lfs.github.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Git-LFS&lt;/a&gt; 와 같은 툴을 사용하게되며, 적극적으로 권장되는 방식이다.&lt;/li&gt;
&lt;li&gt;Level 3 : 대용량 데이터 관리를 위한 &lt;strong&gt;특별한 솔루션&lt;/strong&gt;을 도입. 합리적인 이유 (데이터 용량이 지나치게 크거나, 데이터에 많은 규제가 붙는 경우 등) 가 없다면 불필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 작업을 위한 툴로는 &lt;a class=&#34;link&#34; href=&#34;https://dvc.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DVC&lt;/a&gt; 가 있다. 데이터를 원격 저장소에 저장하고, 필요시 이전 버전으로 회귀하는 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 3</title>
        <link>https://meme2515.github.io/mlops/fsdl_3/</link>
        <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_3/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_3_title.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 3" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=RLemHNAO5Lw&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/13UAHw1A7hM-O0jYGdGStN5gFCUb5XzLv/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-software&#34;&gt;Testing Software&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;테스트란 제품의 버그 발생 빈도를 줄여 더 빠른 배포가 가능하도록 도움을 주지만, 모든 버그를 차단할 수는 없다. 즉, 중요하다고 판단되는 부분에 대해서만 테스트를 작성할 것.&lt;/li&gt;
&lt;li&gt;린팅 (linting) 툴 적용은 권장되지만, 모든 스타일 가이드를 맹목적으로 지킬 필요는 없다.&lt;/li&gt;
&lt;li&gt;테스팅, 린팅 워크플로의 자동화 툴 또한 본 강의에서 소개.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;1.1 - Tests Help Us Ship Faster. They Don&amp;rsquo;t Catch All Bugs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;테스트란 작성한 코드가 실패할 시 이를 탐지하기 위해 작성된 또 다른 코드이다.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;테스트가 존재하더라도 모든 버그를 탐지할순 없다. 특히 파이썬과 같은 하이레벨 코드에선 테스트란 단순히 보조적인 역할을 수행하게 된다.&lt;/li&gt;
&lt;li&gt;또 다른 관점은 테스트를 일종의 분류기로 생각하는 것. 작성된 코드가 버그를 포함하는지 예측하는 모델을 구축한다고 볼 수도 있다.&lt;/li&gt;
&lt;li&gt;분류 문제와 유사하게 테스트란 True Positive / False Positive 간 밸런스를 잡아줄 필요가 있다. 지나치게 많은 False Positive 를 방지하기 위해선 다음과 같은 질문을 해볼 필요가 있다.
&lt;ul&gt;
&lt;li&gt;작성된 test 가 탐지하는 실제 버그는 무엇인가?&lt;/li&gt;
&lt;li&gt;버그가 존재하지 않는 경우 test 가 실패하는 경우는 무엇인가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;위와 같은 질문을 했을때 1번 질문 보다 2번 질문에 대한 답이 더 많다면 테스트 적용을 다시 한번 고민해 보는 것이 필요하다.&lt;/li&gt;
&lt;li&gt;모델의 정확도가 특별히 중요한 경우 또한 고려해야 한다. 의료진단, 자율주행, 금융과 같은 경우를 예시로 들 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.2 - Use Testing Tools, But Don&amp;rsquo;t Chase Coverage&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;파이썬 코드 테스팅을 위한 기본 툴은 Pytest 이다. Test Suite 구분, 테스트간 자원 공유, 파라미터 기반 테스팅 등의 기능을 지원.&lt;/li&gt;
&lt;li&gt;단순 텍스트 기반 테스트는 자동화가 어렵기 때문에 유지가 어려운 측면이 있다. 하지만 파이썬의 경우 doctest 모듈을 지원하기 때문에 documentation 내 테스팅이 가능.&lt;/li&gt;
&lt;li&gt;노트북 활용 시, assert 기능과 nbformat 을 활용해 테스팅이 가능하지만, 구현이 지저분한 편.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;코드베이스 규모가 커질수록 테스팅된 코드와 그렇지 않은 코드를 관리하는 일이 복잡해진다. Codecov 란 이러한 코드 테스팅 현황을 시각화해주는 툴.&lt;/li&gt;
&lt;li&gt;Codecov 는 또한 코드의 일정 비율 이상이 테스팅 되지 않으면 commit 을 reject 하는 등의 개발 편의를 위한 기능들을 제공한다.&lt;/li&gt;
&lt;li&gt;이와 같은 커버리지 타겟팅은 사실 강사진은 추천하지 않는 방식이며, 경험/인터뷰/연구에 의하면 의미있는 테스트는 전체 테스트의 아주 작은 부분에 불과하다.&lt;/li&gt;
&lt;li&gt;엔지니어링 관점에서 가장 효과적인 전략은 의미있는 적은 수의 테스트를 아주 높은 수준으로 구현하는 것. 커버리지 타겟팅을 설정하면 질낮은 테스트를 많이 작성해 커버리지 비율에 집중하게 될 위험성이 높다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.3 - Use Linting Tools, But Leave Escape Valves&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Clean code is of uniform and standard style&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;통일된 스타일은 pull request 와 코드 리뷰 단계에서 불필요한 논쟁을 줄일 수 있다. 또한 스타일과 관련된 diff 수를 줄여 버전 컨트롤 시스템 활용도를 높인다.&lt;/li&gt;
&lt;li&gt;스탠다드 스타일은 오픈소스 기여 시 마찰을 줄이고, 신규 프로젝트에서 새로운 팀 멤버 합류 과정 또한 더욱 매끄럽게 만들어준다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Black :&lt;/strong&gt; whitespace 와 같은 일관된 포맷팅을 위한 툴이다. 기본적으로 자동화가 가능한 영역을 담당하고, 에디터와 자동화 워크플로우에 비교적 문제없이 적용이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flake8 :&lt;/strong&gt; missing docstring 과 같이 자동화가 어려운 영역을 담당하며, docstring completeness, type hinting, security, common bugs 등 영역에서 관련 기능을 제공하는 extension 과 plug-in 을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shellcheck :&lt;/strong&gt; BASH 와 관련된 주요 에러 요인 등을 확인해준다. 실행 속도가 빠르고 에디터에 쉽게 적용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;스타일의 무지성적인 적용은 바람직하지 않다. 관련한 문제를 방지하기 위해 강사진은 다음과 같은 방식을 추천
&lt;ul&gt;
&lt;li&gt;적용되는 룰을 목적에 부합하는 수준에서 미니멀하게 유지할 것 (스탠다드 유지, 버전 컨트롤 시스템 활용 등).&lt;/li&gt;
&lt;li&gt;선택적인 룰 적용. 단계적인 룰 커버리지 상승 (특히 수정이 많이 필요한 큰 기존 코드베이스에 적용할 시).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.4 - Always Be Automating&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;앞서 설명된 테스팅, 린팅을 업무 환경에 잘 적용하기 위해선 버전 컨트롤 시스템 (VCS) 과의 연동을 통한 자동화가 필요하다.&lt;/li&gt;
&lt;li&gt;VCS 와의 연동은 에러 재현을 가능하게 한다거나, 자동화를 통해 개발자가 본연에 업무에 보다 집중할 수 있다는 등의 장점이 존재한다.&lt;/li&gt;
&lt;li&gt;인기있는 오픈소스 repository 는 관련된 best practice 를 배울 수 있는 최적의 장소이다 (예. PyTorch Github library).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyTorch 가 활용하는 툴은 GitHub Actions 이며, 해당 툴은 VCS 와 연동된 자동화 기능을 제공.&lt;/li&gt;
&lt;li&gt;Pre-commit.ci, CircleCI, Jenkins 와 같은 유사한 기능의 툴이 존재하지만 GitHub Actions 는 현재 오픈소스 커뮤니티에서 가장 활발하게 활용되는 툴이다.&lt;/li&gt;
&lt;li&gt;버전 관리 내역을 깨끗하게 유지하기 위해선 commit 전 테스팅과 린팅을 로컬 환경에서 구동할 수 있어야 한다. 강사진은 이러한 작업을 위해 pre-commit 을 추천.&lt;/li&gt;
&lt;li&gt;자동화를 위해선 사용하는 툴을 깊게 이해하고 있어야한다. 예를 들어 Docker 를 단순히 사용할 줄 아는 것은 Docker 를 자동화 할 수 있는 것과 다르며, 제대로된 자동화가 아닌 경우 오히려 생산성을 저하시킬 우려가 존재한다.&lt;/li&gt;
&lt;li&gt;따라서 자동화는 보다 높은 직급의 개발자가 담당하는 편이 좋으며, 코드의 오너십, 자동화에 대한 의사결정을 필요로 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-ml-systems&#34;&gt;Testing ML Systems&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;ML 테스팅은 어렵지만, 불가능하진 않다.&lt;/li&gt;
&lt;li&gt;쉬운 작업부터 차근차근 시작할 것.&lt;/li&gt;
&lt;li&gt;배포 환경에서 테스트를 진행하나, 질낮은 코드를 배포하지는 않을 것.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;2.1 - Testing ML Is Hard, But Not Impossible&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;테스팅 개념이 발전된 영역은 소프트웨어 엔지니어링 분야이다. 소프트웨어 엔지니어링은 코드를 배포하는 과정이지만, ML 은 학습을 통해 데이터와 모델을 결합하며, 따라서 다음과 같은 어려움을 동반한다.
&lt;ul&gt;
&lt;li&gt;데이터는 소스 코드 보다 무겁고, 검증이 어렵다.&lt;/li&gt;
&lt;li&gt;데이터는 보다 복잡하고, 명확한 정의를 가지고있지 않다.&lt;/li&gt;
&lt;li&gt;데이터는 컴파일된 프로그램에 비해 빈약한 디버깅, 검증 툴 셋을 가지고있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;본 섹션은 Smoke Testing 개념에 집중하며, 이는 구현이 쉽고 효과적이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.2 - Use Expectation Testing on Data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터에 대한 테스팅은 기본적인 속성에 대한 검증으로부터 시작한다. null 이 존재하지 않는 컬럼, 시작일 이전의 마감일 등 데이터에 대한 기본적인 기대치에 대한 검증을 진행하는 식.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;강사진은 이와 같은 작업을 위해 great_expectations 라이브러리를 추천한다. 본 툴은 데이터 질에 대한 리포트를 자동으로 생성하며, logging, alerting 등의 기능 또한 지원.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;원활한 작업 진행을 위해서는, 가능한 모델러와 데이터 간 거리를 좁히는 편이 좋다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;첫째 방안은 프로젝트 시작 시 모델 개발자가 임의로 데이터를 레이블링 하는 것.&lt;/li&gt;
&lt;li&gt;하지만 더 많은 개발자가 팀에 들어오고, 데이터 레이블링을 진행한 개발자가 다른 일에 착수하며 관련된 정보는 필연적으로 유실된다. 이보다 나은 솔루션은 모델 개발자와 주기적으로 소통하는 데이터 레이블링 조직을 운영하는 것.&lt;/li&gt;
&lt;li&gt;최적은 방안은 모델 개발자들이 순차적으로 레이블링 작업을 진행하는 것이다. 이러한 방식을 통해 모델 개발자는 데이터에 대한 이해와 전문성을 높일 수 있다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;2.3 - Use Memorization Testing on Training&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;암기는 가장 단순한 형태의 학습이다. 특히 딥러닝의 경우 데이터를 암기하는 작업을 특히 잘 수행하기 때문에 전체 데이터셋의 일부분을 잘 암기하는지 확인하는 것 만으로 학습이 원활하게 이루어지는지 확인할 수 있다.&lt;/li&gt;
&lt;li&gt;이러한 방식으로 확인 가능한 이슈는 아주 심각할 확률이 높다. 예를 들어 gradient 계산이 제대로 이루어지지 않거나, numerical type 이슈가 존재하거나, 레이블이 섞여있는 등.&lt;/li&gt;
&lt;li&gt;보다 작은 규모의 문제 확인을 위해서는 학습에 소요되는 런타임을 확인하는 것이 좋다. 기대 수준의 성능을 달성하기 까지 소요되는 배치 수가 갑자기 증가한다면, 학습 과정에서 버그가 발생했을 가능성이 있다.&lt;/li&gt;
&lt;li&gt;PyTorch Lightning 은 이러한 작업을 위해 overfit_batches 기능을 제공.&lt;/li&gt;
&lt;li&gt;Memorization 테스팅 개발 시에는 실행 속도를 염두해두어야 한다. 잦은 테스팅을 위해 실행 속도가 빨라야하며, 10분 이내의 테스팅 타음으로 모든 PR, 또는 코드 변경 후 실행하는 편이 좋다.&lt;/li&gt;
&lt;li&gt;실행 속도 개선을 위해서는 다음 이미지 참조 - 이러한 아이디어들은 여러 시나리오에 따른 학습 결과를 사전에 확인할 수 있는 방법이기도 함.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;또 다른 테스팅 방법은 이전과 동일한 조건의 학습을 새로운 코드로 실행하는 것. 자주 수행이 가능하지는 않지만, 학습 파이프라인에서 예기치 못하게 발생한 문제를 바로 확인할 수 있다.&lt;/li&gt;
&lt;li&gt;이러한 방법의 주된 단점은 학습에 필요한 많은 리소스이다. CircleCI 와 같은 CI (Continuous Integration) 플랫폼은 GPU 활용에 많은 비용을 청구하며, GitHub Actions 는 관련 기기 접근에 많은 제약이 있다.&lt;/li&gt;
&lt;li&gt;가장 좋은 방법은 배포 환경에서 새로 유입되는 데이터를 활용해 주기적인 학습을 진행하는 것. 여전히 많은 리소스가 소요되지만, 실제 모델 개선에 직접적으로 기여하며 관련 작업을 위해 data flywheel 을 필수적으로 구축하게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.4 - Adapt Regression Testing for Models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델은 하나의 함수로 규정할 수 있다 - 기본적으로 인풋에 의한 아웃풋을 출력하기 때문. 따라서 보통의 함수와 같이 regression testing (코드 변경 전후, 동일한 인풋에 대한 아웃풋 출력을 대조하는 방법) 을 통한 코드 검증이 가능하다.&lt;/li&gt;
&lt;li&gt;Regression testing 은 분류기와 같은 보다 단순한 모델에 가장 적합하며, 구조가 복잡한 경우 또한 적용이 조금 어려울순 있지만 배포 과정에서 도움을 줄 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;보다 우아한 테스팅 방법은 손실값과 모델 지표를 활용한 test suite 작성이다.&lt;/li&gt;
&lt;li&gt;하기 test-driven development (TDD) 코드 작성 패러다임 (테스트 작성 후 코드를 작성하는 방식, 코드에 기인한 테스트 작성을 방지함으로서 테스트가 본연에 역할에 보다 충실할 수 있다) 과 유사한데, 일정 수준의 손실값을 사전에 정의한 후, 모델이 정의된 성능을 보일때 까지 개발을 진행하게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;하지만 손실값 threshold 기반의 테스팅은 에러 발생의 원인을 특정할 수 없기 때문에 TDD 와 완전한 동일 선상에서 볼 수는 없다.&lt;/li&gt;
&lt;li&gt;이와 같은 문제를 보완하기 위해서 손실값이 가장 크게 발생한 데이터를 면밀히 살펴볼 필요가 있다. 이러한 데이터들을 하나의 세트로 모은 후 해당 세트를 기반으로 별도의 테스팅을 진행할 수도 있는데, 이에 따른 이점은 (1) 모델이 개선 가능한 영역을 확인할 수 있으며 (2) 데이터 자체의 문제 또한 찾을 수 있다는 점 (레이블 오류 등).&lt;/li&gt;
&lt;li&gt;특이 데이터 확인 시에는 타입별로 데이터를 묶는 작업이 필요할 수 있다. 자율운행을 예시로 들자면 주위 환경이 너무 어두운 경우, 앞유리에 빛반사가 발생한 경우 등을 그룹핑.&lt;/li&gt;
&lt;li&gt;이러한 방법을 통해 모델 개선시 동일한 문제가 발생하지 않는지 확인하는 작업이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;꽤나 손이 많이 가는 작업인데, 별도 레이블링 팀과의 협업 등을 통해 효율 개선이 가능한 부분. Domino, Checklist 와 같이 이러한 문제를 별도 ML 모델로 해결하는 방법 또한 존재한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.5 - Test in Production, But Don&amp;rsquo;t YOLO&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;테스트는 실제 배포 환경에서 진행되어야 한다. 특히 ML 분야의 경우 배포 환경과 개발 환경 간 데이터 유사성을 담보하기 어렵기 때문에 배포 환경 내 테스팅이 중요.&lt;/li&gt;
&lt;li&gt;또한 배포 환경 테스팅을 위해서 구축하게 되는 툴과 인프라는 실제 배포 문제가 발생했을때 이를 해결하는데 활용될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.6 - ML Test Score&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;코드베이스가 커지고, 팀이 성숙해가며 단순한 smoke testing 보다 완전한 형태의 테스팅이 필요해질 수 있다. 이러한 예시 중 하나가 ML Test Score.&lt;/li&gt;
&lt;li&gt;ML Test Score 는 구글 ML 개발팀에서 발전한 평가기준인데, 데이터, 모델, 학습, 인프라, 배포 모니터링 등의 영역을 객관적으로 평가할 수 있도록 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;해당 방법은 기준치가 매우 높고, 영역이 광범위하다. 강사진이 개발한 모델 조차 몇개의 영역에서 기준에 미치지 못하기 때문에 일종의 참고 자료로 활용하는 것이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting-models&#34;&gt;Troubleshooting Models&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;테스팅은 잘못된 부분을 찾도록 돕지만, 트러블슈팅은 실제 잘못된 부분을 고치는 과정이다. ML 트러블슈팅이란 다음과 같은 순차적 방법론으로 정의할 수 있다.
&lt;ol&gt;
&lt;li&gt;Make It Run - 자주 발생하는 에러를 방지해 모델이 작동하도록 할 것.&lt;/li&gt;
&lt;li&gt;Make It Fast - 비효율성을 개선해 모델이 빠르게 동작하도록 할 것.&lt;/li&gt;
&lt;li&gt;Make It Right - 검증된 구조와 보다 방대한 데이터 활용으로 올바른 모델을 구축할 것.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.1 - Make It Run&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;세단계의 과정 중 가장 쉬운 단계이다. 모델 실행을 막는 버그는 아주 일부분에 불과한데, 이러한 버그들은 미리 내용을 숙지한 후 사전에 방지하는 편이 좋다.&lt;/li&gt;
&lt;li&gt;첫번째 타입은 shape error, 즉 행렬 연산 과정에서 행렬의 크기가 맞지 않는 경우이다. 이러한 에러를 방지하기 위해 개발 과정에서 예상되는 텐서의 크기를 중간 중간 코드 내에 적어주는 것이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_18.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;두번째 타입은 메모리 에러이다. GPU 에 비해 지나치게 큰 용량의 텐서를 처리할 시 발생되며, 이를 예방하기 위해서는 가능한 낮은 precision 을 활용할 것 (주로 16비트 precision).&lt;/li&gt;
&lt;li&gt;다른 원인은 지나치게 많은 데이터, 혹은 배치 사이즈. PyTorch Lightning 내 autoscale batch size 기능을 활용해 방지 가능하며, 이로도 해결이 어렵다면 tensor parallelism, gradient checkpoint 등의 옵션을 검토.&lt;/li&gt;
&lt;li&gt;NaN, Infinite 등의 값이 텐서 내 발생하는 경우 또한 학습 실패로 이어질 수 있다. 주로 gradient 발생 후, 모델에 전파되는 형태이며 PyTorch Lightning 은 이러한 이슈 트래킹을 위한 기능을 제공.&lt;/li&gt;
&lt;li&gt;주로 Normalization Layer 에서 발생하며, 64 비트 float 적용 시 문제가 해결될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.2 - Make It Fast&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_19.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델이 정상적으로 작동한다면, 이후 실행 속도 개선이 필요하다.&lt;/li&gt;
&lt;li&gt;DNN 의 경우 실행 속도와 관련해 직관적이지 않은 부분이 다소 존재하는데, 예시적으로 트랜스포머 모델 내 MLP 레이어 실행 속도가 Attention 레이어 실행 속도보다 느리거나, 데이터 로딩 등에 상당한 시간이 소요될 수 있다.&lt;/li&gt;
&lt;li&gt;이러한 이슈를 해결하기 위해서 가장 좋은 방법은 단순히 코드를 재점검하는 것. 관련해 아주 작은 코드 변화도 큰 효과를 가져올 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.3 - Make It Right&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;기존 소프트웨어와는 다르게 ML 모델은 태생적으로 완벽할 수 없다.&lt;/li&gt;
&lt;li&gt;하지만 모델/데이터 스케일링을 통해 모델은 상당한 성능 개선을 보일 수 있는데, OpenAI 리서치에 의하면 스케일링에 의한 장점은 명확히 측정될 수 있고, 리소스, 데이터 사이즈, 파라미터 수 등에 기반해 예측될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3_20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;직접적인 스케일링이 어렵다면, finetuning 을 검토.&lt;/li&gt;
&lt;li&gt;언급된 조언보다 세부적인 사항들은 모델과 관련 과제 마다 많은 차이가 있을 것. 가능하면 이미 존재하는 모델 구조와 하이퍼파라미터 등을 활용하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 2</title>
        <link>https://meme2515.github.io/mlops/fsdl_2/</link>
        <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_2/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_2_7.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 2" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=BPYOsDCZbno&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-2-development-infrastructure-and-tooling/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/16pEG5GesO4_UAWiD5jrIReMGzoyn165M/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;이상적인 ML 환경이란 &lt;strong&gt;정의된 프로젝트 목표와 샘플 데이터를 기반으로, 지속적으로 개선되는 예측 시스템을 큰 규모로 운영&lt;/strong&gt;하는 것이다.&lt;/li&gt;
&lt;li&gt;현실은 이와는 다를 수 밖에 없다. 데이터에 대한 &lt;strong&gt;수집, 처리, 레이블, 버저닝&lt;/strong&gt;이 필요하며, &lt;strong&gt;적합한 모델 구조와 사전 학습된 가중치&lt;/strong&gt;를 찾아야하고, 프로젝트에 적합하게 &lt;strong&gt;디버깅&lt;/strong&gt;해야 한다. 또한 여러 &lt;strong&gt;학습 과정을 기록 및 리뷰&lt;/strong&gt;해야하며, 모델 배포 후에도 끊임없이 생성되는 데이터를 기반으로 모델을 개선해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 환경의 3가지 주요한 컴포넌트는 &lt;strong&gt;데이터, 개발, 배포&lt;/strong&gt;이다. 각각의 컴포넌트는 방대한 툴을 가지고 있고, 3주간 강의를 통해 이들 모두를 전반적으로 살핀다. 본 강의의 주제는 개발이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;software-engineering&#34;&gt;Software Engineering&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;개발 언어의 경우 데이터 컴퓨팅 분야에선 현재 &lt;strong&gt;Python&lt;/strong&gt; 이 절대적인 우위를 점하고 있다. 너무나 많은 부속 라이브러리들이 개발되었기 때문이며, Julia, C/C++ 와 같은 경쟁자가 존재했지만 사실상 Python 이 생태계를 독점하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파이썬 코드를 작성하기 위해서는 에디터를 사용해야 한다. Vim, Emacs, Jupyter Notebook/Lab, PyCharm 등 수많은 옵션이 있지만 FSDL 팀이 제안하는 에디터는 &lt;strong&gt;VS Code&lt;/strong&gt; 이다. 내장된 Git 버전 컨트롤, docs peeking, 원격 접속, 린터, 디버깅 기능 등을 제공하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;수많은 현업들이 Jupyter Notebook 환경을 사용하지만, 에디터가 별다른 기능을 제공하지 못하고, 코드의 작성 순서가 중요하지 않으며, 버전 컨트롤, 테스팅이 어렵다는 문제를 가지고 있다. &lt;a class=&#34;link&#34; href=&#34;https://nbdev.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Nbdev&lt;/a&gt; 패키지를 활용하면 이러한 문제들은 어느 정도 해결은 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deep-learning-frameworks&#34;&gt;Deep Learning Frameworks&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;딥러닝의 본질적인 요소인 행렬 연산은 사실 Numpy 정도의 라이브러리만으로 해결 가능하다. 하지만 CUDA 를 통한 GPU 자원 활용, 전통적이지 않은 형태의 레이어 구축, 옵티마이저/데이터 인터페이스 활용 등을 위해서는 딥러닝 프레임워크가 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PyTorch, TensorFlow, Jax 등 다양한 프레임워크들이 존재하며, 모델을 구축 한 후 배포 환경에 따라 최적화된 execution graph 를 찾는다는 점에서 근본적인 작동 원리는 서로 유사하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;강사진은 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch&lt;/a&gt; 를 선호하는데, 구현된 모델 수, 연관 논문 수, 대회 수상 모델 수 등에서 압도적인 우세를 보이기 때문이다. 2021년도만 하더라도 ML 대회 우승 모델의 약 77%가 PyTorch 를 사용했다.&lt;/li&gt;
&lt;li&gt;PyTorch 의 경우 TorchScript 등의 파생 제품을 이용하면 실행 속도가 더욱 빨라지며, 분산 처리, 비전, 오디오, 모바일 배포 환경등의 생태계를 이루고 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.pytorchlightning.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Lightning&lt;/a&gt; 을 PyTorch 와 함께 사용하면 코드를 보다 구조적으로 유지할 수 있으며, 어떠한 하드웨어에서도 코드를 실행할 수 있다. 모델 체크포인팅 등 추가적인 기능 또한 제공.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/?gclid=CjwKCAiAhKycBhAQEiwAgf19euf21xRE6IFNBHwFXUSdIUSJu5-q_H8dscz8q1AeULry-_1pOeBGyBoCWO8QAvD_BwE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorFlow&lt;/a&gt; 의 경우 브라우저에서 딥러닝을 실행할 수 있는 TensorFlow.js, 쉽게 딥러닝 개발이 가능한 Keras 등의 파생 제품을 가지고있다.&lt;/li&gt;
&lt;li&gt;이외의 옵션으로는 &lt;a class=&#34;link&#34; href=&#34;https://www.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FasiAI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/google/jax&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JAX&lt;/a&gt; 등이 있으며, 이들 라이브러리를 사용할 구체적인 이유가 있지않다면 비추천.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대부분의 ML 프로젝트는 이미 배포/개발된 모델 구조를 기반으로 시작하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://onnx.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ONNX&lt;/a&gt; 는 딥러닝 모델을 저장하는 표준 방식을 제공하는 패키지이며, PyTorch 에서 Tensorflow 등으로의 모델 변환을 가능하게 한다. 잘 작동하는 경우도 있지만, 모든 경우의 수를 감안하지는 못한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huggingface&lt;/a&gt; 는 최근 가장 떠오르는 모델 저장소이다. NLP 라이브러리로 시작했지만, 오디오/이미지 분류 등의 다양한 분야로 확장했으며 약 60,000 개의 사전 학습 모델, 7,500 개의 데이터셋을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://timm.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TIMM&lt;/a&gt; 은 최신 비전 모델을 중점적으로 제공하는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;distributed-training&#34;&gt;Distributed Training&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;다수의 GPU 를 내장한, 다수의 PC 에서 모델 학습이 가능한 환경에 있다고 가정하자. &lt;strong&gt;(1) 데이터 배치&lt;/strong&gt;와 &lt;strong&gt;(2) 모델 파라미터&lt;/strong&gt; 를 GPU 에 분산하여 처리하게 되며, 데이터 배치가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도, 모델 파라미터가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도 있다.&lt;/li&gt;
&lt;li&gt;베스트 케이스는 데이터 배치와 모델 파라미터가 모두 한 개의 GPU 에 담길 수 있는 경우이다. 이와 같은 경우를 &lt;strong&gt;Trivial Parallelism&lt;/strong&gt; 이라 부르며, 다른 GPU/PC 에서 독립적인 학습을 수행할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델 파라미터가 한 개 GPU 에 담기나, 데이터 배치가 담기지 않는 경우 &lt;strong&gt;Data Parallelism&lt;/strong&gt; 을 수행할 수 있다. 즉, 단일 배치의 데이터를 여러대의 GPU 에 분산한 후 모델에 의해 연산된 gradient 의 평균값을 구하는 것이다.&lt;/li&gt;
&lt;li&gt;A100 등의 서버 카드를 활용한다며 연산 속도가 선형적으로 증가하며, 3090 과 같은 소비자용 카드 활용시 이보다 효율성이 떨어진다.&lt;/li&gt;
&lt;li&gt;PyTorch 라이브러리는 Data Parallelism 을 구현한 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistributedDataParallel&lt;/a&gt; 라이브러리를 제공한다. 써드파티 라이브러리로는 &lt;a class=&#34;link&#34; href=&#34;https://horovod.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Horovod&lt;/a&gt; 같은 옵션이 있으며, PyTorch Lightning 을 활용한다면 이 두 라이브러리 활용이 더욱 쉬워진다. 두 개 라이브러리의 성능은 서로 유사한 편이다.&lt;/li&gt;
&lt;li&gt;이보다 복잡한 경우는 모델 파라미터가 한 개 GPU 에 담기지 않는 경우인데, 이 경우 대표적으로 세가지의 솔루션, (1) Sharded Data Parallelism, (2) Pipelined Model Parallelism, (3) Tensor Parallelism, 이 존재한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sharded Data Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sharded 데이터 분산 처리는 GPU 메모리를 차지하는 요소인 (1) 모델 파라미터, (2) 미분값, (3) 옵티마이저 기록, (4) 데이터 배치를 모두 분산하여 다수의 GPU 메모리를 효율적으로 운영하는 방법이다.&lt;/li&gt;
&lt;li&gt;Microsoft 의 ZeRO 라는 방법론으로 처음 고안되었고, 기존 방식과 대비해 약 10배 큰 배치 사이즈를 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;Microsoft DeepSpeed, Facebook FairScale 등의 라이브러리가 존재하며, PyTorch 또한 기본적으로 Fully Sharded DataParallel 기능을 제공한다.&lt;/li&gt;
&lt;li&gt;ZeRO 접근법은 한 대의 GPU 에 적용될 수 있다 (분산된 데이터를 순차적으로 처리).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pipelined Model Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델의 각 레이어를 개별적인 GPU 에 분산시키는 방식이다. 어렵지 않게 구현이 가능하지만 별도의 패키지를 활용하지 않는다면 각 단계에서 하나의 GPU 만 활용하게 되기에 효율적이지 않다.&lt;/li&gt;
&lt;li&gt;DeepSpeed 와 FairScale 같은 라이브러리는 연산 스케줄링을 통해 모든 GPU 가 한꺼번에 동작하도록 설정이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tensor Parallelism 은 연산 대상 행렬을 다수의 GPU 에 분산하는 접근법이다. NVIDIA 에서 배포한 Megatron-LM repo 는 이러한 분산 방식을 Transformer 모델에 적용했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT3 규모의 모델을 핸들링해야 한다면 언급한 3가지의 분산 처리 기법을 함께 사용하는 것 또한 가능하다. 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/bloom-megatron-deepspeed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BLOOM 학습&lt;/a&gt; 관련 자료를 참고.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;compute&#34;&gt;Compute&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지난 10년 간 발전된 ML 모델이 요구하는 연산 자원은 빠른 속도로 성장했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모델의 효율적인 학습을 위해선 GPU 활용은 필수적이다. 제조사 중 가장 큰 영향력을 행사하는 기업은 NVIDIA 이지만, Google 또한 자체적으로 설계/생산한 TPU 를 Google Cloud 를 통해 제공한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 선택할땐 다음의 3가지 고민이 필요하다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;한번에 얼마나 많은 데이터를 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;데이터를 얼마나 빠르게 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;CPU 와 GPU 간 통신 속도는 어느정도인가? 다수의 GPU 간 통신 속도는 어느정도인가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;개선된 성능의 최신 GPU 구조는 거의 매년 소개되고 있다. 이러한 GPU 들은 소비자용과 기업용으로 나눌 수 있는데, 기업 환경에서는 항상 서버 카드를 사용해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 평가하는 2가지 중요한 지표는 RAM 과 Tensor TFlops 이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RAM 이 더 큰 GPU 는 상대적으로 더 많은 모델 파라미터와 데이터를 처리할 수 있다.&lt;/li&gt;
&lt;li&gt;Tensor TFlops 란 NVIDIA 에서 개발한 딥러닝 전용 GPU 코어를 뜻한다. Mixed Precision 연산, 즉 연산 성격에 따라 16bit 와 32bit 부동소수점 (floating point) 타입을 적절히 혼용하여 연산 속도와 사용 용량을 개선하는 작업에 최적화 되어있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/gpu-benchmarks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.aime.info/en/blog/deep-learning-gpu-benchmarks-2021/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AIME&lt;/a&gt; 과 같은 업체는 실사용 환경에 기반한 벤치마크 자료를 제공한다. NVIDIA A100 은 기존 V100 보다 2.5 배 정도 빠르며, RTX 칩 또한 V100 을 상회하는 성능을 보여준다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대형 클라우드 서비스인 Microsoft Azure, Google Cloud Platfrom, Amazon Web Services 등이 이러한 GPU 연산 자원을 이용할 수 있는 가장 기본적인 장소이며, 유사한 스타트업 서비스인 &lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.coreweave.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CoreWeave&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt; 또한 참고할 만 하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TPU 의 경우 현재 4세대 까지 발전한 상태이며, 딥러닝을 위한 최적의 하드웨어이다. 상단의 그래프는 TPU 와 NVIDIA A100 의 성능을 비교한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;클라우드 서비스를 활용한 GPU 가용 비용은 미리 계산하기 까다로운 측면이 있기에 FSDL 팀은 이러한 문제를 해결하기 위한 &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/cloud-gpus/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GPU Cost Metric&lt;/a&gt; 툴을 공개했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;성능/비용을 함께 고려했을때 고성능 GPU 는 시간당 비용이 비싸더라도 전체 학습 관점에서 비용을 절감하는 효과를 가질 수 있다. 예를 들어 동일한 트랜스포머 학습 시 4개의 V100 GPU 에서 72시간 동안 1,750 달러의 비용이 발생하지만, 4개의 A100 GPU 에선 8시간 동안 250 달러의 비용만 발생한다. 때문에 무조건 단가가 싼 GPU 를 활용하기 보다는 이러한 비용 절감 요소를 고려해 자원을 선택할 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음과 같은 룰이 이러한 자원 선택 과정에 도움을 줄 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;가장 저렴한 클라우드 서비스에서 시간당 비용이 가장 비싼 GPU 활용&lt;/strong&gt;할 것.&lt;/li&gt;
&lt;li&gt;Paperspace 와 같은 &lt;strong&gt;스타트업은 메이저 클라우드 사업자 대비 저렴한 비용으로 GPU 자원 제공&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 자원을 활용한다면 조립 PC 를 구축하거나, NVIDIA 와 같은 제조사에서 판매하는 딥러닝용 PC 를 구매할 수 있다. 128 GB 램, 2개의 RTX 3090 이 탑재된 PC 를 약 7,000 달러 정도에 구축할 수 있으며, 이보다 향상된 성능이 필요하다면 Lambda Labs 에서 판매하는 60,000 달러 학습용 PC 와 같은 옵션이 있다 (8개의 A100 탑재).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 vs. 클라우드&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU 자원을 소유하고 있다면 &lt;strong&gt;비용을 최소화한다는 관점보다는 활용도를 최대화한다는 관점에서 문제 접근이 가능&lt;/strong&gt;하다.&lt;/li&gt;
&lt;li&gt;스케일 아웃을 지향한다면, 가장 저렴한 클라우드 사업자를 이용하는 편이 맞다.&lt;/li&gt;
&lt;li&gt;연산 부담이 큰 작업이라면 TPU 활용을 진지하게 고려해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;resource-management&#34;&gt;Resource Management&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;다수의 연산 자원이 확보되었다면 해당 자원들을 어떻게 관리/운영 할 것인지에 대한 고민 또한 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단일 자원 환경에선 &lt;a class=&#34;link&#34; href=&#34;https://python-poetry.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;poetry&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://docs.conda.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;conda&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://pypi.org/project/pip-tools/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;pip-tools&lt;/a&gt; 와 같은 패키지 매니저 / 가상환경을 활용해 쉽게 분석 환경을 설정할 수 있다. 이에 반해 다수의 자원을 활용할 때에는 &lt;a class=&#34;link&#34; href=&#34;https://slurm.schedmd.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SLURM&lt;/a&gt; 과 같은 리소스 매니저 활용이 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;휴대성/이식성을 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://www.docker.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker&lt;/a&gt; 를 통해 가볍게 모든 디펜던시 스택을 패키징할 수 있다. 자원 클러스터에서 다수의 Docker 컨테이너를 운영하기 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes&lt;/a&gt; 와 같은 툴이 필요하며, &lt;a class=&#34;link&#34; href=&#34;https://www.kubeflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubeflow&lt;/a&gt; 는 Kubernetes 에 기반한 ML 프로젝트 운영을 돕는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;자원 클러스터 구축을 위한 옵션은 다음과 같다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS 를 활용한다면 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/pm/sagemaker/?trk=83e980bd-feef-4dc8-827c-21089d3b5592&amp;amp;sc_channel=ps&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&amp;amp;ef_id=Cj0KCQiA7bucBhCeARIsAIOwr-8hHn1JQyePYZvkT7YpagXav6_7hAP7L8afpmbCQJ-oRYxKnSnwpooaArmfEALw_wcB:G:s&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sagemaker&lt;/a&gt; 를 통해 데이터 레이블링 부터 모델 배포 까지의 과정을 모두 마칠 수 있다. Sagemaker 는 AWS 에만 존재하는 많은 설정값을 가진다는 단점이 있지만, 학습을 위한 수많은 학습 알고리즘을 제공하고 있다. 약간의 추가 비용이 발생하지만, PyTorch 또한 점차 지원하고 있는 추세이다.&lt;/li&gt;
&lt;li&gt;Anyscale 의 &lt;a class=&#34;link&#34; href=&#34;https://docs.ray.io/en/latest/train/train.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ray Train&lt;/a&gt; 은 Sagemaker 와 유사한 형태의 자원 클러스터 구축 도구이다. 하지만 비용이 다소 비싸다는 단점이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined.AI&lt;/a&gt; 는 온프레미스와 클라우드 클러스터를 관리하는 툴이다. 분산 학습 등의 기능을 지원하며, 계속 개발이 진행되고 있는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다양한 클라우드 자원을 관리하는 작업은 난이도가 있고, 아직 개선의 여지가 존재하는 영역이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiment-and-model-management&#34;&gt;Experiment and Model Management&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;연산 자원 관리와는 달리, 학습 모니터링은 체계확립이 거의 완료된 영역이다. 학습 모니터링이란 모델 개발과정에서 변동하는 코드, 모델 파라미터, 데이터 셋에 대한 관리를 뜻하며, 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/tensorboard&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorBoard&lt;/a&gt; : 구글이 개발한 단발적인 학습 모니터링 툴이며, 다수의 학습을 체계적으로 관리하기 어려운 측면이 존재.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mlflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLFlow&lt;/a&gt; : Databricks 에서 개발한 모델 패키징, 학습 모니터링 툴이며, self-hosting 이 필수적이다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=Performance-Max&amp;amp;utm_content=site&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=%7bcampaign%7d&amp;amp;utm_term=&amp;amp;utm_content=%7bcontent%7d&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr-9FBRDAmcSqE8zwkd1LTzevHny63DrOR_97Q19FVD_PdFLTC07m5SAaAiXHEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Weights and Biases&lt;/a&gt; : 개인적, 학업적 사용은 무료이며, &amp;ldquo;experiemnt config&amp;rdquo; 커맨드를 통해 학습 내용을 로그에 기록할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://neptune.ai/?utm_source=googleads&amp;amp;utm_medium=googleads&amp;amp;utm_campaign=[SG][HI][brand][rsa][all]&amp;amp;utm_term=neptune%20ai&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr--0uGPxuUEQLd9BHDlEAYPhIiF0-C-HvyadckWhW_3GCfg3ZCyeC0oaAsJxEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Neptune AI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.comet.com/site/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Comet ML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined AI&lt;/a&gt; 또한 연관 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;상단에 언급된 다수의 툴은 Hyperparameter Optimization 기능을 제공한다. 모델 튜닝을 효율적으로 수행하는데 도움을 주는데, 예를 들어 Weights and Biases 의 &lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site/sweeps&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sweeps&lt;/a&gt; 같은 기능이 이 역할을 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;all-in-one&#34;&gt;&amp;ldquo;All-In-One&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;학습 모니터링, 분산 처리, 배포, 스케일링 등 언급된 모든 기능을 수행하는 인프라 솔루션 또한 존재하는데, 그 가격이 상당한 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/gradient&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradient by Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.dominodatalab.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Domino Data Lab&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/sagemaker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Sagemaker&lt;/a&gt; 와 같은 옵션이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 1</title>
        <link>https://meme2515.github.io/mlops/fsdl_1/</link>
        <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_1/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_4.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 1" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=-Iob-FW5jVM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-1-course-vision-and-when-to-use-ml/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/18EVuJpnJ9z5Pz7oRYcgax_IzRVhbuAMC/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;course-vision&#34;&gt;Course Vision&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;FSDL 과정이 처음 시작한 2018년에는 규모가 큰 기업들만 ML 제품을 내놓고 있는 상태였으며, 이들 이외의 기업들은 ML로 부터 부가가치를 창출하기 어렵다는 생각이 업계 전반에 있었다.&lt;/li&gt;
&lt;li&gt;2022년 현재에는 트랜스포머의 등장으로 인해 NLP 분야가 더 많은 적용 사례들을 찾아내고 있고, 이외에도 많은 ML 제품들의 등장으로 MLOps 라는 단어가 사용되기 시작했다.&lt;/li&gt;
&lt;li&gt;물론 업계 전반이 더 성숙해졌고, 주요한 연구 실적 또한 있었지만, ML 제품 개발이 더욱 활성화된 주요한 이유는 &lt;strong&gt;선행학습이 완료된 모델이 점차 상품화되고 있다는 점&lt;/strong&gt;이다.
&lt;ul&gt;
&lt;li&gt;이제 HuggingFace 와 같은 툴을 이용하면 최신 NLP, 비전 모델을 코드 한두줄로 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;회사들은 학습된 모델을 네트워크를 통해 제공하기 시작했다.&lt;/li&gt;
&lt;li&gt;Keras, PyTorch Lightning 을 중심으로 유관한 프레임워크들이 표준화되기 시작했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI 분야는 항상 대중의 관심 속에 있어왔지만, 기대에 부흥하지 못한 실용성으로 지난 수십년간 굴곡을 겪어왔다. 분야가 다시 성장하고 있는 지금, 또다른 혹한기를 피하기 위해 관련 연구를 real-world 제품으로 승화시켜야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학계에서 다루는 ML 은 단차원적이다. 문제를 정의하고, 데이터를 수집하고, 정제한 다음 모델 개발 과정을 거쳐 잘 작동하는 ML 모델을 평가/보고함으로 과정이 끝난다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이에 반해 ML 제품은 배포 후 관리를 필요로한다. 실제 사용자들이 제품을 어떻게 경험하는지 관찰/측정한 후, 사용자들의 데이터에 기반한 data flywheel 을 만들어 모델을 고도화하게 된다.&lt;/li&gt;
&lt;li&gt;본 과정은 모델 학습을 넘어 &lt;strong&gt;좋은 ML 제품을 만들기 위해 필요한 지식과 노하우를 전달한다&lt;/strong&gt;. 이러한 제품에 어떤 부분들이 있어야 하는지, 제품 개발에서 발생하는 문제 해결을 위한 접근법은 어떠한 것들이 있는지 등을 가르친다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;MLOps 란 지난 몇년간 새로 등장한 분야이며, ML 시스템에 대한 배포, 유지, 운영에 관한 개념을 다룬다. 통제/반복 가능한 환경에서 모델을 구축하는 법, high scale 세팅에서 시스템을 운영하는 법, 시스템 유지를 위해 팀이 협업하는 법 등을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 기반 제품&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ML 기반 제품이란 이와 유사성을 가진 개념이나, 완전히 같다고 볼 수 없다. 좋은 제품 개발은 운영 이외의 분야에 대한 깊은 생각을 필요로하고, 최종 제품에서 ML 이 어떠한 역할을 하는지에 집중하게 된다. 유저가 제품을 사용하면서 어떠한 경험을 가지는지, 조직과 효율적으로 협업하는 방법은 무엇인지, ML 분야의 프로덕트 매니징은 어떻게 이루어지는지 등의 개념을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;본 과정은 좋은 ML 기반 제품을 만들기 위한 end-to-end 과정을 가르치며, 이에 필요한 기본적인 MLOps 개념만을 전달한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;when-to-use-machine-learning&#34;&gt;When To Use Machine Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML 프로젝트는 일반적인 소프트웨어 개발보다 높은 실패율을 보인다.&lt;/strong&gt; 많은 적용 분야에서 ML 이란 아직 연구 단계에 있기 때문이며, 때문에 100% 성공을 목표로 할 수는 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외에도 ML 프로젝트가 실패하는 이유 중 대표적인 예시는 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;기술적으로 불가능하거나 스코프 설정이 잘못되었기 때문&lt;/li&gt;
&lt;li&gt;제품화로의 도약을 이루지 못하기 때문&lt;/li&gt;
&lt;li&gt;조직적으로 ML 프로젝트 성공의 기준을 정하지 못했기 때문&lt;/li&gt;
&lt;li&gt;문제 해결을 이루어냈으나, 복잡성에 비례한 정당성을 가지지 못했기 때문&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 ML 프로젝트를 시작하기 전, 다음과 같은 질문을 할 필요가 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML을 활용할 준비가 되었는가?&lt;/strong&gt; 구체적으로는 적용할 제품이 있는가? 이미 데이터를 활용 가능한 방식으로 수집하고 있는가? 적절한 인력을 보유하고 있는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제를 해결하기 위해 정말 ML이 필요한가?&lt;/strong&gt; 문제는 애초에 해결되어야 하는 것인가? 룰베이스 혹은 간단한 통계학을 통한 문제 해결이 가능하진 않은가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML의 활용이 윤리적으로 올바른가?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모든 분야의 프로젝트와 같이, 적절한 ML 프로젝트 선정을 위해선 &lt;strong&gt;큰 임팩트&lt;/strong&gt;와 &lt;strong&gt;적은 비용&lt;/strong&gt;을 가진 유즈케이스 선정이 필요하다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;큰 임팩트란 ML 이 서비스 파이프라인의 복잡한 구조를 해결하거나, 간단한 예측이 큰 의미를 가지는 경우를 뜻한다. 업계에서 ML 을 어떻게 활용하고 있는지 또한 좋은 지표가 될 수 있다.&lt;/li&gt;
&lt;li&gt;적은 비용이란 데이터의 이미 존재하거나, 잘못된 예측이 어느정도 허용되는 경우를 말한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;큰 임팩트를 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML 활용이 상대적 경제성을 가지는 경우.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;제품이 필요로 하는 것이 무엇인지를 고민해야 한다.&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://spotify.design/article/three-principles-for-designing-ml-powered-products&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spotify - Discover Weekly 를 구현하면서 세운 3가지 원칙&lt;/a&gt; 참조.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 이 특히 잘하는 것이 무엇인가를 생각.&lt;/strong&gt; 시스템에 복잡하고 수동적으로 정의된 부분이 있다면 ML 적용이 큰 도움이 될 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;업계에서 ML 이 어떤 문제를 해결하고 있는지를 참고.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;적은 비용을 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;데이터 유무를 파악.&lt;/strong&gt; 새로운 데이터를 확보하는 것은 얼마나 어려운지, 데이터 레이블링은 어느정도의 비용이 드는지, 얼마나 많은 데이터가 필요할 것인지, 데이터는 얼마나 정적인지, 어떠한 보안 규제가 존재하는지 등.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델 정확도의 중요성을 고려.&lt;/strong&gt; 잘못된 예측으로 인한 비용은 어느정도인지, 실용성을 위해 모델의 정확도는 어느 정도여야 하는지를 파악해야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제의 난이도에 대한 고민.&lt;/strong&gt; ML 활용으로 해결될 문제는 얼마나 잘 정의되었는지, 관련 주제에 대한 논의가 충분히 존재하는지, 연산 자원은 얼마나 필요한지 등.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML이 어려워하는 대표적 문제들&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;결과값이 복잡한 경우.&lt;/strong&gt; 예측치의 정의가 불확실하거나, 고차원의 형상을 다루는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;높은 정확도를 요구하는 경우.&lt;/strong&gt; ML 모델은 예상치 못한 부분에서 실패하기 때문에, 일정 수준 이상의 정확도를 요구하는 경우 ML 적용이 적절하지 않을 수 있음.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;일반화가 필요한 경우.&lt;/strong&gt; 통계치에서 벗어난 데이터에 대한 예측을 요구하거나, 논리/계획을 세우거나 인과관계를 판단하는 작업을 요구하는 경우.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;같은 ML 프로젝트라 할지라도 프로젝트의 성격에 따라 계획 과정은 판이하게 달라진다. 관련한 방법론을 수립하기 위해 강사진은 다음과 같은 3가지 카테고리로 ML 제품을 구분한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Software 2.0&lt;/strong&gt; : 전통적인 소프트웨어에 머신러닝을 적용하는 경우이다. 코드 작성 AI 인 Github Copilot 을 예시로 들 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human-in-the-loop&lt;/strong&gt; : ML 시스템이 사람의 의사결정 체계를 돕거나, 효율성을 향상시키는 경우를 말한다. 단순한 스케치를 기반으로 PPT 슬라이드를 생성하는 등의 예시를 들 수 있으며, 이 경우 모델 아웃풋의 품질을 사람이 확인하는 과정이 수반된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autonomous Systems&lt;/strong&gt; : ML 을 활용해 사람이 개입할 필요가 없는 완전한 자동화 시스템을 구축하는 경우이다. 자율주행 등을 예시로 들 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 의 경우, &lt;strong&gt;ML 적용이 실제 성능 개선에 도움이 되는지&lt;/strong&gt;를 꼼꼼하게 점검해 볼 필요가 있다. 또한 서비스 배포 후 data flywheel, 즉 신규 데이터를 기반으로 모델을 개선시킬 수 있는 사이클이 구축될 수 있는지 또한 검토가 필요하다.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 &lt;strong&gt;사용자가 어떠한 배경, 환경을 가지고 모델을 활용하는지&lt;/strong&gt;를 염두해야 하며, &lt;strong&gt;그들의 니즈 또한 파악&lt;/strong&gt;할 필요가 있다. 유저에게 실질적인 도움을 제공하려면 어느 정도 수준의 성능을 보여야 하는지 등을 고려해야 한다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 &lt;strong&gt;실패율과 그에 따른 결과&lt;/strong&gt;에 집중할 필요가 있다. 사람이 개입할 여지가 없다면 실패 케이스들을 면밀하게 주시해야 하며, 자율주행이 이에 대한 좋은 예시라고 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;언급했듯 Software 2.0 프로젝트 내에선 data flywheel 개념을 곱씹을 필요가 있다. 경우에 따라 차이가 존재할 수 있지만, 대체로 유저의 데이터를 수집하여 모델 개선에 활용한다면 성능이 서비스 기간이 지남에 따라 개선될 가능성이 높다.&lt;/li&gt;
&lt;li&gt;data flywheel 을 구축하기 전, 다음과 같은 3가지 질문에 대한 답이 필요하다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 loop 이 존재하는가?&lt;/strong&gt; Data flywheel 을 구축하기 위해서는 정제된 데이터를 스케일링이 가능한 방식으로 유저로 부터 수집할 수 있어야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;더 많은 데이터가 더 나은 모델과 상응하는가?&lt;/strong&gt; 모델러의 역량과는 별개로 문제 특성상 더 많은 데이터가 더 나은 모델을 의미하지 않는 경우가 발생할 수 있다. data flywheel 시스템 구축 전 더 많은 데이터가 가치를 전달하는지를 확실히 해 둘 필요가 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델의 성능이 제품 활용성에 기여하는가?&lt;/strong&gt; 보다 근본적인 질문인데, 모델의 성능 개선이 유저의 경험에 긍정적으로 기여할 수 있는지 또한 짚고 넘어가야 할 부분이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;상단 이미지는 &lt;strong&gt;영향성 vs. 실현 가능성&lt;/strong&gt; 그래프에서 정의된 3가지 타입의 과제가 상대적으로 어디에 위치해 있는지를 보여준다. 대체로 &lt;strong&gt;모델을 구축하기 힘들수록 더 큰 영향을 끼친다&lt;/strong&gt;라는 규칙이 통용된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 는 data flywheel 구축을 통해 더 큰 영향력을 가질 수 있다. 모델의 성능이 증가하며, 이로 인한 사용자의 경험이 계속 개선되기 때문.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 충분한 고민이 반영된 설계 과정, 혹은 적절한 단계에서 배포 후 점차 성능을 개선시킨다는 &amp;ldquo;good enough&amp;rdquo; 마인드 셋이 제품에 대한 기대치와 목표 성능을 낮추는데 도움을 줄 수 있다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 사람의 개입을 유도해 모델의 실패에 대비하는 체계가 도움을 줄 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 결국 엔지니어링의 가장 중요한 측면은 &lt;strong&gt;무언가를 만드는 일&lt;/strong&gt;이다. 우리는 Google, Uber 와 항상 같은 환경을 구축할 필요가 없으며, 최신 툴과 완벽한 체계를 추구하기 전 먼저 문제에 대한 해결책을 찾는 것이 핵심이라는 점을 상기해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lifecycle&#34;&gt;Lifecycle&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 프로젝트가 계획적/단계적으로 진행되기엔 현실적으로 어려운 부분이 많으며, 중간 과정에서 발견된 인사이트로 인해 이전 단계의 작업을 번복하거나, 성능 요건을 재정의 하는 등 단계 별 작업이 병렬적으로 진행되는 경향이 있다.&lt;/li&gt;
&lt;li&gt;본 부트캠프는 이러한 프로젝트 lifecycle 의 각 단계를 가급적 성공적으로 수행하는 방법을 전달하고, 채용, 인프라 등 프로젝트 외 요소들 또한 어떻게 다루어야 하는지 공유한다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Overview</title>
        <link>https://meme2515.github.io/mlops/fsdl/</link>
        <pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_title.jpg" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Overview" /&gt;&lt;h2 id=&#34;부트캠프-소개-및-전반적인-느낌&#34;&gt;부트캠프 소개 및 전반적인 느낌&lt;/h2&gt;
&lt;p&gt;회사분의 소개로 2022년 코호트의 일환이 되었다. Early Registration 으로 495 달러인 참가비보다 약간 저렴한 300 달러를 지불했고, 돈을 내면서 까지 참가하고 싶다는 생각이 들기까지는 카일님의 블로그에 올라온 &lt;a class=&#34;link&#34; href=&#34;https://zzsza.github.io/mlops/2019/10/06/fullstack-deeplearning-bootcamp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;긍정적인 리뷰&lt;/a&gt; 도 중요한 역할을 했던 것 같다.&lt;/p&gt;
&lt;p&gt;강사진들도 직접 언급하는 부분이지만, 널리 알려진 것과 다르게 해당 부트캠프 과정은 MLOps 개론과는 거리가 있다. 그저 MLOps 란 기본적으로 어떤 구성을 가지며, 더 배우고 싶다면 어떠한 분야들을 더 탐색해야 하는지에 대한 소개만을 할 뿐이며, 사실 강사진이 집중하는 영역은 좋은 ML 모델 서비스를 만들기 위해서는 어떠한 부분들을 신경써야 하는지에 대한 노하우 전수에 더 가깝다고 할 수 있다.&lt;/p&gt;
&lt;p&gt;한가지 예를 들자면 8주차 강의는 ML 조직 구성과 프로젝트 운영 방법론을 심도있게 다루고 있다. 알고리즘 등을 깊이있게 탐구하기 좋아하는 주니어들이 깊게 고민하지 않을 수 있는 주제이지만, 결국 제품을 만드는건 사람이기 때문에 foundation 모델, MLOps 와 같은 레벨에서 주제를 다루고 있는 것.&lt;/p&gt;
&lt;p&gt;전반적인 인상은 굉장히 좋았고, 직장에서 놓쳤던 요소들을 다른 업계 선배들에게 배운다는 느낌이 강하게 들었다. 모든 수업 자료가 유튜브에 공개되어 있기 때문에 만약 몇년 후 다시 참여할 의사가 생긴다면 저렴하지 않은 비용을 다시 지불하지는 않을 것 같다.&lt;/p&gt;
&lt;p&gt;실용적인 ML을 추구하기 때문에 강사진의 업계 경험 및 배경 또한 중요하다고 생각했다. 강사진은 버클리 대학에서 박사과정을 마친 이력을 공유하고 있고, Weights &amp;amp; Biases, OpenAI 등의 기업에서의 실무 경험을 가지고있다. 개별적인 강사진의 공개된 이력은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/charles-frye-38654abb/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Charles Frye&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Chicago 학부 졸업 (Computational Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;Weights &amp;amp; Biases 2년 근무&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/sergeykarayev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sergey Karayev&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Washington 학부 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;Turnitin 2년 근무 (교육 관련 소프트웨어 개발사)&lt;/li&gt;
&lt;li&gt;GSV Ventures 3년 근무 (벤처 캐피탈)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/josh-tobin-4b3b10a9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Josh Tobin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Columbia University 학부 졸업 (Mathematics 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;McKinsey &amp;amp; Company 2년 근무&lt;/li&gt;
&lt;li&gt;OpenAI 3년 근무&lt;/li&gt;
&lt;li&gt;Gantry 창업 (ML 스타트업)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>(논문 리뷰) Scene Text Recognition 을 위한 CRNN 구조</title>
        <link>https://meme2515.github.io/neural_network/crnn/</link>
        <pubDate>Sat, 26 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/crnn/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/crnn_2.png" alt="Featured image of post (논문 리뷰) Scene Text Recognition 을 위한 CRNN 구조" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;CRNN 구조는 학계에서 CNN/RNN 구조에 대한 연구가 탄력을 받고있던 2015년, 중국의 화중과기대에서 공개한 &lt;strong&gt;Scene Text Recognition (일상 이미지 속 테스트 인식 과제)&lt;/strong&gt; 모델이다. 이후 어텐션 구조가 추가된 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.researchgate.net/figure/The-network-structure-of-MA-CRNN-The-whole-network-consists-of-three-parts-1_fig2_337288162&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MA-CRNN&lt;/a&gt;&lt;/strong&gt; 등 다양한 변형 모델이 공개되었으나, 현재까지 널리 쓰이는 오픈소스 OCR 라이브러리인 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/JaidedAI/EasyOCR&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;EasyOCR&lt;/a&gt;&lt;/strong&gt; 의 문자 인식 모듈은 논문에서 공개된 모델 구조를 그대로 따르고있다 (참고로 해당 라이브러리의 문자 감지 모듈은 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/clovaai/CRAFT-pytorch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;네이버의 CRAFT&lt;/a&gt;&lt;/strong&gt; 모델을 사용한다).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_3.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. EasyOCR, 다양한 언어의 문자 인식 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;CRNN 이란 이름에서 보이듯 전통적인 CNN 과 RNN 의 구조를 합성한 형태를 가지고 있다. 자칫 트렌디한 두 구조를 엮어 이목을 끄려는 목적으로 보여질 수 있지만, Scene Text Recognition 이라는 적절한 과제 선정으로 관련 분야 연구에 적지않은 영향을 끼쳤다. 또한 두 모델 구조의 결합 후에도 단일 학습이 가능하다는 점, &lt;strong&gt;CTC 손실 함수&lt;/strong&gt; 사용으로 프레임 별 레이블링 작업을 필요로 하지 않는다는 점에서 실사용도가 높다는 장점을 가지고있다.&lt;/p&gt;
&lt;h2 id=&#34;네트워크-구조&#34;&gt;네트워크 구조&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;CRNN 네트워크는 크게 Convolution Layer (합성곱 레이어), Recurrent Layer (순환 레이어), Transcription Layer 3가지 모듈로 구성되어있다.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;합성곱 레이어는 우선 이미지의 영역 별 feature 를 추출하며, 순환 레이어가 추출된 각 이미지 영역에 속한 텍스트를 순차적으로 예측하게 된다. 합성곱 연산은 단어 (word) 별 문자열 (character) 영역을 구분하지 못하기 때문에 추출된 feature 사이에 중첩 영역이 발생할 수 있는데 &lt;em&gt;(예. -s-t-aatte)&lt;/em&gt; Transcription Layer 는 이를 실제 단어로 정리하는 역할을 수행한다 &lt;em&gt;(예. state)&lt;/em&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. CRNN 기본 구조&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;convolution-layer&#34;&gt;Convolution Layer&lt;/h3&gt;
&lt;p&gt;인풋된 이미지 데이터가 최초로 처리되는 영역이며 전통적인 CNN 구조에서 fully-connected layer 를 제외해 feature 아웃풋에 상응하는 원본 이미지의 영역 (receptive field) 이 특정되도록 설계되었다. 보다 디테일한 포인트들을 언급하자면 인풋 이미지는 항상 같은 높이값을 가지도록 조정되며, 아웃풋이 n 채널을 가진다면 동일한 영역에 대한 모든 채널의 합산 값을 feature 로 정의한다.&lt;/p&gt;
&lt;p&gt;또한 이미지의 Text 영역이 이미 추출되었다고 가정하기 때문에 좌우 움직임을 가지는 영역 sequence 고려하게 된다 &lt;em&gt;(인풋 이미지가 두 줄 이상이라면 처리가 어려울 것).&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Feature Sequence 와 Receptive Field 간 1-to-1 매칭 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;recurrent-layer&#34;&gt;Recurrent Layer&lt;/h3&gt;
&lt;p&gt;합성곱 레이어에 의해 아웃풋된 feature sequence, $X = x_1, x_2, &amp;hellip; , x_T$, 는 순서가 특정 가능하기 때문에 각 프레임 $x_t$ 에 대한 레이블 분포 $y_t$ 를 예측하는 순환 레이어의 인풋으로 활용된다.&lt;/p&gt;
&lt;p&gt;논문의 저자는 RNN 구조 활용의 장점을 다음과 같이 정리한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이미지 context 에 대한 정보를 활용하기 때문에 이전 문자열 (character) 또는 단어 (word) 에 기반한 예측이 가능하며, 여러개 feature 영역 (receptive field) 이 한개 문자열에 걸쳐있는 경우, &amp;ldquo;il&amp;rdquo; 과 같이 상대적인 비교가 필요한 경우 또한 성능 향상을 기대할 수 있다.&lt;/li&gt;
&lt;li&gt;역전파 수행이 가능하기에 CNN 레이어와 함께 학습할 수 있다.&lt;/li&gt;
&lt;li&gt;인풋 sequence 의 길이가 중요하지 않다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;또한 저자는 sequence 간 거리에 비례해 발생하는 &lt;a class=&#34;link&#34; href=&#34;https://velog.io/@yunyoseob/Gradient-Vanishing-%EA%B8%B0%EC%9A%B8%EA%B8%B0-%EC%86%8C%EC%8B%A4#:~:text=Gradient%20Vanishg%20%EB%AC%B8%EC%A0%9C%EB%8A%94%20%EC%8B%A0%EA%B2%BD%EB%A7%9D,%EC%88%98%20%EC%97%86%EA%B2%8C%20%EB%90%98%EB%8A%94%20%EB%AC%B8%EC%A0%9C%EC%9E%85%EB%8B%88%EB%8B%A4.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gradient vanishing problem&lt;/a&gt;, RNN 의 단방향성 문제 등을 해결하기 위해 당시 널리 사용된 &lt;a class=&#34;link&#34; href=&#34;https://techbrad.tistory.com/38&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bidirectional LSTM&lt;/a&gt; 구조를 채택했다.&lt;/p&gt;
&lt;h3 id=&#34;transcription-layer&#34;&gt;Transcription Layer&lt;/h3&gt;
&lt;p&gt;Transcription 이란 프레임 단위로 추출된 RNN 레이어의 예측값 &lt;em&gt;(예. -s-t-aatte)&lt;/em&gt;  을 실제 단어로 &lt;em&gt;(예. state)&lt;/em&gt; 변환하는 과정을 칭한다. 수학적으로는 RNN 레이어가 예측한 프레인 단위 시퀀스가 주어졌을때 가장 높은 확률을 가진 실제 단어 시퀀스를 연산하는 조건부 확률 모델이며, 저자는 예측 가능한 단어 시퀀스에 있어 실제 사전을 참조하는 lexicon 모드와 단순 확률값에 기반한 lexicon-free 모드를 모두 구현하였다. 또한 프레임 단위 시퀀스에 따른 조건부 확률은 &lt;strong&gt;Connectionist Temporal Classification (CTC)&lt;/strong&gt; 에 기반하여 계산된다.&lt;/p&gt;
&lt;h2 id=&#34;ctc&#34;&gt;CTC&lt;/h2&gt;
&lt;p&gt;CTC 에 대한 개념은 사실 음성인식 문제를 해결하기 위해 등장했다. &lt;a class=&#34;link&#34; href=&#34;https://brightwon.tistory.com/11&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MFCC&lt;/a&gt; 와 같은 음성 피처는 대게 짧은 시간 단위로 쪼개서 생성하게 되는데, 전통적인 손실 함수를 이용하고자 한다면 이러한 프레임 각각에 레이블을 달아주어야 하기 때문에 공수가 크게 들고 정확도 또한 떨어진다는 문제가 발생한다. 때문에 CTC 는 음성 인풋의 프레임 시퀀스와 타깃 문자열 시퀀스간의 명시적인 alignment 없이 모델 학습이 가능하도록 고안되었다.&lt;/p&gt;
&lt;p&gt;예측 파이프라인은 하단 도식화와 같이 구성된다. 우선 프레임 별 레이블을 예측한 후, 중첩되는 레이블을 하나로 묶어주는 작업과 &lt;em&gt;(예. lll -&amp;gt; l)&lt;/em&gt; 공란을 뜻하는 epsilon 값에서 예측 값을 바꾸는 작업을 수행한다 &lt;em&gt;(예. ee lll -&amp;gt; el)&lt;/em&gt;. 보다 자세한 내용은 네이버 이기창님의 &lt;a class=&#34;link&#34; href=&#34;https://ratsgo.github.io/speechbook/docs/neuralam/ctc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ratsgo 블로그&lt;/a&gt;에 기술되어 있으니 참고하면 좋을듯 하다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. CTC Input 과 프레임 시퀀스 별 예측치, 최종 아웃풋 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;lexicon-활용&#34;&gt;Lexicon 활용&lt;/h2&gt;
&lt;p&gt;언어 예측 분야에서는 예측된 시퀀스의 품질을 보장하기위해 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;http://hunspell.github.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hunspell Spell Checking Dictionary&lt;/a&gt;&lt;/strong&gt; 와 같은 렉시콘 (Lexicon, 어휘 사전) 을 사용하고는 한다. 본 논문은 아웃풋이 이와 같은 렉시콘에 의해 처리된 lexicon-based mode, 그렇지 않은 lexicon-free mode 를 모두 구현하고 있다.&lt;/p&gt;
&lt;h3 id=&#34;lexicon-free-transcription&#34;&gt;Lexicon-free Transcription&lt;/h3&gt;
&lt;p&gt;Lexicon-free mode 는 처리된 최종 레이블 시퀀스 아웃풋을 별도 검증 과정 없이 그대로 출력하게 된다. 상단 Fig 4. 의 &amp;ldquo;hello!&amp;rdquo; 예측값이 실제 사전에 존재하는지 여부는 고려되지 않으며, 인터넷 언어와 같이 어휘 검증이 어려운 경우 적합할 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;lexicon-based-transcription&#34;&gt;Lexicon-based Transcription&lt;/h3&gt;
&lt;p&gt;예측값을 어휘 사전과 비교해 아웃풋 가능한 레이블 시퀀스의 영역을 한정하게된다. 다만 어휘 사전이 클 경우 모든 레이블에 대한 비교에 지나치게 큰 연산 자원과 시간이 소모되기 때문에, 저자는 예측치와 어휘 사전에 포함된 단어들 간 거리를 계산한 후 가장 가까운 거리에 있는 어휘 사전 단어들로 탐색 영역을 한정하는 Nearest-Neighbor 방식을 사용한다.&lt;/p&gt;
&lt;p&gt;이때 거리란 단어 A 에서 단어 B 로 변형되기까지의 수정 횟수를 뜻하는 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://hoony-gunputer.tistory.com/entry/%EB%A0%88%EB%B2%A4%EC%8A%88%ED%83%80%EC%9D%B8-%EA%B1%B0%EB%A6%AC%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4%EC%84%9C-%EB%91%90-%EB%AC%B8%EC%9E%A5-%EB%B9%84%EA%B5%90%ED%95%98%EA%B8%B0#:~:text=%EB%A0%88%EB%B2%A4%EC%8A%88%ED%83%80%EC%9D%B8%20%EA%B1%B0%EB%A6%AC%EB%8A%94%20%EB%8F%85%EC%9D%BC%EC%9D%98,%EB%8B%A4%EB%A5%B8%EC%A7%80%20%EA%B5%AC%EB%B6%84%ED%95%98%EB%8A%94%20%EB%B0%A9%EB%B2%95%EC%9D%B4%EB%8B%A4.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Levenshtein Distance&lt;/a&gt;&lt;/strong&gt; 로 정의한다 &lt;em&gt;(예. help 와 hello 간 거리는 help -&amp;gt; hell -&amp;gt; hello 두 번의 수정을 필요로 하기때문에 2가 된다)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Nearest-Neighbor 후보군을 탐색하는 과정은 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;%28https://medium.com/future-vision/bk-trees-unexplored-data-structure-ec234f39052d%29&#34; &gt;Burkhard-Keller Tree (BK-tree)&lt;/a&gt;&lt;/strong&gt; 데이터 구조를 활용해 효율적으로 수행이 가능하다. 이는 1973년도에 &lt;strong&gt;문자열에 대한 근사값을 빠르게 찾도록 설계된 트리 구조&lt;/strong&gt;인데, 각 노드는 단어 정보를, 엣지는 단어 간 Levenshtein 거리값을 가지게 된다. 부모 노드에 연결된 자식 노드들은 모두 다른 Levenshtein 거리값을 가져야하며, 같은 거리값을 가진 단어가 추가된다면 중첩되는 단어의 자식 노드로 추가되는 식이다.&lt;/p&gt;
&lt;p&gt;새로운 단어 (query) 에 가장 유사한 단어를 찾을때는 임곗값 (threshold) 을 특정해줘야 한다. 먼저 루트 단어 (root) 와 쿼리 단어 간 거리 $D = \text{Levenshtein}(\text{root}, \text{query})$ 를 측정한 후, 해당 거리가 임곗값보다 크다면 $D - \text{threshold}$, $D + \text{threshold}$ 사이의 엣지값을 가진 자식 노드들에서 동일한 작업을 재귀적으로 수행한다. 이 과정에서 임곗값 안에 들어오는 단어가 발견되면 리턴 하게된다. 논문 저자에 따르면 이러한 알고리즘은 렉시콘 크기 $|D|$ 에 대해 $O(log(|D|))$ 효율성을 가지게 된다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Burknard-Keller Tree 구조 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;모델-성능&#34;&gt;모델 성능&lt;/h2&gt;
&lt;p&gt;IIIT5k, SVT, IC03, IC13 4개 데이터셋에 비해 2015년 당시 최신 모델과 견줄만한 성능을 기록했다. 또한 비언어 문제인 악보 인식 또한 기존 모델보다 월등한 성능을 보여 모든 시퀀스 인식 분야에 적용될 수 있음을 시사했다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 6. CRNN 모델의 성능 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;레퍼런스&#34;&gt;레퍼런스&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://tw0226.tistory.com/90&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://tw0226.tistory.com/90&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1507.05717.pd&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/pdf/1507.05717.pd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ratsgo.github.io/speechbook/docs/neuralam/ctc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ratsgo.github.io/speechbook/docs/neuralam/ctc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/future-vision/bk-trees-unexplored-data-structure-ec234f39052d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://medium.com/future-vision/bk-trees-unexplored-data-structure-ec234f39052d&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>(논문 리뷰) 핵심만 추려낸 VGGNet 논문 요약</title>
        <link>https://meme2515.github.io/neural_network/vggnet/</link>
        <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/vggnet/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/vggnet_1.jpg" alt="Featured image of post (논문 리뷰) 핵심만 추려낸 VGGNet 논문 요약" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;컨볼루션 필터를 아주 작은 사이즈 (3x3) 로 고정해, 당시로서는 획기적으로 깊은 16~19 레이어 CNN 을 구축해 네트워크의 깊이가 신경망 모델의 성능에 끼치는 영향을 연구한 교과서적인 논문이다. 저자는 이러한 인사이트를 바탕으로 2014년 ImageNet Challenge 우승 모델을 구축했는데, 불과 2년전 우승 모델인 &lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/neural_network/alexnet/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AlexNet&lt;/a&gt; 이 8 레이어로 구축됐던 것을 감안하면 네트워크의 깊이가 빠르게 상승한 것을 볼수있다 (2015년 대회에선 152 레이어의 ResNet이 등장). 해당 글에서는 네트워크의 하이퍼파라미터, 세부 구조에 대한 내용을 제외한 핵심 내용만을 전달하고자 하며, 본문은 &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1409.1556.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;여기&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;
&lt;h2 id=&#34;네트워크-구조&#34;&gt;네트워크 구조&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 6개 VGGNet 모델 아키텍처&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;네트워크 깊이 변화에 따른 성능의 차이를 검증하기 위해 논문에 등장하는 6개 모델은 모두 동일한 세팅을 가지고있다. 언급했던 필터 (커널) 사이즈가 3x3 인 이유는 상하좌우 픽셀을 고려할 수 있는 최소 크기이기 때문이며, 필터가 작을수록 다음 레이어에서 정보유실이 적다는 점을 이용해 신경망의 깊이를 키우는 목적을 가지고 있다. 컨볼루션 레이어 이후에 FC 레이어가 뒤따르고, 마지막 softmax 레이어를 통해 분류 예측을 수행하는 전통적인 CNN 구조를 계승하고있다.&lt;/p&gt;
&lt;p&gt;A 부터 E 까지의 알파벳 순으로 네트워크의 깊이와 복잡도가 증가하고, 이에 불구하고 작은 필터 사이즈로 인해 이전에 등장한 네트워크와 비교해 가중치 개수가 크게 차이나지 않는다. 네트워크 구조에 대해 언급할만한 부분은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AlexNet 에 등장했던 LRN 레이어를 모델 A에 적용 후, 저자는 LRN 이 모델 성능에 크게 기여하지 않는다고 판단해 이후 모델에 LRN 을 적용하지 않는다.&lt;/li&gt;
&lt;li&gt;모델 C 는 모델 B 에 1x1 필터를 추가한 것이다. 인/아웃 채널 수가 같기 때문에 channel reduction 역할은 수행하지 않고, 단순한 activation 레이어의 추가라고 보는 것이 타당하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3x3-컨볼루션-필터&#34;&gt;3x3 컨볼루션 필터&lt;/h3&gt;
&lt;p&gt;본 논문 이전에 등장한 CNN 구조는 대부분 7x7, 5x5 등의 컨볼루션 필터 (커널) 를 사용하며, 초기 레이어에서 상대적으로 더 큰 필터 사이즈를 적용한다 (AlexNet 의 경우 11x11 w/ stride 4).  이에 반해 VGGNet 은 네트워크는 필터 사이즈를 3x3 으로 최소화하여 네트워크의 깊이를 19 레이어까지 끌어올렸다. 언급했듯 이는 작은 필터 사이즈가 레이어 간 정보유실을 최소화하기 때문인데, 논문의 저자는 이에 대한 부연 설명으로 7x7 필터가 적용된 한개 레이어가 3x3 필터가 적용된 세개 레이어와 사실상 같은 기능을 한다는 점을 언급한다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 예시는 5x5 필터 레이어 1개와 3x3 필터 레이어 2개 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;그렇다면 VGGNet 과 같이 필터 사이즈를 줄이고, 레이어 수를 늘린 경우엔 어떤 이점이 있을까? 첫째로 ReLU (혹은 다른 activation) 레이어가 여러번 적용되기 때문에 네트워크가 가장 핵심적인 정보만 추려내도록 유도하는 것이 가능하다. 둘째로 학습이 필요한 파라미터 수가 상당히 감소하게된다. 인풋/아웃풋의 채널수가 모두 C 로 동일하다 가정했을 때, 3x3 필터로 구성된 3 레이어 네트워크는 $3^2 C^2 = 27 C^2$ 파라미터를 가지게되는 반면, 7x7 필터로 구성된 1 레이어 네트워크는 $7^2 C^2 = 49 C^2$ 파라미터를 가지게 됨으로 전자 대비 약 181% 의 파라미터로 구성된다. 이에 따라 VGGNet 은 학습속도 개선, 과적합 방지 효과를 누리게 된다고 저자는 결론짓는다.&lt;/p&gt;
&lt;h2 id=&#34;모델-학습-과정&#34;&gt;모델 학습 과정&lt;/h2&gt;
&lt;h3 id=&#34;전이-학습&#34;&gt;전이 학습&lt;/h3&gt;
&lt;p&gt;깊어진 네트워크의 복잡성으로 인해 적절한 초기 가중치 세팅 (weight initilization) 없이는 네트워크 학습이 어려운 문제가 발생한다. 이를 해결하기 위해 저자는 레이어 수가 가장 적은 A 모델을 pre-train 모델로 활용하여, 더 깊은 모델 학습 시 레이어를 이어 붙이고, 이후 fine-tuning 을 진행한다.&lt;/p&gt;
&lt;h3 id=&#34;이미지-리사이징&#34;&gt;이미지 리사이징&lt;/h3&gt;
&lt;p&gt;네트워크는 기본적으로 인풋 이미지에서 랜덤하게 크롭된 224x224 이미지를 처리한다. 이러한 인풋 크롭이 진행되기 전, 이미지는 가로세로 비율이 유지되는 상태에서 리스케일되는데 (isotropical rescale - 1024x512 이미지가 512x256 사이즈로 리스케일 되어 2:1 비율을 유지하는 식), 리스케일 후 가로세로 중 더 작은 면의 이미지 크기를 학습 시 $S$, 테스팅 시 $Q$ 라 칭한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학습은 $S$ 를 256 또는 384로 고정하는 single-scale 방식, 혹은 이미지 별로 256 과 512 사이 랜덤한 숫자를 부여하는 multi-scale 방식으로 나뉘어진다.&lt;/li&gt;
&lt;li&gt;테스팅은 $Q$ 를 256 또는 384로 고정하는 single-sclae 방식, 혹은 224, 256, 288, 416, 512 중 세가지 숫자에서 랜덤하게 부여하는 multi-scale 방식으로 나뉘어진다.&lt;/li&gt;
&lt;li&gt;학습과 테스팅은 single/multi-sclae 방식의 조합 (single-multi, multi-single 도 가능) 으로 이루어진다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_4.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Multi-Scale 리사이징 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;fc-layer---conv-layer&#34;&gt;FC layer -&amp;gt; Conv. layer&lt;/h3&gt;
&lt;p&gt;모델 뒷단에 위치한 FC (Fully Connected) 레이어는 파라미터 수가 고정되어있기 때문에 학습에 활용된, 고정된 사이즈의 이미지만 처리할 수 있다. 때문에 저자는 학습에 활용된 FC 레이어를 컨볼루션 레이어로 변경하여, 각자 다른 크기의 최종 아웃풋에서 평균치를 구하는 방식으로 (Averaged Sum-Pooling) softmax 레이어를 연산한다. 구체적인 레이어 변경 방식과 Sum-Pooling 방식은 논문에 언급되어있지 않으나, 다음 이미지를 참고하면 대략적인 접근법이 이해될 것이다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_5.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. Conv. layer 변환 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;모델-성능&#34;&gt;모델 성능&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Single Test Scale 성능 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;여기서 top-1, top-5 error rate 란 AlexNet 과 동일하게 가장 높은 확률로 예측된 1개, 5개 레이블 중 실제 레이블이 포함되어 있는 비율이다. 모델의 깊이가 깊어질 수록 성능이 증가하며, LRN 레이어가 성능에 오히려 악영향을 끼치는 점을 확인할 수 있다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Multiple Test Scale 성능 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;저자는 모델의 성능은 깊이에 비례하며, 동일한 깊이라도 1x1 convolution 레이어보다 3x3 convolution 레이어를 구성하는 것이 성능에 도움이 된다는 점을 발견한다. 또한 test 이미지 사이즈가 고정된 경우, 랜덤하게 선택된 경우 모두 학습 시 랜덤한 이미지 사이즈를 사용한 경우에 모델 성능이 가장 좋았으며, 저자는 이러한 방식이 데이터 증강 역할을 수행해 이미지들에 대한 통계치를 얻는 것에 도움이 되었다고 결론짓는다.&lt;/p&gt;
&lt;p&gt;VGGNet 은 2014년 ILSVRC 챌린지에서 GooGLeNet 다음으로 2등을 차지했다. 마지막으로 저자는 VGGNet 이 다양한 task 와 데이터셋에서 높은 범용성을 보인다는 점을 언급한다.&lt;/p&gt;
&lt;h2 id=&#34;레퍼런스&#34;&gt;레퍼런스&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1409.1556.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/pdf/1409.1556.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://oi.readthedocs.io/en/latest/computer_vision/cnn/vggnet.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://oi.readthedocs.io/en/latest/computer_vision/cnn/vggnet.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://bskyvision.com/504&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://bskyvision.com/504&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>AdaBoost 를 통한 Boosting 개념 이해</title>
        <link>https://meme2515.github.io/machine_learning/adaboost/</link>
        <pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/machine_learning/adaboost/</guid>
        <description>&lt;img src="https://meme2515.github.io/machine_learning/images/adaboost.png" alt="Featured image of post AdaBoost 를 통한 Boosting 개념 이해" /&gt;&lt;h2 id=&#34;앙상블-학습&#34;&gt;앙상블 학습&lt;/h2&gt;
&lt;p&gt;앙상블 학습이란 트리 계열 모델 뿐만이 아니라 신경망, 회귀식 등 다양에 형태의 모델에 적용할 수 있다. 예측력이 낮지만 연산 부담 또한 적은 여러개의 모델을 조합해, 하나의 복잡한 모델보다 향상된 성능의 아웃풋을 내는 것을 목적으로 하고 있는데, 특히 Kaggle 등의 데이터 대회에서 트리 계열의 앙상블 학습법은 비신경망 모델링 중 최상위권의 성능을 보여주고있다.&lt;/p&gt;
&lt;p&gt;앙상블 학습법은 크게 Bagging, Stacking, Boosting 으로 분류할 수 있으며, 이 중 가장 복잡하지만 성능이 높은 Boosting 알고리즘을 초기 알고리즘인 AdaBoost 를 통해 설명하고자 한다.&lt;/p&gt;
&lt;h3 id=&#34;bagging--stacking&#34;&gt;Bagging &amp;amp; Stacking&lt;/h3&gt;
&lt;p&gt;Bagging 알고리즘은 &lt;strong&gt;homogenous 한 여러 모델의 조합이다&lt;/strong&gt;. 여기서 homogenous 라 함은 모델의 종류가 하나인, 예를 들어 결정 트리만으로 이루어진 앙상블 모델 등을 의미하며, &lt;strong&gt;개별 모델의 학습은 독립적으로 이루어지게 된다&lt;/strong&gt;. 널리 알려진 랜덤 포레스트 알고리즘은 이러한 Bagging 알고리즘에 데이터 샘플링을 적용한 경우이다.&lt;/p&gt;
&lt;p&gt;Stacking 알고리즘은 이와 다르게 &lt;strong&gt;heterogenous, 즉 서로 다른 종류의 모델의 독립적인 조합&lt;/strong&gt;으로 설명할 수 있다. GLM, 신경망, Bagging 앙상블 모델 등을 조합한 모델을 그 예시로 들 수 있으며, 따라서 모델의 의미를 직관적으로 해석하기에 많은 어려움이 따를 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;boosting&#34;&gt;Boosting&lt;/h3&gt;
&lt;p&gt;Boosting 알고리즘은 &lt;strong&gt;개별 모델의 학습이 이전 모델의 성능에 따라 순차적으로 이루어지는&lt;/strong&gt; 앙상블 학습 방식이다. 따라서 각 모델의 학습은 독립적으로 이루어지지 않으며, 대표적인 예시로 AdaBoost, Gradient Boosting 등을 들 수 있다.&lt;/p&gt;
&lt;h2 id=&#34;adaboost&#34;&gt;AdaBoost&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AdaBoost (Adaptive Boosting)&lt;/strong&gt; 은 1995년 학계에 공개된 이진 분류 모델이다. 유사한 트리 기반 모델인 랜덤 포레스트 알고리즘 또한 같은 연도에 공개되었는데, 이 글에서는 유명한 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=LsK-xG1cLYA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;StatQuest 비디오&lt;/a&gt;를 참고하여 AdaBoost, 랜덤 포레스트 간의 차이점을 기반으로 개념을 소개하고자 한다. 글을 읽기 전 &lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/machine_learning/decision_tree/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;결정 트리&lt;/a&gt;, 랜덤 포레스트 등의 개념을 이해하고 있다는 것을 전제로 하고 있다.&lt;/p&gt;
&lt;p&gt;AdaBoost 알고리즘을 랜덤 포레스트와 구분짓는 중요한 포인트는 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;랜덤 포레스트의 각 트리는 그 자체로 하나의 완전한 결정 트리 모델인 반면, AdaBoost의 각 트리는 &lt;strong&gt;Stump 라는, 한 개 특성을 대상으로 한 번의 분류만을 수행하는 weak learner&lt;/strong&gt; 이다.&lt;/li&gt;
&lt;li&gt;랜덤 포레스트 모델은 각 트리에 동일한 가중치를 적용해 최종 분류값를 결정하는 반면, AdaBoost 는 &lt;strong&gt;트리마다 서로 다른 가중치를 적용한다&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;랜덤 포레스트의 트리는 서로의 학습에 영향을 끼치지않는, 독립적인 모델인 반면 AdaBoost의 각 트리는 &lt;strong&gt;이전 모델의 오분류 케이스를 기반으로, 순차적으로 학습된다&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/adaboost_1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Random Forest 와 AdaBoost 의 차이점&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;stump-생성&#34;&gt;Stump 생성&lt;/h3&gt;
&lt;p&gt;결정 트리 한 개 학습 사이클과 동일하다고 생각하면 된다. 우선 &lt;strong&gt;각 특성 마다 지니 불순도와 CART 알고리즘을 기반으로 한 최적의 임곗값을 특정한 후, 특성 별 모델 중 지니 불순도가 가장 낮은 특성/모델을 기반으로 Stump 를 생성하게 된다.&lt;/strong&gt; 한 개 특성을 대상으로 한 번의 분류만을 수행하기 때문에 (1) 키가 176 보다 크다, (2) 몸무게가 50kg 이상이다 등의 아주 기초적인 분류만을 수행하게 된다.&lt;/p&gt;
&lt;h3 id=&#34;amount-of-say&#34;&gt;Amount of Say&lt;/h3&gt;
&lt;p&gt;Stump 를 생성한 직후에는 &lt;strong&gt;앙상블 모델에 해당 Stump 가 기여할 가중치, Amount of Say (AoS) 를 부여하게된다&lt;/strong&gt;. 이러한 개별 모델의 AoS 는 해당 모델의 분류 정확도에 기반하게 되며, 여기서 &lt;strong&gt;분류 정확도란 지니 계수가 아닌 오분류된 데이터 샘플의 가중치 합, Total Error&lt;/strong&gt; 이다. 데이터의 가중치는 AoS 와는 다른 개념이다. Stump 가 분류하기 어려워하는 데이터를 특정한 후, 이에 더욱 큰 가중치를 부여해 이후 학습에서 강조하는 역할을 한다. 모든 데이터의 가중치 합은 항상 1 이어야 하며, 최초 학습 시 모든 데이터는 동일한 가중치를 부여 받는다.&lt;/p&gt;
&lt;p&gt;AoS 를 구하는 수식은 다음과 같이 정리할 수 있으며, 마치 sigmoid 함수를 90도 돌려놓은 듯한 모양을 가지고있다. 따라서 분류 정확도가 낮아지거나, 높아질수록 AoS 값은 극단적으로 변하게된다.&lt;/p&gt;
&lt;p&gt;$$
\text{AoS} = \frac{1}{2} \text{log} (\frac{1 - \text{total error}}{\text{total error}})
$$&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/adaboost_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Amount of Say&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;오분류된 데이터를 강조한다는 룰에 따라 데이터 별 가중치는 잘못 분류된 경우 증가하고, 제대로 분류된 경우 감소하게 된다.&lt;/p&gt;
&lt;p&gt;오분류된 데이터의 가중치를 증가시키는 경우, 새로운 가중치는 다음과 같이 정의된다.&lt;/p&gt;
&lt;p&gt;$$
\text{새로운 샘플 가중치} = \text{현재 샘플 가중치} \cdot e^{AoS}
$$&lt;/p&gt;
&lt;p&gt;반대로 정분류된 데이터의 가중치를 감소시키는 경우, 새로운 가중치는 다음과 같이 정의된다.&lt;/p&gt;
&lt;p&gt;$$
\text{새로운 샘플 가중치} = \text{현재 샘플 가중치} \cdot e^{-AoS}
$$&lt;/p&gt;
&lt;p&gt;수식의 의미를 해석하자면, &lt;strong&gt;AoS 가 높은 경우엔 (즉 Stump 의 분류 성능이 좋은 경우) 정분류된 데이터는 해결된 문제라고 판단해 더욱 작은 가중치를 부여하고, 특정된 오분류 데이터에 더욱 높은 가중치를 부여해 이후 해결하는 과정&lt;/strong&gt;이라고 볼 수 있다. 또한 이렇게 업데이트 된 데이터 가중치는 정규화를 통해 그 합이 1 이 되도록 유지한다.&lt;/p&gt;
&lt;h3 id=&#34;의사-결정&#34;&gt;의사 결정&lt;/h3&gt;
&lt;p&gt;Amount of Say 와 Stump 의 개념을 이해했다면 AdaBoost 모델이 의사 결정을 내리는 과정을 쉽게 이해할 수 있다. 일정 개수의 Stump 가 생성된 후, &lt;strong&gt;AdaBoost 는 test 케이스에 대해 A 로 분류한 Stump 의 AoS 합과 B 로 분류한 Stump 의 AoS 합을 비교하여 더욱 큰 AoS 를 가진 클래스로 test 케이스를 분류한다&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;랜덤 포레스트와 Bagging 알고리즘의 관계와 같이 AdaBoost 는 Boosting 알고리즘의 한 케이스에 불과하며, 순차적인 학습의 개념을 이해하기 위해 해당 글이 제시한 예시로 보면 좋을 것 같다. 나아가 이후에 LightGBM, XGBoost 와 같은 Gradient Boosting 알고리즘 또한 정리해 볼 예정이다.&lt;/p&gt;
&lt;h2 id=&#34;레퍼런스&#34;&gt;레퍼런스&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=eLt4a8-316E&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=eLt4a8-316E&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=LsK-xG1cLYA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=LsK-xG1cLYA&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Transformer 네트워크 개념 소개</title>
        <link>https://meme2515.github.io/neural_network/transformer/</link>
        <pubDate>Sun, 18 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/transformer/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/transformer_1.bmp" alt="Featured image of post Transformer 네트워크 개념 소개" /&gt;&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;기존 RNN 기반의 모델의 느린 학습 속도 문제를 해결하기 위해 2017년 구글이 주도한 &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Attention Is All You Need&lt;/a&gt; 논문에서 제시한 NLP 신경망 구조이다.&lt;/li&gt;
&lt;li&gt;LSTM, GRU 등의 NLP 도메인의 선발주자들이 해결하고자 한, 문장 속 단어간의 관계성을 Attention 이라는 개념을 통해 해결했다. 이는 기존 RNN 모델과 달리 병렬 처리가 가능한 구조를 가지고 있다.&lt;/li&gt;
&lt;li&gt;논문은 통역을 적용 영역으로 다루었으며, 따라서 주어진 문장을 해석하는 Encoder, 새로운 문장을 생성하는 Decoder 로 나뉘어진 구조를 가지고 있다. 여기서 Encoder 의 구조를 차용한 것이 BERT, Decoder 의 구조를 차용한 것이 GPT 모델이다.&lt;/li&gt;
&lt;li&gt;본 글을 작성하는 시점에 가장 활발하게 사용되고 있는 NLP 신경망 구조이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;등장-배경&#34;&gt;등장 배경&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_3.bmp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. RNN 모델 구조 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;본 모델 구조가 발표되기 이전의 주류 자연어 신경망 구조는 기본적으로 단어, 또는 글자를 순차적으로 처리하는 구조를 가지고 있다. Input 단어가 신경망을 활성화해 다음 단어를 예측하는 방식이다. 언어는 단어의 순차적인 조합을 통해 구성되고, 또한 Input 과 Output 문장의 길이가 항상 다르기 때문에 이는 가장 자연스러운 방식으로 여겨졌는데, 이러한 구조는 학습이 느리고, 간격이 먼 단어 간의 관계를 해석하지 못한다는 단점을 가지고 있다. 이 중 후자의 문제를 해결하기 위해 연구자들은 Memory Unit 이라는 개념을 고안해 일종의 단어 기억 장치를 만들어낸다. 이 Memory Unit 은 간격이 먼 단어에 대한 정보를 저장해 문장의 맥락을 보다 정확하게 해석하는 것에 의의를 두고 있으며, 널리 알려진 GRU, LSTM 과 같은 셀 구조가 이에 해당한다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_2.bmp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 베이스 RNN, LSTM 및 GRU 셀 구조 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;하지만 셀의 구조가 복잡해질수록 순차적 학습은 연산 부담이 크다는 문제가 악화된다. 한 개 셀에서 처리할 정보가 그만큼 늘어나니 이는 당연한 결과인데, 자연어 처리 분야가 발전하며 연구자들은 보다 방대한 데이터를 학습시키고자 했고, 이를 위해 병렬 처리가 가능한 NLP 모델인 트랜스포머를 2017년 발표하게된다.&lt;/p&gt;
&lt;h2 id=&#34;attention&#34;&gt;Attention&lt;/h2&gt;
&lt;p&gt;트랜스포머 구조의 혁신적인 점은 마치 비전 분야의 convolution 개념과 같이 언어에 대한 병렬처리를 가능하게 했다는 점이다. 이와 같은 처리 방식은 &amp;ldquo;attention&amp;rdquo; 이라고 불리고 (맥락 이해를 위해 문장의 각 단어에 대한 &amp;ldquo;집중도&amp;rdquo; 를 연산한다는 의미), 세부적으로는 Self-Attention 과 Multi-Head Attention 으로 그 구조를 나눌 수 있다. Self-Attention 은 문장의 각 단어에 대해 attention 점수, 즉 가중치를 매기는 과정을 가르키며, Multi-Head Attention 은 이러한 점수 부여 과정을 여러번 수행하는 것이라고 짧게 설명할 수 있다.&lt;/p&gt;
&lt;p&gt;아래 설명에서는 관련 &lt;a class=&#34;link&#34; href=&#34;https://www.coursera.org/learn/nlp-sequence-models&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Coursera 강의&lt;/a&gt; 에서 등장하는 번역 문제를 예시로 다루고있다. Jane visite l&amp;rsquo;Afrique en septembre 라는 불어 문장을 Janes visits Africa in September 라는 영어 문장으로 번역하는 예시이다.&lt;/p&gt;
&lt;h3 id=&#34;self-attention&#34;&gt;Self-Attention&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_4.bmp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. qKV 매트릭스 연산 과정 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(1) Jane (2) visite (3) l&amp;rsquo;Afrique (4) en (5) septembre 와 같은 형태로 토큰화된 각 단어는 q, K, V 라는 세가지 특성을 부여받는다. 여기서 qKV 특성이란 데이터베이스의 query, key, value 에 해당하는 개념인데, 직관적인 비유를 들자면 (3) l&amp;rsquo;Afrique 에서 어떠한 일이 일어났는가? 를 l&amp;rsquo;Afrique 의 $q^3$ 특성이라고 가정했을때 $q^3 \cdot k^1$ 은 이 질문에 대한 답변으로 (1) Jane 이라는 단어의 적합도를 나타내게 된다 ($q^3 \cdot k^2$ 는 (2) visite 의 적합도, $q^3 \cdot k^3$ 는 (3) l&amp;rsquo;Afrique 의 적합도와 같은 식).&lt;/p&gt;
&lt;p&gt;이렇게 연산된 적합도는 softmax 함수를 통해 정규화되며, 정규화된 각 질문의 적합도에 value 값을 곱해줌으로서 질문에 적합한 정보를 추출하게 되는 원리이다. 수식으로 표현하면 다음과 같다.&lt;/p&gt;
&lt;p&gt;$$
A(q, K, V) = \Sigma_i \frac{\text{exp}(q \cdot k^i)}{\Sigma_j \text{exp}(q \cdot k^j)} v^i
$$&lt;/p&gt;
&lt;p&gt;Fig 3. 에서 확인할 수 있듯이 인풋은 임베딩된 단어 벡터이며, 도출되는 qKV 특성 또한 각각의 벡터이다. 따라서 마치 convolution layer 와 같이 행렬 곱셈을 위한 커널 학습이 가능하며 (learned matrix), 병렬처리가 가능해지는 것이다. 또한 도출된 $A(q, K, V)$ 도 벡터의 형태를 유지하게 되며, 각각의 단어에 대해 Attention Vector 를 추출한다 ((1) Jane -&amp;gt; $A^1$, (2) visite -&amp;gt; $A^2$, etc.).&lt;/p&gt;
&lt;h3 id=&#34;multi-head-attention&#34;&gt;Multi-Head Attention&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_6.bmp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. Multi-Head Attention 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Self-Attention 의 개념을 이해했다면, Multi-Head Attention 은 이러한 Self-Attention 을 여러번 수행하는 과정이라고 설명할 수 있다. 한번의 Self-Attention 과정은 &amp;ldquo;Head&amp;rdquo; 로 표현되며, 8-Head Attention 이란 Self-Attention 이 8번 수행된 결과가 되는 식이다. 여기서 각각의 Head 는 qKV 특성에 서로 다른 가중치를 적용하여 구분되며, 개념적으로는 (1) 무엇을 했는가? (2) 언제 했는가? 와 같이 질문의 내용이 변형되는 과정이다.&lt;/p&gt;
&lt;p&gt;이렇게 구해진 n개의 Attention Vector 를 이어붙인 정보를 통해 Multi-Head Attention 아웃풋 행렬을 도출하며, 실제 학습시에는 for-loop 이 아닌 병렬처리를 수행한다. 질문의 내용이 다양해지기 때문에 도출된 결과는 단일 Attention Vector 보다 더 깊이있는 정보를 가지게된다.&lt;/p&gt;
&lt;h2 id=&#34;모델-구조&#34;&gt;모델 구조&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_1.bmp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Transformer 네트워크 구조&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;트랜스포머 네트워크는 machine translation, 즉 언어 간 해석 문제를 염두하고 만들어졌기 때문에 한개의 언어를 해석하는 encoder 블록, 다른 언어를 생성하는 decoder 블록으로 구분할 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;encoder&#34;&gt;Encoder&lt;/h3&gt;
&lt;p&gt;Fig 5. 의 좌측 도식화에 해당하는 부분이다. 우선 임베딩된 인풋 문장 Jane visite l&amp;rsquo;Afrique en septembre (Input Encoding) 에서 Q, K, V 특성을 추출한 후, 이에 Multi-Head Attention 을 적용해 문장에 대한 해석 정보가 담긴 매트릭스를 생성한다 (여기서 Q, K, V 특성은 세갈래의 화살표로 표기되어있다). 이후 일반적인 신경망 구조를 통해 해당 매트릭스에서 중요한 정보를 선별하며, 여기까지의 과정을 N 번 반복한다. Multi-Head Attention 과 Feed Forward 레이어에서 생성되는 아웃풋에는 여타 신경망의 &lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/neural_network/batchnorm/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Batch Normalization&lt;/a&gt; 과 유사한 Add &amp;amp; Normalization 이 적용된다.&lt;/p&gt;
&lt;h3 id=&#34;decoder&#34;&gt;Decoder&lt;/h3&gt;
&lt;p&gt;Fig 5. 의 우측 도식화에 해당하는 부분이다. 인풋엔 생성하고자 하는 문장의 단어들이 순차적으로 입력되며, 최초엔 이러한 문장 정보가 없기 때문에 start-of-sentence 라는 의미의 SOS 토큰 등을 활용하게 된다. 이후 임베딩된 단어 인풋에서 Q, K, V 특성을 추출 후, 이에 Multi-Head Attention 을 적용한다. Encoder 와 다른 점은 이 Multi-Head Attention 의 아웃풋이 해석 정보를 가진 매트릭스가 아닌 Q, 즉 인풋 단어에 대한 복수의 질문 정보를 담은 매트릭스라는 점이다.&lt;/p&gt;
&lt;p&gt;앞서 설명한 Encoder 는 궁극적으로 이에 대응하는 K, V 매트릭스를 생성하게 된다 (양 블록을 있는 두개의 화살표로 표현). 따라서 Decoder 의 질문에 대응하는 답변을 줄 수 있게 설계된 것이다. 이러한 두 갈래의 Q, K, V 특성은 다시 Multi-Head Attention 레이어에 적용되며, 이를 통해서 아웃풋된 두 언어의 상관성 정보를 담은 매트릭스는 Feed Forward 레이어를 통해 중요한 정보만을 남기게 된다. 여기까지의 과정 또한 N 번 반복 후, Softmax Activation 을 통해 여러 단어 중 가장 알맞은 단어를 선택하게 된다.&lt;/p&gt;
&lt;p&gt;Decoder 블록 또한 각 레이어 별로 Add &amp;amp; Normalization 이 적용된다.&lt;/p&gt;
&lt;h3 id=&#34;positional-encoding&#34;&gt;Positional Encoding&lt;/h3&gt;
&lt;p&gt;트랜스포머 구조를 처음 접할때 가장 강조되는 부분이 CNN 과의 유사성이다. 병렬 처리를 통한 연산 속도의 개선은 이미 설명했지만, 언어 영역에서 이러한 유사성이 가지는 단점은 없을까?&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_5.bmp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 6. Translation Invariance&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;비전 분야에서 CNN 이 각광받는 이유 중 하나는 Convolution Layer 내의 커널을 이미지의 여러 영역에 동일하게 적용하기 때문이다. 이로 인해 고양이를 분류하도록 학습된 커널은 고양이가 이미지의 좌하단, 우상단, 중앙 등 어떠한 영역에 있던 문제없이 고양이의 특성을 추출해 그 존재 유무를 추측할 수 있게된다. 입력 위치가 변해도 출력은 변하지 않는다는 의미이며, 학술적으로 이는 Translation Invariance 라 칭한다 (관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://seoilgun.medium.com/cnn%EC%9D%98-stationarity%EC%99%80-locality-610166700979&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;해당 Medium 글&lt;/a&gt;에서 보다 상세한 내용을 확인할 수 있다).&lt;/p&gt;
&lt;p&gt;트랜스포머의 qKV 매트릭스 추출 과정 또한 이와 유사하다. CNN 의 커널과 유사하게 동일한 learned matrix 를 각 단어 벡터에 곱하게 되며, 이로 인해 단어의 위치와 무관하게 qKV 특성을 추출할 수 있게 되는 것이다. 이는 l&amp;rsquo;Afrique 라는 단어가 문장의 어느 위치에서 등장하던 같은 질문을 던지고, 다른 질문에 대한 동일한 답을 준다는 점을 의미한다. 하지만 언어에서 단어의 위치는 중요한 정보를 담고 있다. 예시로 같은 단어일지라도 문맥과 위치에 따라 주어가 될 수도, 목적어가 될 수도 있기 때문이다.&lt;/p&gt;
&lt;p&gt;이렇듯 유실된 단어의 위치 정보를 활용하기 위해 논문의 저자는 position encoder 라는 개념을 소개한다. 우선 (1) Jane 과 같은 각 토큰은 길이 4의 벡터에 임베드 된다고 가정하자. Position 인코딩은 이와 동일한 길이의 벡터에 해당 토큰의 위치 정보 (이 경우 1) 를 표현한 후, 이를 (1) Jane 을 해석한 기존 임베드에 더해줌으로서 의미, 맥락과 더불어 위치 정보 또한 벡터에 추가하게 된다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 7. Positional Encoding 벡터 덧셈 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;그렇다면 토큰의 위치 정보는 어떻게 벡터로 표현될 수 있을까? 사실 각 위치에 대한 벡터의 값이 일정하고, 구분될 수 있다면 생성 과정 자체는 크게 중요하지 않다. 다만 감안할 부분은 (1) Position encoding 값이 기존 임베딩 값을 지나치게 변형하면 안된다는 점 (2) 연산 과정이 복잡해 학습 시간을 지연시키면 안된다는 점 등을 들 수 있다. 논문은 sine, cosine 함수를 활용해 다음과 같은 position encoding 생성 함수를 제안한다.&lt;/p&gt;
&lt;p&gt;$$
\text{PE}_{\text{pos}, 2i} = \text{sin}(\frac{\text{pos}}{10000^{\frac{2i}{d}}})
$$&lt;/p&gt;
&lt;p&gt;$$
\text{PE}_{\text{pos}, 2i+1} = \text{cos}(\frac{\text{pos}}{10000^{\frac{2i}{d}}})
$$&lt;/p&gt;
&lt;p&gt;여기서 d 는 타깃 벡터의 길의 (예시의 경우 d=4), i 는 타깃 벡터에 존재하는 모든 인덱스 (i=[1, 2, 3, 4]), pos 는 단어의 위치 (Jane 은 첫 토큰임으로 pos=1) 를 나타낸다. 함수가 두개인 이유는 홀수 인덱스의 경우 하단의 cosine 함수를, 짝수 인덱스의 경우 상단의 sine 함수를 활용하기 위함이다. 이러한 각 변수와 함수간의 관계는 다음과 같이 도식화할 수 있다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/transformer_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 8. Positional Encoding 함수 아웃풋 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;즉, 한정된 레인지에서 추출된 position encoding 값을 통해 기존 임베딩 정보를 지나치게 왜곡하지 않는 선에서 위치 정보를 추가하는 것이다.&lt;/p&gt;
&lt;h3 id=&#34;masking&#34;&gt;Masking&lt;/h3&gt;
&lt;p&gt;Decoder 블록의 첫 Multi-Head Attention 레이어는 Masking 이라는 매커니즘을 통해 학습된다. 간단히 말해, 이미 완성된 영문장 Jane visits Africa in September 을 마스킹 처리하여 &amp;ldquo;Jane visits Africa __ __&amp;rdquo; 라는 인풋이 &amp;ldquo;Jane visits Africa in __&amp;rdquo; 이라는 아웃풋을 생성하도록 유도하고, 학습하는 것이다. 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://medium.com/analytics-vidhya/masking-in-transformers-self-attention-mechanism-bad3c9ec235c&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;해당 Medium 글&lt;/a&gt; 에서 더욱 자세한 내용을 확인할 수 있다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Vim 에디터 소개와 기본적인 명령어 정리</title>
        <link>https://meme2515.github.io/computer_science/vim/</link>
        <pubDate>Mon, 05 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/computer_science/vim/</guid>
        <description>&lt;img src="https://meme2515.github.io/computer_science/images/vim.bmp" alt="Featured image of post Vim 에디터 소개와 기본적인 명령어 정리" /&gt;&lt;h2 id=&#34;mit에서-공개한-vim-관련-강의&#34;&gt;MIT에서 공개한 Vim 관련 강의&lt;/h2&gt;
&lt;p&gt;유명한 &lt;a class=&#34;link&#34; href=&#34;https://missing.csail.mit.edu/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Missing Semester of Your CS Education&lt;/a&gt; 의 Vim 관련 강의 비디오 링크.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=a6Q8Na575qc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/vim_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;등장-배경과-특징&#34;&gt;등장 배경과 특징&lt;/h2&gt;
&lt;p&gt;1976년 배포된 유닉스 운영체제의 텍스트 에디터 프로그램이었던 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Vi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;vi&lt;/a&gt; 의 개선판으로, 그 이름 또한 Vi IMproved 의 약자이다. 최초 버전은 1991년 배포되었으며, 현재까지 VS Code, Sublime 등과 함께 개발자들이 가장 선호하는 텍스트 에디터 중 하나이다. 아직까지도 리눅스, 맥OS 등의 주요 유닉스 기반 운영체제에 기본으로 탑재되어 있다.&lt;/p&gt;
&lt;p&gt;Vim을 처음 접한 사용자는 마우스 사용 없이 문서 수정이 이루어지는 환경이 당황스럽게 받아들여질 수 밖에 없다. 하지만 이는 일정 수준 사용에 익숙해지면 마우스를 조작하는 시간을 절약할 수 있다는 의미이기도 하다 (물론 나는 익숙하지 않다). 당연하지만 Vim 의 문서 수정 방식은 VSCode 같은 기존 텍스트 에디터를 더 편하게 사용하기 위해 고안된 것이 아니라, 주로 검은 화면에 키보드로 입력한 명령어만으로 컴퓨터를 조작하던 시절 문서를 수정하기 위한 가장 현실적인 방안으로 고안된 것이다.&lt;/p&gt;
&lt;p&gt;Vim 은 개발자들이 문서를 작성하기보다 수정하는 일에 더 많은 시간을 보낸다는 점에 집중한다. 따라서 기능의 많은 부분들이 방대한 양의 텍스트를 효율적으로 다룰수 있도록 설계되어있다. 또한 맥OS, 리눅스, 윈도우 환경에서 모두 쉽고 빠르게 사용할 수 있기 때문에 범용성이 높다는 특징 또한 존재한다 (사실 개발자용 텍스트 에디터는 모두 이렇기에 특징이라고 하기는 어렵다).&lt;/p&gt;
&lt;h2 id=&#34;장단점-정리-및-기본-개념-소개&#34;&gt;장단점 정리 및 기본 개념 소개&lt;/h2&gt;
&lt;h3 id=&#34;기타-환경-대비-장단점&#34;&gt;기타 환경 대비 장단점&lt;/h3&gt;
&lt;p&gt;장점&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;일정 수준 이상 익숙해진다면 마우스+키보드 조합에 비해 월등한 효율을 낼 수 있다.&lt;/li&gt;
&lt;li&gt;.vimrc 파일 수정을 통해 생각할 수 있는 거의 모든 customization 이 가능하다. 또한 다른 유저가 공개한 설정을 사용함으로서 바로 효율적인 세팅을 이용할 수 있다.&lt;/li&gt;
&lt;li&gt;SSH 터미널 세션에서 별도 GUI 로딩이 필요하지 않다. GUI 세팅이 어렵다면 사실상 유일하게 사용할 수 있는 텍스트 에디터이다 (이게 크다).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;단점&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;단축키, 각종 모드 등 배워야 할 것이 많다. 굳이 배우지 않아도 예외적인 사례 몇가지를 제외하면 사실 개발에 큰 지장을 주지 않는다.&lt;/li&gt;
&lt;li&gt;폰트 구분, 이미지 렌더링, UI 개발 등 여러 현대적인 그래픽 기반 기능들을 태생적으로 제공하지 못한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;뭣모르고 하는 소리일 수 있겠지만, 개인적으로는 VSCode 와 같은 주류 IDE 를 메인으로 사용하고, SSH 접속과 같은 상황에 Vim 을 서브 에디터로 사용하는 것이 바람직하다고 생각한다. 굳이 모든 상황에 CLI 환경 에디터를 고집함으로서 생기는 득보다는 실이 크지 않을까 조심스럽게 적어본다.&lt;/p&gt;
&lt;h3 id=&#34;데이터-사이언티스트는-vim을-공부해야할까&#34;&gt;데이터 사이언티스트는 Vim을 공부해야할까?&lt;/h3&gt;
&lt;p&gt;나는 그렇다고 생각한다, 다만 너무 깊이 들어갈 필요는 없을듯하다. 대학교, 부트캠프 등에서 노트북 기반 환경에 익숙해진 초심자는 커맨드 라인에서 문서 편집이 오히려 불편하고, 귀찮은 경험이 될 수 있다. 하지만 클라우드 등 서버 컴퓨팅을 활용 시 발생할 수 있는 여러 문제들 (사내 보안, 자원 절약, 한정된 시간 등) 로 인해 Vim 은 유일한 문서 편집 방법이 될 가능성이 많다.&lt;/p&gt;
&lt;p&gt;또한 단순 실험에서 벗어나 스크립트를 작성하고, 모델을 저장/로드하는 과정에서 터미널 사용은 필수적이다. 터미널에서 파일을 브라우징하며 짤막한 코드 수정이 필요할때 Vim 은 실제로 많은 시간을 단축시켜준다.&lt;/p&gt;
&lt;h3 id=&#34;vim-모드&#34;&gt;Vim 모드&lt;/h3&gt;
&lt;p&gt;Vim 은 모드 기반의 에디터이다. 여타 텍스트 에디터가 파일을 열게되면 바로 편집, 읽기 기능을 제공하는 것과 다르게 Vim은 주로 문서 탐색 기능을 제공하는 Normal 모드, 편집 기능을 제공하는 Insert 모드, 명령어 입력을 지원하는 Command 모드, 하이라이팅 기능을 제공하는 Visual 모드로 구분할 수 있다.&lt;/p&gt;
&lt;h4 id=&#34;normal-모드&#34;&gt;Normal 모드&lt;/h4&gt;
&lt;p&gt;개발자가 가장 많은 시간을 할애하는 모드이며, &lt;code&gt;vim filename&lt;/code&gt; 커맨드로 문서를 열면 기본적으로 Normal 모드에서 편집을 시작하게 된다. Undo, redo, find, replace 등 직접적인 텍스트 입력 및 하이라이팅을 제외한 거의 모든 기능을 제공하며, 기타 모드에서 &lt;code&gt;esc&lt;/code&gt; 키를 클릭하면 다시 Normal 모드로 돌아올 수 있다.&lt;/p&gt;
&lt;h4 id=&#34;insert-모드&#34;&gt;Insert 모드&lt;/h4&gt;
&lt;p&gt;직접적인 텍스트 입력을 지원하며, Normal 모드에서 &lt;code&gt;i&lt;/code&gt; 키를 클릭해 전환한다. 일반적인 텍스트 에디터와 동일한 상태라고 생각하면 되지만, Vim 의 강점인 단축키가 대부분 지원되지 않는다.&lt;/p&gt;
&lt;h4 id=&#34;command-모드&#34;&gt;Command 모드&lt;/h4&gt;
&lt;p&gt;프로그래밍 언어처럼 명령어를 입력할 수 있는 모드이며, Normal 모드에서 &lt;code&gt;:&lt;/code&gt; 키를 입력해 전환할 수 있다. 예를 들자면 &lt;code&gt;:q&lt;/code&gt; 입력 후 엔터를 누르면 문서를 닫는 식이다.&lt;/p&gt;
&lt;h4 id=&#34;visual-모드&#34;&gt;Visual 모드&lt;/h4&gt;
&lt;p&gt;하이라이팅 기능을 제공하며, Normal 모드에서 &lt;code&gt;v&lt;/code&gt; 키를 입력해 전환한다. 주로 코드의 특정 부분을 선택해 복사 및 잘라내기 기능을 수행할때 활용한다.&lt;/p&gt;
&lt;h3 id=&#34;기본적인-커맨드-정리&#34;&gt;기본적인 커맨드 정리&lt;/h3&gt;
&lt;p&gt;다음 커맨드들은 별도 표기가 없다면 모두 Normal 모드에서만 지원된다.&lt;/p&gt;
&lt;h4 id=&#34;저장-및-파일-닫기&#34;&gt;저장 및 파일 닫기&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;:w filename&lt;/code&gt; 현재 문서를 filename 문서에 저장한다. 문서 이름을 지정하지 않으면 현재 문서에 저장한다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;:q&lt;/code&gt; Vim 을 종료한다. 문서 편집이 이루어졌다면 저장이 필요하다는 문구가 뜨게된다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;:q!&lt;/code&gt; 문서 저장없이 Vim 을 종료한다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wq&lt;/code&gt; 문서를 저장하고 Vim 을 종료한다.&lt;/p&gt;
&lt;h4 id=&#34;파일-탐색&#34;&gt;파일 탐색&lt;/h4&gt;
&lt;p&gt;화살표키, 또는 j, k, h, l 키로 커서를 이동할 수 있다. 권장되는 탐색 방법은 후자인데, 단축키 조합이 빈번한 Vim 에서 손가락의 움직임을 최소화할 수 있기 때문이다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;j&lt;/code&gt; 아래 &lt;code&gt;k&lt;/code&gt; 위 &lt;code&gt;h&lt;/code&gt; 왼쪽 &lt;code&gt;l&lt;/code&gt; 오른쪽 이동에 해당한다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;w&lt;/code&gt; 다음 단어로 이동. &lt;code&gt;B&lt;/code&gt; 이전 단어로 이동.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;b&lt;/code&gt; 단어의 처음으로 이동. &lt;code&gt;e&lt;/code&gt; 단어의 마지막으로 이동.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;0&lt;/code&gt; 현재 라인의 처음으로 이동. &lt;code&gt;$&lt;/code&gt; 현재 라인의 마지막으로 이동.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;:123&lt;/code&gt; 123 번째 줄로 이동.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ctrl-f&lt;/code&gt; 한페이지 위로. &lt;code&gt;ctrl-b&lt;/code&gt; 한페이지 아래로.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ctrl-u&lt;/code&gt; 반페이지 위로. &lt;code&gt;ctrl-d&lt;/code&gt; 반페이지 아래로.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;gg&lt;/code&gt; 파일의 첫 라인으로 이동. &lt;code&gt;G&lt;/code&gt; 파일의 마지막 라인으로 이동.&lt;/p&gt;
&lt;h4 id=&#34;찾기-기능&#34;&gt;찾기 기능&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;/foo&lt;/code&gt; 파일에서 foo 를 검색한다. 엔터를 누르면 검색 결과간 이동이 가능하다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;n&lt;/code&gt; 다음 검색 결과로 이동.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;N&lt;/code&gt; 이전 검색 결과로 이동.&lt;/p&gt;
&lt;h4 id=&#34;텍스트-편집&#34;&gt;텍스트 편집&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;dd&lt;/code&gt; 혹은 &lt;code&gt;:d&lt;/code&gt; 현재 라인 잘라내기.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yy&lt;/code&gt; 혹은 &lt;code&gt;:y&lt;/code&gt; 현재 라인 복사하기.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;p&lt;/code&gt; 잘라내거나 복사한 내용 붙여넣기.&lt;/p&gt;
&lt;h4 id=&#34;undoredo&#34;&gt;Undo/Redo&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;u&lt;/code&gt; 마지막 액션 취소.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;U&lt;/code&gt; 현재 라인에 모든 수정 내용 취소.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ctrl-u&lt;/code&gt; redo.&lt;/p&gt;
&lt;h4 id=&#34;텍스트-하이라이트&#34;&gt;텍스트 하이라이트&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;v&lt;/code&gt; 캐릭터 레벨에서 하이라이트.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;V&lt;/code&gt; 라인 레벨에서 하이라이트 (위/아래 이동만 가능).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ctrl-v&lt;/code&gt; 행렬 레벨에서 하이라이트.&lt;/p&gt;
&lt;p&gt;텍스트 하이라이트 후, 잘라내기 (&lt;code&gt;d&lt;/code&gt;), 복사 (&lt;code&gt;y&lt;/code&gt;), 붙여넣기 (&lt;code&gt;p&lt;/code&gt;) 등의 기능을 사용할 수 있다. Visual 모드에서 Normal 모드로 돌아가기 위해서는 &lt;code&gt;esc&lt;/code&gt; 키를 누르면 된다.&lt;/p&gt;
&lt;h2 id=&#34;더-나아가기&#34;&gt;더 나아가기&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=a6Q8Na575qc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Missing Semester&lt;/a&gt;와 &lt;a class=&#34;link&#34; href=&#34;https://web.stanford.edu/class/cs107/resources/vim.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Stanford CS107&lt;/a&gt;에서 짧지만 양질의 Vim 강의를 제공한다. 두 강의 모두 기본적인 소개는 물론 고급 사용법의 공부법 또한 제공하니 관심이 있다면 참고하면 좋을듯 하다.&lt;/p&gt;
&lt;h2 id=&#34;참고-링크&#34;&gt;참고 링크&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Vim_%28text_editor%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://en.wikipedia.org/wiki/Vim_(text_editor)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Vi&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://en.wikipedia.org/wiki/Vi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@fay_jai/what-is-vim-and-why-use-vim-54c67ce3c18e&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://medium.com/@fay_jai/what-is-vim-and-why-use-vim-54c67ce3c18e&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=a6Q8Na575qc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=a6Q8Na575qc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://web.stanford.edu/class/cs107/resources/vim.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://web.stanford.edu/class/cs107/resources/vim.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>결정 트리 (Decision Tree) 기초 개념</title>
        <link>https://meme2515.github.io/machine_learning/decision_tree/</link>
        <pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/machine_learning/decision_tree/</guid>
        <description>&lt;img src="https://meme2515.github.io/machine_learning/images/decision_tree_1.png" alt="Featured image of post 결정 트리 (Decision Tree) 기초 개념" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;구직 활동 중 한 회사에서 입사제의를 받았다고 가정하자. 개인마다 그 정도에는 차이가 있겠지만, 제안을 수락하기 까지에는 일종의 의사결정 체계가 존재할 것이다. 대표적으로 다음과 같은 질문을 자신에게 던져볼 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;나의 배경과 직급에 적당한 보수를 받을 수 있는가?&lt;/li&gt;
&lt;li&gt;출근 위치는 내가 감내할 수 있는 거리 내에 있는가?&lt;/li&gt;
&lt;li&gt;직원 복지제도가 존재하는가?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;질문에 연관성이 있는 데이터를 가지고 있다면 (보수, 통근거리, 복지제도 유무), 다수의 입사제의에 대해 수락(1) 또는 거절(0) 중 하나의 클래스로 제안에 대한 답변을 분류할 수 있는 알고리즘을 만들 수 있다. 이와 같이 일련의 결정 체계를 통해 분류와 회귀 문제를 효율적으로 수행하는 머신러닝 알고리즘을 결정 트리라고 부른다.&lt;/p&gt;
&lt;p&gt;버클리와 스탠포드에서 1977년 개발한 &lt;strong&gt;CART 알고리즘&lt;/strong&gt; (Breiman et al.) 을 그 기반으로 하고있으며, 2010년 후반부터 널리 사용되고있는 &lt;a class=&#34;link&#34; href=&#34;https://lightgbm.readthedocs.io/en/v3.3.2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LightGBM&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://xgboost.readthedocs.io/en/stable/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;XGBoost&lt;/a&gt; 와 같은 앙상블 학습 알고리즘의 기반이기도하다.&lt;/p&gt;
&lt;h2 id=&#34;결정-트리&#34;&gt;결정 트리&lt;/h2&gt;
&lt;p&gt;머신러닝 예시에서 자주 사용되는 Iris 데이터셋을 활용해 모델의 작동방법을 자세히 알아보자. 아래 시각화된 모델은 주어진 붓꽃의 꽃잎 길이를 기반으로 품종을 분류한다. 먼저 첫 노드에서는 꽃잎의 길이 (petal width) 가 0.8 cm 보다 작거나 같은지 확인한 다음, 그렇다면 붓꽃의 품좀을 setosa 클래스로 분류한다.&lt;/p&gt;
&lt;p&gt;만약 꽃잎의 길이가 0.8 cm 보다 클 경우, 모델은 다음 노드로 이동하여 꽃잎 길이가 1.75 cm 보다 작거나 같은지 확인한다. 그렇다면 붓꽃을 versicolor 클래스로, 그렇지 않다면 virginica 클래스로 분류한다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/decision_tree_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Sklearn 패키지의 결정 트리 모델 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;노드의 &lt;strong&gt;samples 속성&lt;/strong&gt;은 학습 과정에서 얼마나 많은 훈련 샘플이 적용되었는지를 헤아리고 있다. 예를 들어 위 예시의 경우 총 150 개의 데이터를 기반으로 학습되었으며, setosa 클래스에는 50 개의 데이터가, versicolor 클래스에는 54 개의 데이터가 학습 과정에서 사용되었던 것을 확인할 수 있다.&lt;/p&gt;
&lt;p&gt;이에 반해 &lt;strong&gt;value 속성&lt;/strong&gt;은 노드에 속한 각 클래스 별 데이터의 수를 보여준다. 예를 들어 우측 하단의 virginica 클래스에는 setosa 클래스가 0 개, versicolor 클래스가 1 개, virginica 클래스가 45 개가 분류되었다. 분류 체계가 완벽하지 않음을 뜻하며, 이는 &lt;strong&gt;gini 속성&lt;/strong&gt;, 즉 이후 설명할 지니 불순도와 연계된다.&lt;/p&gt;
&lt;h2 id=&#34;지니-불순도와-엔트로피&#34;&gt;지니 불순도와 엔트로피&lt;/h2&gt;
&lt;h3 id=&#34;지니-불순도-gini-impurity-score&#34;&gt;지니 불순도 (Gini Impurity Score)&lt;/h3&gt;
&lt;p&gt;지니 불순도는 &lt;strong&gt;특정 노드에 얼마나 다양한 클래스가 분포해있는지를 측정하는 성능 지표&lt;/strong&gt;이다. 노드에 속해있는 샘플의 클래스 분포가 작을수록 0 에 가까워지며, $p_{i,k}$ 를 $i$ 번째 노드에 속한 샘플 중 클래스 $k$ 에 속한 샘플의 비율이라고 했을때 노드 $i$ 에 대한 지니 불순도 $G_i$ 는 다음과 같이 정의할 수 있다.&lt;/p&gt;
&lt;p&gt;$$
G_i = 1 - \sum_{k=1}^n p_{i,k}^2
$$&lt;/p&gt;
&lt;h3 id=&#34;엔트로피-entropy&#34;&gt;엔트로피 (Entropy)&lt;/h3&gt;
&lt;p&gt;지니 불순도와 interchangeably 사용되는 개념이며, 본래 열역학의 개념이다 (분자가 안정되고 질서 정연할 수록 엔트로피는 0에 가까워진다). 노드 $i$ 에 대한 엔트로피 $H_i$ 는 다음과 같이 정의된다.&lt;/p&gt;
&lt;p&gt;$$
H_i = - \sum_{k=1, p_{i,k} \neq 0}^n p_{i,k} \cdot log_2(p_{i,k})
$$&lt;/p&gt;
&lt;p&gt;지니 불순도와 엔트로피 간 생성하는 모델에 큰 차이는 없으며, 지니 불순도의 연산속도가 더 빠르기 때문에 일반적으로 트리 기반 모델은 지니 불순도 평가 지표를 사용하고있다. 다만 모델에 차이가 발생하는 경우 엔트로피가 상대적으로 더 균형 잡힌 트리를 만들게된다.&lt;/p&gt;
&lt;p&gt;여기서 드는 의문점은 지니 불순도와 엔트로피 모두 개별적인 노드에 대한 성능 지표라는 점이다. 일반적인 기계학습이란 모델의 단일 성능 지표 (RMSE, Cross Entropy 등) 를 기반으로 오차율을 줄이는 과정을 거치게 되는데, &lt;strong&gt;결정 트리는 학습 과정 시 전체 모델이 아닌 개별 노드의 성능만을 최적화한다&lt;/strong&gt;. 이러한 알고리즘을 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Greedy_algorithm&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Greedy Algorithm&lt;/a&gt; 이라 칭한다.&lt;/p&gt;
&lt;h2 id=&#34;cart-훈련-알고리즘&#34;&gt;CART 훈련 알고리즘&lt;/h2&gt;
&lt;p&gt;CART (Classification And Regression Tree) 는 데이터에 대한 최적의 의사 결정 기준을 찾기 위해 고안된 알고리즘이다. 개념적으로 CART 알고리즘은 다음과 같은 순서로 수행된다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;훈련 세트를 여러 특성 $k$ 와 임곗값 $t_k$ 의 조합으로 반복해 분리한다 (예. 꽃잎의 길이 &amp;lt;= 2.45 cm).&lt;/li&gt;
&lt;li&gt;매 사이클 마다 나누어진 두 서브셋에 대한 다음 비용 함수를 계산한다. &lt;em&gt;(여기서 $G$ 는 서브셋의 불순도, $m$ 은 서브셋의 샘플 수를 뜻한다)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
J(k, t_k) = \frac{m_{left}}{m} G_{left} + \frac{m_{right}}{m} G_{right}
$$&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;가장 작은 비용 함수를 가진 특성과 임곗값 조합으로 데이터를 나눈다.&lt;/li&gt;
&lt;li&gt;요건을 충족할때 까지 동일한 방식을 통해 나누어진 서브셋에 대한 최적의 특성과 임곗값 조합을 찾는다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;설명한바와 같이 CART 알고리즘은 Greedy Algorithm (탐욕적 알고리즘) 이다. 매 단계에서 알고리즘은 주어진 노드에 대한 최적의 특성과 임곗값 조합을 찾을뿐, 그 이후 과정에 대한 고려는 하지 않는다.&lt;/p&gt;
&lt;h2 id=&#34;하이퍼파라미터&#34;&gt;하이퍼파라미터&lt;/h2&gt;
&lt;p&gt;결정 트리는 별다른 데이터 전처리를 필요로하지 않을뿐만 아니라, 별다른 하이퍼파라미터 또한 필요로 하지 않는다. 대표적으로 조절할 수 있는 것은 결정 트리의 깊이 (depth) 인데, 이는 트리의 높이에 해당하는 개념이며 Scikit-learn 패키지는 &lt;code&gt;max_depth&lt;/code&gt; 매개변수를 통해 이를 조절한다. &lt;code&gt;max_depth&lt;/code&gt; 의 값이 낮을수록 모델을 규제하는 효과를 가진다. 이외에 Scikit-learn 패키지 DecisionTreeClassifier 가 가진 매개변수는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;min_samples_split&lt;/code&gt; : 분할되기 위해 노드가 가져야 하는 최소 샘플 수&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_samples_leaf&lt;/code&gt; : 리프 노드가 가지고 있어야 할 최소 샘플 수&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_leaf_nodes&lt;/code&gt; : 리프 노드의 최대 수&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_features&lt;/code&gt; : 각 노드에서 분할에 사용할 특성의 최대 수&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;회귀-문제-적용&#34;&gt;회귀 문제 적용&lt;/h2&gt;
&lt;p&gt;클래스의 개념에 노드에 속한 샘플의 평균값을 대입하면 결정 트리를 회귀 문제에 또한 적용할 수 있다. 다만 여기서 CART 알고리즘은 훈련 세트를 불순도를 최소화하는 방향으로 분할하는 대신 평균제곱오차 (MSE) 를 최소화하도록 분할하도록 작동한다.&lt;/p&gt;
&lt;p&gt;$$
J(k,t_k) = \frac{m_{left}}{m} MSE_{left} + \frac{m_{right}}{m} MSE_{right}
$$&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/decision_tree_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 결정 트리를 사용한 회귀 모델 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;참고-자료&#34;&gt;참고 자료&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Hands-On Machine Learning with Scikit-Learn, Keras &amp;amp; Tensorflow&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.explorium.ai/blog/the-complete-guide-to-decision-trees/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.explorium.ai/blog/the-complete-guide-to-decision-trees/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>(논문 리뷰) 쉽게 이해하는 AlexNet 과 PyTorch 코드 예시</title>
        <link>https://meme2515.github.io/neural_network/alexnet/</link>
        <pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/alexnet/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/alexnet_1.png" alt="Featured image of post (논문 리뷰) 쉽게 이해하는 AlexNet 과 PyTorch 코드 예시" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;2012년 토론토 대학의 &lt;a class=&#34;link&#34; href=&#34;https://www.cs.toronto.edu/~kriz/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Alex Krizhevsky&lt;/a&gt; 팀이 공개한 AlexNet 은 &lt;a class=&#34;link&#34; href=&#34;https://image-net.org/challenges/LSVRC/2012/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ILSVRC-2012&lt;/a&gt; 대회에서 2등 모델의 정확도 26.2%를 10% 이상 상회하는 15.3% 의 정확도를 기록해 많은 관심을 받았던 CNN 구조이다. 특히 GPU 를 활용한 연산가속이 컴퓨터 비전 커뮤니티에서 적극적으로 사용되는 것에 기여하였으며, 이외에도 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ReLU 활성화 함수&lt;/a&gt;, Overlapping Pooling 등 &amp;lsquo;22년 현재 당연하게 받아들여지는 CNN 구조를 정립했다.&lt;/p&gt;
&lt;h2 id=&#34;코드-예시&#34;&gt;코드 예시&lt;/h2&gt;
&lt;p&gt;아래는 &lt;a class=&#34;link&#34; href=&#34;https://blog.paperspace.com/alexnet-pytorch/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Paperspace&lt;/a&gt; 의 구현예시 이다. 논문에서 보이지 않는 디테일은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolution 레이어와 FC 레이어가 분리되어 있다.&lt;/li&gt;
&lt;li&gt;Output 의 클래스 수를 설정할 수 있다. 기본값은 논문과 같은 1,000 으로 설정.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;라이브러리 :&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torchvision&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torchvision&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.data.sampler&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SubsetRandomSampler&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Device configuration&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;cuda&amp;#39;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cuda&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;is_available&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;cpu&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;데이터 로딩 :&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;96
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_train_valid_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;n&#34;&gt;augment&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;n&#34;&gt;random_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;n&#34;&gt;valid_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;normalize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4914&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.4822&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.4465&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.2023&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.1994&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.2010&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# define transforms&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;valid_transform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Compose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Resize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;227&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;227&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;augment&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;train_transform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Compose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RandomCrop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RandomHorizontalFlip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;train_transform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Compose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Resize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;227&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;227&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# load the dataset&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;train_dataset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;valid_dataset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;valid_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;num_train&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;indices&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;split&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;floor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;valid_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;train_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;valid_idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;indices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;indices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;train_sampler&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SubsetRandomSampler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;valid_sampler&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SubsetRandomSampler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;valid_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;utils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;train_dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampler&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_sampler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;valid_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;utils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;valid_dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampler&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;valid_sampler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;valid_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;normalize&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.485&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.456&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.406&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.229&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.224&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.225&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# define transform&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Compose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Resize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;227&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;227&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;data_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;utils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data_loader&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# CIFAR10 dataset &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;valid_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_train_valid_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_dir&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;./data&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;                                      &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       &lt;span class=&#34;n&#34;&gt;augment&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;                             		     &lt;span class=&#34;n&#34;&gt;random_seed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;get_test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_dir&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;./data&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                              &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;모델 본문 :&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;AlexNet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_classes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AlexNet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;96&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;96&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;96&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer4&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer5&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Dropout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;9216&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4096&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fc1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Dropout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4096&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4096&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fc2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4096&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_classes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fc1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fc2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;하이퍼파라미터 세팅 :&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;num_classes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;num_epochs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;learning_rate&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.005&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AlexNet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_classes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Loss and optimizer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;criterion&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;optimizer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SGD&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;learning_rate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;weight_decay&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.005&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;momentum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Train the model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;total_step&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;학습 과정 :&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;total_step&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epoch&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_epochs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;enumerate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Move tensors to the configured device&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Forward pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;criterion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Backward and optimize&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;optimizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zero_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;optimizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Epoch [&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;], Step [&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;], Loss: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{:.4f}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                   &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;epoch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_epochs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;total_step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Validation&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;no_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;correct&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;total&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;valid_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predicted&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;total&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;correct&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predicted&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;del&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Accuracy of the network on the &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; validation images: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; %&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;correct&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;total&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;테스팅 과정 :&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;no_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;correct&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;total&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predicted&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;total&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;correct&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predicted&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;del&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Accuracy of the network on the &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; test images: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; %&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;correct&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;total&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;   &lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;imagenet-ilsvrc&#34;&gt;ImageNet (ILSVRC)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;스탠포드 대학 교수인 &lt;a class=&#34;link&#34; href=&#34;https://profiles.stanford.edu/fei-fei-li&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Fei-Fei Li&lt;/a&gt; 가 주로 알고리즘 위주의 연구가 이루어지던 당시 AI 분야에 기여하기위해 2009년 공개한 이미지-레이블 데이터셋이다.&lt;/li&gt;
&lt;li&gt;매년 &lt;a class=&#34;link&#34; href=&#34;https://www.image-net.org/challenges/LSVRC/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ImageNet Large Scale Visual Recognition Challenge (ILSVRC)&lt;/a&gt; 라는 레이블 예측 대회를 개최하고 있으며, 2012년 기준 약 120만개의 이미지-레이블 셋으로 이루어져 있었다 (22년 현재 1,400만).&lt;/li&gt;
&lt;li&gt;Top-1 에러율, top-5 에러율 등으로 모델의 정확도를 평가하는데, 여기서 top-5 에러란 likelihood 가 가장 높은 5개 레이블에 실제 레이블이 포함되지 않은 경우를 가르킨다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. ImageNet 데이터 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;cnn-구조&#34;&gt;CNN 구조&lt;/h2&gt;
&lt;h3 id=&#34;relu-nonlinearity&#34;&gt;ReLU Nonlinearity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;논문이 게재되던 시점 CNN 구조에서 주로 사용되던 tanh, sigmoid 활성화 함수는 학습 속도가 느리다는 문제점을 안고있다. 따라서 AlexNet은 &lt;a class=&#34;link&#34; href=&#34;https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Nair and Hinton&lt;/a&gt; 에서 처음 소개된 ReLU 활성화 함수를 사용해 학습속도를 단축시킨다 (fig 2. 참조).&lt;/li&gt;
&lt;li&gt;논문은 ReLU activation function 을 다음과 같이 정의한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
f(x) = max(0,x)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ReLU 활성화를 사용하게 된 배경에는 2012 당시 AlexNet 의 구조가 기타 CNN에 비해 복잡하고, 크다는 점이 있었다 (&amp;lsquo;92년 공개된 LeNet-5 가 대략 6만개의 학습 가능한 파라미터를 가지고 있는 반면, AlexNet은 6천만개의 파라미터를 가지고있다).&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. CIFAR-10 데이터에 대한 ReLU (실선) vs. tanh (점선) 학습율 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;training-on-multiple-gpus&#34;&gt;Training on Multiple GPUs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;AlexNet 팀은 2012년 당시 최신 GPU 였던 NVIDIA GTX 580 2대를 활용해 모델을 학습시켰다. 각 GPU는 3GB 의 메모리를 가지고 있었으며, 적은 메모리 용량으로 인해 한대의 GPU를 사용해 전체 ImageNet 데이터를 학습하는 것이 불가능했다.&lt;/li&gt;
&lt;li&gt;2대의 GPU는 서로의 메모리에 직접적으로 접근할 수 있으며, 학습 과정에서의 병렬처리는 뉴런, 또는 커널을 반으로 나눠 각 GPU 에 할당하는 방식을 취한다. 다만 모든 레이어에서 커뮤니케이션이 이루어지는 것은 아니고, 특정 레이어에서만 이러한 기능을 활용해 리소스를 관리한다.&lt;/li&gt;
&lt;li&gt;GPU 병렬처리는 학습 시간을 단축시킬뿐만 아니라, GPU 한대에서 처리가능한 사이즈의 네트워크에 비해 top-1 과 top-5 에러율을 각각 1.7% 와 1.2% 감소시킨다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;local-response-normalization-lrn&#34;&gt;Local Response Normalization (LRN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lsquo;22년 기준 최신 CNN 구조에서는 잘 사용되지 않는 개념이다. AlexNet 이후 연구에 따르면 모델의 성능에 크게 기여하지 않는 것으로 밝혀졌다.&lt;/li&gt;
&lt;li&gt;ReLU 활성화 함수 사용으로 인풋 정규화를 반드시 사용해야할 이유는 없으나, AlexNet 의 경우 Local Response Normalization 이 모델의 일반화에 도움을 준다는 점을 발견했다.&lt;/li&gt;
&lt;li&gt;인접한 $n$ 개 채널에 대한 정규화라고 이해하면된다. 하단 슬라이드의 좌측 도표 참고.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Local Response Normalization 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;$a^i_{x,y}$ 가 채널 $i$ 에 대한 $x, y$ 좌표의 ReLU activation output 이라고 했을때, LRN 이 적용된 아웃풋 $b^i_{x,y}$ 는 다음과 같이 정의된다.
&lt;ul&gt;
&lt;li&gt;$n$ 은 인접 채널 수를 특정하는 파라미터, $N$ 은 전체 채널 수&lt;/li&gt;
&lt;li&gt;논문은 $k = 2$, $n = 5$, $\alpha = 10^{-4}$, $\beta = 0.75$ 로 설정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
b^i_{x,y} = a^i_{x,y}/(k + \alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a^j_{x,y})^2)^\beta
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;실제 인접 뉴런 간 정규화가 이루어지는 사람의 두뇌를 기반으로 하고있으며, top-1 과 top-5 에러율을 각각 1.4% 와 1.2% 감소시키는 효과를 보였다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;overlapping-pooling&#34;&gt;Overlapping Pooling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lsquo;12년 당시 pooling layer 는 각각의 pool 이 겹치지 않도록 stride 를 설정하는 것이 일반적이었으나, 이를 서로 겹치도록 설정함으로 top-1 에러율과 top-5 에러율을 각각 0.4% 와 0.3% 씩 감소시켰다.&lt;/li&gt;
&lt;li&gt;기본적인 룰은 $z$ x $z$ 의 pooling kernel 에서 $z$ 보다 작은 stride 사이즈, $s &amp;lt; z$ 를 적용시키는 것이다. 논문에서는 $s=2$, $z=3$ 를 사용하였다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;overall-architecture&#34;&gt;Overall Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;총 8개의 레이어를 가지고 있으며, 5개의 convolution 레이어 후 3개의 FC 레이어를 가지는 전형적인 CNN 구조이다. 마지막 FC 레이어는 1,000 개의 뉴런을 가지고 있는데 이에 softmax 함수를 적용해 클레스 레이블을 유추한다.&lt;/li&gt;
&lt;li&gt;2번, 4번, 5번 convolution 레이어의 경우 GPU 간 소통이 이루어지지 않는다. 따라서 같은 GPU 의 메모리에 속한 뉴런과의 관계만을 통해 학습을 진행한다. FC 레이어의 경우 앞선 레이어의 모든 뉴런과 연결되어있다.&lt;/li&gt;
&lt;li&gt;1번, 2번 convolution 레이어에만 LRN 이 적용된다. 해당 2개 레이어와 5번 convolution 레이어는 또한 Max Pooling 레이어를 가지고 있다.&lt;/li&gt;
&lt;li&gt;모든 convolution 레이어와 FC 레이어에 ReLU 활성화가 적용된다.&lt;/li&gt;
&lt;li&gt;최초 인풋 사이즈는 227 x 227 x 3 이다 (논문에는 224 x 224 x 3 으로 잘못 표기되어있는 것으로 보인다).&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. AlexNet 구조 (실제 논문 또한 이미지의 상단이 잘려있다)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;overfitting&#34;&gt;Overfitting&lt;/h2&gt;
&lt;p&gt;AlexNet 은 약 6천만개의 파라미터에 대한 과적합을 방지하기 위해 다음 두가지 방법 (Data Augmentation 과 Dropout)을 사용한다. Dropout 을 사용한 초기 아키텍쳐 중 하나이며, PCA Color Augmentation 개념이 조금 어렵게 다가온다.&lt;/p&gt;
&lt;h3 id=&#34;data-augmentation&#34;&gt;Data Augmentation&lt;/h3&gt;
&lt;p&gt;아래 translation, reflection 및 PCA color augmentation 기법을 통한 데이터 증강은 학습 과정과 병행되며 (디스크에 저장하지 않는다), GPU 가 아닌 CPU 에서 별도로 처리되기 때문에 사실상 연산에 부담을 주지 않는다.&lt;/p&gt;
&lt;h4 id=&#34;translation--reflection&#34;&gt;Translation &amp;amp; Reflection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;256 x 256 이미지에서 랜덤하게 추출된 5개의 224 x 224 패치와 (4개의 코너 패치와 한개의 중앙 패치), 패치들에 적용된 좌우반전을 통해 10배 사이즈의 학습 데이터를 구축했다. 이후 이 10개 증강 이미지에 대한 평균값을 통해 레이블을 예측하게 된다.&lt;/li&gt;
&lt;li&gt;이러한 데이터 증강 없이 학습된 네트워크는 심각한 과적합 문제를 가지고있다. 네트워크의 큰 사이즈 때문이며, 데이터 증강 기법을 사용하지 않는다면 네트워크 사이즈를 줄이는 방법 밖에는 없다고 저자는 기술한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pca-color-augmentation&#34;&gt;PCA Color Augmentation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;데이터 증강을 목적으로 RGB 채널의 강도를 조정하는 방식이며, PCA 를 통해 얻은 채널 별 분산에 비례하는 난수를 각 채널에 더하거나 빼주게된다.&lt;/li&gt;
&lt;li&gt;PCA 는 한개의 이미지가 아닌 모든 학습 데이터의 RGB 채널값을 대상으로 적용하게 된다. 따라서 자연스러운 채널 별 분산치를 얻을 수 있다.&lt;/li&gt;
&lt;li&gt;모든 RGB 픽셀 값에 대한 3 x 3 공분산 행렬의 eigenvector 를 $p$, eigenvalue 를 $\lambda$ 라고 칭하고, $\alpha$ 는 평균이 0, 표준 편차가 0.1인 Gaussian 분포의 난수일때, RGB 이미지 픽셀 $[I^R_{xy}, I^G_{xy}, I^B_{xy}]$ 에 다음의 값을 더하는 방식이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
[p_1, p_2, p_3][\alpha_1 \lambda_1, \alpha_2 \lambda_2, \alpha_2 \lambda_2]^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;개인적으로 아직 관련 이해도와 설명이 아쉽다. 차후 별도의 글을 통해 PCA 개념을 다시 짚어볼 계획.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dropout&#34;&gt;Dropout&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;모델의 성능을 높이기 위한 가장 좋은 방식은 여러 모델의 결과값을 구해 평균을 내는 것이나, 모델의 규모가 너무 크기때문에 이는 현실적으로 어려운 접근법이다.&lt;/li&gt;
&lt;li&gt;그 대안으로 논문은 0.5 의 확률로 개별 뉴런을 활성화하거나 비활성화하는 Dropout 방식을 제안한다. 이러한 확률로 비활성화된 뉴런은 순전파, 역전파 과정에 기여하지 않으며, 활성/비활성화의 사이클을 통해 여러개의 네트워크를 학습시키는 것과 동일한 결과를 얻을 수 있다.&lt;/li&gt;
&lt;li&gt;Dropout 방식은 뉴런이 다른 특정 뉴런에 지나치게 의존하는 것을 사전에 방지한다. 개별 뉴런이 이전 레이어의 activation 정보를 적절히 조합하도록 유도하는 구조이다.&lt;/li&gt;
&lt;li&gt;테스트시에는 이러한 학습과정으로 인해 뉴런의 아웃풋값에 0.5를 곱하게 된다.&lt;/li&gt;
&lt;li&gt;AlexNet은 처음 2개의 FC 레이어에서만 Dropout 을 사용하고 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;details-of-learning&#34;&gt;Details of Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;모델은 SGD 방식으로 학습되었으며, batch size는 128, momentum은 0.9, weight decay는 0.0005로 설정되었다.&lt;/li&gt;
&lt;li&gt;모든 weight 는 평균이 0, 표준편차가 0.01 인 Gaussian Distribution 의 난수로 설정되었으며, 2번, 3번, 5번 convolution 레이어와 모든 hidden FC 레이어의 bias 값은 1로 설정되었다 (ReLU activation 에 양수값을 input 함으로 훈련으로 가속시키는 효과를 가짐; 나머지 bias 값은 0 으로 설정).&lt;/li&gt;
&lt;li&gt;learning rate 는 모든 레이어에 동일하게 적용되었으며, 학습과정에서 manual 하게 조정되었다.
&lt;ul&gt;
&lt;li&gt;최초 learning rate는 0.01 로 설정&lt;/li&gt;
&lt;li&gt;validation error rate 감소가 멈췄을 경우, learning rate 를 10 으로 나눔&lt;/li&gt;
&lt;li&gt;학습 종료까지 총 세번의 learning rate 조정 발생&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;총 학습은 120만개의 이미지를 대상으로 90 사이클 진행.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ILSVRC-2010 데이터셋을 대상으로 top-1 에러율, top-5 에러율 각각 37.5% 와 17.0% 를 기록함 (대회 진행 시 우승 모델의 성능은 각각 47.1%와 28.2%).&lt;/li&gt;
&lt;li&gt;ILSVRC-2012 데이터셋의 test set label 은 &amp;lsquo;12년 당시 공개되지 않았음으로 validation error rate를 기록, 18.2%의 top-5 에러율을 보였다.
&lt;ul&gt;
&lt;li&gt;5개 CNN 구조의 평균값을 구했을때 16.4% 에러율 기록&lt;/li&gt;
&lt;li&gt;6번째 convolution 레이어를 추가한 후, &amp;lsquo;11년 대회 데이터셋을 기반으로 fine tuning 을 진행했을때 16.6% 에러율 기록, 5개 CNN 모델의 평균값과 다시 평균을 내었을때 15.3% 의 에러율을 보였다&lt;/li&gt;
&lt;li&gt;해당 대회의 2번째 높은 에러율은 26.2% 였음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Precision, Recall, F1 스코어 등의 모델 평가 방법</title>
        <link>https://meme2515.github.io/machine_learning/performance_measurement/</link>
        <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/machine_learning/performance_measurement/</guid>
        <description>&lt;img src="https://meme2515.github.io/machine_learning/images/performance_1.png" alt="Featured image of post Precision, Recall, F1 스코어 등의 모델 평가 방법" /&gt;&lt;h2 id=&#34;배경&#34;&gt;배경&lt;/h2&gt;
&lt;p&gt;모델 평가 방법에 대한 사전지식이 없는 누군가에게 스팸 필터 모델에 대한 평가를 요구한다면 아마 정확도 (accuracy) 를 평가 기준으로 선택할 것이다. 정확도는 직관적으로 다음과 같이 정의할 수 있다.&lt;/p&gt;
&lt;p&gt;$$
\text{Accuracy} = \frac{\text{Number of correct labels}}{\text{Number of all cases}}
$$&lt;/p&gt;
&lt;p&gt;경우에 따라 정확도는 적절한 평가 지표가 될 수 있겠지만, 문제가 될 여지 또한 존재한다. 예를 들어 데이터셋에 90가지의 비스팸 메일과, 10가지의 스팸메일이 존재한다고 가정한다면, 별도의 수학적 계산 없이 무조건 메일을 비스팸으로 정의하는 더미 모델은 앞서 정의한 정확도가 90% 에 이르게 된다. 따라서 이 경우에 정확도는 모델의 성능 평가라는 목적에 부합하지 않는 지표이다.&lt;/p&gt;
&lt;p&gt;다음 글에서는 이러한 &lt;a class=&#34;link&#34; href=&#34;https://machinelearningmastery.com/what-is-imbalanced-classification/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Class Imbalance&lt;/a&gt; 문제를 해결하기 위해 고안된 기타 평가 지표들을 설명하고있다.&lt;/p&gt;
&lt;h2 id=&#34;confusion-matrix&#34;&gt;Confusion Matrix&lt;/h2&gt;
&lt;p&gt;평가 지표 개념을 설명하기 전에 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Confusion_matrix&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;오차 행렬 (Confusion Matrix)&lt;/a&gt; 의 개념을 짚고가자. 기본적으로 오차 행렬은 문제 내 존재하는 클래스들의 예측 조합을 보여준다. 예를 들자면 90건의 클래스 Non-Spam 이 Non-Spam 으로 예측된 경우가 82건, Spam 으로 예측된 경우가 8건과 같은 식이다. 아래 그림을 확인하자.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/performance_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 단순 OX 문제에 대한 오차 행렬&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;위 그림에서 Positive(1)이 스팸메일을 뜻할 경우 다음과 같은 네가지 경우의 수가 존재한다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;True Positive (TP)&lt;/strong&gt;: 실제 스팸 메일이 스팸 메일로 올바르게 예측된 경우&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;False Positive (FP)&lt;/strong&gt;: 실제 비스팸 메일이 스팸 메일로 잘못 예측된 경우&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;False Negative (FN)&lt;/strong&gt;: 실제 스팸 메일이 비스팸 메일로 잘못 예측된 경우&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;True Negative (TN)&lt;/strong&gt;: 실제 비스팸 메일이 비스팸 메일로 올바르게 예측된 경우&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;이와 같은 오차 행렬의 언어를 사용하면 Accuracy 지표를 다음과 같이 정의할 수 있게된다.&lt;/p&gt;
&lt;p&gt;$$
\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}
$$&lt;/p&gt;
&lt;p&gt;경우의 수가 세분화 되었으니, 유사한 방법으로 성능 평가 지표에 대한 다양한 접근이 가능해졌다. 다음 부분에서는 대표적 대안 지표인 Precision 과 Recall 의 정의를 살펴보자.&lt;/p&gt;
&lt;h2 id=&#34;precision--recall&#34;&gt;Precision &amp;amp; Recall&lt;/h2&gt;
&lt;h3 id=&#34;precision&#34;&gt;Precision&lt;/h3&gt;
&lt;p&gt;Precision 이란 다음과 같이 정의할 수 있다.&lt;/p&gt;
&lt;p&gt;$$
\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}
$$&lt;/p&gt;
&lt;p&gt;즉, 기존 예시에서 &lt;strong&gt;스팸메일로 예측되었던 메일 중 실제 스팸메일의 비율&lt;/strong&gt;을 나타내는 지표이다. Precision 은 예측이 이미 이루어진 상황에서 예측값의 불순도를 측정하며, 무조건적으로 메일을 비스팸으로 분류하는 더미 모델의 경우 10% 의 Precision Score를 가지게 된다. &lt;em&gt;(여기서 positive(1) 값을 스팸으로 정의하는 것이 중요하다. 스팸 메일과 같은 minority class로 positive(1) 값을 설정해야 class imbalance 문제를 해결할 수 있다).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Precision 이 중요한 지표로 작용하는 예시로는 신선한 야채를 골라내는 분류기가 있다. 골라낸 야채 중 상하고 오래된 야채의 비중이 높을수록 판매자는 여러 심각한 리스크를 떠안게 된다. 신선한 야채를 몇개 버릴지언정 상한 야채를 신선한 야채로 분류하는 비율은 최소한으로 유지해야한다.&lt;/p&gt;
&lt;h3 id=&#34;recall&#34;&gt;Recall&lt;/h3&gt;
&lt;p&gt;Recall 이란 다음과 같이 정의할 수 있다.&lt;/p&gt;
&lt;p&gt;$$
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
$$&lt;/p&gt;
&lt;p&gt;Recall 은 &lt;strong&gt;실제 스팸메일 중 스팸메일로 예측된 메일의 비율&lt;/strong&gt;을 나타내는 지표이다. Recall 스코어는 예측이 이루어지기 전 실제 수치와 예측값의 유사도를 측정하며, 더미 모델의 경우 0% 의 Recall Score를 가지게 된다.&lt;/p&gt;
&lt;p&gt;Recall 이 중요한 지표로 작용하는 예시로는 의료적 진단이 있다. 실제 암환자에게 정확한 진단을 내리지 못하는 경우가 많아질수록 환자가 치료시기를 놓칠 위험이 증가하게 된다. 아프지 않은 환자에게 암 진단을 내리는 경우가 생길지언정 실제 암 환자에게 암 진단을 내리지 못하는 비율은 최소한으로 유지해야한다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/performance_3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Precision Recall 개념의 이해를 돕는 그림&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;f1-score&#34;&gt;F1 Score&lt;/h3&gt;
&lt;p&gt;Precision 과 Recall 을 F1 Score 라는 하나의 지표로 통일하는 방법 또한 존재한다.&lt;/p&gt;
&lt;p&gt;$$
\text{F1 Score} = 2 \cdot \frac{\text{Recall} \cdot \text{Precision}}{\text{Recall} + \text{Precision}}
$$&lt;/p&gt;
&lt;p&gt;Precision 과 Recall 간 &lt;a class=&#34;link&#34; href=&#34;https://wikidocs.net/23088&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;조화평균 (Harmonic Mean)&lt;/a&gt; 값을 구하는 것인데, 산술평균이나 기하평균이 아닌 조화평균을 사용하는 이유는 Precision 과 Recall 간 분모값 차이로 인한 스케일 차이가 발생하기 때문이다. &lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/26355942/why-is-the-f-measure-a-harmonic-mean-and-not-an-arithmetic-mean-of-the-precision&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;참고 설명&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;tpr-fpr&#34;&gt;TPR, FPR&lt;/h3&gt;
&lt;p&gt;TPR (True Positive Rate) 의 정의는 다음과 같으며, Recall 의 정의와 동일하다. 따라서 &lt;strong&gt;실제 스팸메일 중 스팸메일로 올바르게 예측된 메일의 비율&lt;/strong&gt; 을 측정한다.&lt;/p&gt;
&lt;p&gt;$$
TPR = \frac{TP}{TP + FN}
$$&lt;/p&gt;
&lt;p&gt;같은 지표가 TPR 이라는 또 다른 이름은 가지는 이유는 FPR (False Positive Rate) 의 개념과 대비하기 위해서다. FPR 은 다음과 같이 정의되며, &lt;strong&gt;실제 비스팸메일 중 스팸메일로 잘못 예측된 메일의 비율&lt;/strong&gt; 을 측정한다.&lt;/p&gt;
&lt;p&gt;$$
FPR = \frac{FP}{FP + TN}
$$&lt;/p&gt;
&lt;h3 id=&#34;sensitivity-specificity&#34;&gt;Sensitivity, Specificity&lt;/h3&gt;
&lt;p&gt;의료 분야에서 주로 사용되는 지표인 Sensitivity 또한 TPR, Recall 의 정의와 동일하며, &lt;strong&gt;실제 스팸메일 중 스팸메일로 올바르게 예측된 메일의 비율&lt;/strong&gt; 을 측정한다.&lt;/p&gt;
&lt;p&gt;$$
\text{Sensitivity} = \frac{TP}{TP + FN}
$$&lt;/p&gt;
&lt;p&gt;Sensitivity 는 Specificity 의 다음 정의와 대비되며, &lt;strong&gt;실제 비스팸메일 중 비스팸메일로 올바르게 예측된 메일의 비율&lt;/strong&gt; 을 측정한다. 즉, FPR 이 비스팸메일 데이터의 오류에 대한 비율이라면 Sensitivity 는 정확도에 대한 비율이라고 이해하면 된다. 같은 분모를 가지고 있지만 다른 분자를 가지고 있는 것을 확인할 수 있다.&lt;/p&gt;
&lt;p&gt;$$
\text{Specificity} = \frac{TN}{FP + TN}
$$&lt;/p&gt;
&lt;h2 id=&#34;pr-curve-roc-curve&#34;&gt;PR Curve, ROC Curve&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/performance_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. 분류기 모델의 ROC, PR Curve 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;precision-recall-pr-curve&#34;&gt;Precision-Recall (PR) Curve&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;신선한 야채를 몇개 버릴지언정&amp;rdquo;, &amp;ldquo;아프지 않은 환자에게 암 진단을 내리는 경우가 생길지언정&amp;rdquo; 과 같은 말은 이 두개 지표 사이에 trade-off 관계가 있음을 암시한다.&lt;/p&gt;
&lt;p&gt;더미 모델이 아닌 실제 각 클래스에 속할 확률을 구하는 모델의 경우, &lt;strong&gt;확률이 몇퍼센트 이상일때 positive(1) 으로 분류할 것인가를 정의하는 threshold 파라미터&lt;/strong&gt;를 가지고 있게된다 &lt;em&gt;(30% 이상의 확률일때 스팸으로 분류, 50% 이상의 확률일때 스팸으로 분류 등)&lt;/em&gt;. 이 threshold 를 움직임에 따라 Precision Recall 지표값이 어떠한 상관관계를 가지고 있는지를 나타내는 그래프를 &lt;strong&gt;Precision-Recall Curve, 혹은 PR Curve&lt;/strong&gt; 라 칭한다.&lt;/p&gt;
&lt;p&gt;위의 예시와 같이 일반적인 분류기는 Precision 이 상승하면 Recall 이 하락하고, Recall 이 상승하면 Precision 이 하락하는 관계를 가지고 있다.&lt;/p&gt;
&lt;h3 id=&#34;roc-curve&#34;&gt;ROC Curve&lt;/h3&gt;
&lt;p&gt;Receiver Operating Characteristic (ROC) Curve 또한 동일하게 threshold 의 움직임에 따라 TPR, FPR 지표의 상관관계를 나타내는 그래프이다. PR Curve 와는 반대로 하나의 지표가 상승할때 다른 하나의 지표 또한 같이 상승하는 관계를 가지고 있으며, 이는 TPR 은 정확도에 대한 지표인 반면 FPR 은 오류율에 대한 지표이기 때문이라고 이해하면 된다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;이상적인 모델은 ROC Curve 의 좌상단에 위치한, 즉 1의 TPR과 0의 FPR을 가지고 있는 모델이다&lt;/strong&gt;. 이는 스팸메일은 항상 스팸메일로, 비스팸메일은 항상 비스팸메일로 분류하는 모델을 뜻하기 때문이다.&lt;/p&gt;
&lt;h3 id=&#34;area-under-the-curve&#34;&gt;Area Under the Curve&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Area Under the Curve (AUC)&lt;/strong&gt; 는 말 그대로 적분을 통해 &lt;strong&gt;PR Curve 와 ROC Curve 의 부피&lt;/strong&gt;를 구한 값이다. 어떤 그래프의 부피인가에 따라 ROC-AUC, PR-AUC 로 정의되며, 모델 평가에 가장 일반적으로 쓰이는 지표는 ROC-AUC 이다. AUC 는 (0, 1) 의 범위를 가지고 있기 떄문에 &lt;strong&gt;ROC-AUC, PR-AUC 모두 1에 가까울수록 정확도가 높은 분류기로 정의할 수 있다&lt;/strong&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/machine_learning/images/performance_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. 분류기 모델의 ROC-AUC 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.floydhub.com/a-pirates-guide-to-accuracy-precision-recall-and-other-scores/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.floydhub.com/a-pirates-guide-to-accuracy-precision-recall-and-other-scores/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://uberpython.wordpress.com/2012/01/01/precision-recall-sensitivity-and-specificity/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://uberpython.wordpress.com/2012/01/01/precision-recall-sensitivity-and-specificity/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hands-On Machine Learning with Scikit-learn, Keras and Tersorflow&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>리눅스/우분투 명령어 모음 (Cheatsheet)</title>
        <link>https://meme2515.github.io/computer_science/linux_cheatsheet/</link>
        <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/computer_science/linux_cheatsheet/</guid>
        <description>&lt;img src="https://meme2515.github.io/computer_science/images/linux.jpg" alt="Featured image of post 리눅스/우분투 명령어 모음 (Cheatsheet)" /&gt;&lt;h2 id=&#34;linux-명령어-모음&#34;&gt;Linux 명령어 모음&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/Linux-Reference-1-1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Linux 명령어 모음&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;ubuntu-명령어-모음&#34;&gt;Ubuntu 명령어 모음&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/computer_science/images/Ubuntu-Reference-1-1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Ubuntu 명령어 모음&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        <item>
        <title>PyTorch Deep Learning - Backpropagation &amp; Gradient Descent</title>
        <link>https://meme2515.github.io/neural_network/pytorch_3/</link>
        <pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/pytorch_3/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/pytorch.jpeg" alt="Featured image of post PyTorch Deep Learning - Backpropagation &amp; Gradient Descent" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;머신러닝과 분야에서 가장 뼈대가 되는 수학 공식은 &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;경사하강&lt;/a&gt;이다. 왜일까? &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EC%84%9C%ED%8F%AC%ED%8A%B8_%EB%B2%A1%ED%84%B0_%EB%A8%B8%EC%8B%A0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SVM&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;선형회귀&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.ibm.com/kr-ko/cloud/learn/neural-networks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;신경망&lt;/a&gt;과 같은 통상적인 예측 모델은 모두 다른 방식으로 예측값 $\tilde{Y}$ 를 예측하지만, 이 모든 모델의 정확도를 향상하는 학습과정에서는 언제나 알고리즘에 알맞는 경사하강 공식을 사용하기 때문이다. 구체적으로 경사하강이란 모델의 성능을 더 나은 방향으로 개선시킬 수 있도록 조절 가능한 모델의 변수를 업데이트하는 과정을 가르킨다.&lt;/p&gt;
&lt;p&gt;모든 경사하강 과정은 그에 알맞는 기울기 값, 즉 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Gradient&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gradient&lt;/a&gt; 를 필요로하며, 이는 모델의 변수가 어떤 방향으로 (음수 또는 양수) 움직일때 성능이 개선되는지에 대한 정보를 제공한다. 신경망의 경우, 이러한 변수 별 gradient 값을 연산하기 위해 오차역전파라는 방법을 사용한다. 해당 글에서는 PyTorch 프레임워크를 사용하여 오차역전파를 수행하고, 신경망 모델의 경사하강을 구현하기까지의 과정을 실습해보고자 한다.&lt;/p&gt;
&lt;h2 id=&#34;autograd-복습&#34;&gt;Autograd 복습&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/neural_network/pytorch_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Deep Learning - 2. Autograd&lt;/a&gt; 글에서 살펴보았듯 신경망의 gradient 값을 도출하기 위해서는 역전파를 수행해야하며, 이는 PyTorch 라이브러리의 autograd 기능을 활용해 구현이 가능하다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_2_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 단일 뉴런의 역전파 과정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;$x = 1$ 의 인풋을 활용해 $y = 2$ 를 예측하는 단일 뉴런 모델의 역전파 과정을 PyTorch 로 구현한 코드는 다음과 같다. 이 경우 가중치인 $w$ 의 초기값이 최적치에 비해 낮기 때문에 gradient 는 음수가 되어야 한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.tensor(1.0)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = torch.tensor(2.0)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; w = torch.tensor(1.0, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # forward pass and compute the loss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y_hat = w * x
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; loss = (y_hat - y)**2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(loss)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor(1., grad_fn=&amp;lt;PowBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # backward pass
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; loss.backward()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(w.grad)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor(-2.)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;경사하강&#34;&gt;경사하강&lt;/h2&gt;
&lt;p&gt;경사하강이란 연산한 gradient 의 반대방향, 즉 손실함수를 낮추는 방향으로 모델의 파라미터를 업데이트하는 과정을 일컫는다. 아래 그림에서 start 지점의 gradient, 즉 미분값은 경사가 상대적으로 큰 양수값이며, 따라서 손실함수 $J(W)$ 를 최소화하기 위해 반대방향인 음수값으로 $w$ 를 업데이트하는 과정을 확인할 수 있다. 아직 gradient가 어떻게 손실함수를 낮추는 방향을 제시하는가에 대한 직관적인 이해가 이루어지지 않는다면 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=GEdLNvPIbiM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=IHZwWFHWa-w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2&lt;/a&gt; 비디오를 참고하길 바란다. 또한 &lt;a class=&#34;link&#34; href=&#34;http://localhost:1313/neural_network/optimizer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;해당&lt;/a&gt; 글은 Momentum, RMSProp, Adam 등 다양한 경사하강법을 소개하고있다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_3_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 단일 뉴런의 역전파 과정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;신경망 모델에서 경사하강을 수행하기 위해서는 다음과 같은 과정을 순차적으로 수행해야한다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Prediction&lt;/strong&gt;: 현재 파라미터 값을 사용한 예측&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss Computation&lt;/strong&gt;: 손실값 계산&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gradients Computation&lt;/strong&gt;: 예측값을 기반으로 한 gradient 연산&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parameter updates&lt;/strong&gt;: gradient 값을 기반으로 한 파라미터 업데이트&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;manual-접근법&#34;&gt;Manual 접근법&lt;/h3&gt;
&lt;p&gt;우선 PyTorch 라이브러리 없이 Numpy 만으로 이와 같은 손실함수 과정을 구현하는 코드를 살펴보자. 해당 코드의 gradient 는 MSE 함수에 대한 미분값을 별도로 계산한 것이며, 다음 식을 기반으로 하고있다.&lt;/p&gt;
&lt;p&gt;$$
\frac{\delta J}{\delta w} = \frac{1}{N} \cdot 2x (wx - y)
$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import numpy as np
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; X = np.array([1, 2, 3, 4], dtype=np.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Y = np.array([2, 4, 6, 8], dypte=np.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; w = 0.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # model prediction
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def forward(x):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return w * x
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # loss = MSE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def loss(y, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return ((y_pred - y) ** 2).mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # gradient
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def gradient(x, y, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return np.dot(2 * x, y_pred - y).mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # training
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; learning_rate = 0.01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; n_iters = 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; for epoch in range(n_iters):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    y_pred = forward(X)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    l = loss(Y, y_pred)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    dw = gradient(X, Y, y_pred)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # update weights
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w -= learning_rate * dw
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;autograd-활용&#34;&gt;Autograd 활용&lt;/h3&gt;
&lt;p&gt;다음 코드는 상단 경사하강 과정의 Gradients Computation 단계에서 수식이 아닌 Autograd 패키지의 자동미분 기능을 사용한 것이다. gradient 함수가 사라지고, 학습과정의 코드 변화를 확인할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Y = torch.tensor([2, 4, 6, 8], dypte=torch.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # requires_grad 매개변수 설정
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # model prediction
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def forward(x):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return w * x
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # loss = MSE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def loss(y, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return ((y_pred - y) ** 2).mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # training
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; learning_rate = 0.01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; n_iters = 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; for epoch in range(n_iters):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    y_pred = forward(X)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    l = loss(Y, y_pred)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # backward pass
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    l.backward()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # update weights
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    with torch.no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        w -= learning_rate * w.grad
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # reset gradient
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w.grad.zero_()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>배치정규화 (Batch Normalization) 란?</title>
        <link>https://meme2515.github.io/neural_network/batchnorm/</link>
        <pubDate>Sun, 26 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/batchnorm/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/batchnorm.png" alt="Featured image of post 배치정규화 (Batch Normalization) 란?" /&gt;&lt;h2 id=&#34;관련-논문위키-링크&#34;&gt;관련 논문/위키 링크&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1502.03167&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1805.11604&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How Does Batch Normalization Help Optimization?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Batch_normalization&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Wikipedia - Batch Normalization&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;딥러닝 모델의 mini-batch 학습은, 학습 단계 별 데이터의 분포가 서로 다르다는 점에서 그 복잡성이 올라가고는 한다. 배치정규화 논문이 공개되기 전에는 이 문제를 해결하기 위해 단순히 input data $X$ 를 정규화 하는것에 그쳤으나, 해당 논문을 개재한 Google 팀은 각 중간 레이어의 아웃풋에 또한 정규화를 적용함으로 모델의 학습속도를 끌어올릴 수 있다는 점을 발견했다. 이와 같은 레이어 별 정규화 과정은 배치 스텝마다 별도로 적용되어야 하며 &lt;em&gt;(input data $X$에 대한 정규화는 전체 분포에 대한 정보가 있기때문에 일괄적으로 이루어질 수 있지만 중간 레이어의 결과값은 그렇지 못함)&lt;/em&gt;, 따라서 이를 &lt;strong&gt;배치정규화&lt;/strong&gt;라 칭한다.&lt;/p&gt;
&lt;h2 id=&#34;internal-covariate-shift&#34;&gt;Internal Covariate Shift&lt;/h2&gt;
&lt;p&gt;Google 팀이 중간레이어의 아웃풋을 정규화하게 된 배경에는 그들이 internal covariate shift 라고 명명한 문제가 존재한다. 비신경망 머신러닝 모델에 서로 다른 분포를 가진 데이터를 넣을떄 발생하는 &lt;a class=&#34;link&#34; href=&#34;https://www.google.com/search?client=firefox-b-d&amp;amp;q=covariate&amp;#43;shift&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;covariate shift&lt;/a&gt; 라는 문제를 중간레이어 개념에 도입한 것인데, 특히 hyperbolic tangent, sigmoid와 같은 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Activation_function&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;비선형 활성화 함수 (non-linear activation function)&lt;/a&gt; 를 무겁게 사용하는 딥러닝 모델의 경우 이와 같은 분포 차이에 취약해질 여지가 많다.&lt;/p&gt;
&lt;p&gt;$$
g(x) = \frac{1}{1 + e^{-x}}
$$&lt;/p&gt;
&lt;p&gt;위의 sigmoid 함수에서 input 값 $x$가 조금만 올라가거나 내려가도 학습 속도는 기하급수적으로 느려지게된다는 점을 기억할 것이다 &lt;em&gt;(함수의 결과값이 0에 가까워지며 그 기울기가 작아지기 때문)&lt;/em&gt;. 분포차가 심한 데이터를 단계별로 학습할때 이와 같은 문제로 인해 convergence를 찾는 과정이 심각하게 느려질 수 있다.&lt;/p&gt;
&lt;p&gt;또 하나의 문제는 레이어를 통과할수록 배치 간 데이터의 분포가 점차 더 큰 차이를 가지게 된다는 점이다. 신경망 구조가 워낙 복잡하기도 하지만, 이전 레이어의 가중치 (weight) 와 편향 (bias) 이 학습과정에서 계속 업데이트 되기 때문인데, 이쯤되면 중간레이어의 정규화 없이 학습이 이루어진다는게 오히려 이상하게 보인다.&lt;/p&gt;
&lt;h2 id=&#34;방법론&#34;&gt;방법론&lt;/h2&gt;
&lt;p&gt;일반적인 배치정규화는 activation function 의 아웃풋 $a$ 가 아닌 인풋 $z$ 에 적용된다. 비교적 일정하고, 적정한 범위내의 데이터를 activation function 에 집어넣어 activation layer 내 가능한 많은 노드가 제 역할을 하게하자는 취지이다. 한 개 레이어에서 배치정규화를 수행하는 방법은 다음과 같다.&lt;/p&gt;
&lt;p&gt;$$
\mu = \frac{1}{m} \sum_{i} z^i
$$&lt;/p&gt;
&lt;p&gt;$$
\sigma^2 = \frac{1}{m} \sum_{i} (z_i - \mu)^2
$$&lt;/p&gt;
&lt;p&gt;우선 선형함수 $z$ 의 평균 $\mu$ 와 분산 $\sigma^2$ 를 구한다. 해당 값들은 레이어, 배치 별로 그 값이 다르기 때문에 학습, 예측 단계에서 매번 계산이 필요하다.&lt;/p&gt;
&lt;p&gt;$$
z_{norm}^i = \frac{z^i - \mu}{\sqrt{\sigma^2 + \epsilon}}
$$&lt;/p&gt;
&lt;p&gt;정규화 수식을 이용하여 $z_{norm}$ 값을 구한다. 여기서 수식의 분모에 있는 $\epsilon$ 은 $\sigma^2$ 가 $0$ 일 경우에 대비한 아주 작은 safety term 이다. 이로 인해 $z_{norm}$ 은 평균이 $0$ 이며, 표준편차가 $1$ 에 해당하는 분포를 가지게된다.&lt;/p&gt;
&lt;p&gt;Input에 대한 정규화 처리는 이 단계에서 끝나겠지만 배치정규화는 다음과 같이 평균값과 표준편차에 대한 자유도를 주게된다. 처음 접했을때 다소 헷갈렸던 부분인데 데이터에 관계 없이 고른 분포를 추출하는 과정이라고 생각하면된다.&lt;/p&gt;
&lt;p&gt;$$
\tilde{z^i} = \Gamma z_{norm}^i + \Beta
$$&lt;/p&gt;
&lt;p&gt;여기서 $\Gamma$ 와 $\Beta$ 는 학습을 통해 최적값에 수렴하게된다. 이후 레이어, 배치 별 정규화가 적용된 $\tilde{z^i}$ 를 활성함수의 인풋으로 사용하면 배치정규화가 적용된 것이다.&lt;/p&gt;
&lt;h2 id=&#34;기타-효과&#34;&gt;기타 효과&lt;/h2&gt;
&lt;p&gt;구체적으로 배치정규화가 모델의 학습과정을 개선시키는 방법은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;1-학습-속도-개선&#34;&gt;1. 학습 속도 개선&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/batchnorm_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;정규화된 분포는 어떻게 학습 속도를 개선할까? 위 그림에서 왼쪽 그래프는 정규화가 적용되지 않은 경우의 손실함수를, 오른쪽 그래프는 정규화가 적용된 경우의 손실함수를 시각화 하고있다. 왼쪽의 경우 전반적인 손실함수 결과값이 $x$ 축 변수보다 $y$ 축 변수의 움직임에 더 민감한 부분을 확인할 수 있는데, 따라서 큰 학습속도 $\alpha$ 를 적용할 경우 방향성을 잃어 최적값을 찾지 못하는 문제가 발생할 여지를 가지게 된다. &lt;strong&gt;두 변수의 스케일 차이가 학습률에 제약을 가져오는 것이다&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;반면 오른쪽 그래프에서는 손실함수의 결과값이 두 개 변수에 유사한 민감도를 가지고 있는 점을 확인할 수 있다. 물론 이 경우 또한 지나치게 큰 $\alpha$ 값은 문제를 야기하겠지만, 전자의 경우에 비해 그 정도가 개선되었다는 점을 독자는 시각적으로 확인이 가능할 것이다.&lt;/p&gt;
&lt;h3 id=&#34;2-초기값에-대한-내성&#34;&gt;2. 초기값에 대한 내성&lt;/h3&gt;
&lt;p&gt;위 그림을 다시 참조하자. 왼쪽 그래프의 경우 초기값이 타원의 오른쪽 끝에 있을 경우와, 중하단에 있을 경우 중심점 (최적값) 으로 부터의 상당한 거리차가 발생한다. 이는 모델의 초기값에 따른 학습속도 차이가 발생할 수 있음을 의미한다. 오른쪽 그래프 또한 이러한 문제점을 어느정도 안고 있지만, 적어도 동일한 붉은 원 안에서는 거리차가 발생하지 않는다는 점을 확인할 수 있다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Conda 환경 공유 방법</title>
        <link>https://meme2515.github.io/machine_learning/conda_1/</link>
        <pubDate>Thu, 23 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/machine_learning/conda_1/</guid>
        <description>&lt;img src="https://meme2515.github.io/machine_learning/images/conda.png" alt="Featured image of post Conda 환경 공유 방법" /&gt;&lt;h2 id=&#34;배경&#34;&gt;배경&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.conda.io/en/latest/#&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;콘다&lt;/a&gt;는 윈도우, 맥OS, 리눅스에서 동작하는 패키지 관리 시스템이며, 데이터 분석 환경에서 주로 사용되지만 파이썬, R, 루비, 자바 등 다양한 언어를 지원한다. 본 글에서는 짧게 콘다 환경 생성과 세팅, 저장, 그리고 다른 컴퓨터에서 저장된 환경을 불러오는 법을 살펴보고자 한다.&lt;/p&gt;
&lt;h2 id=&#34;환경-생성-및-세팅-저장&#34;&gt;환경 생성 및 세팅, 저장&lt;/h2&gt;
&lt;h3 id=&#34;생성-및-패키지-설치&#34;&gt;생성 및 패키지 설치&lt;/h3&gt;
&lt;p&gt;Conda 환경은 다음과 같이 생성할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda create --name [환경이름] python=3.10
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;생성된 모든 conda 환경은 다음 커맨드로 확인할 수 있다. &lt;code&gt;*&lt;/code&gt; 표시는 현재 환경을 나타낸다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda env list
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; conda environments:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     base                       *
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     environment1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     environment2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;환경을 바꾸기 위해서는 &lt;code&gt;activate&lt;/code&gt; 커맨드를 사용한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda activate environment1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda env list
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; conda environments:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     base
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     environment1               *
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     environment2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;현재 환경에 설치된 패키지는 다음과 같이 확인할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda list
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; numba             0.48.0              py37h47e9c7a_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     numpy             1.18.1              py37h93ca92e_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     openssl           1.1.1d                  he774522_4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     pandas            1.0.1               py37h47e9c7a_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;패키지를 설치하기 위해서는 주로 &lt;code&gt;pip install&lt;/code&gt;, 혹은 &lt;code&gt;conda install&lt;/code&gt; 커맨드를 사용하게 된다. &lt;a class=&#34;link&#34; href=&#34;https://pypi.org/project/pip/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;pip&lt;/a&gt;은 파이썬 전용 패키지인 반면, conda는 기타 언어의 패키지 관리를 지원한다는 차이점을 가지고있다. 다음 예시는 pip 패키지 매니저를 활용했다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; pip install cython
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda list
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; cython            0.29.15             py37ha925a31_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     numba             0.48.0              py37h47e9c7a_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     numpy             1.18.1              py37h93ca92e_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     openssl           1.1.1d                  he774522_4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     pandas            1.0.1               py37h47e9c7a_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;yaml-파일-저장&#34;&gt;YAML 파일 저장&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.redhat.com/en/topics/automation/what-is-yaml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YAML&lt;/a&gt; 포맷으로 환경 설정을 저장하기 위해서는 다음 커맨드를 활용한다. YAML 파일명은 굳이 환경 이름과 매칭되지 않아도 괜찮다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda env export &amp;gt; environment1.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;이후 해당 커맨드를 실행한 경로에 environment1.yaml 이라는 파일이 생성되게 된다. 해당 파일을 열어보면 다음과 같이 설치된 패키지가 나열되어 있는것을 확인할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; name: environment1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; channels:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - conda_forge
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - defaults
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; dependencies:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - cython=0.29.15=py37ha925a31_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - numba=0.48.0=py37h47e9c7a_0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;yaml-파일을-활용한-환경-생성&#34;&gt;YAML 파일을 활용한 환경 생성&lt;/h2&gt;
&lt;p&gt;다른 컴퓨터에서 저장된 conda 환경과 동일한 환경을 생성하고자 할때, 커맨드창에서 YAML 파일 경로로 이동 후 다음을 실행시키면 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; conda env create --file environment1.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>PyTorch Deep Learning - Autograd</title>
        <link>https://meme2515.github.io/neural_network/pytorch_2/</link>
        <pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/pytorch_2/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/pytorch.jpeg" alt="Featured image of post PyTorch Deep Learning - Autograd" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;신경망을 수학적으로 구현함에 있어 가장 까다로운 부분은 &lt;a class=&#34;link&#34; href=&#34;http://wiki.hash.kr/index.php/%EC%97%AD%EC%A0%84%ED%8C%8C&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;역전파 (backpropagation)&lt;/a&gt; 과정이다. 짧게 설명하자면, 모델에 존재하는 각각의 가중치(weight)와 편향(bias)이 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Loss_function&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;손실함수&lt;/a&gt;에 어떠한 영향을 끼치는지를 연산한 다음, 이 정보를 활용해 가중치와 편향의 값을 손실함수를 줄이는 방향으로 갱신시키는 과정이다. 개념적인 이해가 필요하다면 앞선 역전파 해시넷 링크와 더불어 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Ilg3gGewQ5U&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;번, &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=1Q_etC_GHHk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2&lt;/a&gt;번 비디오를 참고하자.&lt;/p&gt;
&lt;p&gt;역전파 과정에서 가장 중요한 수학적 요소는 손실함수에 대한 가중치와 편향의 편미분 (partial derivative) 연산이다. 가중치가 증가할때 손실함수 또한 같이 증가한다면 가중치값을 내리고, 편향 값이 내려갈때 손실함수가 증가한다면 반대로 편향값을 증가시키는 식이다. 이러한 과정을 반복함으로 인해 모델은 가능한 낮은 손실함수, 즉 높은 정확도를 가지게 된다.&lt;/p&gt;
&lt;p&gt;하지만 신경망 네트워크에는 경우에 따라 수십만개의 가중치와 편향이 존재하고, 이를 학습 사이클마다 일일이 손으로 계산할 수 없기 때문에 편미분 연산을 자동적으로 처리해주는 알고리즘을 필요로 하게 되었다. 주요 딥러닝 프레임워크인 PyTorch 의 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Autograd&lt;/a&gt; 패키지는 이러한 역전파 과정을 자동적으로 처리해주는 기능을 가지고있다.&lt;/p&gt;
&lt;h2 id=&#34;자동-미분-automatic-differentiation&#34;&gt;자동 미분 (Automatic Differentiation)&lt;/h2&gt;
&lt;p&gt;Autograd 패키지를 소개하기에 앞서, 자동 미분이 어떠한 방식으로 이루어지는지를 우선 살펴보고자 한다. 자동 미분의 접근 방식은 크게 세가지 (Numerical, Symbolic, Automatic) 가 존재한다.&lt;/p&gt;
&lt;h3 id=&#34;a-numerical&#34;&gt;a. Numerical&lt;/h3&gt;
&lt;p&gt;Numerical 접근은 고등학교 수학에서 등장하는, 극한을 통한 미분의 정의를 이용한다. $f(x)$가 input vector $x$에 대한 손실함수라고 가정했을때의 공식은 다음과 같다.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\frac{\delta f}{\delta x_i} = \lim_{h \to 0} \frac{f(x+he^i) - f(x)}{h}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;여기서 $x$란 길이 $n$의 input 벡터이며, $e^i$ 란 길이가 $n$이며 $i$ 번째 값이 1, 나머지 값이 0인 단위벡터 (unit vector) 이다.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
x = \begin{bmatrix}
x_1 \
x_2 \
\dots \
x_n
\end{bmatrix}
; \
e^1 = \begin{bmatrix}
1 \
0 \
\dots \
0
\end{bmatrix}
; \
e^2 = \begin{bmatrix}
0 \
1 \
\dots \
0
\end{bmatrix}
; \
\dots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;따라서 (1)번 식은 $x^i$ 값이 아주 작게 움직였을때, 함수 $f$의 결과값이 얼만큼 움직이는지를 나타내고있다.&lt;/p&gt;
&lt;p&gt;Numerical 접근에선 크게 두가지 문제점이 존재한다. 첫번째 문제는 극한 (limit) 정의를 코드로 구현할 때 발생하는 오차 문제 (rounding error) 이다. 이는 아주 작은 $h$ 값을 컴퓨터의 floating point로 표현할 때 발생하는 물리적인 한계에서 비롯된 문제이다. 관심이 있는 독자들은 &lt;a class=&#34;link&#34; href=&#34;https://blog.demofox.org/2017/11/21/floating-point-precision/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;링크&lt;/a&gt;를 통해 더 자세한 내용을 확인하자.&lt;/p&gt;
&lt;p&gt;두번째 문제는 해당 접근법이 $O(n)$ 만큼의 연산, 즉 각 가중치와 편향 값에 대한 개별적인 연산을 수행해야 한다는 점이다. 이는 수십만개의 가중치와 편향 값을 학습하는 신경망 네트워크에 지나친 연산 부담을 줄 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;b-symbolic&#34;&gt;b. Symbolic&lt;/h3&gt;
&lt;p&gt;Symbolic 접근은 사람이 실제 미분 연산시에 사용하는 연산 규칙 (예를 들어 $\sin (x)$ 의 미분값은 $\cos (x)$) 을 기반으로 편미분을 구하는 방식이다. 해당 접근법에서 손실함수는 가중치와 편향의 수식으로 표현되며, 연산 규칙을 그 기반으로 하기에 numerical 접근법의 오차 문제를 해결한다. 대표적인 예시로 &lt;a class=&#34;link&#34; href=&#34;https://www.sympy.org/en/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SymPy&lt;/a&gt; 패키지가 있다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_2_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. SymPy 패키지 적분 연산 사용 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(고등학생때 알았더라면&amp;hellip;!)&lt;/p&gt;
&lt;p&gt;얼핏 생각하기에 타당해 보이는 symbolic 접근 또한 역전파 적용이 어려운 이유가 존재한다. 가장 대표적인 문제는 expression swell 인데, 손실함수의 수식보다 그 미분 수식이 기하급수적으로 복잡해지는 문제이다. 다음 예시와 함께 미분의 곱 규칙을 생각해보자.&lt;/p&gt;
&lt;p&gt;$$
h(x) = f(x)g(x) \newline
h&amp;rsquo;(x) = f&amp;rsquo;(x)g(x) + f(x)g&amp;rsquo;(x) \newline
$$&lt;/p&gt;
&lt;p&gt;$f(x)$를 다음과 같이 정의하면 $h&amp;rsquo;(x)$는 더욱 복잡해진다.&lt;/p&gt;
&lt;p&gt;$$
f(x) = u(x)v(x) \newline
h&amp;rsquo;(x) = (u&amp;rsquo;(x)v(x) + u(x)v&amp;rsquo;(x))g(x) + u(x)v(x)g&amp;rsquo;(x) \newline
$$&lt;/p&gt;
&lt;p&gt;이는 한가지 예시에 불과하고, 미분 수식의 복잡성은 손실함수의 수식과 비례하지 않기 때문에 해당 접근은 numerical 접근의 $O(n)$ 연산을 뛰어넘는 연산 부담을 네트워크에 줄 가능성이 있다. 또한 미분 연산의 대상이 항상 특정 수식으로 표현되어야 한다는 제약을 가지고 있다.&lt;/p&gt;
&lt;h3 id=&#34;c-automatic&#34;&gt;c. Automatic&lt;/h3&gt;
&lt;p&gt;Automatic 접근은 수식에 기반하는 대신, 덧셈, 곱셈과 같은 개별적인 연산자 그래프 (DAG) 를 생성하여 미분 연산 과정을 가장 작은 단위에서 수행하는 접근법이다. 다음 그래프를 참고하자.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_2_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 단일 뉴런의 Autograd DAG 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;여기서 $w$는 가중치, $b$는 편향, $z$는 활성함수를 나타낸다 (편의를 위해 loss 또한 $L$로 지칭하겠다). 위 그래프에서 가중치 $w$의 편미분값, $\frac{\delta L}{\delta w}$ 값을 연산한다고 가정해보자. 우선 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Cross_entropy&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CE (Cross Entropy)&lt;/a&gt; 함수의 미분식을 통해 $\frac{\delta L}{\delta z}$ 를 구한 후, $z$ 함수의 미분식을 사용해 구한 $\frac{\delta z}{\delta w}$를 $\frac{\delta L}{\delta z}$ 에 곱해줌으로서 $\frac{\delta L}{\delta z} \cdot \frac{\delta z}{\delta w} = \frac{\delta L}{\delta w}$를 연산할 수 있다. 더 작은 단위의 (레이어가 아닌 연산자 단위) 역전파라 생각해도 무방할 듯 하며, 복잡해 보이지만 편미분의 정의를 되새기며 기호와 그래프를 유심히 따라가면 그 의미가 전달 될 것이라 생각한다.&lt;/p&gt;
&lt;h2 id=&#34;jacobian-vector-products-jvps&#34;&gt;Jacobian-Vector Products (JVPs)&lt;/h2&gt;
&lt;p&gt;위 Fig 3. 의 예시에서는 2개의 input $w$, $b$와, 1개의 output $L$에 대한 연산자 그래프를 살펴보았다. Input의 개수가 $n$이고, output의 개수가 $m$인 경우는 어떨까? 해당 연산자 그래프에 대해서 다음과 같은 &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EC%95%BC%EC%BD%94%EB%B9%84_%ED%96%89%EB%A0%AC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;편미분 매트릭스 (야코비 행렬, Jacobian Matrix)&lt;/a&gt;를 구할 수 있을 것이다.&lt;/p&gt;
&lt;p&gt;(여기서 $x$는 input을, $f$는 output을 뜻하고 있다)&lt;/p&gt;
&lt;p&gt;$$
\begin{equation*}
J_{f} =
\begin{bmatrix}
\frac{\delta f_1}{\delta x_1 } &amp;amp; \frac{\delta f_2}{\delta x_1 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_1 } \newline
\frac{\delta f_1}{\delta x_2 } &amp;amp; \frac{\delta f_2}{\delta x_2 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_2 } \newline
\vdots  &amp;amp; \vdots  &amp;amp; \ddots &amp;amp; \vdots  \newline
\frac{\delta f_1}{\delta x_n } &amp;amp; \frac{\delta f_2}{\delta x_n } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_n } \newline
\end{bmatrix}
\end{equation*}
$$&lt;/p&gt;
&lt;p&gt;야코비 행렬은 모든 input과 output의 조합에 대한 편미분 값을 가지고 있으며, 각 열에는 output $f_i$, 행에는 input $x_j$에 속하는 값이 정렬되어있다. 특정 output 값 $f_i$에 대한 모든 input $x$의 편미분 벡터를 구하기 위해서는 다음과 같이 적합한 벡터 $r$을 곱해주어야 한다.&lt;/p&gt;
&lt;p&gt;$$
\begin{equation*}
\frac{\delta f_i}{\delta x} =
J_f r =
\begin{bmatrix}
\frac{\delta f_1}{\delta x_1 } &amp;amp; \frac{\delta f_2}{\delta x_1 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_1 } \newline
\frac{\delta f_1}{\delta x_2 } &amp;amp; \frac{\delta f_2}{\delta x_2 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_2 } \newline
\vdots  &amp;amp; \vdots  &amp;amp; \ddots &amp;amp; \vdots  \newline
\frac{\delta f_1}{\delta x_n } &amp;amp; \frac{\delta f_2}{\delta x_n } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_n } \newline
\end{bmatrix}
\cdot
\begin{bmatrix}
1 \newline
0 \newline
\vdots \newline
0 \newline
\end{bmatrix}
=
\begin{bmatrix}
\frac{\delta f_1}{\delta x_1 } \newline
\frac{\delta f_1}{\delta x_2 } \newline
\vdots \newline
\frac{\delta f_1}{\delta x_n } \newline
\end{bmatrix}
\end{equation*}
$$&lt;/p&gt;
&lt;h2 id=&#34;autograd-사용법&#34;&gt;Autograd 사용법&lt;/h2&gt;
&lt;p&gt;PyTorch의 Autograd 패키지는 이러한 야코비 행렬을 연산해주는 기능을 가지고있다. 우선 input 벡터인 $x$를 지정하는 법을 알아보자.&lt;/p&gt;
&lt;h3 id=&#34;requires_grad-파라미터&#34;&gt;requires_grad 파라미터&lt;/h3&gt;
&lt;p&gt;Input 벡터로 사용하고자 하는 tensor를 최초로 생성할때는 &lt;code&gt;requires_grad&lt;/code&gt; 파라미터를 &lt;code&gt;True&lt;/code&gt;로 설정해야한다. 다음 예시를 확인하자.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.randn(3, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([-1.0475, 0.2038, 0.2971], requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = x + 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([1.6828, 2.3467, 2.6648], grad_fn=&amp;lt;AddBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z = y * y * 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(z)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([1.5855, 2.3060, 2.3540], grad_fn=&amp;lt;MulBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z = z.mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(z)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor(8.9153, grad_fn=&amp;lt;MeanBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;x&lt;/code&gt; tensor 생성 시 &lt;code&gt;requires_grad&lt;/code&gt; 파라미터를 True로 설정할 경우, &lt;code&gt;x&lt;/code&gt;를 변수로 사용한 함숫값 &lt;code&gt;y&lt;/code&gt;, &lt;code&gt;z&lt;/code&gt; tensor에 &lt;code&gt;grad_fn&lt;/code&gt; 이라는 미분 함수가 내제되어있는 것을 확인할 수 있다. 이는 언급했던 연산자 그래프의 노드에 해당하며, 편미분 연산시에는 이러한 노드를 순차적으로 되돌아가며 결과값을 연산하게된다.&lt;/p&gt;
&lt;h3 id=&#34;backward-함수&#34;&gt;backward() 함수&lt;/h3&gt;
&lt;p&gt;앞선 예시에서 최종 함숫값인 &lt;code&gt;z&lt;/code&gt;에 다음과 같이 &lt;code&gt;backward&lt;/code&gt; 함수를 호출할 시, 역전파에 필요한 편미분값 $\frac{\delta z}{\delta x}$ 를 &lt;code&gt;x.grad&lt;/code&gt; 속성을 통해 확인할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z.backward() # dz/dx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x.grad)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([0.0160, 3.3650, 4.5153])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;이 경우에는 &lt;code&gt;z&lt;/code&gt;가 단일값이기 때문에 야코비 행렬이 그대로 리턴되었다. &lt;code&gt;z&lt;/code&gt;가 단일값이 아닌 벡터일때는 어떻게 해야할까? 결과값이 매트릭스이기 때문에 어떤 $z$값에 대한 편미분을 구해야 하는지가 명확하지 않다. 이러한 경우 앞선 예시에 사용된 벡터 $r$을 매개변수로 집어넣어야 한다. 다음 예시를 확인하자.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.randn(3, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = x + 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z = y * y * 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z.backward()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; RuntimeError: grad can be implicitly created only for scalar outputs.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; r = torch.tensor([1.0, 0, 0], dtype=torch.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z.backward(r)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x.grad)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([5.0823, 0.0000, 0.0000])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;대부분의 경우 편미분 연산은 단일값인 손실함수 $L$에 대해 이루어지기 때문에 &lt;code&gt;backward&lt;/code&gt; 함수 사용 시 별도의 매개변수는 사용하지 않게된다. 관련 내용에 궁금증이 남는다면 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=hjnVLfvhN0Q&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;본 영상&lt;/a&gt;을 참고하자.&lt;/p&gt;
&lt;h2 id=&#34;참고-링크&#34;&gt;참고 링크&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=c36lUUr864M&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=c36lUUr864M&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=wG_nF1awSSY&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=wG_nF1awSSY&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>수학적으로 이해하는 최적화 기법 - 모멘텀, RMSProp, ADAM </title>
        <link>https://meme2515.github.io/neural_network/optimizer/</link>
        <pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/optimizer/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/adam.png" alt="Featured image of post 수학적으로 이해하는 최적화 기법 - 모멘텀, RMSProp, ADAM " /&gt;&lt;h2 id=&#34;관련-논문-링크&#34;&gt;관련 논문 링크&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1412.6980&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Adam: A Method for Stochastic Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1609.04747.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;경사하강법&lt;/a&gt;이란 여러개의 변수를 활용해 정의된 머신러닝 모델의 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Loss_function&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;손실함수 (Loss Function)&lt;/a&gt; 를 최저치로 낮추는 기법이다. 변수 $i$ 에 대한 손실함수 $J$ 의 미분값을 $\alpha$, 혹은 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Learning_rate&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;학습률 (learning rate)&lt;/a&gt; 로 불리는 학습 속도 설정값에 곱한 후, 변수 $i$ 에 적용되는 가중치 $\theta_i$ 에서 빼주는 방식이다. 수식은 다음과 같이 정의된다.&lt;/p&gt;
&lt;p&gt;$$
\theta_i := \theta_i - \alpha \frac{\partial}{\partial \theta_i}J(\theta)
$$&lt;/p&gt;
&lt;p&gt;다만 mini-batch 경사하강의 경우 매 iteration에서 리소스적인 문제로 전체 데이터가 아닌 부분 데이터를 활용하기 때문에 여기서 하강이 이루어지는 방향이 직진성을 띄고 있지 않을 가능성이 높은데, &lt;strong&gt;모멘텀&lt;/strong&gt;은 이러한 문제를 해결하기 위해 &lt;strong&gt;변수 별 미분값의 점진적 평균값 (지수 가중 평균) 을 구해 하강의 방향성을 찾는다&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/adam_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;위 그림에서 y축 변수의 하강 방향은 지그재그 형태를 띄는 반면, x축 변수의 하강 방향은 일정한 방향성을 띄고있다. 이로 인해 기본적인 형태의 경사하강 진행 시 &lt;strong&gt;학습 과정이 불필요하게 길어지게되는 결과&lt;/strong&gt;를 야기하게되나, 모멘텀 최적화 방식을 이용하면 y축 변수 하강 방향의 점진적 평균은 0에 가까워지며, x축 변수 하강 방향의 점진적 평균값은 유지되기 때문에 &lt;strong&gt;불필요한 학습 과정이 줄어드는 (직진성) 효과를 가진다&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;RMSProp은 유사하지만 평균치가 아닌 제곱평균제곱근 (RMS) 을 통해 그 방향성을 구하고자하며, ADAM 은 이 두가지 최적화 방식의 조합이다.&lt;/p&gt;
&lt;h2 id=&#34;지수-가중-평균의-정의-exponentially-weighted-averages&#34;&gt;지수 가중 평균의 정의 (Exponentially Weighted Averages)&lt;/h2&gt;
&lt;h3 id=&#34;개념-및-정의&#34;&gt;개념 및 정의&lt;/h3&gt;
&lt;p&gt;위 세개의 최적화 개념을 수학적으로 이해하기 위해서는 지수 가중 평균 (EWMA) 개념을 먼저 이해할 필요가 있다. 개념은 생각보다 복잡하지 않은데, $\theta_1,\theta_2, \theta_3, &amp;hellip; , \theta_n$ 와 같이 순차적인 $n$개의 데이터셋이 있을 시 $n$ 보다 작거나 같은 시점 $t$ 의 지수 가중 평균 $V_t$는 다음과 같이 정의된다.&lt;/p&gt;
&lt;p&gt;$$
V_0 = 0；　
V_t = \beta V_{t-1} + (1-\beta)\theta_t
$$&lt;/p&gt;
&lt;p&gt;여기서 $\beta$ 값은 사용자가 지정하며 (가장 일반적인 값은 $0.9$ 이다), 이렇게 계산된 $V_t$ 값은 대략 $t - \frac{1}{1 - \beta}$ 부터 $t$ 까지 기간의 단순 평균치에 근접하게 된다. 누적된 평균값에 일정 비율로 현재 값을 반영하는 접근법이며, Bayesian 통계와 개념적으로 유사한 부분이 있다.&lt;/p&gt;
&lt;p&gt;아래 그래프는 파란색으로 표기된 Original 데이터에 조금씩 큰 $\beta$ 값을 사용하며 계산한 EWMA 를 시각화한 결과이다. 회색이 가장 낮은 $\beta$, 빨간색이 가장 높은 $\beta$ 에 해당하는데, &lt;strong&gt;$\beta$ 값이 높을수록 과거 데이터에 큰 영향을 받으며 신규 데이터에 대한 적응 딜레이가 생기는 점이 확인 가능하다&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/adam_4.jpeg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;bias-correction&#34;&gt;Bias Correction&lt;/h3&gt;
&lt;p&gt;예리한 독자라면 알아챘겠지만, 위 알고리즘을 그대로 적용할 시 초반 $V_t$ 값은 거의 $0$ 에 근접한 값이 나오게 된다.&lt;/p&gt;
&lt;p&gt;더 나은 방법은 &lt;strong&gt;$V_t$ 를 $\frac{V_t}{1 - \beta^t}$ 로 스케일링하는 것&lt;/strong&gt;이다. 이로 인해 실제 데이터와 다르게 $0$ 에 가까웠던 작은 $t$ 영역의 값은 큰 폭으로 상향되고, 큰 $t$ 영역의 값은 별다른 영향을 받지 않게 된다. 이와 같이 적절한 초기 값을 부여함으로 인해 값이 작은 $t$ 영역의 EWMA 값을 실제 데이터와 유사하게 바꿀 수 있으며, 이를 &lt;strong&gt;Bias Correction&lt;/strong&gt; 이라고 한다.&lt;/p&gt;
&lt;h2 id=&#34;momentum&#34;&gt;Momentum&lt;/h2&gt;
&lt;p&gt;TL;DR 섹션에서 첨부한 이미지를 다시 보자. 붉은색 경사하강은 지그재그 방향으로 움직이고 있기 떄문에 파란색 경사하강을 유도하기 위해서는 &lt;strong&gt;y축 움직임을 최소화하고, x축 움직임을 최대화해야 한다&lt;/strong&gt;. 여기서 우리는 EWMA 개념을 다음 pseudo code와 같이 적용한다 ($w_i$ 는 $i$ 변수에 적용되는 가중치를 의미).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; on interation t:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    compute dy, dx on current mini-batch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    V_dy = beta * V_dy + (1 - beta) * dy
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    V_dx = beta * V_dx + (1 - beta) * dx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w_y = w_y - alpha * V_dy
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w_x = w_x - alpha * V_dx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;해당 로직을 적용하면 &lt;strong&gt;y축 변수는 음수와 양수 사이를 반복적으로 움직이기 때문에 점차 $0$ 에 가까운 EWMA 값에 수렴하게 되며, x축 변수는 계속해 양수 방향으로 움직이기 때문에 EWMA 값은 양수 방향을 유지하게 된다&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;한 가지 유념해야 할 부분은, 경사하강법에 모멘텀을 적용하게 되면 기존에는 없던 $\beta, \alpha$ 두 개 하이퍼파라미터가 발생하게 된다는 점이다. 앞서 언급했듯 초기 $\beta$ 값은 $0.9$ 정도로 세팅하는 것이 세월에 따른 검증을 통해 권장되고 있으며, 이는 대략 과거 10개 iteration 의 평균 미분값에 해당하게 된다. Bias correction 의 경우 초기 iteration 에서만 영향을 끼치기 때문에 실제 모델링 시 생략되는 경우가 많다.&lt;/p&gt;
&lt;h2 id=&#34;rmsprop&#34;&gt;RMSProp&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://machinelearningmastery.com/gradient-descent-with-rmsprop-from-scratch/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RMSProp&lt;/a&gt; (Root Mean Squared Prop) 은 모멘텀과 유사하게 경사하강의 방향성을 찾는 알고리즘이다. 구체적인 설명에 들어가기 전 다음 pseudo code를 확인하자.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; on interation t:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    compute dy, dx on current mini-batch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    S_dy = beta * S_dy + (1 - beta) * (dy ** 2)  # element-wise square
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    S_dx = beta * S_dx + (1 - beta) * (dx ** 2)  # element-wise square
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w_y = w_y - alpha * ( dy / (sqrt(S_dy) + epsilon) )
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w_x = w_x - alpha * ( dx / (sqrt(S_dx) + epsilon) )
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;모멘텀 알고리즘이 $V_{dy}$ 와 $V_{dx}$ 값을 업데이트하기 위해 변수 별 미분값 $d_y$ 와 $d_x$ 을 그대로 사용했던 것과 달리, RMSProp 알고리즘은 두 미분값의 제곱을 사용하고 있다. 자연스럽게 y축 변수는 위아래로 큰 움직임을 가지고있기 때문에 $d_y$ 의 제곱값의 누적치는 큰 결과값을 가지게 되며 (x축 변수의 경우 반대로 작은 결과값), 이러한 누적치의 제곱근을 $d_y$ 에서 나누어줌으로써 경사하강 과정에서 $w_y$ 를 상대적으로 작은 값으로 업데이트하게 된다 (x축 변수의 경우 상대적으로 큰 값).&lt;/p&gt;
&lt;p&gt;$\epsilon$ 은 단순한 safety term 정도로 이해하면 되는데, $\sqrt{S_{dy}}$ 값이 0이 될때 $\frac{d_y}{\sqrt{S_{dy}}}$ 이 무한대로 커지는 경우를 방지하기 위해 $\epsilon = 10^{-8}$ 라는 식의 아주 작은 값을 대입하는 것이라고 이해하면 된다. 개념적인 설명이 길어 어렵게 느낄 수 있지만, 천천히 위 코드의 진행과정을 읽어보며 설명을 참조하면 단순히 모멘텀 알고리즘에 단순평균이 아닌 RMS 개념을 도입했다는 것을 이해할 수 있을 것이다.&lt;/p&gt;
&lt;p&gt;여담으로 한가지 재밌는 점은 RMSProp 알고리즘의 경우 학술적인 논문이 아닌 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Turing_Award&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Turing Award&lt;/a&gt; 수상자 &lt;a class=&#34;link&#34; href=&#34;https://www.cs.toronto.edu/~hinton/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Geoffrey Hinton&lt;/a&gt; 교수가 &lt;a class=&#34;link&#34; href=&#34;https://www.utoronto.ca/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;토론토 대학&lt;/a&gt;에서 가르치던 수업에서 제안한 모멘텀 알고리즘의 대안으로 처음 알려지게 되었다는 점이다. 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;본 링크&lt;/a&gt;에서 해당 수업의 파워포인트 슬라이드를 확인할 수 있다.&lt;/p&gt;
&lt;h2 id=&#34;adam&#34;&gt;ADAM&lt;/h2&gt;
&lt;p&gt;모멘텀 알고리즘, RMSProp 알고리즘까지 개념적인 이해가 이루어졌다면 바로 다음 ADAM (Adaptive Moment Estimation) Optimizer 알고리즘을 이해할 수 있을 것이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; on interation t:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    compute dy, dx on current mini-batch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    V_dy = beta_1 * V_dy + (1 - beta_1) * dy
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    V_dx = beta_1 * V_dx + (1 - beta_1) * dx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    S_dy = beta_2 * S_dy + (1 - beta_2) * (dy ** 2)  # element-wise square
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    S_dx = beta_2 * S_dx + (1 - beta_2) * (dx ** 2)  # element-wise square
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    V_dy = V_dy / (1 - beta_1 ** t)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    V_dx = V_dx / (1 - beta_1 ** t)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    S_dy = V_dy / (1 - beta_2 ** t)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    S_dx = V_dx / (1 - beta_2 ** t)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w_y = w_y - alpha * ( V_dy / (sqrt(S_dy) + epsilon) )
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w_x = w_x - alpha * ( V_dx / (sqrt(S_dx) + epsilon) )
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;모멘텀의 $V$ 값, RMSProp의 $S$ 값을 개별적으로 구한 후, 각각 bias correction 이 이루어진 $V$ 값에서 $S$ 값의 제곱근을 나눈 결과를 기반으로 경사하강을 진행하는 방식이다. 반복적인 실험을 통해 일반화가 가능할 정도로 그 효과성이 검증되었으며, $\beta_1$ 의 경우 $0.9$, $\beta_2$ 의 경우 $0.999$, $\epsilon$ 의 경우 $10^{-8}$ 의 초기값을 기본으로 하고있다. $\alpha$ 값의 경우 모델에 따라 기본적인 튜닝을 필요로 한다.&lt;/p&gt;
&lt;p&gt;PyTorch, Keras, Tensorflow 와 같은 메이저한 딥러닝 프레임워크는 당연히 ADAM Optimizer, RMSProp, 모멘텀과 같은 최적화 알고리즘을 기본으로 제공하고 있으며, 이러한 최적화 알고리즘의 작동방식과 각 하이퍼파라미터의 의미를 정확하게 알고있다면 보다 효율적인 모델링이 가능할 것이다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>배치 관리 소프트웨어 런데크 (Rundeck)</title>
        <link>https://meme2515.github.io/mlops/rundeck/</link>
        <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/rundeck/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/rundeck-wordmark.svg" alt="Featured image of post 배치 관리 소프트웨어 런데크 (Rundeck)" /&gt;&lt;h2 id=&#34;프로그램-사용-배경&#34;&gt;프로그램 사용 배경&lt;/h2&gt;
&lt;p&gt;업무 중 머신러닝 학습 데이터 생성을 위해 6대 로컬 PC에서 다소 리소스 인텐시브한 작업을 반복적으로, 장기간 진행할 니즈가 생겼다. 최초에는 6대 각각의 로컬 환경에서 Windows 공식 배치관리 툴인 &lt;a class=&#34;link&#34; href=&#34;https://docs.microsoft.com/en-us/windows/win32/taskschd/task-scheduler-start-page&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Task Scheduler&lt;/a&gt; 에 관련 .bat 파일을 등록할 요량이었으나 다음과 같은 이유로 별도 배치 관리 툴을 찾아보게 되었다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;6대 PC에서 개별적인 로컬 스케줄러를 관리한다는 것은 물리적인 모니터링을 필요로하기에 데이터 생성 기간동안 지나치게 많은 시간을 뺏길 것 같았다. &lt;strong&gt;빠른 대응이 가능한 중앙화된 모니터링 체계&lt;/strong&gt;가 필요했다.&lt;/li&gt;
&lt;li&gt;프로세스는 경우에 따른 작업 시간이 달라 일정기간 지속 시 재시작 가능한 &lt;strong&gt;룰 기반 배치 관리&lt;/strong&gt;가 필요했다.&lt;/li&gt;
&lt;li&gt;데이터 생성 도중 프로세스에 변동이 있을 가능성이 있었기때문에 &lt;strong&gt;프로세스 일괄 수정이 가능&lt;/strong&gt;한 툴이 필요했다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;최초 머리에 떠오른 솔루션은 &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Airflow&lt;/a&gt; 였으나 그닥 익숙한 솔루션도 되지 못했고, 모니터링 환경이 Windows 10 이었기때문에 환경 세팅에 어려움이 있었다. 그렇게 구글링을 계속하며 &lt;a class=&#34;link&#34; href=&#34;https://www.ansible.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ansible&lt;/a&gt;과 같은 SSH 기반 솔루션을 생각했으나 보안상 이유로 다시 세팅에 어려움이 있었고&amp;hellip; 적합한 오픈소스 솔루션인 &lt;a class=&#34;link&#34; href=&#34;https://www.pagerduty.com/integrations/rundeck-runbook-automation/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck&lt;/a&gt;를 발견했다.&lt;/p&gt;
&lt;h2 id=&#34;rundeck-소개&#34;&gt;Rundeck 소개&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/rundeck_example.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Rundeck 파이프라인 예 - 유저가 생성한 Job 들을 Node 별로 할당 및 실행, 에러 발생 등 유사시 알림 설정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;미국의 클라우드 소프트웨어 업체인 &lt;a class=&#34;link&#34; href=&#34;https://www.pagerduty.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PagerDuty&lt;/a&gt; 사에서 개발한 작업 관리 소프트웨어이며, Physical, VM, Container, Serverless 환경에서 스크립트, API 호출 등의 작업을 스케줄링 및 관리 할 수 있다. 유학 중 룸메이트가 취업했다고 좋아하던 회사인데 좋은 프로그램을 만들고있었다.&lt;/p&gt;
&lt;p&gt;많은 유즈 케이스들이 있는데, 가장 대중적인 예시는 &lt;a class=&#34;link&#34; href=&#34;https://sre.google/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SRE (사이트 신뢰성 엔지니어링)&lt;/a&gt; 영역이다. Google 엔지니어 &lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/benjamin-treynor-sloss-207120/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ben Treynor Sloss&lt;/a&gt;가 창안한 개념인데, DevOps가 개발과 운영영역 간 사일로를 줄이는 철학적 접근이라고 한다면, SRE란 operation 영역의 문제들을 엔지니어링 관점에서 해결하는 방법론이라고 정의할 수 있다. 조직의 SRE팀이 계정 및 권한 관리, 인프라 리소스 관리 등의 운영 관점의 문제들을 자동화를 통해 해결하고나면, Dev팀은 소프트웨어 개발에, Ops팀은 제품 안정화에 더욱 집중할 수 있다는 식이다 (나도 현재는 이정도로만 이해하고 있고, 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://www.dynatrace.com/news/blog/what-is-site-reliability-engineering/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1번&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=uTEL8Ff1Zvk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2번&lt;/a&gt; 링크에서 더욱 상세한 내용을 확인할 수 있다).&lt;/p&gt;
&lt;p&gt;Rundeck 솔루션은 이러한 SRE 관점의 운영 절차를 표준화할 수 있는 플랫폼을 제공하며, 이러한 절차들은 조직 내에서 안전하게 공유되게 된다. 나의 경우는 아직 관련 지식이 부족하며, 당장 필요한 영역은 workload automation 으로 한정되어있기 때문에 깊은 내용은 추후에 더 알아보기로 하자.&lt;/p&gt;
&lt;p&gt;핵심적으로 짚고 넘어가야 할 개념은 다음과 같다.&lt;/p&gt;
&lt;h3 id=&#34;projects&#34;&gt;Projects&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/manual/projects/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck Documentation - Projects&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rundeck 내 작업 환경의 개념이다. 한개 Rundeck 서버에 여러개의 Project를 관리할 수 있으며, 프로젝트의 개념은 사용자가 정의하기 나름이다. 팀, 인프라, 어플리케이션, 환경 등 사용 목적에 맞게 Project를 구분하게 된다.&lt;/p&gt;
&lt;h3 id=&#34;jobs&#34;&gt;Jobs&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/manual/04-jobs.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck Documentation - Jobs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;실행하고자 하는 프로세스의 묶음이다. &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Batch_file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;윈도우 batch 파일&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow의 DAG&lt;/a&gt; 개념과 유사하다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/airflow_example.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Airflow의 DAG 개념 예 - branch_b를 에러 케이스라고 보면 될 듯 하다&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Rundeck 내에서는 Job 단위로 스케줄러 설정이 가능하고, 개별적인 히스토리가 남게된다. 한개 Job을 생성할 때 input option을 설정하거나, 에러 핸들링 룰을 생성하는 등 부수적인 옵션이 주어지게 된다.&lt;/p&gt;
&lt;h3 id=&#34;steps&#34;&gt;Steps&lt;/h3&gt;
&lt;p&gt;CLI 커맨드, 스크립트 실행, 다른 Job 호출 등 하나의 Job을 구성하는 개별적인 태스크를 지칭하는 용어이다. 또한 개별 Step 내에서 다양한 플러그인 활용이 가능하다.&lt;/p&gt;
&lt;h3 id=&#34;nodes&#34;&gt;Nodes&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/manual/05-nodes.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck Documentation - Nodes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Job이 실행되는 대상이다 (Physical, VM, Container, API, Database 등). 나의 경우에는 6대로 분할된 로컬 PC에 해당한다. 각각의 Node는 태그와 속성값을 지니게된다.&lt;/p&gt;
&lt;p&gt;Rundeck의 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=QSY_qw9Buic&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 소개 영상&lt;/a&gt;을 확인하면 Projects -&amp;gt; Jobs -&amp;gt; Steps -&amp;gt; Nodes 순으로 계층구조 개념을 띄고있다.&lt;/p&gt;
&lt;h2 id=&#34;설치-방법-&#34;&gt;설치 방법 💻&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/administration/install/windows.html#folder-structure&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;윈도우 설치 Doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/administration/install/linux-deb.html#installing-rundeck&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ubuntu 설치 Doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/administration/install/linux-rpm.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CentOS 설치 Doc&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;내가-사용한-방법&#34;&gt;내가 사용한 방법&lt;/h2&gt;
&lt;h3 id=&#34;winrm&#34;&gt;WinRM&lt;/h3&gt;
&lt;p&gt;네트워크를 통해 원격으로 터미널을 제어하는 방법은 SSH (Secure Shell) 커맨드가 가장 익숙했고, Windows 10 부터는 OpenSSH라는 연관 툴을 기본으로 제공한다는 &lt;a class=&#34;link&#34; href=&#34;https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 가이드&lt;/a&gt;를 확인해 세팅을 시도했다. 하지만 세팅에 필요한 PowerShell이 보안상의 이유로 제한되어있어 진행이 어려웠다.&lt;/p&gt;
&lt;p&gt;이런 저런 대안을 찾아보다 Rundeck에서 제공하는 &lt;a class=&#34;link&#34; href=&#34;https://github.com/diyan/pywinrm&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;pywinrim&lt;/a&gt; 이라는 플러그인을 통해 Windows Node 설정이 가능하다는 &lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/learning/howto/configuring-windows-nodes.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 가이드&lt;/a&gt;를 확인했다. WinRM (Windows Remote Management)은 SSH의 Windows 네이티브 버전 정도로 이해가 되는데, 실제 프로토콜 방식은 굉장히 다르다고한다 (&lt;a class=&#34;link&#34; href=&#34;https://www.reddit.com/r/sysadmin/comments/nadfbs/winrm_vs_openssh/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;연관 글&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;pywinrm은 이런 WinRM 연결을 파이썬 환경에서 구현 가능하도록 하는 패키지인데, Rundeck내에서 해당 패키지를 활용한 노드 생성 기능을 구현한 듯 했다. 하지만 세팅이 생각보다 간단하지는 않았고, 나는 파이썬 스크립팅을 선호했기에 해당 패키지를 별도로 사용해 Rundeck에서는 .py 파일만 실행하는 접근법을 택했다.&lt;/p&gt;
&lt;p&gt;하단은 pywinrm 패키지 사용 예시이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import winrm
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; s = winrm.Session(&amp;#39;windows-host.example.com&amp;#39;, auth=(&amp;#39;username&amp;#39;, &amp;#39;password&amp;#39;))
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; r = s.run_cmd(&amp;#39;ipconfig&amp;#39;, [&amp;#39;/all&amp;#39;])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; r.status_code
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; r.std_out
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Windows IP Configuration
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Host Name . . . . . . . . . . . . : WINDOWS-HOST
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Primary Dns Suffix  . . . . . . . :
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Node Type . . . . . . . . . . . . : Hybrid
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    IP Routing Enabled. . . . . . . . : No
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    WINS Proxy Enabled. . . . . . . . : No
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;filezilla-pscp&#34;&gt;FileZilla, PSCP&lt;/h3&gt;
&lt;p&gt;학습 데이터 생성에 필요한 초기 데이터를 6대 PC에 분할하는 작업을 위해 메인 PC에 세팅한 &lt;a class=&#34;link&#34; href=&#34;https://filezilla-project.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FileZilla&lt;/a&gt; 서버를 활용했다. 세팅 난이도도 높지 않고, 단순한 파일공유 (FTP) 프로그램으로 생각하면 될 듯 하다.&lt;/p&gt;
&lt;p&gt;일련의 과정을 통해 생성된 학습 데이터는 각각 6대 PC로 부터 실제 학습을 수행할 리눅스 서버에 &lt;a class=&#34;link&#34; href=&#34;https://documentation.help/PuTTY/pscp.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PSCP&lt;/a&gt; 커맨드를 통해 전송했다. 윈도우 환경에서 리눅스 환경으로 파일을 전송하기 위해 주로 사용되는 명령어라고 한다.&lt;/p&gt;
&lt;h2 id=&#34;결론&#34;&gt;결론&lt;/h2&gt;
&lt;p&gt;6대 PC에 스케줄링된 batch job의 성공 여부를 하나의 환경에서 모니터링 가능한 체계를 구축했다. 또한 일정시간 이상 batch job 지속 시 이를 취소하는 룰을 손쉽게 세팅할 수 있었고, 핵심 코드 또한 중심이 되는 서버 PC에서 수정이 가능하도록 했다. 언급한 3가지 요건을 어느정도 충족한 결과였다.&lt;/p&gt;
&lt;p&gt;MLOps와 어느정도 연관성이 있는지는 사실 잘 모르겠다. 리소스 인텐시브한 데이터 생성 과정에서 유지/보수가 가능한 체계를 구축했다는데 의미가 있을수는 있으나 구축하게 될 모델과 직접적인 연관성이 있는건 아니고, Rundeck 이라는 프로그램 또한 분야에서 자주 활용되는 툴은 아닌 것 같다는 인상을 받았다.&lt;/p&gt;
&lt;p&gt;다만 데이터 생성 과정을 여러대의 PC에 분산하고, 이를 모니터링 할 수 있는 체계는 생각보다 유용했고, 다시 사용할 일이 있지않을까 하는 생각이 들었다. 향후에는 조금 더 언급량이 많은 Ansible이나 Airflow같은 툴을 리눅스 기반의 환경에서 사용해보고 싶다.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>PyTorch Deep Learning - Tensor</title>
        <link>https://meme2515.github.io/neural_network/pytorch_1/</link>
        <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/pytorch_1/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/pytorch.jpeg" alt="Featured image of post PyTorch Deep Learning - Tensor" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;tensor&lt;/code&gt;란 &lt;code&gt;numpy&lt;/code&gt;와 유사하게 다차원 행렬을 다룰수있는 PyTorch 패키치의 자료구조다. 신경망 개론 수업에서 &lt;code&gt;numpy&lt;/code&gt; 패키지를 활용해 node와 weight, bias 등을 구현하고는 하는데 같은 개념의 연산을 &lt;strong&gt;GPU 등 적합한 하드웨어 자원을 통해 수행하고자 할때&lt;/strong&gt; &lt;code&gt;tensor&lt;/code&gt;를 이용하게 된다. Tensorflow 패키지 또한 동일한 개념과 이름을 가진 &lt;code&gt;tf.Tensor&lt;/code&gt;를 사용한다.&lt;/p&gt;
&lt;h2 id=&#34;tensor-생성&#34;&gt;Tensor 생성&lt;/h2&gt;
&lt;p&gt;값이 비어있는 tensor를 생성하기 위해서는 &lt;code&gt;torch.empty()&lt;/code&gt; 메소드를 다음과 같이 호출한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.empty(1) # scalar 생성
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x2 = torch.empty(3) # 1d vector 생성
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x3 = torch.empty(2, 3) # 2d matrix 생성
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x4 = torch.empty(2, 2, 3) # 3d matrix 생성
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;유사하게 0과 1 사이의 랜덤한 값이 부여된 tensor를 사용하기 위해서는 &lt;code&gt;torch.rand()&lt;/code&gt; 함수를, 0값의 경우 &lt;code&gt;torch.zeros()&lt;/code&gt; 함수를, 1값의 경우 &lt;code&gt;torch.ones()&lt;/code&gt; 함수를 차원값과 함께 호출한다 (&lt;code&gt;numpy&lt;/code&gt;와 유사하게 구성).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.rand(2, 2, 3)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;데이터-타입&#34;&gt;데이터 타입&lt;/h2&gt;
&lt;p&gt;별도로 데이터 타입을 지정하지 않은 경우 위 저장된 변수의 데이터 타입은 &lt;code&gt;torch.float32&lt;/code&gt;로 자동 지정된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.ones(2, 2, 3)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1.dtype) # output: torch.float32
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;다른 데이터 타입을 사용하고자 할 경우 &lt;code&gt;tensor&lt;/code&gt; 생성시 &lt;code&gt;dtype&lt;/code&gt; 매개변수로 다음과 같이 지정이 가능하다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.ones(2, 2, 3, dtype=torch.int)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1.dtype) # output: torch.int
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x2 = torch.ones(2, 2, 3, dtype=torch.double)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x2.dtype) # output: torch.double
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x3 = torch.ones(2, 2, 3, dtype=torch.float16)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x3.dtype) # output: torch.float16
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;행렬-구조-확인&#34;&gt;행렬 구조 확인&lt;/h2&gt;
&lt;p&gt;생성된 &lt;code&gt;tensor&lt;/code&gt;의 구조는 &lt;code&gt;size&lt;/code&gt; 함수를 통해 확인이 가능하다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.ones(2, 2, dtype=torch.int)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1.size) # output: torch.Size([2, 2])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;불러오기-기능&#34;&gt;불러오기 기능&lt;/h2&gt;
&lt;h3 id=&#34;python-list&#34;&gt;Python List&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;numpy&lt;/code&gt; 패키지의 &lt;code&gt;np.array&lt;/code&gt; 함수와 동일하게 행렬구조를 가진 파이썬 &lt;code&gt;list&lt;/code&gt; 로부터 &lt;code&gt;tensor&lt;/code&gt; 생성을 지원한다. &lt;code&gt;torch.tensor()&lt;/code&gt; 함수의 매개변수로 &lt;code&gt;list&lt;/code&gt; 를 넣어주는 일반적인 구조다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;numpy-array&#34;&gt;Numpy Array&lt;/h3&gt;
&lt;p&gt;자연스럽게 &lt;code&gt;numpy.array&lt;/code&gt; 를 활용한 &lt;code&gt;tensor&lt;/code&gt; 생성 또한 &lt;code&gt;torch.from_numpy()&lt;/code&gt; 함수를 통해 다음과 같이 지원한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import numpy as np
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1_np = np.array([2,5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.from_numpy(x1_np)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;반대로 &lt;code&gt;tensor&lt;/code&gt; 에서 &lt;code&gt;numpy&lt;/code&gt; 로의 변환은 다음과 같이 수행한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1_np = x1.numpy()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;여기서 유의할 부분은 &lt;strong&gt;&lt;code&gt;tensor&lt;/code&gt; 의 메모리 위치가 GPU 가 아닌 CPU 일 경우, x1의 변형은 x1_np 에 그대로 반영&lt;/strong&gt;되게 된다는 점이다. 이는 위의 두개 예시 (&lt;code&gt;tensor&lt;/code&gt; -&amp;gt; &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;numpy&lt;/code&gt; -&amp;gt; &lt;code&gt;tensor&lt;/code&gt;)에 공통적으로 적용된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1_np = x1.numpy()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1.add_(1)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1_np) # output: [3.5, 1.1]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;CUDA 지원 하드웨어 가용이 가능한 경우, 다음 두가지 방식을 통해 &lt;code&gt;tensor&lt;/code&gt; 저장 위치를 GPU로 설정할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; if torch.cuda.is_available():
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    device = torch.device(&amp;#34;cuda&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x1 = torch.tensor([2.5, 0.1], device=device) # 1. 생성 시 GPU 메모리 가용
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x2 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x2 = x2.to(device) # 2. 생성 후 GPU 메모리 가용
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x3 = x1 + x2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x3 = x3.to(&amp;#34;cpu&amp;#34;) # CPU 메모리 가용
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;행렬-연산&#34;&gt;행렬 연산&lt;/h2&gt;
&lt;h3 id=&#34;일반적인-연산&#34;&gt;일반적인 연산&lt;/h3&gt;
&lt;p&gt;덧셈, 곱셈과 같은 기본적인 행렬 연산 방식또한 &lt;code&gt;numpy&lt;/code&gt;와 크게 다르지 않다. &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt; 등의 수학 기호, 또는 &lt;code&gt;torch.add()&lt;/code&gt;, &lt;code&gt;torch.mul()&lt;/code&gt; 등의 함수를 호출해 연산을 수행할 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;numpy&lt;/code&gt;와 동일하게 내적 연산을 위해서는 &lt;code&gt;torch.mul()&lt;/code&gt; 이 아닌 다른 함수를 호출한다. 이와 관련된 내용은 이후 글에서 언급할 예정.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 덧셈
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z1 = x + y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z2 = torch.add(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 뺄셈
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z3 = x - y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z4 = torch.sub(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 곱셈, element-wise
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z5 = x * y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z6 = torch.mul(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 나눗셈, element-wise
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z7 = x / y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z8 = torch.div(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;바꿔치기-연산-in-place-operation&#34;&gt;바꿔치기 연산 (In-Place Operation)&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;torch&lt;/code&gt; 는 &lt;code&gt;.add_&lt;/code&gt;, &lt;code&gt;.sub_&lt;/code&gt; 등 &amp;lsquo;_&amp;rsquo; 접미사가 붙은 바꿔치기 연산 함수를 제공한다. 바꿔치기 라는 단어에서 유추 가능하듯 이는 &lt;strong&gt;타겟 변수의 값을 바꾸는 효과&lt;/strong&gt;를 가지게 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y.add_(x) # y 변수의 값이 y + x 의 output으로 변경
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;슬라이싱&#34;&gt;슬라이싱&lt;/h2&gt;
&lt;p&gt;슬라이싱의 경우 또한 &lt;code&gt;numpy&lt;/code&gt; 패키지와 동일한 방법을 고수한다. 2차원 행렬구조의 경우 &lt;code&gt;x[i, j]&lt;/code&gt; 와 같은 포맷으로 &lt;code&gt;i&lt;/code&gt; 번째 로우, &lt;code&gt;j&lt;/code&gt; 번째 컬럼을 리턴하며, &lt;code&gt;x[i1:i2, j1:j2]&lt;/code&gt; 와 같이 범위 설정이 가능하다.&lt;/p&gt;
&lt;p&gt;유의가 필요한 부분은 1개의 값이 리턴될때 &lt;code&gt;tensor&lt;/code&gt; 오브젝트가 아닌 기입된 실제 값을 보고싶다면 &lt;code&gt;item()&lt;/code&gt; 함수를 별도로 호출해야 하며, 해당 함수는 &lt;code&gt;tensor&lt;/code&gt; 에 1개 값만 들어있을때 사용 가능하다는 점이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(5, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[:, 0]) # 1번 컬럼 슬라이스
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[0, :]) # 1번 로우 슬라이스
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[1, 1]) # 2번 로우, 2번 컬럼 슬라이스 (tensor 형태 유지)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[1, 1]).item() # 2번 로우, 2번 값
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;행렬-구조-변경-reshaping&#34;&gt;행렬 구조 변경 (Reshaping)&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;np.reshape&lt;/code&gt;이 아닌 &lt;code&gt;view&lt;/code&gt; 함수를 이용하게 된다. 매개변수로 들어가는 &lt;strong&gt;차원의 element 수은 항상 input &lt;code&gt;tensor&lt;/code&gt;의 element 수와 같아야 하며&lt;/strong&gt; (예. (4, 4) -&amp;gt; (2, 8)), 마지막 숫자가 유추 가능한 경우 -1 으로 매개변수를 대체할 수 있다 (하단 예시 참조).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(4, 4)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y1 = x.view(16) # x.view(-1)와 동일
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y2 = x.view(2, 8) # x.view(-1, 8)와 동일
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>About</title>
        <link>https://meme2515.github.io/about/</link>
        <pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/about/</guid>
        <description>&lt;img src="https://meme2515.github.io/about.jpg" alt="Featured image of post About" /&gt;&lt;p&gt;email: &lt;a class=&#34;link&#34; href=&#34;mailto:meme2515@gmail.com&#34; &gt;meme2515@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;제가 기술을 좋아하는 이유는, 거창하게 말하면 시대를 만들어 간다는 느낌을 받기 때문인 것 같아요. 구체적으로 사람들이 자주 언급하는 감정은 아니지만 그렇다고 또 대단히 특별할 것은 없는 욕구라고 생각해요. 산업혁명이 일어나고, 컴퓨터가 개인화되고, 이어폰에서 줄이 사라지고, 자동차가 전기로 움직였듯이 제가 느낌 가장 가시적인 시대의 변화는 기술의 발전으로 이루어졌고, 작은 제 삶에서 세상에 무언가 내가 뿌듯해할만한 기여를 할 수 있다면 기술을 통해서가 아닐까 하고 생각했습니다.&lt;/p&gt;
&lt;p&gt;하지만 사람들은 전기차, 내연기관차 가릴 것 없이 주말 드라이브에서 웃고 울겠지요. 다른 일을 해봤으면 어땠을까 또한 자주 상상해봅니다. 더 나은 사회를 조직하는 일도 있을것이고, 질서를 지키는 일도, 아픈 사람을 고치는 일도, 듣기 좋은 음악을 만드는 일도 멋있어 보이더라구요. 그래도 제가 그나마 익숙하고 잘할 수 있는 분야에서, 그저 수단으로써 기술이 우리 삶에서 가지는 위치를 인지하고, 묵묵하게 제가 할 수 있는 것들을 찾고 나아가려고 항상 노력하고 있어요.&lt;/p&gt;
&lt;p&gt;어렸을때 8년간 인도네시아라는 나라에서 생활하고 공부했습니다. 이후에 4년간 미국 &lt;a class=&#34;link&#34; href=&#34;https://www.berkeley.edu/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;UC버클리&lt;/a&gt;에서 유학하며 경제학과 신설된 데이터과학 학부 과정을 마쳤습니다. 현재 &lt;a class=&#34;link&#34; href=&#34;https://www.ey.com/ko_kr&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;EY&lt;/a&gt;라는 국내 회계법인 산하 컨설팅펌에서 데이터 관련 IT 컨설팅을 수행하는 업무를 맡고 있어요. 짧지만 자동차 제조, 핸드폰 글로벌 리테일, 가구업 글로벌 리테일, 식품제조업, 게임업, 유통업 등을 경험해 보았습니다. 컨설팅으로 시작하게 된 계기는 여러가지가 있겠지만 가능한 어릴때 가능한 많은 기업을 경험하고, 그들의 니즈를 경청하고, 다양한 데이터를 보고 싶었어요. 장점은 역동성과 업무 역량의 빠른 성장이고 단점은 공부할 시간이 없다입니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; 으로 컴퓨터 공학에 입문했고 데이터를 배웠습니다. 경제학에 배경을 두고 있어 &lt;code&gt;Matlab&lt;/code&gt;, &lt;code&gt;STATA&lt;/code&gt; 등의 통계툴을 다뤄본 경험이 있고 업무적으로 &lt;code&gt;BigQuery&lt;/code&gt;, &lt;code&gt;Apache AirFlow&lt;/code&gt;, &lt;code&gt;PyTorch&lt;/code&gt; 등의 파이프라인 구축 및 모델링 프레임워크를 사용하고 있습니다. &lt;code&gt;Tableau&lt;/code&gt;, &lt;code&gt;Spotfire&lt;/code&gt; 등의 대시보드 툴 또한 자주 사용하고 있어요. 개인적으로 많은 관심을 가지고 있는 분야로는 MLOps, Deep Learning, Fintech 등이 있습니다.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
