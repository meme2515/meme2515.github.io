<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='워드 임베딩 방법론 소개 및 코드 예시'>
<title>ELMo (Embeddings from Language Model)</title>

<link rel='canonical' href='https://meme2515.github.io/neural_network/elmo/'>

<link rel="stylesheet" href="/scss/style.min.8191399262444ab68b72a18c97392f5349be20a1615d77445be51e974c144cff.css"><meta property='og:title' content='ELMo (Embeddings from Language Model)'>
<meta property='og:description' content='워드 임베딩 방법론 소개 및 코드 예시'>
<meta property='og:url' content='https://meme2515.github.io/neural_network/elmo/'>
<meta property='og:site_name' content='Soon&#39;s Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Neural_network' /><meta property='article:tag' content='엘모' /><meta property='article:tag' content='임베딩' /><meta property='article:tag' content='뉴럴넷' /><meta property='article:tag' content='ELMo' /><meta property='article:tag' content='NLP' /><meta property='article:tag' content='엘모 예시' /><meta property='article:tag' content='ELMo 예시' /><meta property='article:published_time' content='2023-02-21T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2023-02-21T00:00:00&#43;00:00'/><meta property='og:image' content='https://meme2515.github.io/neural_network/images/elmo_title2.png' />
<meta name="twitter:title" content="ELMo (Embeddings from Language Model)">
<meta name="twitter:description" content="워드 임베딩 방법론 소개 및 코드 예시"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://meme2515.github.io/neural_network/images/elmo_title2.png' />
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-135204357-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "light");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/dalle_hue8ec4a583e6bdc009645942c9f1a7733_1562101_300x0_resize_box_3.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Soon&#39;s Blog</a></h1>
            <h2 class="site-description">데이터 블로그입니다 :)</h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/meme2515'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 512 512" id="Layer_1" version="1.1" viewBox="0 0 512 512" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g><path d="M200,513c0-20.3,0-40.7,0-61c3.1,0.6,1.9,3.1,1.9,4.8c0.1,16.3,0.2,32.6,0,48.9c-0.1,4.1,1,5.4,5.2,5.4   c36.6-0.2,73.2-0.2,109.8,0c4.4,0,5.1-1.6,5.1-5.5c-0.2-25-0.1-49.9-0.1-74.9c0-9.3,0.2-18.6,0.2-27.9c2.8,1.2,1.6,3.8,1.6,5.7   c0.1,34.8,0.1,69.6,0.1,104.4C282.7,513,241.3,513,200,513z" fill="#D1D1D1"/><path d="M322.2,402.8c-0.1,9.3-0.2,18.6-0.2,27.9c0,25-0.1,49.9,0.1,74.9c0,3.9-0.7,5.5-5.1,5.5   c-36.6-0.2-73.2-0.2-109.8,0c-4.2,0-5.3-1.3-5.2-5.4c0.2-16.3,0.1-32.6,0-48.9c0-1.7,1.2-4.2-1.9-4.8c-9.7,0.9-19.3,3.2-29.2,2.8   c-33.5-1.3-59.5-15.4-74.7-45.8c-8.2-16.4-17.8-31.7-29.1-46c-3.1-3.9-7.9-5.5-11.5-8.7c-1.1-1-2.4-1.8-3.3-3   c-2.3-3.3-1.2-5.8,2.8-6.2c18.5-1.9,33.8,4.2,46.2,18.1c6.3,7.1,10.2,15.8,16.3,23.1c12.3,14.7,28,22.7,47,24.9   c11.5,1.3,22.4-0.9,33.3-4.2c2.2-0.6,3.1-2,3.3-4.3c0.7-10.3,2.8-20.3,6.8-29.9c1.8-4.3,4.7-7.9,6.9-12.3   c-10.3-2.6-20.7-3.4-30.5-6.4c-27.1-8.2-50.9-21.6-68.2-44.7c-8.3-11-14.1-23.3-17.4-36.5c-1.8-7.2-3.9-14.4-3.8-22   c0.1-13.3-0.5-26.7,0.3-40c0.9-16.8,3.1-33.5,9.2-49.2c3.8-9.7,9.3-18.6,17.1-25.9c2.4-2.3,3.3-4.1,1.8-7.9   c-7.4-19.7-8.1-39.8-1.8-60c0.2-0.6,0.3-1.3,0.4-2c2.2-10.3,4.5-11.3,14.3-7.4c19.2,7.5,33.3,21,45.3,37.3c3.4,4.6,2.7,6.6,10,1.9   c9.7-6.2,21-8.1,32.2-9.3c20.1-2.1,40.3-1.5,60.4-1.1c14.3,0.3,28.5,2.2,42,7.2c3.1,1.1,6,2.8,8.7,4.8c2.1,1.6,3.6,1.6,5.6-1.1   c9.1-12.8,19.5-24.4,33-32.6c6.6-4,13.4-7.7,21.4-8.6c3.3-0.4,4.7,0.7,5.6,3.3c8.3,22.9,9.5,45.7-0.2,68.5   c-1.2,2.8-0.8,4.6,1.3,6.5c16,15,21.8,34.5,24.8,55.5c2.5,17.7,3.2,35.5,2.7,53.3c-0.8,31.2-11.4,58.4-34.4,80.1   c-13.5,12.7-29.7,21.1-47.1,27.5c-12.4,4.6-25.5,5.8-38.5,9c1.3,3.1,3.7,5.4,4.3,8.5c-0.3,1.3,0.4,2,1.6,2.3   c0.1,0.6,0.3,1.1,0.4,1.7c0.3,2.1,0.1,4.3,2.5,5.4c0.5,2.2,1,4.5,1.4,6.7c-0.1,1.7-0.7,3.5,1.6,4.3c0,0.6,0.1,1.2,0.1,1.9   c-1.5,2.3-0.1,4.1,1.1,6C322.1,398.9,322.2,400.9,322.2,402.8z" fill="#A7A7A7"/><path d="M322,397c-1.1-1.9-2.6-3.7-1.1-6C322.1,392.9,323,394.8,322,397z" fill="#D1D1D1"/><path d="M317.7,378.2c-2.4-1.1-2.2-3.3-2.5-5.4C317.4,374,317.7,376,317.7,378.2z" fill="#D1D1D1"/><path d="M320.8,389.1c-2.3-0.8-1.7-2.6-1.6-4.3C321.5,385.6,321,387.5,320.8,389.1z" fill="#D1D1D1"/><path d="M314.8,371.1c-1.2-0.3-1.9-1-1.6-2.3C314.5,369.1,315.1,369.8,314.8,371.1z" fill="#D1D1D1"/></g></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://www.linkedin.com/in/soon-hyung-kwon-73a3221ab/'
                        target="_blank"
                        title="LinkedIn"
                        rel="me"
                    >
                        
                        
                            <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 512 512" id="Layer_1" version="1.1" viewBox="0 0 512 512" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g><path d="M1,53c2.5,0,1.7-2,1.9-3.3C5.9,29,16.6,13.9,36.6,7.4c16.1-5.2,32.9-4.6,47.9,4c9.4,5.5,16.6,14,20.4,24.5   c2.8,7.8,4.9,15.9,4,24.2c-2.1,20.9-11.5,38.3-34.5,46.4c-17.4,6-34.3,3.8-50.2-5.7c-1-3.6-3.5-5.4-7.1-6c0,0,0,0,0,0   c-0.1-1.4-0.3-2.8-2.2-2.8C7.7,84,4.3,74.3,2.9,63.8C2.7,62.6,3.2,60.9,1,61C1,58.3,1,55.7,1,53z" fill="#A7A7A7"/><path d="M276.2,216.1c4.3-2.6,6-6.4,8.2-9.5c10.9-15,24.4-26.6,41.2-34.9c23-11.3,47.4-12.5,72-10.2   c18.9,1.7,36.8,8.1,53.1,18.5c19.4,12.4,33.3,29.6,42.8,50.2c5.8,12.5,9.6,25.8,11.9,39.6c2.1,12.9,3.7,25.6,3.7,38.7   c-0.1,65-0.1,130,0.1,195c0,4.6-1.3,5.8-5.8,5.7c-30.7-0.2-61.3-0.2-92,0c-4.5,0-5.5-1.3-5.5-5.6c0.1-61.3,0.4-122.7-0.1-184   c-0.1-13.9-2-27.7-9.2-40.4c-6.4-11.2-15.3-19.2-27-23.8c-15.7-6.2-31.9-7.4-48.3-2.8c-16.6,4.6-28.1,15.5-36.3,30.3   c-4.6,8.3-6.2,17-7.5,26.3c-1.3,10-1.1,19.8-1.1,29.7c-0.2,54.7-0.2,109.3,0,164c0,5-1.2,6.4-6.3,6.3c-30.3-0.3-60.7-0.2-91,0   c-4.2,0-5.7-1.3-5.6-5.2c0.1-2.8,0.3-5.6,0.3-8.4c0-105.5,0.1-211-0.1-316.5c0-4.4,0.9-6,5.7-6c30.5,0.2,61,0.2,91.5,0   c4.1,0,5.5,1,5.4,5.3C276,190.6,276.2,202.9,276.2,216.1z" fill="#A7A7A7"/><path d="M109,176.1c0,3.5,0.1,7,0.1,10.5c0,105.3,0,210.6,0,316c0,6.4,0,6.4-6.5,6.4c-31.8,0-63.7,0-95.5,0   c-0.1-2.5-0.2-5-0.2-7.5c0-78.8,0-157.5,0-236.3c0-28.1,0.1-56.3-0.1-84.4c0-3.6,0.9-4.9,4.7-4.9C44,176.1,76.5,176,109,176.1z" fill="#A7A7A7"/><path d="M109,176.1c-32.5,0-64.9,0-97.4-0.2c-3.8,0-4.7,1.2-4.7,4.9C7,208.9,6.9,237,6.9,265.2   c0,78.8,0,157.5,0,236.3c0,2.5,0.1,5,0.2,7.5c-1.7,0.1-3-0.3-3-2.3c0-1.3,0-2.7,0-4c0-106.8,0-213.5,0-320.3c0-7.6,0.7-8.3,8.2-8.3   c30.5,0,61,0,91.4,0.1C105.5,174.1,108.2,172.7,109,176.1z" fill="#E0E0E0"/><path d="M17.1,94.9c3.6,0.6,6.1,2.4,7.1,6C21.1,99.7,18.8,97.7,17.1,94.9z" fill="#E0E0E0"/><path d="M14.9,92.1c1.9,0,2,1.4,2.2,2.8C15,95,15,93.6,14.9,92.1z" fill="#E0E0E0"/></g></svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/about' >
                
                
                
                <span>About</span>
            </a>
        </li>
        
        
        <li >
            <a href='/machine_learning' >
                
                
                
                <span>Machine Learning</span>
            </a>
        </li>
        
        
        <li >
            <a href='/neural_network' >
                
                
                
                <span>Neural Network</span>
            </a>
        </li>
        
        
        <li >
            <a href='/mlops' >
                
                
                
                <span>MLOps</span>
            </a>
        </li>
        
        
        <li >
            <a href='/statistics' >
                
                
                
                <span>Statistics</span>
            </a>
        </li>
        
        
        <li >
            <a href='/computer_science' >
                
                
                
                <span>Computer Science</span>
            </a>
        </li>
        
        
        <li >
            <a href='/projects' >
                
                
                
                <span>Projects</span>
            </a>
        </li>
        
        
        <li >
            <a href='/daily' >
                
                
                
                <span>Daily</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#word2vec">Word2Vec</a></li>
    <li><a href="#contextual-word-embedding">Contextual Word Embedding</a></li>
    <li><a href="#elmo">ELMo</a>
      <ol>
        <li><a href="#character-based-word-representations">Character-based word representations</a></li>
        <li><a href="#bidirectional-lstm-structure">Bidirectional LSTM structure</a></li>
        <li><a href="#pre-trained-as-a-language-model">Pre-trained as a language model</a></li>
      </ol>
    </li>
    <li><a href="#elmo-architecture">ELMo Architecture</a></li>
    <li><a href="#reference">Reference</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/neural_network/elmo/">
                
                    <img src="/neural_network/images/elmo_title2.png" loading="lazy" alt="Featured image of post ELMo (Embeddings from Language Model)" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/nlp/" >
                NLP
            </a>
        
            <a href="/categories/%EB%89%B4%EB%9F%B4%EB%84%B7/" >
                뉴럴넷
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/neural_network/elmo/">ELMo (Embeddings from Language Model)</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            워드 임베딩 방법론 소개 및 코드 예시
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Feb 21, 2023</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    5 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h2 id="introduction">Introduction</h2>
<ul>
<li>ELMo 는 2018년 공개된 워드 임베딩 방법론이며, GloVe, Word2Vec 등 기존 여러 임베딩 방식이 문맥을 파악하지 못하는 단점을 보완하고자 설계되었다.</li>
<li>예시로 River Bank (강둑) 와 Bank Account (은행 계좌) 라는 단어에서 Bank 는 전혀 다른 의미를 가지지만, 문맥을 파악하지 못하는 임베딩 기법은 Bank 에 동일한 벡터를 부여함으로 NLP 성능이 떨어질 수 밖에 없음.</li>
</ul>
<h2 id="word2vec">Word2Vec</h2>
<ul>
<li>ELMo 의 등장 배경을 이해하기 위해선 2014년 공개 후 한동안 널리 사용되었던 Word2Vec 모델을 이해할 필요가 있다.</li>
<li>하단의 예시는 몇 가지의 Word2Vec 알고리즘 중 가장 널리 활용된 방식인 Skipgram 버전에 대한 소개.</li>
</ul>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo1.png"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 1. Word2Vec 피처 설계</td>
</tr>
</tbody>
</table></div>
<ul>
<li>임의로 설정된 컨텍스트 사이즈 (상단 예시의 경우 5) 를 활용해, 특정 단어 $X$ 가 가운데에 위치해 있을때 함께 등장한 단어 $Y$ 를 피처로 설계한다.</li>
<li>문장 별로 한개의 $X$ 에 대해 복수의 $Y$ 가 추출되고, 문장이 여러개 활용되기 때문에 $X$ 와 $Y$ 의 관계에 대한 통계 정보를 얻을 수 있다. (예. $X$ 값 &ldquo;the&rdquo; 에 대한 $Y$ 값 &ldquo;quick&rdquo;, &ldquo;brown&rdquo;)</li>
</ul>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo2.png"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 2. Word2Vec 신경망 모델</td>
</tr>
</tbody>
</table></div>
<ul>
<li>이렇게 추출된 데이터셋은 1개의 hidden layer 를 가진 작은 신경망 모델에 학습된다. 모델 구조는 10,000 사이즈의 벡터로 one-hot encode 된 인풋 $X$ 에 대해 동일한 사이즈로 one-hot encode 된 아웃풋 $Y$ 에 확률값을 부여하는 것.</li>
<li>모델의 hidden layer 는 300개의 뉴런으로 구성되어 있으며, 학습이 끝난 hidden layer 는 그대로 단어의 피처로 활용된다.</li>
</ul>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo3.jpeg"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 3. Word2Vec 임베딩의 의미론적 (semantic), 구문론적 (syntactic) 관계</td>
</tr>
</tbody>
</table></div>
<ul>
<li>이렇게 추출된 임베딩이 실제 단어의 의미와 연관성을 가진다는 근거는 임베딩 벡터 간의 관계와 실제 단어 간의 관계가 유사성을 가진다는 점. 대표적인 예시로 &ldquo;Queen&rdquo; 과 &ldquo;King&rdquo; 이라는 단어 간 벡터의 차이값은 &ldquo;Woman&rdquo; 과 &ldquo;Man&rdquo; 이라는 단어 간 벡터의 차이값과 유사하다.</li>
<li>Word2Vec 모델이 특히 널리 활용된 이유는 이와같이 추출된 단어 임베딩이 LSTM 과 같은 Sequence 모델의 인풋으로 활용될 수 있었다는 점. 이로 인해 Sequence 모델은 단어의 의미를 유추하기 보다, 문장 내 단어 간 관계를 파악하는 것으로 활용 목적을 좁힐 수 있었다.</li>
</ul>
<h2 id="contextual-word-embedding">Contextual Word Embedding</h2>
<ul>
<li>이렇듯 발전되어 온 워드 임베딩 기법에 ELMo 가 기여한 부분은 문맥에 기반한 단어 임베딩을 가능하게 했다는 점이다. 상기된 예시인 River Bank (강둑) 와 Bank Account (은행 계좌) 를 생각하면 됨.</li>
<li>문장에 기반한 단어의 임베딩은 Word2Vec 의 예시와 같이 사전에 생성될 수 없으며, 사전 학습된 모델을 통해 생성되어야 한다. 이러한 기법은 CoVe, ULMFit 등 ELMo 등장 이전에 시도되었지만, ELMo 가 중요한 이유는 State-of-the-Art 성능을 기록했기 때문.</li>
</ul>
<h2 id="elmo">ELMo</h2>
<ul>
<li>ELMo 를 구성하는 주요 요소는 크게 (1) 캐릭터 단위의 단어 representation (2) 양방향 LSTM 네트워크 (3) 언어 모델 학습 과정을 들 수 있다.</li>
</ul>
<h3 id="character-based-word-representations">Character-based word representations</h3>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo4.png"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 4. Character CNN Architecture</td>
</tr>
</tbody>
</table></div>
<ul>
<li>우선 문장의 개별적인 단어는 (sat) 더 작은 단위인 character 로 분할된다 (s, a, t). 이후 각 character 는 고유한 임베딩 벡터로 변환. 따라서 한 개의 단어는 character 레벨 임베딩 벡터로 구성된 매트릭스로 변형되며, 이는 다양한 kernel width 를 가진 CNN 레이어를 통해 처리된다.</li>
<li>각 CNN 레이어의 아웃을 하나의 채널로 합친 후 maxpooling 적용.</li>
<li>Maxpooling 아웃풋은 두 개의 linear layer 에 연결되며, 각 linear layer 는 residual connection 과 유사한 highway connection 을 통해 연결되어 있다 (차이점은 highway connection 은 모수를 가진다는 점).</li>
<li>최종 linear layer 의 아웃풋은 1차적인 word representation 의 기능을 수행하며, 512 사이즈를 가짐.</li>
<li>Character representation 의 장점은 오타와 같이 실제 상황에서 발생 가능한 단어를 유연하게 다룰 수 있다는 점.</li>
</ul>
<h3 id="bidirectional-lstm-structure">Bidirectional LSTM structure</h3>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo5.png"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 5. Bidirectional LSTM Architecture</td>
</tr>
</tbody>
</table></div>
<ul>
<li>문맥을 파악하기 위해 ELMo 는 RNN 기법을 활용하며, 서로 다른 진행 방향을 가진 두개의 LSTM 모델을 적용.</li>
<li>진행 방향이 다르기 때문에 하나의 임베딩은 단어의 왼편에 속한 문맥을, 또 하나의 임베딩은 단어의 오른편에 속한 문맥을 파악하는 역할을 수행한다.</li>
</ul>
<h3 id="pre-trained-as-a-language-model">Pre-trained as a language model</h3>
<ul>
<li>언어 모델이란 특정 단어나, character 배열에 확률값을 부여하는 통계 모델이다. 예를 들자면 “Congratulations you have won a prize” 라는 영문장이 발생할 확률을 각 단어들의 조합이라는 관점에서 계산하는 것.</li>
<li>이를 수식으로는 다음과 같이 표현할 수 있다.</li>
</ul>
<p>$$P(W_1 = Congratulations, W_2 = you, W_3 = have, W_4 = won, W_5 = a, W_6 = prize)$$</p>
<ul>
<li>하지만 단어의 조합이란 무한의 영역이며, 실제 데이터를 기반으로 이와 같은 통계치를 직접적으로 얻는 것은 불가능한 작업이다. 때문에 다음과 같은 조건부 확률의 규칙를 활용하게 된다.</li>
</ul>
<p>$$P(x, y) = P(x|y)P(y)$$</p>
<ul>
<li>4개의 단어가 등장하는 문장에 대한 확률값 $P(W_1, W_2, W_3, W_4)$ 는 조건부 확률을 규칙을 적용해 다음과 같이 확장하는 것이 가능.</li>
</ul>
<p>$$P(W_1, W_2, W_3, W_4)$$</p>
<p>$$= P(W_1, W_2, W_3 | W_4)P(W_4)$$</p>
<p>$$= P(W_1, W_2 | W_3, W_4)P(W_3 | W_4)P(W_4)$$</p>
<p>$$= P(W_1 | W_2, W_3, W_4)P(W_2 | W_3, W_4)P(W_3 | W_4)P(W_4)$$</p>
<ul>
<li>위와 같은 문제의 재정의에 따라, 이제 우리가 계산하고자 하는 값은 이전에 등장한 모든 단어에 비추었을때 특정한 단어가 발생할 확률로 정의할 수 있다. 이러한 조건부 확률을 계산할 수 있다면, 각 단어의 조건부 확률을 곱해줌으로 전체 문장의 확률값을 계산하는 것이 가능해지는 것.</li>
<li>이를 로그로 치환할 시, 조건부 확률의 곱을 단순한 합계로 변형하는 것이 가능하다.</li>
</ul>
<p>$$\text{log} P(\text{sentence}) = \Sigma_{\text{word}} log P(\text{word} | \text{all words that came before})$$</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo6.png"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 6. Language Modeling in LSTM</td>
</tr>
</tbody>
</table></div>
<ul>
<li>따라서 위와 같이 다음 단어를 예측하는 시퀀스 모델은 언어 모델의 조건부 확률을 구하는 작업을 수행한다고 볼 수 있으며, 최종 레이어 내 확률 부여를 위해서 softmax 함수가 적용된다.</li>
</ul>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo7.png"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 7. Language Modeling As a Task</td>
</tr>
</tbody>
</table></div>
<ul>
<li>이론적인 부분을 간단하게 짚고 넘어갔지만, 위와 같은 상황에서 단어 별로 알맞은 확률값을 부여하기 위해서는 상당한 수준의 사전 지식을 요구한다.</li>
<li>등장하는 4개 단어 중 cyclcing 을 제외한 단어는 모두 문법적으로 적법할 수 있지만, window &gt; aquarium &gt; pool 순서의 확률값을 부여한다는 것은 각각 단어에 대한 특성을 이해한다는 것을 의미.</li>
<li>이러한 상황에서 완벽히 확률값을 부여하는 모델을 AI Complete 라 지칭할 수 있으며, 이를 위해서는 common sense, context 에 대한 인간 수준의 이해를 필요로 한다.</li>
</ul>
<h2 id="elmo-architecture">ELMo Architecture</h2>
<div class="table-wrapper"><table>
<thead>
<tr>
<th style="text-align:center"><img src="/neural_network/images/elmo8.png"
	
	
	
	loading="lazy"
	
		alt="alt text"
	
	
></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Fig 8. ELMo Architecture</td>
</tr>
</tbody>
</table></div>
<ul>
<li>상기된 컴포넌트를 바탕으로 구축된 ELMo 모델 구조의 다이어그램이다. Char-CNN 모델이 생성한 최초 단어 임베딩을 기준으로 2개의 LSTM 모델을 언어 모델로서 학습시키는 것.</li>
<li>최종 단어 임베딩은 다음과 같이 정의된다.</li>
</ul>
<p>$$
e_k = \gamma i h_K^{init} + \gamma \sum_{j=0}^{L} f_j h_{k,j}^{forward} + \gamma \sum_{j=0}^{L} b_j h_{k,j}^{backward}
$$</p>
<ul>
<li>위 방정식에서 등장하는 $h^{init}$, $h^{forward}$, $h^{backward}$ 는 각각 Char-CNN, Forward LSTM, Backward LSTM 의 아웃풋이며, 이외 변수를 통해 finetuning 을 지원하는 것.</li>
<li>특히 $\gamma$ 는 Weight 파라미터로 부여된 태스크에 따라 서로 다른 가중치를 부여하게 된다.</li>
</ul>
<h2 id="reference">Reference</h2>
<ol>
<li><a class="link" href="https://www.youtube.com/watch?v=csAlW9HmwAQ"  target="_blank" rel="noopener"
    >https://www.youtube.com/watch?v=csAlW9HmwAQ</a></li>
<li><a class="link" href="https://wikidocs.net/33930"  target="_blank" rel="noopener"
    >https://wikidocs.net/33930</a></li>
<li><a class="link" href="https://reniew.github.io/22/"  target="_blank" rel="noopener"
    >https://reniew.github.io/22/</a></li>
</ol>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%EC%97%98%EB%AA%A8/">엘모</a>
        
            <a href="/tags/%EC%9E%84%EB%B2%A0%EB%94%A9/">임베딩</a>
        
            <a href="/tags/%EB%89%B4%EB%9F%B4%EB%84%B7/">뉴럴넷</a>
        
            <a href="/tags/elmo/">ELMo</a>
        
            <a href="/tags/nlp/">NLP</a>
        
            <a href="/tags/%EC%97%98%EB%AA%A8-%EC%98%88%EC%8B%9C/">엘모 예시</a>
        
            <a href="/tags/elmo-%EC%98%88%EC%8B%9C/">ELMo 예시</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css"integrity="sha256-J&#43;iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s="crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js"integrity="sha256-InsNdER1b2xUewP&#43;pKCUJpkhiqwHgqiPXDlIk7GzBu4="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js"integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="has-image">
    <a href="/neural_network/roberta/">
        
        
            <div class="article-image">
                
                    <img src="/neural_network/images/roberta_1.gif" loading="lazy" data-key="roberta" data-hash="/neural_network/images/roberta_1.gif"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">(논문 리뷰) RoBERTa: A Robustly Optimized BERT Pretraining Approach</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/neural_network/t5/">
        
        
            <div class="article-image">
                
                    <img src="/neural_network/images/t5_1.gif" loading="lazy" data-key="t5" data-hash="/neural_network/images/t5_1.gif"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">T5 (Text-To-Text Transfer Tranformer) 구조 소개</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/neural_network/crnn/">
        
        
            <div class="article-image">
                
                    <img src="/neural_network/images/crnn_2.png" loading="lazy" data-key="crnn" data-hash="/neural_network/images/crnn_2.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">(논문 리뷰) Scene Text Recognition 을 위한 CRNN 구조</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/neural_network/vggnet/">
        
        
            <div class="article-image">
                
                    <img src="/neural_network/images/vggnet_1.jpg" loading="lazy" data-key="vggnet" data-hash="/neural_network/images/vggnet_1.jpg"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">(논문 리뷰) 핵심만 추려낸 VGGNet 논문 요약</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/neural_network/alexnet/">
        
        
            <div class="article-image">
                
                    <img src="/neural_network/images/alexnet_1.png" loading="lazy" data-key="alexnet" data-hash="/neural_network/images/alexnet_1.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">(논문 리뷰) 쉽게 이해하는 AlexNet 과 PyTorch 코드 예시</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "meme2515" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (typeof DISQUS == 'object') {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2022 - 
        
        2023 Soon&#39;s Blog
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.16.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
