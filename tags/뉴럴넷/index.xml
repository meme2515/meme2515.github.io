<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>뉴럴넷 on Soon Hyung Kwon</title>
        <link>https://meme2515.github.io/tags/%EB%89%B4%EB%9F%B4%EB%84%B7/</link>
        <description>Recent content in 뉴럴넷 on Soon Hyung Kwon</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 26 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://meme2515.github.io/tags/%EB%89%B4%EB%9F%B4%EB%84%B7/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>(논문 리뷰) Scene Text Recognition 을 위한 CRNN 구조</title>
        <link>https://meme2515.github.io/neural_network/crnn/</link>
        <pubDate>Sat, 26 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/crnn/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/crnn_2.png" alt="Featured image of post (논문 리뷰) Scene Text Recognition 을 위한 CRNN 구조" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;CRNN 구조는 학계에서 CNN/RNN 구조에 대한 연구가 탄력을 받고있던 2015년, 중국의 화중과기대에서 공개한 &lt;strong&gt;Scene Text Recognition (일상 이미지 속 테스트 인식 과제)&lt;/strong&gt; 모델이다. 이후 어텐션 구조가 추가된 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.researchgate.net/figure/The-network-structure-of-MA-CRNN-The-whole-network-consists-of-three-parts-1_fig2_337288162&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MA-CRNN&lt;/a&gt;&lt;/strong&gt; 등 다양한 변형 모델이 공개되었으나, 현재까지 널리 쓰이는 오픈소스 OCR 라이브러리인 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/JaidedAI/EasyOCR&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;EasyOCR&lt;/a&gt;&lt;/strong&gt; 의 문자 인식 모듈은 논문에서 공개된 모델 구조를 그대로 따르고있다 (참고로 해당 라이브러리의 문자 감지 모듈은 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/clovaai/CRAFT-pytorch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;네이버의 CRAFT&lt;/a&gt;&lt;/strong&gt; 모델을 사용한다).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_3.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. EasyOCR, 다양한 언어의 문자 인식 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;CRNN 이란 이름에서 보이듯 전통적인 CNN 과 RNN 의 구조를 합성한 형태를 가지고 있다. 자칫 트렌디한 두 구조를 엮어 이목을 끄려는 목적으로 보여질 수 있지만, Scene Text Recognition 이라는 적절한 과제 선정으로 관련 분야 연구에 적지않은 영향을 끼쳤다. 또한 두 모델 구조의 결합 후에도 단일 학습이 가능하다는 점, &lt;strong&gt;CTC 손실 함수&lt;/strong&gt; 사용으로 프레임 별 레이블링 작업을 필요로 하지 않는다는 점에서 실사용도가 높다는 장점을 가지고있다.&lt;/p&gt;
&lt;h2 id=&#34;네트워크-구조&#34;&gt;네트워크 구조&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;CRNN 네트워크는 크게 Convolution Layer (합성곱 레이어), Recurrent Layer (순환 레이어), Transcription Layer 3가지 모듈로 구성되어있다.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;합성곱 레이어는 우선 이미지의 영역 별 feature 를 추출하며, 순환 레이어가 추출된 각 이미지 영역에 속한 텍스트를 순차적으로 예측하게 된다. 합성곱 연산은 단어 (word) 별 문자열 (character) 영역을 구분하지 못하기 때문에 추출된 feature 사이에 중첩 영역이 발생할 수 있는데 &lt;em&gt;(예. -s-t-aatte)&lt;/em&gt; Transcription Layer 는 이를 실제 단어로 정리하는 역할을 수행한다 &lt;em&gt;(예. state)&lt;/em&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. CRNN 기본 구조&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;convolution-layer&#34;&gt;Convolution Layer&lt;/h3&gt;
&lt;p&gt;인풋된 이미지 데이터가 최초로 처리되는 영역이며 전통적인 CNN 구조에서 fully-connected layer 를 제외해 feature 아웃풋에 상응하는 원본 이미지의 영역 (receptive field) 이 특정되도록 설계되었다. 보다 디테일한 포인트들을 언급하자면 인풋 이미지는 항상 같은 높이값을 가지도록 조정되며, 아웃풋이 n 채널을 가진다면 동일한 영역에 대한 모든 채널의 합산 값을 feature 로 정의한다.&lt;/p&gt;
&lt;p&gt;또한 이미지의 Text 영역이 이미 추출되었다고 가정하기 때문에 좌우 움직임을 가지는 영역 sequence 고려하게 된다 &lt;em&gt;(인풋 이미지가 두 줄 이상이라면 처리가 어려울 것).&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Feature Sequence 와 Receptive Field 간 1-to-1 매칭 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;recurrent-layer&#34;&gt;Recurrent Layer&lt;/h3&gt;
&lt;p&gt;합성곱 레이어에 의해 아웃풋된 feature sequence, $X = x_1, x_2, &amp;hellip; , x_T$, 는 순서가 특정 가능하기 때문에 각 프레임 $x_t$ 에 대한 레이블 분포 $y_t$ 를 예측하는 순환 레이어의 인풋으로 활용된다.&lt;/p&gt;
&lt;p&gt;논문의 저자는 RNN 구조 활용의 장점을 다음과 같이 정리한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이미지 context 에 대한 정보를 활용하기 때문에 이전 문자열 (character) 또는 단어 (word) 에 기반한 예측이 가능하며, 여러개 feature 영역 (receptive field) 이 한개 문자열에 걸쳐있는 경우, &amp;ldquo;il&amp;rdquo; 과 같이 상대적인 비교가 필요한 경우 또한 성능 향상을 기대할 수 있다.&lt;/li&gt;
&lt;li&gt;역전파 수행이 가능하기에 CNN 레이어와 함께 학습할 수 있다.&lt;/li&gt;
&lt;li&gt;인풋 sequence 의 길이가 중요하지 않다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;또한 저자는 sequence 간 거리에 비례해 발생하는 &lt;a class=&#34;link&#34; href=&#34;https://velog.io/@yunyoseob/Gradient-Vanishing-%EA%B8%B0%EC%9A%B8%EA%B8%B0-%EC%86%8C%EC%8B%A4#:~:text=Gradient%20Vanishg%20%EB%AC%B8%EC%A0%9C%EB%8A%94%20%EC%8B%A0%EA%B2%BD%EB%A7%9D,%EC%88%98%20%EC%97%86%EA%B2%8C%20%EB%90%98%EB%8A%94%20%EB%AC%B8%EC%A0%9C%EC%9E%85%EB%8B%88%EB%8B%A4.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gradient vanishing problem&lt;/a&gt;, RNN 의 단방향성 문제 등을 해결하기 위해 당시 널리 사용된 &lt;a class=&#34;link&#34; href=&#34;https://techbrad.tistory.com/38&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bidirectional LSTM&lt;/a&gt; 구조를 채택했다.&lt;/p&gt;
&lt;h3 id=&#34;transcription-layer&#34;&gt;Transcription Layer&lt;/h3&gt;
&lt;p&gt;Transcription 이란 프레임 단위로 추출된 RNN 레이어의 예측값 &lt;em&gt;(예. -s-t-aatte)&lt;/em&gt;  을 실제 단어로 &lt;em&gt;(예. state)&lt;/em&gt; 변환하는 과정을 칭한다. 수학적으로는 RNN 레이어가 예측한 프레인 단위 시퀀스가 주어졌을때 가장 높은 확률을 가진 실제 단어 시퀀스를 연산하는 조건부 확률 모델이며, 저자는 예측 가능한 단어 시퀀스에 있어 실제 사전을 참조하는 lexicon 모드와 단순 확률값에 기반한 lexicon-free 모드를 모두 구현하였다. 또한 프레임 단위 시퀀스에 따른 조건부 확률은 &lt;strong&gt;Connectionist Temporal Classification (CTC)&lt;/strong&gt; 에 기반하여 계산된다.&lt;/p&gt;
&lt;h2 id=&#34;ctc&#34;&gt;CTC&lt;/h2&gt;
&lt;p&gt;CTC 에 대한 개념은 사실 음성인식 문제를 해결하기 위해 등장했다. &lt;a class=&#34;link&#34; href=&#34;https://brightwon.tistory.com/11&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MFCC&lt;/a&gt; 와 같은 음성 피처는 대게 짧은 시간 단위로 쪼개서 생성하게 되는데, 전통적인 손실 함수를 이용하고자 한다면 이러한 프레임 각각에 레이블을 달아주어야 하기 때문에 공수가 크게 들고 정확도 또한 떨어진다는 문제가 발생한다. 때문에 CTC 는 음성 인풋의 프레임 시퀀스와 타깃 문자열 시퀀스간의 명시적인 alignment 없이 모델 학습이 가능하도록 고안되었다.&lt;/p&gt;
&lt;p&gt;예측 파이프라인은 하단 도식화와 같이 구성된다. 우선 프레임 별 레이블을 예측한 후, 중첩되는 레이블을 하나로 묶어주는 작업과 &lt;em&gt;(예. lll -&amp;gt; l)&lt;/em&gt; 공란을 뜻하는 epsilon 값에서 예측 값을 바꾸는 작업을 수행한다 &lt;em&gt;(예. ee lll -&amp;gt; el)&lt;/em&gt;. 보다 자세한 내용은 네이버 이기창님의 &lt;a class=&#34;link&#34; href=&#34;https://ratsgo.github.io/speechbook/docs/neuralam/ctc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ratsgo 블로그&lt;/a&gt;에 기술되어 있으니 참고하면 좋을듯 하다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. CTC Input 과 프레임 시퀀스 별 예측치, 최종 아웃풋 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;lexicon-활용&#34;&gt;Lexicon 활용&lt;/h2&gt;
&lt;p&gt;언어 예측 분야에서는 예측된 시퀀스의 품질을 보장하기위해 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;http://hunspell.github.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hunspell Spell Checking Dictionary&lt;/a&gt;&lt;/strong&gt; 와 같은 렉시콘 (Lexicon, 어휘 사전) 을 사용하고는 한다. 본 논문은 아웃풋이 이와 같은 렉시콘에 의해 처리된 lexicon-based mode, 그렇지 않은 lexicon-free mode 를 모두 구현하고 있다.&lt;/p&gt;
&lt;h3 id=&#34;lexicon-free-transcription&#34;&gt;Lexicon-free Transcription&lt;/h3&gt;
&lt;p&gt;Lexicon-free mode 는 처리된 최종 레이블 시퀀스 아웃풋을 별도 검증 과정 없이 그대로 출력하게 된다. 상단 Fig 4. 의 &amp;ldquo;hello!&amp;rdquo; 예측값이 실제 사전에 존재하는지 여부는 고려되지 않으며, 인터넷 언어와 같이 어휘 검증이 어려운 경우 적합할 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;lexicon-based-transcription&#34;&gt;Lexicon-based Transcription&lt;/h3&gt;
&lt;p&gt;예측값을 어휘 사전과 비교해 아웃풋 가능한 레이블 시퀀스의 영역을 한정하게된다. 다만 어휘 사전이 클 경우 모든 레이블에 대한 비교에 지나치게 큰 연산 자원과 시간이 소모되기 때문에, 저자는 예측치와 어휘 사전에 포함된 단어들 간 거리를 계산한 후 가장 가까운 거리에 있는 어휘 사전 단어들로 탐색 영역을 한정하는 Nearest-Neighbor 방식을 사용한다.&lt;/p&gt;
&lt;p&gt;이때 거리란 단어 A 에서 단어 B 로 변형되기까지의 수정 횟수를 뜻하는 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://hoony-gunputer.tistory.com/entry/%EB%A0%88%EB%B2%A4%EC%8A%88%ED%83%80%EC%9D%B8-%EA%B1%B0%EB%A6%AC%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4%EC%84%9C-%EB%91%90-%EB%AC%B8%EC%9E%A5-%EB%B9%84%EA%B5%90%ED%95%98%EA%B8%B0#:~:text=%EB%A0%88%EB%B2%A4%EC%8A%88%ED%83%80%EC%9D%B8%20%EA%B1%B0%EB%A6%AC%EB%8A%94%20%EB%8F%85%EC%9D%BC%EC%9D%98,%EB%8B%A4%EB%A5%B8%EC%A7%80%20%EA%B5%AC%EB%B6%84%ED%95%98%EB%8A%94%20%EB%B0%A9%EB%B2%95%EC%9D%B4%EB%8B%A4.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Levenshtein Distance&lt;/a&gt;&lt;/strong&gt; 로 정의한다 &lt;em&gt;(예. help 와 hello 간 거리는 help -&amp;gt; hell -&amp;gt; hello 두 번의 수정을 필요로 하기때문에 2가 된다)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Nearest-Neighbor 후보군을 탐색하는 과정은 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;%28https://medium.com/future-vision/bk-trees-unexplored-data-structure-ec234f39052d%29&#34; &gt;Burkhard-Keller Tree (BK-tree)&lt;/a&gt;&lt;/strong&gt; 데이터 구조를 활용해 효율적으로 수행이 가능하다. 이는 1973년도에 &lt;strong&gt;문자열에 대한 근사값을 빠르게 찾도록 설계된 트리 구조&lt;/strong&gt;인데, 각 노드는 단어 정보를, 엣지는 단어 간 Levenshtein 거리값을 가지게 된다. 부모 노드에 연결된 자식 노드들은 모두 다른 Levenshtein 거리값을 가져야하며, 같은 거리값을 가진 단어가 추가된다면 중첩되는 단어의 자식 노드로 추가되는 식이다.&lt;/p&gt;
&lt;p&gt;새로운 단어 (query) 에 가장 유사한 단어를 찾을때는 임곗값 (threshold) 을 특정해줘야 한다. 먼저 루트 단어 (root) 와 쿼리 단어 간 거리 $D = \text{Levenshtein}(\text{root}, \text{query})$ 를 측정한 후, 해당 거리가 임곗값보다 크다면 $D - \text{threshold}$, $D + \text{threshold}$ 사이의 엣지값을 가진 자식 노드들에서 동일한 작업을 재귀적으로 수행한다. 이 과정에서 임곗값 안에 들어오는 단어가 발견되면 리턴 하게된다. 논문 저자에 따르면 이러한 알고리즘은 렉시콘 크기 $|D|$ 에 대해 $O(log(|D|))$ 효율성을 가지게 된다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Burknard-Keller Tree 구조 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;모델-성능&#34;&gt;모델 성능&lt;/h2&gt;
&lt;p&gt;IIIT5k, SVT, IC03, IC13 4개 데이터셋에 비해 2015년 당시 최신 모델과 견줄만한 성능을 기록했다. 또한 비언어 문제인 악보 인식 또한 기존 모델보다 월등한 성능을 보여 모든 시퀀스 인식 분야에 적용될 수 있음을 시사했다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/crnn_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 6. CRNN 모델의 성능 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;레퍼런스&#34;&gt;레퍼런스&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://tw0226.tistory.com/90&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://tw0226.tistory.com/90&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1507.05717.pd&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/pdf/1507.05717.pd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://ratsgo.github.io/speechbook/docs/neuralam/ctc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ratsgo.github.io/speechbook/docs/neuralam/ctc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/future-vision/bk-trees-unexplored-data-structure-ec234f39052d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://medium.com/future-vision/bk-trees-unexplored-data-structure-ec234f39052d&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>(논문 리뷰) 핵심만 추려낸 VGGNet 논문 요약</title>
        <link>https://meme2515.github.io/neural_network/vggnet/</link>
        <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/vggnet/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/vggnet_1.jpg" alt="Featured image of post (논문 리뷰) 핵심만 추려낸 VGGNet 논문 요약" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;컨볼루션 필터를 아주 작은 사이즈 (3x3) 로 고정해, 당시로서는 획기적으로 깊은 16~19 레이어 CNN 을 구축해 네트워크의 깊이가 신경망 모델의 성능에 끼치는 영향을 연구한 교과서적인 논문이다. 저자는 이러한 인사이트를 바탕으로 2014년 ImageNet Challenge 우승 모델을 구축했는데, 불과 2년전 우승 모델인 &lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/neural_network/alexnet/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AlexNet&lt;/a&gt; 이 8 레이어로 구축됐던 것을 감안하면 네트워크의 깊이가 빠르게 상승한 것을 볼수있다 (2015년 대회에선 152 레이어의 ResNet이 등장). 해당 글에서는 네트워크의 하이퍼파라미터, 세부 구조에 대한 내용을 제외한 핵심 내용만을 전달하고자 하며, 본문은 &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1409.1556.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;여기&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;
&lt;h2 id=&#34;네트워크-구조&#34;&gt;네트워크 구조&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 6개 VGGNet 모델 아키텍처&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;네트워크 깊이 변화에 따른 성능의 차이를 검증하기 위해 논문에 등장하는 6개 모델은 모두 동일한 세팅을 가지고있다. 언급했던 필터 (커널) 사이즈가 3x3 인 이유는 상하좌우 픽셀을 고려할 수 있는 최소 크기이기 때문이며, 필터가 작을수록 다음 레이어에서 정보유실이 적다는 점을 이용해 신경망의 깊이를 키우는 목적을 가지고 있다. 컨볼루션 레이어 이후에 FC 레이어가 뒤따르고, 마지막 softmax 레이어를 통해 분류 예측을 수행하는 전통적인 CNN 구조를 계승하고있다.&lt;/p&gt;
&lt;p&gt;A 부터 E 까지의 알파벳 순으로 네트워크의 깊이와 복잡도가 증가하고, 이에 불구하고 작은 필터 사이즈로 인해 이전에 등장한 네트워크와 비교해 가중치 개수가 크게 차이나지 않는다. 네트워크 구조에 대해 언급할만한 부분은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AlexNet 에 등장했던 LRN 레이어를 모델 A에 적용 후, 저자는 LRN 이 모델 성능에 크게 기여하지 않는다고 판단해 이후 모델에 LRN 을 적용하지 않는다.&lt;/li&gt;
&lt;li&gt;모델 C 는 모델 B 에 1x1 필터를 추가한 것이다. 인/아웃 채널 수가 같기 때문에 channel reduction 역할은 수행하지 않고, 단순한 activation 레이어의 추가라고 보는 것이 타당하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3x3-컨볼루션-필터&#34;&gt;3x3 컨볼루션 필터&lt;/h3&gt;
&lt;p&gt;본 논문 이전에 등장한 CNN 구조는 대부분 7x7, 5x5 등의 컨볼루션 필터 (커널) 를 사용하며, 초기 레이어에서 상대적으로 더 큰 필터 사이즈를 적용한다 (AlexNet 의 경우 11x11 w/ stride 4).  이에 반해 VGGNet 은 네트워크는 필터 사이즈를 3x3 으로 최소화하여 네트워크의 깊이를 19 레이어까지 끌어올렸다. 언급했듯 이는 작은 필터 사이즈가 레이어 간 정보유실을 최소화하기 때문인데, 논문의 저자는 이에 대한 부연 설명으로 7x7 필터가 적용된 한개 레이어가 3x3 필터가 적용된 세개 레이어와 사실상 같은 기능을 한다는 점을 언급한다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 예시는 5x5 필터 레이어 1개와 3x3 필터 레이어 2개 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;그렇다면 VGGNet 과 같이 필터 사이즈를 줄이고, 레이어 수를 늘린 경우엔 어떤 이점이 있을까? 첫째로 ReLU (혹은 다른 activation) 레이어가 여러번 적용되기 때문에 네트워크가 가장 핵심적인 정보만 추려내도록 유도하는 것이 가능하다. 둘째로 학습이 필요한 파라미터 수가 상당히 감소하게된다. 인풋/아웃풋의 채널수가 모두 C 로 동일하다 가정했을 때, 3x3 필터로 구성된 3 레이어 네트워크는 $3^2 C^2 = 27 C^2$ 파라미터를 가지게되는 반면, 7x7 필터로 구성된 1 레이어 네트워크는 $7^2 C^2 = 49 C^2$ 파라미터를 가지게 됨으로 전자 대비 약 181% 의 파라미터로 구성된다. 이에 따라 VGGNet 은 학습속도 개선, 과적합 방지 효과를 누리게 된다고 저자는 결론짓는다.&lt;/p&gt;
&lt;h2 id=&#34;모델-학습-과정&#34;&gt;모델 학습 과정&lt;/h2&gt;
&lt;h3 id=&#34;전이-학습&#34;&gt;전이 학습&lt;/h3&gt;
&lt;p&gt;깊어진 네트워크의 복잡성으로 인해 적절한 초기 가중치 세팅 (weight initilization) 없이는 네트워크 학습이 어려운 문제가 발생한다. 이를 해결하기 위해 저자는 레이어 수가 가장 적은 A 모델을 pre-train 모델로 활용하여, 더 깊은 모델 학습 시 레이어를 이어 붙이고, 이후 fine-tuning 을 진행한다.&lt;/p&gt;
&lt;h3 id=&#34;이미지-리사이징&#34;&gt;이미지 리사이징&lt;/h3&gt;
&lt;p&gt;네트워크는 기본적으로 인풋 이미지에서 랜덤하게 크롭된 224x224 이미지를 처리한다. 이러한 인풋 크롭이 진행되기 전, 이미지는 가로세로 비율이 유지되는 상태에서 리스케일되는데 (isotropical rescale - 1024x512 이미지가 512x256 사이즈로 리스케일 되어 2:1 비율을 유지하는 식), 리스케일 후 가로세로 중 더 작은 면의 이미지 크기를 학습 시 $S$, 테스팅 시 $Q$ 라 칭한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학습은 $S$ 를 256 또는 384로 고정하는 single-scale 방식, 혹은 이미지 별로 256 과 512 사이 랜덤한 숫자를 부여하는 multi-scale 방식으로 나뉘어진다.&lt;/li&gt;
&lt;li&gt;테스팅은 $Q$ 를 256 또는 384로 고정하는 single-sclae 방식, 혹은 224, 256, 288, 416, 512 중 세가지 숫자에서 랜덤하게 부여하는 multi-scale 방식으로 나뉘어진다.&lt;/li&gt;
&lt;li&gt;학습과 테스팅은 single/multi-sclae 방식의 조합 (single-multi, multi-single 도 가능) 으로 이루어진다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_4.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Multi-Scale 리사이징 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;fc-layer---conv-layer&#34;&gt;FC layer -&amp;gt; Conv. layer&lt;/h3&gt;
&lt;p&gt;모델 뒷단에 위치한 FC (Fully Connected) 레이어는 파라미터 수가 고정되어있기 때문에 학습에 활용된, 고정된 사이즈의 이미지만 처리할 수 있다. 때문에 저자는 학습에 활용된 FC 레이어를 컨볼루션 레이어로 변경하여, 각자 다른 크기의 최종 아웃풋에서 평균치를 구하는 방식으로 (Averaged Sum-Pooling) softmax 레이어를 연산한다. 구체적인 레이어 변경 방식과 Sum-Pooling 방식은 논문에 언급되어있지 않으나, 다음 이미지를 참고하면 대략적인 접근법이 이해될 것이다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_5.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. Conv. layer 변환 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;모델-성능&#34;&gt;모델 성능&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Single Test Scale 성능 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;여기서 top-1, top-5 error rate 란 AlexNet 과 동일하게 가장 높은 확률로 예측된 1개, 5개 레이블 중 실제 레이블이 포함되어 있는 비율이다. 모델의 깊이가 깊어질 수록 성능이 증가하며, LRN 레이어가 성능에 오히려 악영향을 끼치는 점을 확인할 수 있다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/vggnet_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 5. Multiple Test Scale 성능 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;저자는 모델의 성능은 깊이에 비례하며, 동일한 깊이라도 1x1 convolution 레이어보다 3x3 convolution 레이어를 구성하는 것이 성능에 도움이 된다는 점을 발견한다. 또한 test 이미지 사이즈가 고정된 경우, 랜덤하게 선택된 경우 모두 학습 시 랜덤한 이미지 사이즈를 사용한 경우에 모델 성능이 가장 좋았으며, 저자는 이러한 방식이 데이터 증강 역할을 수행해 이미지들에 대한 통계치를 얻는 것에 도움이 되었다고 결론짓는다.&lt;/p&gt;
&lt;p&gt;VGGNet 은 2014년 ILSVRC 챌린지에서 GooGLeNet 다음으로 2등을 차지했다. 마지막으로 저자는 VGGNet 이 다양한 task 와 데이터셋에서 높은 범용성을 보인다는 점을 언급한다.&lt;/p&gt;
&lt;h2 id=&#34;레퍼런스&#34;&gt;레퍼런스&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1409.1556.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/pdf/1409.1556.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://oi.readthedocs.io/en/latest/computer_vision/cnn/vggnet.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://oi.readthedocs.io/en/latest/computer_vision/cnn/vggnet.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://bskyvision.com/504&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://bskyvision.com/504&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>(논문 리뷰) 쉽게 이해하는 AlexNet 과 PyTorch 코드 예시</title>
        <link>https://meme2515.github.io/neural_network/alexnet/</link>
        <pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/alexnet/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/alexnet_1.png" alt="Featured image of post (논문 리뷰) 쉽게 이해하는 AlexNet 과 PyTorch 코드 예시" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;2012년 토론토 대학의 &lt;a class=&#34;link&#34; href=&#34;https://www.cs.toronto.edu/~kriz/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Alex Krizhevsky&lt;/a&gt; 팀이 공개한 AlexNet 은 &lt;a class=&#34;link&#34; href=&#34;https://image-net.org/challenges/LSVRC/2012/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ILSVRC-2012&lt;/a&gt; 대회에서 2등 모델의 정확도 26.2%를 10% 이상 상회하는 15.3% 의 정확도를 기록해 많은 관심을 받았던 CNN 구조이다. 특히 GPU 를 활용한 연산가속이 컴퓨터 비전 커뮤니티에서 적극적으로 사용되는 것에 기여하였으며, 이외에도 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ReLU 활성화 함수&lt;/a&gt;, Overlapping Pooling 등 &amp;lsquo;22년 현재 당연하게 받아들여지는 CNN 구조를 정립했다.&lt;/p&gt;
&lt;h2 id=&#34;imagenet-ilsvrc&#34;&gt;ImageNet (ILSVRC)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;스탠포드 대학 교수인 &lt;a class=&#34;link&#34; href=&#34;https://profiles.stanford.edu/fei-fei-li&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Fei-Fei Li&lt;/a&gt; 가 주로 알고리즘 위주의 연구가 이루어지던 당시 AI 분야에 기여하기위해 2009년 공개한 이미지-레이블 데이터셋이다.&lt;/li&gt;
&lt;li&gt;매년 &lt;a class=&#34;link&#34; href=&#34;https://www.image-net.org/challenges/LSVRC/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ImageNet Large Scale Visual Recognition Challenge (ILSVRC)&lt;/a&gt; 라는 레이블 예측 대회를 개최하고 있으며, 2012년 기준 약 120만개의 이미지-레이블 셋으로 이루어져 있었다 (22년 현재 1,400만).&lt;/li&gt;
&lt;li&gt;Top-1 에러율, top-5 에러율 등으로 모델의 정확도를 평가하는데, 여기서 top-5 에러란 likelihood 가 가장 높은 5개 레이블에 실제 레이블이 포함되지 않은 경우를 가르킨다.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. ImageNet 데이터 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;cnn-구조&#34;&gt;CNN 구조&lt;/h2&gt;
&lt;h3 id=&#34;relu-nonlinearity&#34;&gt;ReLU Nonlinearity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;논문이 게재되던 시점 CNN 구조에서 주로 사용되던 tanh, sigmoid 활성화 함수는 학습 속도가 느리다는 문제점을 안고있다. 따라서 AlexNet은 &lt;a class=&#34;link&#34; href=&#34;https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Nair and Hinton&lt;/a&gt; 에서 처음 소개된 ReLU 활성화 함수를 사용해 학습속도를 단축시킨다 (fig 2. 참조).&lt;/li&gt;
&lt;li&gt;논문은 ReLU activation function 을 다음과 같이 정의한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
f(x) = max(0,x)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ReLU 활성화를 사용하게 된 배경에는 2012 당시 AlexNet 의 구조가 기타 CNN에 비해 복잡하고, 크다는 점이 있었다 (&amp;lsquo;92년 공개된 LeNet-5 가 대략 6만개의 학습 가능한 파라미터를 가지고 있는 반면, AlexNet은 6천만개의 파라미터를 가지고있다).&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. CIFAR-10 데이터에 대한 ReLU (실선) vs. tanh (점선) 학습율 비교&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;training-on-multiple-gpus&#34;&gt;Training on Multiple GPUs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;AlexNet 팀은 2012년 당시 최신 GPU 였던 NVIDIA GTX 580 2대를 활용해 모델을 학습시켰다. 각 GPU는 3GB 의 메모리를 가지고 있었으며, 적은 메모리 용량으로 인해 한대의 GPU를 사용해 전체 ImageNet 데이터를 학습하는 것이 불가능했다.&lt;/li&gt;
&lt;li&gt;2대의 GPU는 서로의 메모리에 직접적으로 접근할 수 있으며, 학습 과정에서의 병렬처리는 뉴런, 또는 커널을 반으로 나눠 각 GPU 에 할당하는 방식을 취한다. 다만 모든 레이어에서 커뮤니케이션이 이루어지는 것은 아니고, 특정 레이어에서만 이러한 기능을 활용해 리소스를 관리한다.&lt;/li&gt;
&lt;li&gt;GPU 병렬처리는 학습 시간을 단축시킬뿐만 아니라, GPU 한대에서 처리가능한 사이즈의 네트워크에 비해 top-1 과 top-5 에러율을 각각 1.7% 와 1.2% 감소시킨다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;local-response-normalization-lrn&#34;&gt;Local Response Normalization (LRN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lsquo;22년 기준 최신 CNN 구조에서는 잘 사용되지 않는 개념이다. AlexNet 이후 연구에 따르면 모델의 성능에 크게 기여하지 않는 것으로 밝혀졌다.&lt;/li&gt;
&lt;li&gt;ReLU 활성화 함수 사용으로 인풋 정규화를 반드시 사용해야할 이유는 없으나, AlexNet 의 경우 Local Response Normalization 이 모델의 일반화에 도움을 준다는 점을 발견했다.&lt;/li&gt;
&lt;li&gt;인접한 $n$ 개 채널에 대한 정규화라고 이해하면된다. 하단 슬라이드의 좌측 도표 참고.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 3. Local Response Normalization 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;$a^i_{x,y}$ 가 채널 $i$ 에 대한 $x, y$ 좌표의 ReLU activation output 이라고 했을때, LRN 이 적용된 아웃풋 $b^i_{x,y}$ 는 다음과 같이 정의된다.
&lt;ul&gt;
&lt;li&gt;$n$ 은 인접 채널 수를 특정하는 파라미터, $N$ 은 전체 채널 수&lt;/li&gt;
&lt;li&gt;논문은 $k = 2$, $n = 5$, $\alpha = 10^{-4}$, $\beta = 0.75$ 로 설정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
b^i_{x,y} = a^i_{x,y}/(k + \alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a^j_{x,y})^2)^\beta
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;실제 인접 뉴런 간 정규화가 이루어지는 사람의 두뇌를 기반으로 하고있으며, top-1 과 top-5 에러율을 각각 1.4% 와 1.2% 감소시키는 효과를 보였다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;overlapping-pooling&#34;&gt;Overlapping Pooling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lsquo;12년 당시 pooling layer 는 각각의 pool 이 겹치지 않도록 stride 를 설정하는 것이 일반적이었으나, 이를 서로 겹치도록 설정함으로 top-1 에러율과 top-5 에러율을 각각 0.4% 와 0.3% 씩 감소시켰다.&lt;/li&gt;
&lt;li&gt;기본적인 룰은 $z$ x $z$ 의 pooling kernel 에서 $z$ 보다 작은 stride 사이즈, $s &amp;lt; z$ 를 적용시키는 것이다. 논문에서는 $s=2$, $z=3$ 를 사용하였다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;overall-architecture&#34;&gt;Overall Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;총 8개의 레이어를 가지고 있으며, 5개의 convolution 레이어 후 3개의 FC 레이어를 가지는 전형적인 CNN 구조이다. 마지막 FC 레이어는 1,000 개의 뉴런을 가지고 있는데 이에 softmax 함수를 적용해 클레스 레이블을 유추한다.&lt;/li&gt;
&lt;li&gt;2번, 4번, 5번 convolution 레이어의 경우 GPU 간 소통이 이루어지지 않는다. 따라서 같은 GPU 의 메모리에 속한 뉴런과의 관계만을 통해 학습을 진행한다. FC 레이어의 경우 앞선 레이어의 모든 뉴런과 연결되어있다.&lt;/li&gt;
&lt;li&gt;1번, 2번 convolution 레이어에만 LRN 이 적용된다. 해당 2개 레이어와 5번 convolution 레이어는 또한 Max Pooling 레이어를 가지고 있다.&lt;/li&gt;
&lt;li&gt;모든 convolution 레이어와 FC 레이어에 ReLU 활성화가 적용된다.&lt;/li&gt;
&lt;li&gt;최초 인풋 사이즈는 227 x 227 x 3 이다 (논문에는 224 x 224 x 3 으로 잘못 표기되어있는 것으로 보인다).&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/alexnet_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 4. AlexNet 구조 (실제 논문 또한 이미지의 상단이 잘려있다)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;코드-예시&#34;&gt;코드 예시&lt;/h3&gt;
&lt;p&gt;아래는 &lt;a class=&#34;link&#34; href=&#34;https://paperswithcode.com/method/alexnet&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Papers With Code&lt;/a&gt; 에 링크된 &lt;a class=&#34;link&#34; href=&#34;https://github.com/dansuh17/alexnet-pytorch/blob/d0c1b1c52296ffcbecfbf5b17e1d1685b4ca6744/model.py#L40&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;구현 예시&lt;/a&gt;이다. 논문에서 보이지 않는 디테일은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolution 레이어와 FC 레이어가 분리되어 있다.&lt;/li&gt;
&lt;li&gt;Output 의 클래스 수를 설정할 수 있다. 기본값은 논문과 같은 1,000 으로 설정.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;class AlexNet(nn.Module):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    def __init__(self, num_classes=1000):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        super().__init__()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        self.net = nn.Sequential(
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.ReLU(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.ReLU(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.ReLU(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.ReLU(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.ReLU(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        )
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        # classifier is just a name for linear layers
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        self.classifier = nn.Sequential(
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Dropout(p=0.5, inplace=True),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.ReLU(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Dropout(p=0.5, inplace=True),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Linear(in_features=4096, out_features=4096),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.ReLU(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            nn.Linear(in_features=4096, out_features=num_classes),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        )
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        self.init_bias()  # initialize bias
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    def init_bias(self):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    def forward(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;overfitting&#34;&gt;Overfitting&lt;/h2&gt;
&lt;p&gt;AlexNet 은 약 6천만개의 파라미터에 대한 과적합을 방지하기 위해 다음 두가지 방법 (Data Augmentation 과 Dropout)을 사용한다. Dropout 을 사용한 초기 아키텍쳐 중 하나이며, PCA Color Augmentation 개념이 조금 어렵게 다가온다.&lt;/p&gt;
&lt;h3 id=&#34;data-augmentation&#34;&gt;Data Augmentation&lt;/h3&gt;
&lt;p&gt;아래 translation, reflection 및 PCA color augmentation 기법을 통한 데이터 증강은 학습 과정과 병행되며 (디스크에 저장하지 않는다), GPU 가 아닌 CPU 에서 별도로 처리되기 때문에 사실상 연산에 부담을 주지 않는다.&lt;/p&gt;
&lt;h4 id=&#34;translation--reflection&#34;&gt;Translation &amp;amp; Reflection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;256 x 256 이미지에서 랜덤하게 추출된 5개의 224 x 224 패치와 (4개의 코너 패치와 한개의 중앙 패치), 패치들에 적용된 좌우반전을 통해 10배 사이즈의 학습 데이터를 구축했다. 이후 이 10개 증강 이미지에 대한 평균값을 통해 레이블을 예측하게 된다.&lt;/li&gt;
&lt;li&gt;이러한 데이터 증강 없이 학습된 네트워크는 심각한 과적합 문제를 가지고있다. 네트워크의 큰 사이즈 때문이며, 데이터 증강 기법을 사용하지 않는다면 네트워크 사이즈를 줄이는 방법 밖에는 없다고 저자는 기술한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pca-color-augmentation&#34;&gt;PCA Color Augmentation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;데이터 증강을 목적으로 RGB 채널의 강도를 조정하는 방식이며, PCA 를 통해 얻은 채널 별 분산에 비례하는 난수를 각 채널에 더하거나 빼주게된다.&lt;/li&gt;
&lt;li&gt;PCA 는 한개의 이미지가 아닌 모든 학습 데이터의 RGB 채널값을 대상으로 적용하게 된다. 따라서 자연스러운 채널 별 분산치를 얻을 수 있다.&lt;/li&gt;
&lt;li&gt;모든 RGB 픽셀 값에 대한 3 x 3 공분산 행렬의 eigenvector 를 $p$, eigenvalue 를 $\lambda$ 라고 칭하고, $\alpha$ 는 평균이 0, 표준 편차가 0.1인 Gaussian 분포의 난수일때, RGB 이미지 픽셀 $[I^R_{xy}, I^G_{xy}, I^B_{xy}]$ 에 다음의 값을 더하는 방식이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
[p_1, p_2, p_3][\alpha_1 \lambda_1, \alpha_2 \lambda_2, \alpha_2 \lambda_2]^T
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;개인적으로 아직 관련 이해도와 설명이 아쉽다. 차후 별도의 글을 통해 PCA 개념을 다시 짚어볼 계획.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dropout&#34;&gt;Dropout&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;모델의 성능을 높이기 위한 가장 좋은 방식은 여러 모델의 결과값을 구해 평균을 내는 것이나, 모델의 규모가 너무 크기때문에 이는 현실적으로 어려운 접근법이다.&lt;/li&gt;
&lt;li&gt;그 대안으로 논문은 0.5 의 확률로 개별 뉴런을 활성화하거나 비활성화하는 Dropout 방식을 제안한다. 이러한 확률로 비활성화된 뉴런은 순전파, 역전파 과정에 기여하지 않으며, 활성/비활성화의 사이클을 통해 여러개의 네트워크를 학습시키는 것과 동일한 결과를 얻을 수 있다.&lt;/li&gt;
&lt;li&gt;Dropout 방식은 뉴런이 다른 특정 뉴런에 지나치게 의존하는 것을 사전에 방지한다. 개별 뉴런이 이전 레이어의 activation 정보를 적절히 조합하도록 유도하는 구조이다.&lt;/li&gt;
&lt;li&gt;테스트시에는 이러한 학습과정으로 인해 뉴런의 아웃풋값에 0.5를 곱하게 된다.&lt;/li&gt;
&lt;li&gt;AlexNet은 처음 2개의 FC 레이어에서만 Dropout 을 사용하고 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;details-of-learning&#34;&gt;Details of Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;모델은 SGD 방식으로 학습되었으며, batch size는 128, momentum은 0.9, weight decay는 0.0005로 설정되었다.&lt;/li&gt;
&lt;li&gt;모든 weight 는 평균이 0, 표준편차가 0.01 인 Gaussian Distribution 의 난수로 설정되었으며, 2번, 3번, 5번 convolution 레이어와 모든 hidden FC 레이어의 bias 값은 1로 설정되었다 (ReLU activation 에 양수값을 input 함으로 훈련으로 가속시키는 효과를 가짐; 나머지 bias 값은 0 으로 설정).&lt;/li&gt;
&lt;li&gt;learning rate 는 모든 레이어에 동일하게 적용되었으며, 학습과정에서 manual 하게 조정되었다.
&lt;ul&gt;
&lt;li&gt;최초 learning rate는 0.01 로 설정&lt;/li&gt;
&lt;li&gt;validation error rate 감소가 멈췄을 경우, learning rate 를 10 으로 나눔&lt;/li&gt;
&lt;li&gt;학습 종료까지 총 세번의 learning rate 조정 발생&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;총 학습은 120만개의 이미지를 대상으로 90 사이클 진행.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ILSVRC-2010 데이터셋을 대상으로 top-1 에러율, top-5 에러율 각각 37.5% 와 17.0% 를 기록함 (대회 진행 시 우승 모델의 성능은 각각 47.1%와 28.2%).&lt;/li&gt;
&lt;li&gt;ILSVRC-2012 데이터셋의 test set label 은 &amp;lsquo;12년 당시 공개되지 않았음으로 validation error rate를 기록, 18.2%의 top-5 에러율을 보였다.
&lt;ul&gt;
&lt;li&gt;5개 CNN 구조의 평균값을 구했을때 16.4% 에러율 기록&lt;/li&gt;
&lt;li&gt;6번째 convolution 레이어를 추가한 후, &amp;lsquo;11년 대회 데이터셋을 기반으로 fine tuning 을 진행했을때 16.6% 에러율 기록, 5개 CNN 모델의 평균값과 다시 평균을 내었을때 15.3% 의 에러율을 보였다&lt;/li&gt;
&lt;li&gt;해당 대회의 2번째 높은 에러율은 26.2% 였음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>PyTorch Deep Learning - Backpropagation &amp; Gradient Descent</title>
        <link>https://meme2515.github.io/neural_network/pytorch_3/</link>
        <pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/pytorch_3/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/pytorch.jpeg" alt="Featured image of post PyTorch Deep Learning - Backpropagation &amp; Gradient Descent" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;머신러닝과 분야에서 가장 뼈대가 되는 수학 공식은 &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;경사하강&lt;/a&gt;이다. 왜일까? &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EC%84%9C%ED%8F%AC%ED%8A%B8_%EB%B2%A1%ED%84%B0_%EB%A8%B8%EC%8B%A0&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SVM&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;선형회귀&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.ibm.com/kr-ko/cloud/learn/neural-networks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;신경망&lt;/a&gt;과 같은 통상적인 예측 모델은 모두 다른 방식으로 예측값 $\tilde{Y}$ 를 예측하지만, 이 모든 모델의 정확도를 향상하는 학습과정에서는 언제나 알고리즘에 알맞는 경사하강 공식을 사용하기 때문이다. 구체적으로 경사하강이란 모델의 성능을 더 나은 방향으로 개선시킬 수 있도록 조절 가능한 모델의 변수를 업데이트하는 과정을 가르킨다.&lt;/p&gt;
&lt;p&gt;모든 경사하강 과정은 그에 알맞는 기울기 값, 즉 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Gradient&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gradient&lt;/a&gt; 를 필요로하며, 이는 모델의 변수가 어떤 방향으로 (음수 또는 양수) 움직일때 성능이 개선되는지에 대한 정보를 제공한다. 신경망의 경우, 이러한 변수 별 gradient 값을 연산하기 위해 오차역전파라는 방법을 사용한다. 해당 글에서는 PyTorch 프레임워크를 사용하여 오차역전파를 수행하고, 신경망 모델의 경사하강을 구현하기까지의 과정을 실습해보고자 한다.&lt;/p&gt;
&lt;h2 id=&#34;autograd-복습&#34;&gt;Autograd 복습&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/neural_network/pytorch_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Deep Learning - 2. Autograd&lt;/a&gt; 글에서 살펴보았듯 신경망의 gradient 값을 도출하기 위해서는 역전파를 수행해야하며, 이는 PyTorch 라이브러리의 autograd 기능을 활용해 구현이 가능하다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_2_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. 단일 뉴런의 역전파 과정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;$x = 1$ 의 인풋을 활용해 $y = 2$ 를 예측하는 단일 뉴런 모델의 역전파 과정을 PyTorch 로 구현한 코드는 다음과 같다. 이 경우 가중치인 $w$ 의 초기값이 최적치에 비해 낮기 때문에 gradient 는 음수가 되어야 한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.tensor(1.0)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = torch.tensor(2.0)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; w = torch.tensor(1.0, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # forward pass and compute the loss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y_hat = w * x
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; loss = (y_hat - y)**2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(loss)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor(1., grad_fn=&amp;lt;PowBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # backward pass
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; loss.backward()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(w.grad)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor(-2.)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;경사하강&#34;&gt;경사하강&lt;/h2&gt;
&lt;p&gt;경사하강이란 연산한 gradient 의 반대방향, 즉 손실함수를 낮추는 방향으로 모델의 파라미터를 업데이트하는 과정을 일컫는다. 아래 그림에서 start 지점의 gradient, 즉 미분값은 경사가 상대적으로 큰 양수값이며, 따라서 손실함수 $J(W)$ 를 최소화하기 위해 반대방향인 음수값으로 $w$ 를 업데이트하는 과정을 확인할 수 있다. 아직 gradient가 어떻게 손실함수를 낮추는 방향을 제시하는가에 대한 직관적인 이해가 이루어지지 않는다면 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=GEdLNvPIbiM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=IHZwWFHWa-w&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2&lt;/a&gt; 비디오를 참고하길 바란다. 또한 &lt;a class=&#34;link&#34; href=&#34;http://localhost:1313/neural_network/optimizer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;해당&lt;/a&gt; 글은 Momentum, RMSProp, Adam 등 다양한 경사하강법을 소개하고있다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_3_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 단일 뉴런의 역전파 과정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;신경망 모델에서 경사하강을 수행하기 위해서는 다음과 같은 과정을 순차적으로 수행해야한다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Prediction&lt;/strong&gt;: 현재 파라미터 값을 사용한 예측&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss Computation&lt;/strong&gt;: 손실값 계산&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gradients Computation&lt;/strong&gt;: 예측값을 기반으로 한 gradient 연산&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parameter updates&lt;/strong&gt;: gradient 값을 기반으로 한 파라미터 업데이트&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;manual-접근법&#34;&gt;Manual 접근법&lt;/h3&gt;
&lt;p&gt;우선 PyTorch 라이브러리 없이 Numpy 만으로 이와 같은 손실함수 과정을 구현하는 코드를 살펴보자. 해당 코드의 gradient 는 MSE 함수에 대한 미분값을 별도로 계산한 것이며, 다음 식을 기반으로 하고있다.&lt;/p&gt;
&lt;p&gt;$$
\frac{\delta J}{\delta w} = \frac{1}{N} \cdot 2x (wx - y)
$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import numpy as np
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; X = np.array([1, 2, 3, 4], dtype=np.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Y = np.array([2, 4, 6, 8], dypte=np.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; w = 0.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # model prediction
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def forward(x):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return w * x
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # loss = MSE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def loss(y, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return ((y_pred - y) ** 2).mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # gradient
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def gradient(x, y, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return np.dot(2 * x, y_pred - y).mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # training
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; learning_rate = 0.01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; n_iters = 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; for epoch in range(n_iters):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    y_pred = forward(X)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    l = loss(Y, y_pred)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    dw = gradient(X, Y, y_pred)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # update weights
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w -= learning_rate * dw
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;autograd-활용&#34;&gt;Autograd 활용&lt;/h3&gt;
&lt;p&gt;다음 코드는 상단 경사하강 과정의 Gradients Computation 단계에서 수식이 아닌 Autograd 패키지의 자동미분 기능을 사용한 것이다. gradient 함수가 사라지고, 학습과정의 코드 변화를 확인할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Y = torch.tensor([2, 4, 6, 8], dypte=torch.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # requires_grad 매개변수 설정
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # model prediction
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def forward(x):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return w * x
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # loss = MSE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; def loss(y, y_pred):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return ((y_pred - y) ** 2).mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # training
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; learning_rate = 0.01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; n_iters = 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; for epoch in range(n_iters):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    y_pred = forward(X)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    l = loss(Y, y_pred)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # backward pass
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    l.backward()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # update weights
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    with torch.no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        w -= learning_rate * w.grad
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # reset gradient
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    w.grad.zero_()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>PyTorch Deep Learning - Autograd</title>
        <link>https://meme2515.github.io/neural_network/pytorch_2/</link>
        <pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/pytorch_2/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/pytorch.jpeg" alt="Featured image of post PyTorch Deep Learning - Autograd" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;신경망을 수학적으로 구현함에 있어 가장 까다로운 부분은 &lt;a class=&#34;link&#34; href=&#34;http://wiki.hash.kr/index.php/%EC%97%AD%EC%A0%84%ED%8C%8C&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;역전파 (backpropagation)&lt;/a&gt; 과정이다. 짧게 설명하자면, 모델에 존재하는 각각의 가중치(weight)와 편향(bias)이 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Loss_function&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;손실함수&lt;/a&gt;에 어떠한 영향을 끼치는지를 연산한 다음, 이 정보를 활용해 가중치와 편향의 값을 손실함수를 줄이는 방향으로 갱신시키는 과정이다. 개념적인 이해가 필요하다면 앞선 역전파 해시넷 링크와 더불어 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Ilg3gGewQ5U&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;번, &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=1Q_etC_GHHk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2&lt;/a&gt;번 비디오를 참고하자.&lt;/p&gt;
&lt;p&gt;역전파 과정에서 가장 중요한 수학적 요소는 손실함수에 대한 가중치와 편향의 편미분 (partial derivative) 연산이다. 가중치가 증가할때 손실함수 또한 같이 증가한다면 가중치값을 내리고, 편향 값이 내려갈때 손실함수가 증가한다면 반대로 편향값을 증가시키는 식이다. 이러한 과정을 반복함으로 인해 모델은 가능한 낮은 손실함수, 즉 높은 정확도를 가지게 된다.&lt;/p&gt;
&lt;p&gt;하지만 신경망 네트워크에는 경우에 따라 수십만개의 가중치와 편향이 존재하고, 이를 학습 사이클마다 일일이 손으로 계산할 수 없기 때문에 편미분 연산을 자동적으로 처리해주는 알고리즘을 필요로 하게 되었다. 주요 딥러닝 프레임워크인 PyTorch 의 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Autograd&lt;/a&gt; 패키지는 이러한 역전파 과정을 자동적으로 처리해주는 기능을 가지고있다.&lt;/p&gt;
&lt;h2 id=&#34;자동-미분-automatic-differentiation&#34;&gt;자동 미분 (Automatic Differentiation)&lt;/h2&gt;
&lt;p&gt;Autograd 패키지를 소개하기에 앞서, 자동 미분이 어떠한 방식으로 이루어지는지를 우선 살펴보고자 한다. 자동 미분의 접근 방식은 크게 세가지 (Numerical, Symbolic, Automatic) 가 존재한다.&lt;/p&gt;
&lt;h3 id=&#34;a-numerical&#34;&gt;a. Numerical&lt;/h3&gt;
&lt;p&gt;Numerical 접근은 고등학교 수학에서 등장하는, 극한을 통한 미분의 정의를 이용한다. $f(x)$가 input vector $x$에 대한 손실함수라고 가정했을때의 공식은 다음과 같다.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\frac{\delta f}{\delta x_i} = \lim_{h \to 0} \frac{f(x+he^i) - f(x)}{h}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;여기서 $x$란 길이 $n$의 input 벡터이며, $e^i$ 란 길이가 $n$이며 $i$ 번째 값이 1, 나머지 값이 0인 단위벡터 (unit vector) 이다.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
x = \begin{bmatrix}
x_1 \
x_2 \
\dots \
x_n
\end{bmatrix}
; \
e^1 = \begin{bmatrix}
1 \
0 \
\dots \
0
\end{bmatrix}
; \
e^2 = \begin{bmatrix}
0 \
1 \
\dots \
0
\end{bmatrix}
; \
\dots
\end{align}
$$&lt;/p&gt;
&lt;p&gt;따라서 (1)번 식은 $x^i$ 값이 아주 작게 움직였을때, 함수 $f$의 결과값이 얼만큼 움직이는지를 나타내고있다.&lt;/p&gt;
&lt;p&gt;Numerical 접근에선 크게 두가지 문제점이 존재한다. 첫번째 문제는 극한 (limit) 정의를 코드로 구현할 때 발생하는 오차 문제 (rounding error) 이다. 이는 아주 작은 $h$ 값을 컴퓨터의 floating point로 표현할 때 발생하는 물리적인 한계에서 비롯된 문제이다. 관심이 있는 독자들은 &lt;a class=&#34;link&#34; href=&#34;https://blog.demofox.org/2017/11/21/floating-point-precision/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;링크&lt;/a&gt;를 통해 더 자세한 내용을 확인하자.&lt;/p&gt;
&lt;p&gt;두번째 문제는 해당 접근법이 $O(n)$ 만큼의 연산, 즉 각 가중치와 편향 값에 대한 개별적인 연산을 수행해야 한다는 점이다. 이는 수십만개의 가중치와 편향 값을 학습하는 신경망 네트워크에 지나친 연산 부담을 줄 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;b-symbolic&#34;&gt;b. Symbolic&lt;/h3&gt;
&lt;p&gt;Symbolic 접근은 사람이 실제 미분 연산시에 사용하는 연산 규칙 (예를 들어 $\sin (x)$ 의 미분값은 $\cos (x)$) 을 기반으로 편미분을 구하는 방식이다. 해당 접근법에서 손실함수는 가중치와 편향의 수식으로 표현되며, 연산 규칙을 그 기반으로 하기에 numerical 접근법의 오차 문제를 해결한다. 대표적인 예시로 &lt;a class=&#34;link&#34; href=&#34;https://www.sympy.org/en/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SymPy&lt;/a&gt; 패키지가 있다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_2_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. SymPy 패키지 적분 연산 사용 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(고등학생때 알았더라면&amp;hellip;!)&lt;/p&gt;
&lt;p&gt;얼핏 생각하기에 타당해 보이는 symbolic 접근 또한 역전파 적용이 어려운 이유가 존재한다. 가장 대표적인 문제는 expression swell 인데, 손실함수의 수식보다 그 미분 수식이 기하급수적으로 복잡해지는 문제이다. 다음 예시와 함께 미분의 곱 규칙을 생각해보자.&lt;/p&gt;
&lt;p&gt;$$
h(x) = f(x)g(x) \newline
h&amp;rsquo;(x) = f&amp;rsquo;(x)g(x) + f(x)g&amp;rsquo;(x) \newline
$$&lt;/p&gt;
&lt;p&gt;$f(x)$를 다음과 같이 정의하면 $h&amp;rsquo;(x)$는 더욱 복잡해진다.&lt;/p&gt;
&lt;p&gt;$$
f(x) = u(x)v(x) \newline
h&amp;rsquo;(x) = (u&amp;rsquo;(x)v(x) + u(x)v&amp;rsquo;(x))g(x) + u(x)v(x)g&amp;rsquo;(x) \newline
$$&lt;/p&gt;
&lt;p&gt;이는 한가지 예시에 불과하고, 미분 수식의 복잡성은 손실함수의 수식과 비례하지 않기 때문에 해당 접근은 numerical 접근의 $O(n)$ 연산을 뛰어넘는 연산 부담을 네트워크에 줄 가능성이 있다. 또한 미분 연산의 대상이 항상 특정 수식으로 표현되어야 한다는 제약을 가지고 있다.&lt;/p&gt;
&lt;h3 id=&#34;c-automatic&#34;&gt;c. Automatic&lt;/h3&gt;
&lt;p&gt;Automatic 접근은 수식에 기반하는 대신, 덧셈, 곱셈과 같은 개별적인 연산자 그래프 (DAG) 를 생성하여 미분 연산 과정을 가장 작은 단위에서 수행하는 접근법이다. 다음 그래프를 참고하자.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/neural_network/images/pytorch_2_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. 단일 뉴런의 Autograd DAG 예시&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;여기서 $w$는 가중치, $b$는 편향, $z$는 활성함수를 나타낸다 (편의를 위해 loss 또한 $L$로 지칭하겠다). 위 그래프에서 가중치 $w$의 편미분값, $\frac{\delta L}{\delta w}$ 값을 연산한다고 가정해보자. 우선 &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Cross_entropy&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CE (Cross Entropy)&lt;/a&gt; 함수의 미분식을 통해 $\frac{\delta L}{\delta z}$ 를 구한 후, $z$ 함수의 미분식을 사용해 구한 $\frac{\delta z}{\delta w}$를 $\frac{\delta L}{\delta z}$ 에 곱해줌으로서 $\frac{\delta L}{\delta z} \cdot \frac{\delta z}{\delta w} = \frac{\delta L}{\delta w}$를 연산할 수 있다. 더 작은 단위의 (레이어가 아닌 연산자 단위) 역전파라 생각해도 무방할 듯 하며, 복잡해 보이지만 편미분의 정의를 되새기며 기호와 그래프를 유심히 따라가면 그 의미가 전달 될 것이라 생각한다.&lt;/p&gt;
&lt;h2 id=&#34;jacobian-vector-products-jvps&#34;&gt;Jacobian-Vector Products (JVPs)&lt;/h2&gt;
&lt;p&gt;위 Fig 3. 의 예시에서는 2개의 input $w$, $b$와, 1개의 output $L$에 대한 연산자 그래프를 살펴보았다. Input의 개수가 $n$이고, output의 개수가 $m$인 경우는 어떨까? 해당 연산자 그래프에 대해서 다음과 같은 &lt;a class=&#34;link&#34; href=&#34;https://ko.wikipedia.org/wiki/%EC%95%BC%EC%BD%94%EB%B9%84_%ED%96%89%EB%A0%AC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;편미분 매트릭스 (야코비 행렬, Jacobian Matrix)&lt;/a&gt;를 구할 수 있을 것이다.&lt;/p&gt;
&lt;p&gt;(여기서 $x$는 input을, $f$는 output을 뜻하고 있다)&lt;/p&gt;
&lt;p&gt;$$
\begin{equation*}
J_{f} =
\begin{bmatrix}
\frac{\delta f_1}{\delta x_1 } &amp;amp; \frac{\delta f_2}{\delta x_1 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_1 } \newline
\frac{\delta f_1}{\delta x_2 } &amp;amp; \frac{\delta f_2}{\delta x_2 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_2 } \newline
\vdots  &amp;amp; \vdots  &amp;amp; \ddots &amp;amp; \vdots  \newline
\frac{\delta f_1}{\delta x_n } &amp;amp; \frac{\delta f_2}{\delta x_n } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_n } \newline
\end{bmatrix}
\end{equation*}
$$&lt;/p&gt;
&lt;p&gt;야코비 행렬은 모든 input과 output의 조합에 대한 편미분 값을 가지고 있으며, 각 열에는 output $f_i$, 행에는 input $x_j$에 속하는 값이 정렬되어있다. 특정 output 값 $f_i$에 대한 모든 input $x$의 편미분 벡터를 구하기 위해서는 다음과 같이 적합한 벡터 $r$을 곱해주어야 한다.&lt;/p&gt;
&lt;p&gt;$$
\begin{equation*}
\frac{\delta f_i}{\delta x} =
J_f r =
\begin{bmatrix}
\frac{\delta f_1}{\delta x_1 } &amp;amp; \frac{\delta f_2}{\delta x_1 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_1 } \newline
\frac{\delta f_1}{\delta x_2 } &amp;amp; \frac{\delta f_2}{\delta x_2 } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_2 } \newline
\vdots  &amp;amp; \vdots  &amp;amp; \ddots &amp;amp; \vdots  \newline
\frac{\delta f_1}{\delta x_n } &amp;amp; \frac{\delta f_2}{\delta x_n } &amp;amp; \cdots &amp;amp; \frac{\delta f_m}{\delta x_n } \newline
\end{bmatrix}
\cdot
\begin{bmatrix}
1 \newline
0 \newline
\vdots \newline
0 \newline
\end{bmatrix}
=
\begin{bmatrix}
\frac{\delta f_1}{\delta x_1 } \newline
\frac{\delta f_1}{\delta x_2 } \newline
\vdots \newline
\frac{\delta f_1}{\delta x_n } \newline
\end{bmatrix}
\end{equation*}
$$&lt;/p&gt;
&lt;h2 id=&#34;autograd-사용법&#34;&gt;Autograd 사용법&lt;/h2&gt;
&lt;p&gt;PyTorch의 Autograd 패키지는 이러한 야코비 행렬을 연산해주는 기능을 가지고있다. 우선 input 벡터인 $x$를 지정하는 법을 알아보자.&lt;/p&gt;
&lt;h3 id=&#34;requires_grad-파라미터&#34;&gt;requires_grad 파라미터&lt;/h3&gt;
&lt;p&gt;Input 벡터로 사용하고자 하는 tensor를 최초로 생성할때는 &lt;code&gt;requires_grad&lt;/code&gt; 파라미터를 &lt;code&gt;True&lt;/code&gt;로 설정해야한다. 다음 예시를 확인하자.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.randn(3, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([-1.0475, 0.2038, 0.2971], requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = x + 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([1.6828, 2.3467, 2.6648], grad_fn=&amp;lt;AddBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z = y * y * 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(z)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([1.5855, 2.3060, 2.3540], grad_fn=&amp;lt;MulBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z = z.mean()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(z)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor(8.9153, grad_fn=&amp;lt;MeanBackward0&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;x&lt;/code&gt; tensor 생성 시 &lt;code&gt;requires_grad&lt;/code&gt; 파라미터를 True로 설정할 경우, &lt;code&gt;x&lt;/code&gt;를 변수로 사용한 함숫값 &lt;code&gt;y&lt;/code&gt;, &lt;code&gt;z&lt;/code&gt; tensor에 &lt;code&gt;grad_fn&lt;/code&gt; 이라는 미분 함수가 내제되어있는 것을 확인할 수 있다. 이는 언급했던 연산자 그래프의 노드에 해당하며, 편미분 연산시에는 이러한 노드를 순차적으로 되돌아가며 결과값을 연산하게된다.&lt;/p&gt;
&lt;h3 id=&#34;backward-함수&#34;&gt;backward() 함수&lt;/h3&gt;
&lt;p&gt;앞선 예시에서 최종 함숫값인 &lt;code&gt;z&lt;/code&gt;에 다음과 같이 &lt;code&gt;backward&lt;/code&gt; 함수를 호출할 시, 역전파에 필요한 편미분값 $\frac{\delta z}{\delta x}$ 를 &lt;code&gt;x.grad&lt;/code&gt; 속성을 통해 확인할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z.backward() # dz/dx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x.grad)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([0.0160, 3.3650, 4.5153])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;이 경우에는 &lt;code&gt;z&lt;/code&gt;가 단일값이기 때문에 야코비 행렬이 그대로 리턴되었다. &lt;code&gt;z&lt;/code&gt;가 단일값이 아닌 벡터일때는 어떻게 해야할까? 결과값이 매트릭스이기 때문에 어떤 $z$값에 대한 편미분을 구해야 하는지가 명확하지 않다. 이러한 경우 앞선 예시에 사용된 벡터 $r$을 매개변수로 집어넣어야 한다. 다음 예시를 확인하자.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.randn(3, requires_grad=True)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = x + 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z = y * y * 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z.backward()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; RuntimeError: grad can be implicitly created only for scalar outputs.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; r = torch.tensor([1.0, 0, 0], dtype=torch.float32)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z.backward(r)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x.grad)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; tensor([5.0823, 0.0000, 0.0000])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;대부분의 경우 편미분 연산은 단일값인 손실함수 $L$에 대해 이루어지기 때문에 &lt;code&gt;backward&lt;/code&gt; 함수 사용 시 별도의 매개변수는 사용하지 않게된다. 관련 내용에 궁금증이 남는다면 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=hjnVLfvhN0Q&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;본 영상&lt;/a&gt;을 참고하자.&lt;/p&gt;
&lt;h2 id=&#34;참고-링크&#34;&gt;참고 링크&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=c36lUUr864M&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=c36lUUr864M&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=wG_nF1awSSY&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=wG_nF1awSSY&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>PyTorch Deep Learning - Tensor</title>
        <link>https://meme2515.github.io/neural_network/pytorch_1/</link>
        <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/neural_network/pytorch_1/</guid>
        <description>&lt;img src="https://meme2515.github.io/neural_network/images/pytorch.jpeg" alt="Featured image of post PyTorch Deep Learning - Tensor" /&gt;&lt;h2 id=&#34;소개&#34;&gt;소개&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;tensor&lt;/code&gt;란 &lt;code&gt;numpy&lt;/code&gt;와 유사하게 다차원 행렬을 다룰수있는 PyTorch 패키치의 자료구조다. 신경망 개론 수업에서 &lt;code&gt;numpy&lt;/code&gt; 패키지를 활용해 node와 weight, bias 등을 구현하고는 하는데 같은 개념의 연산을 &lt;strong&gt;GPU 등 적합한 하드웨어 자원을 통해 수행하고자 할때&lt;/strong&gt; &lt;code&gt;tensor&lt;/code&gt;를 이용하게 된다. Tensorflow 패키지 또한 동일한 개념과 이름을 가진 &lt;code&gt;tf.Tensor&lt;/code&gt;를 사용한다.&lt;/p&gt;
&lt;h2 id=&#34;tensor-생성&#34;&gt;Tensor 생성&lt;/h2&gt;
&lt;p&gt;값이 비어있는 tensor를 생성하기 위해서는 &lt;code&gt;torch.empty()&lt;/code&gt; 메소드를 다음과 같이 호출한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import torch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.empty(1) # scalar 생성
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x2 = torch.empty(3) # 1d vector 생성
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x3 = torch.empty(2, 3) # 2d matrix 생성
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x4 = torch.empty(2, 2, 3) # 3d matrix 생성
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;유사하게 0과 1 사이의 랜덤한 값이 부여된 tensor를 사용하기 위해서는 &lt;code&gt;torch.rand()&lt;/code&gt; 함수를, 0값의 경우 &lt;code&gt;torch.zeros()&lt;/code&gt; 함수를, 1값의 경우 &lt;code&gt;torch.ones()&lt;/code&gt; 함수를 차원값과 함께 호출한다 (&lt;code&gt;numpy&lt;/code&gt;와 유사하게 구성).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.rand(2, 2, 3)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;데이터-타입&#34;&gt;데이터 타입&lt;/h2&gt;
&lt;p&gt;별도로 데이터 타입을 지정하지 않은 경우 위 저장된 변수의 데이터 타입은 &lt;code&gt;torch.float32&lt;/code&gt;로 자동 지정된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.ones(2, 2, 3)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1.dtype) # output: torch.float32
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;다른 데이터 타입을 사용하고자 할 경우 &lt;code&gt;tensor&lt;/code&gt; 생성시 &lt;code&gt;dtype&lt;/code&gt; 매개변수로 다음과 같이 지정이 가능하다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.ones(2, 2, 3, dtype=torch.int)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1.dtype) # output: torch.int
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x2 = torch.ones(2, 2, 3, dtype=torch.double)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x2.dtype) # output: torch.double
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x3 = torch.ones(2, 2, 3, dtype=torch.float16)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x3.dtype) # output: torch.float16
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;행렬-구조-확인&#34;&gt;행렬 구조 확인&lt;/h2&gt;
&lt;p&gt;생성된 &lt;code&gt;tensor&lt;/code&gt;의 구조는 &lt;code&gt;size&lt;/code&gt; 함수를 통해 확인이 가능하다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.ones(2, 2, dtype=torch.int)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1.size) # output: torch.Size([2, 2])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;불러오기-기능&#34;&gt;불러오기 기능&lt;/h2&gt;
&lt;h3 id=&#34;python-list&#34;&gt;Python List&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;numpy&lt;/code&gt; 패키지의 &lt;code&gt;np.array&lt;/code&gt; 함수와 동일하게 행렬구조를 가진 파이썬 &lt;code&gt;list&lt;/code&gt; 로부터 &lt;code&gt;tensor&lt;/code&gt; 생성을 지원한다. &lt;code&gt;torch.tensor()&lt;/code&gt; 함수의 매개변수로 &lt;code&gt;list&lt;/code&gt; 를 넣어주는 일반적인 구조다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;numpy-array&#34;&gt;Numpy Array&lt;/h3&gt;
&lt;p&gt;자연스럽게 &lt;code&gt;numpy.array&lt;/code&gt; 를 활용한 &lt;code&gt;tensor&lt;/code&gt; 생성 또한 &lt;code&gt;torch.from_numpy()&lt;/code&gt; 함수를 통해 다음과 같이 지원한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import numpy as np
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1_np = np.array([2,5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.from_numpy(x1_np)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;반대로 &lt;code&gt;tensor&lt;/code&gt; 에서 &lt;code&gt;numpy&lt;/code&gt; 로의 변환은 다음과 같이 수행한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1_np = x1.numpy()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;여기서 유의할 부분은 &lt;strong&gt;&lt;code&gt;tensor&lt;/code&gt; 의 메모리 위치가 GPU 가 아닌 CPU 일 경우, x1의 변형은 x1_np 에 그대로 반영&lt;/strong&gt;되게 된다는 점이다. 이는 위의 두개 예시 (&lt;code&gt;tensor&lt;/code&gt; -&amp;gt; &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;numpy&lt;/code&gt; -&amp;gt; &lt;code&gt;tensor&lt;/code&gt;)에 공통적으로 적용된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1_np = x1.numpy()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x1.add_(1)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x1_np) # output: [3.5, 1.1]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;CUDA 지원 하드웨어 가용이 가능한 경우, 다음 두가지 방식을 통해 &lt;code&gt;tensor&lt;/code&gt; 저장 위치를 GPU로 설정할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; if torch.cuda.is_available():
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    device = torch.device(&amp;#34;cuda&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x1 = torch.tensor([2.5, 0.1], device=device) # 1. 생성 시 GPU 메모리 가용
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x2 = torch.tensor([2.5, 0.1])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x2 = x2.to(device) # 2. 생성 후 GPU 메모리 가용
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x3 = x1 + x2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    x3 = x3.to(&amp;#34;cpu&amp;#34;) # CPU 메모리 가용
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;행렬-연산&#34;&gt;행렬 연산&lt;/h2&gt;
&lt;h3 id=&#34;일반적인-연산&#34;&gt;일반적인 연산&lt;/h3&gt;
&lt;p&gt;덧셈, 곱셈과 같은 기본적인 행렬 연산 방식또한 &lt;code&gt;numpy&lt;/code&gt;와 크게 다르지 않다. &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt; 등의 수학 기호, 또는 &lt;code&gt;torch.add()&lt;/code&gt;, &lt;code&gt;torch.mul()&lt;/code&gt; 등의 함수를 호출해 연산을 수행할 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;numpy&lt;/code&gt;와 동일하게 내적 연산을 위해서는 &lt;code&gt;torch.mul()&lt;/code&gt; 이 아닌 다른 함수를 호출한다. 이와 관련된 내용은 이후 글에서 언급할 예정.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 덧셈
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z1 = x + y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z2 = torch.add(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 뺄셈
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z3 = x - y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z4 = torch.sub(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 곱셈, element-wise
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z5 = x * y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z6 = torch.mul(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; # 나눗셈, element-wise
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z7 = x / y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; z8 = torch.div(x, y)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;바꿔치기-연산-in-place-operation&#34;&gt;바꿔치기 연산 (In-Place Operation)&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;torch&lt;/code&gt; 는 &lt;code&gt;.add_&lt;/code&gt;, &lt;code&gt;.sub_&lt;/code&gt; 등 &amp;lsquo;_&amp;rsquo; 접미사가 붙은 바꿔치기 연산 함수를 제공한다. 바꿔치기 라는 단어에서 유추 가능하듯 이는 &lt;strong&gt;타겟 변수의 값을 바꾸는 효과&lt;/strong&gt;를 가지게 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y = torch.rand(2, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y.add_(x) # y 변수의 값이 y + x 의 output으로 변경
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;슬라이싱&#34;&gt;슬라이싱&lt;/h2&gt;
&lt;p&gt;슬라이싱의 경우 또한 &lt;code&gt;numpy&lt;/code&gt; 패키지와 동일한 방법을 고수한다. 2차원 행렬구조의 경우 &lt;code&gt;x[i, j]&lt;/code&gt; 와 같은 포맷으로 &lt;code&gt;i&lt;/code&gt; 번째 로우, &lt;code&gt;j&lt;/code&gt; 번째 컬럼을 리턴하며, &lt;code&gt;x[i1:i2, j1:j2]&lt;/code&gt; 와 같이 범위 설정이 가능하다.&lt;/p&gt;
&lt;p&gt;유의가 필요한 부분은 1개의 값이 리턴될때 &lt;code&gt;tensor&lt;/code&gt; 오브젝트가 아닌 기입된 실제 값을 보고싶다면 &lt;code&gt;item()&lt;/code&gt; 함수를 별도로 호출해야 하며, 해당 함수는 &lt;code&gt;tensor&lt;/code&gt; 에 1개 값만 들어있을때 사용 가능하다는 점이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(5, 2)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[:, 0]) # 1번 컬럼 슬라이스
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[0, :]) # 1번 로우 슬라이스
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[1, 1]) # 2번 로우, 2번 컬럼 슬라이스 (tensor 형태 유지)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; print(x[1, 1]).item() # 2번 로우, 2번 값
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;행렬-구조-변경-reshaping&#34;&gt;행렬 구조 변경 (Reshaping)&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;np.reshape&lt;/code&gt;이 아닌 &lt;code&gt;view&lt;/code&gt; 함수를 이용하게 된다. 매개변수로 들어가는 &lt;strong&gt;차원의 element 수은 항상 input &lt;code&gt;tensor&lt;/code&gt;의 element 수와 같아야 하며&lt;/strong&gt; (예. (4, 4) -&amp;gt; (2, 8)), 마지막 숫자가 유추 가능한 경우 -1 으로 매개변수를 대체할 수 있다 (하단 예시 참조).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; x = torch.rand(4, 4)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y1 = x.view(16) # x.view(-1)와 동일
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; y2 = x.view(2, 8) # x.view(-1, 8)와 동일
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
