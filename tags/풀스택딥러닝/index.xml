<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>풀스택딥러닝 on Soon Hyung Kwon</title>
        <link>https://meme2515.github.io/tags/%ED%92%80%EC%8A%A4%ED%83%9D%EB%94%A5%EB%9F%AC%EB%8B%9D/</link>
        <description>Recent content in 풀스택딥러닝 on Soon Hyung Kwon</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 08 Dec 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://meme2515.github.io/tags/%ED%92%80%EC%8A%A4%ED%83%9D%EB%94%A5%EB%9F%AC%EB%8B%9D/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 8</title>
        <link>https://meme2515.github.io/mlops/fsdl_8/</link>
        <pubDate>Thu, 08 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_8/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_8_title.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 8" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=a54xH6nT4Sw&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-8-teams-and-pm/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1o2x8ywivp555__AEbLLI28BsiQmHobOh/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-is-this-hard&#34;&gt;Why is this hard?&lt;/h2&gt;
&lt;p&gt;제품을 만드는 과정은 다음과 같은 이유로 어렵고 험난하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;좋은 인력을 채용해야 한다.&lt;/li&gt;
&lt;li&gt;채용된 인력을 관리하고, 성장시켜야 한다.&lt;/li&gt;
&lt;li&gt;팀의 결과물들을 관리하고, 방향성을 맞춰야 한다.&lt;/li&gt;
&lt;li&gt;장기간 제품에 영향을 끼칠 기술적인 요소들을 적절히 선택해야 한다.&lt;/li&gt;
&lt;li&gt;리더십의 기대치를 관리해야 한다.&lt;/li&gt;
&lt;li&gt;필요 조건을 정의하고, 관련 인력에게 커뮤니케이션 해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;머신러닝은 이와 같은 과정을 더욱 어렵게 만든다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 관련 인력은 아직 시장에 많지 않고, 채용 비용이 비싼 편이다.&lt;/li&gt;
&lt;li&gt;ML 팀에는 상대적으로 다양한 롤 (role) 이 존재한다.&lt;/li&gt;
&lt;li&gt;대부분 프로젝트의 타임라인이 불명확하고, 실패 확률이 높다.&lt;/li&gt;
&lt;li&gt;분야가 빠르게 발전하고 있으며, ML 제품 관리는 어렵고 아직 체계가 확립되지 않았다.&lt;/li&gt;
&lt;li&gt;리더십은 대게 ML 기술을 깊게 이해하지 못한다.&lt;/li&gt;
&lt;li&gt;비전문 인력이 ML 제품의 실패 원인을 파악하기 어렵다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;8주차 강의는 다음과 같은 내용을 담고있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 분야의 롤 (role) 과 롤 별 필요 전문성&lt;/li&gt;
&lt;li&gt;ML 엔지니어 채용 방식 (그리고 취업 방식)&lt;/li&gt;
&lt;li&gt;ML 팀의 구성 방식과 전체 조직과 협업하는 법&lt;/li&gt;
&lt;li&gt;ML 팀과 ML 제품을 운영하는 법&lt;/li&gt;
&lt;li&gt;ML 제품 기획 시 고려 요소&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;roles&#34;&gt;Roles&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;대표적인 롤&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Product Manager&lt;/strong&gt; : ML Product Manager 는 ML 팀, 비즈니스 영역, 제품 유저, 데이터 오너 간 협업하여 도큐먼트를 작성하고, 제품의 뼈대를 세우고, 계획을 수립하고, 그 중 작업의 우선순위를 정해 ML 프로젝트를 진행하는 역할을 맡는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MLOps/ML Platform Engineer&lt;/strong&gt; : 모델 배포 과정을 보다 쉽고 스케일링이 가능하도록 인프라를 설계하는 역할을 맡는다. 이후 AWS, GCP, Kafka, 혹은 다른 ML 툴을 활용해 배포된 제품의 인프라를 관리하는 역할을 수행.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Engineer&lt;/strong&gt; : 모델을 학습하고 배포하는 역할. TensorFlow, Docker 등의 툴을 활용해 예측 시스템을 실제 데이터에 적용한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Researcher&lt;/strong&gt; : 예측 모델을 학습하는 역할을 맡지만, 주로 최신 모델을 실험적인 환경에서 사용해보거나 이외 제품 적용이 시급하지 않은 문제를 다룬다. TensorFlow, PyTorch 등의 라이브러리를 노트북 환경에서 다루며, 실험 결과를 공유하는 역할을 맡는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Scientist&lt;/strong&gt; : 위에 설명된 모든 역할을 포괄하는 단어. 조직에 따라 비즈니스 문제에 대한 해결을 구하는 분석가 역할을 수행할 수도 있으며, SQL, Excel, Pandas, Sklearn 등의 다양한 툴을 다룬다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;필요한 스킬&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;이러한 롤들을 수행하기 위해선 어떤 스킬셋이 필요할까? 하단 차트는 이러한 롤들이 필요로 하는 스킬셋을 도식화 한다 - &lt;em&gt;수평축은 ML 전문성을, 동그라미 크기는 커뮤니케이션과 기술 문서 작성에 대한 스킬을 뜻함&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MLOps&lt;/strong&gt; 란 기본적으로 소프트웨어 엔지리어링 롤이며, 기존의 소프트웨어 엔지니어링 파이프라인에 대한 이해가 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Engineer&lt;/strong&gt; 는 ML 과 소프트웨어 개발 기술에 대한 지식을 모두 요구한다. 이러한 요구조건은 시장에 흔하지 않으며, 상당한 self-study 를 거친 엔지니어, 혹은 소프트웨어 엔지니어로 근무하는 과학/엔지니어링 분야 박사 학위자가 적합.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Researcher&lt;/strong&gt; 는 컴퓨터 공학, 통계학 등의 석/박사 학위를 소지하고 있는 ML 전문가가 적합하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML Product Manager&lt;/strong&gt; 는 기존의 Product Manager 의 역할과 크게 다르지 않지만, ML 제품 개발 과정과 관련 지식에 능통해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Scientist&lt;/strong&gt; 란 학사 학위자 부터 박사 학위자 까지 다양한 배경을 가질 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;버클리 EECS 박사 과정을 밟고 있는 &lt;a class=&#34;link&#34; href=&#34;https://www.shreya-shankar.com/phd-year-one/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Shreya Shankar 가 게시한 글&lt;/a&gt;에 따르면, &lt;strong&gt;ML 엔지니어는 Task ML 엔지니어, Platform ML 엔지니어&lt;/strong&gt;로 세분화해 구분할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Task ML Engineer&lt;/strong&gt; 는 구체적인 ML 파이프라인을 관리하는 역할을 맡는다. 이러한 ML 파이프라인이 정상적으로 작동하는지, 주기적인 업데이트가 이루어지는지 등을 확인하며, 대체로 업무량이 많은 편.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Platform ML Engineer&lt;/strong&gt; 는 다른 ML Engineer 들이 수행하는 반복적인 작업들을 자동화 하는 업무를 맡는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hiring&#34;&gt;Hiring&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI 역량 갭&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;FSDL 이 처음 시작된 2018 년의 경우 채용시장에서 AI 기술을 이해하는 인력을 찾기는 어려운 일이었다. 따라서 기업 내 AI 활용의 가장 큰 걸림돌은 인력 확보 문제였다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2022년 현재, 이러한 채용시장 내 AI 역량에 대한 수요/공급 간 불균형은 여전히 존재하지만, 4년간 이루어진 관련 인력들의 커리어 전환, 이미 ML 수업을 수강한 학부생들의 시장 유입으로 어느 정도 해소된 면이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 아직 시장에는 ML 이 어떻게 실패하고, ML 제품을 성공적으로 배포하는 방법을 아는 인력이 부족하다. 특히 &lt;strong&gt;제품 배포 경험&lt;/strong&gt;을 가진 인력에 대한 품귀 현상이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;채용 소스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이렇듯 작은 인력 풀과 급성장하는 수요로 인해 ML 직군 채용은 어려운 편이다. MLOps, Data Engineer, Product Manager 와 같은 롤은 많은 ML 지식을 요구하지 않기 때문에, 본 섹션에서는 코어 ML 직군에 대한 채용 방법을 설명한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;위와 같은 완벽한, 그리고 비현실적인 JD 를 통한 채용은 잘못된 방식이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이보다는 소프트 엔지니어링 스킬셋을 갖춘 후보 중 ML 분야에 대한 관심이 있고, 배우고자 하는 인력을 추리는 편이 낫다. 기본적인 개발 역량이 있다면 ML 은 충분히 학습 가능한 영역이다.&lt;/li&gt;
&lt;li&gt;주니어 레벨의 채용 또한 고려해 볼 수 있다. 최근 졸업생등은 ML 지식을 상당 수준 가지고 있는 편.&lt;/li&gt;
&lt;li&gt;필요한 시킬셋이 무엇인지 가능한 자세히 기술하는 편이 좋다. DevOps 부터 알고리즘 개발까지 모든 ML 개발 과정에 능통한 인력을 찾기란 불가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML Researcher 를 채용하기 위해 강사진은 다음과 같은 팁을 제시한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;논문의 양보다는 질을 검토할 것. 아이디어의 독창성, 수행 방식 또한 면밀히 검증.&lt;/li&gt;
&lt;li&gt;트렌디한 문제보다 본질적인 문제에 집중하는 연구자를 우선 채용할 것.&lt;/li&gt;
&lt;li&gt;학계 밖에서의 경험은 비즈니스 환경 적응에 도움이 되기 때문에 이 또한 중요하다.&lt;/li&gt;
&lt;li&gt;박사 학위가 없거나, 유사 분야인 물리학, 통계학 등을 공부한 인력 또한 진중하게 검토할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 지원자를 찾기 위해서는 다음과 같은 경로를 시도할 것.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LinkedIn, 리크루터, 캠퍼스 방문 등 기존 채용 경로 검토.&lt;/li&gt;
&lt;li&gt;ArXiv, 유명 컨퍼런스 등을 모니터링하고, 마음에 드는 논문의 1 저자 플래그.&lt;/li&gt;
&lt;li&gt;좋아하는 논문을 누군가 수준있게 구현한 경우 플래그.&lt;/li&gt;
&lt;li&gt;NeurIPS, ICML, ICLR 등 ML 컨퍼런스 참석.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;리크루팅을 진행하면서 지원자들이 회사에 바라는 바를 파악하고, 이에 맞춰 회사를 포지셔닝 하는 과정이 필요하다. ML 전문가들은 흥미로운 데이터를 기반으로 영향력있는 일을 하고 싶어하기 때문에 배움과 영향력을 지향하는 문화를 만들고, 이를 통해 좋은 인력이 지원할 동기를 만들어 주어야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 지원자를 모으기 위해선 채용을 진행중인 팀이 어떻게 우수하고, 미션이 어떻게 의미있는지에 대한 적극적이고 구체적인 설명이 곁들여져야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;인터뷰&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지원자를 인터뷰 할 때는, &lt;strong&gt;지원자의 강점은 재확인하고, 약점은 최소 기준점을 충족하는지 확인&lt;/strong&gt;하자. ML Researcher 의 경우 새로운 ML 프로젝트에 대해 창의적으로 생각할 수 있는지 검증이 필요하지만, 코드 퀄리티의 경우 최소한의 요건만 충족하면 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 인터뷰는 기존 소프트웨어 엔지니어링 인터뷰에 비해 덜 성숙한 분야이다. Chip Huyen 의 &lt;a class=&#34;link&#34; href=&#34;https://huyenchip.com/ml-interviews-book/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;strong&gt;Introduction to ML Inteviews Book&lt;/strong&gt;&lt;/a&gt; 과 같은 레퍼런스를 참조.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;organizations&#34;&gt;Organizations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ML 팀의 구성이란 아직 정답이 존재하지 않는 영역이다. 하지만 조직 내 ML 활용 특성과 성숙도에 따라 존재하는 best practice 는 다음과 같이 정리할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 1 - 초기단계 혹은 Ad-Hoc 성 ML&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;사실상 조직 내 ML 활용이 없으며, 필요시 단발성 프로젝트가 진행되는 경우. 인하우스 ML 전문성은 매우 낮은 편이다.&lt;/li&gt;
&lt;li&gt;중소규모의 비즈니스이거나, 교육, 물류 등 상대적으로 IT 중요도가 낮은 분야일 것.&lt;/li&gt;
&lt;li&gt;ML 적용으로 인한 단기적 이점이 상당히 적은 편.&lt;/li&gt;
&lt;li&gt;ML 프로젝트에 대한 지원이 적으며, 좋은 인력을 채용하고 유지하는 것에 상당한 어려움이 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 2 - ML R&amp;amp;D&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;조직 내 대부분의 ML 관련 업무가 R&amp;amp;D 에 치중되어 있는 경우. 대부분의 채용이 논문 작성 경험이 있는 ML Researcher, 박사 학위자를 대상으로 한다.&lt;/li&gt;
&lt;li&gt;에너지, 제조, 통신 등의 분야에서 규모가 큰 회사일 가능성이 높다.&lt;/li&gt;
&lt;li&gt;경험이 많은 연구 인력 채용을 통해 long-term 비즈니스 문제를 해결할 역량을 가지고 있다.&lt;/li&gt;
&lt;li&gt;하지만 질좋은 데이터 확보가 어려우며, 연구에서 실제 비즈니스 가치를 가진 제품 개발까지의 과정이 잘 이루어지지 않는다. 따라서 투자 규모 또한 작은 편.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 3 - 비즈니스 &amp;amp; 제품 팀 내 적극적인 활용&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;특정한 제품이나, 사업 영역에 속한 소프트웨어, 분석 인력이 이미 ML 전문성을 확보하고 있는 경우이다. 이러한 ML 인력은 소속된 팀의 엔지니어링/기술 담당자에게 보고하는 구조를 가진다.&lt;/li&gt;
&lt;li&gt;IT 회사이거나, 금융 회사일 가능성이 높다.&lt;/li&gt;
&lt;li&gt;이러한 경우 ML 제품 개선은 직접적인 비즈니스 가치를 준다. 또한 아이디어 제시와 제품 개선 간 밀접한 피드백 사이클 또한 존재.&lt;/li&gt;
&lt;li&gt;하지만 높은 수준의 인력을 채용하는 것은 여전히 어렵고, 연산 자원이나 데이터 등을 확보하는 것에 많이 시간이 소요될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 4 - 독립적인 ML 기능&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 부서가 별도 조직으로 구성되어, senior management 에게 직접 보고하는 경우. ML Product Manager 가 연구자, 엔지니어와 협업해 클라이언트가 사용하는 제품을 개발하며, 장기적인 연구 또한 진행한다.&lt;/li&gt;
&lt;li&gt;규모가 큰 금융 회사일 가능성이 높음.&lt;/li&gt;
&lt;li&gt;수준높은 인력을 보유하고 있기 때문에 추가적인 인력 소싱이 쉬운 편이다. 데이터와 연산 자원이 수월하게 배분되며, ML 개발과 관련된 여러 문화와 규율을 형성할 조건이 마련된다.&lt;/li&gt;
&lt;li&gt;하지만 사업 영역에 따라 ML 활용에 대한 이점을 설득하거나, 모델에 대한 기초적인 내용을 교육하는 것에 많은 노력이 들 수 있다. 또 피드백 사이클 또한 빠르게 전개되지 못할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;타입 5 - ML 우선주의&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CEO 의 직접적인 투자가 이루어지며, 비즈니스 전반에서 관련 전문 인력이 빠른 성과를 내기위해 노력한다. 별도의 ML 조직은 난이도가 높고, 호흡이 긴 프로젝트를 주로 전담.&lt;/li&gt;
&lt;li&gt;규모가 큰 IT 회사, 또는 ML 분야 스타트업이 이에 해당한다.&lt;/li&gt;
&lt;li&gt;데이터 접근이 쉽고, ML 전문가가 선호할만한 문화/환경을 가지고 있다. 개발직군 또한 ML 에 대한 이해가 높기 때문에 개발 과정이 수월한 편.&lt;/li&gt;
&lt;li&gt;하지만 ML 관점의 생각을 비즈니스 전반에서 가지기는 어려우며, 현실적으로 구성되기 어려운 조직 환경.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;조직 구성 전략&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;자신의 조직의 상단의 5개 타입 중 어느 타입에 가장 가까운지에 따라 적절한 조직 구성 전략을 선택하는 과정이 필요하다. 강사진이 정리한 조직 구성 전략은 크게 다음과 같은 영역에서 정의된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Software Engineer vs. Research&lt;/strong&gt; : 소프트웨어와의 연동성을 위해 ML 팀이 어느 정도까지 관여하는가? 팀 내 소프트웨어 엔지니어링 역량은 어느 정도의 중요성을 가지는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Ownership&lt;/strong&gt; : 데이터 수집, 웨어하우징, 레이블링, 파이프라이닝 과정에서 ML 팀은 어느 정도의 권한을 가지는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model Ownership&lt;/strong&gt; : ML 팀은 개발된 모델의 배포까지를 담당하는가? 이렇게 배포된 모델은 누가 관리하는가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음 섹션은 조직 특성에 따른 구성 전략을 간단히 설명한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;조직이 &lt;strong&gt;ML R&amp;amp;D&lt;/strong&gt; 에 집중하는 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;개발 보다는 연구 역량이 더욱 중요시되기 때문에, 두 담당 영역간 협업 능력이 다소 저하될 수 있다.&lt;/li&gt;
&lt;li&gt;ML 팀은 데이터에 대한 권한을 가지지 않으며 데이터 엔지니어의 지원을 받지 않는다.&lt;/li&gt;
&lt;li&gt;사실상의 ML 제품화는 발생하지 않는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이미 &lt;strong&gt;제품 내 ML 활용&lt;/strong&gt;이 이루어지는 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;연구 보다는 개발 역량이 중요시되며, 연구직 또한 적절한 엔지니어링 역량을 보유해 연구 단계 이후 제품화를 감안해야 한다.&lt;/li&gt;
&lt;li&gt;데이터 관리와 생성에 대한 권한을 가지지 않는다. 데이터 엔지니어의 지원을 통해 데이터 파이프라인 구축.&lt;/li&gt;
&lt;li&gt;ML Engineer 들은 배포되는 모델에 대한 모든 권한을 가지게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;별도의 ML 조직&lt;/strong&gt;이 구성된 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모든 팀은 연구 &amp;amp; 개발 인력을 보유할 수 있으며, 팀 내 협업이 긴밀하게 이루어진다.&lt;/li&gt;
&lt;li&gt;데이터 거버넌스, 엔지니어링 관련 논의에서 보다 힘이 실린 의견표출이 가능하다.&lt;/li&gt;
&lt;li&gt;모델은 유저에게 배포되지만, 이를 관리하는 책임은 유지된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML 우선주의&lt;/strong&gt;가 존재하는 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;연구 분야에 중점이 있지만, 연구자들 또한 개발 인력과 긴밀히 협업한다.&lt;/li&gt;
&lt;li&gt;전사 데이터 인프라에 대한 권한을 소유하게 된다.&lt;/li&gt;
&lt;li&gt;배포된 모델에 대한 관리/운영 책임은 유저에게 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;managing&#34;&gt;Managing&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Managing ML teams is challenging&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 팀 운영이 어려운 이유로는 다음과 같은 4가지를 들 수 있다.
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;공수 예측&lt;/strong&gt; : ML 프로젝트란 착수 전 난이도를 측정하기 애매한 측면이 존재한다. 데이터를 조회하고, 여러 모델을 적용해보며 새로 습득해야 하는 정보가 무궁무진하며, 이는 프로젝트 타임라인 설정에 차질을 줄 여지가 많다. 또한 어떠한 모델이 잘 작동할지 사전에 파악하는 것은 불가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;비선형적인 업무 진전도&lt;/strong&gt; : Weights and Biases 의 CEO 인 Lukas Biewald 가 쓴 &lt;a class=&#34;link&#34; href=&#34;https://medium.com/@l2k/why-are-machine-learning-projects-so-hard-to-manage-8e9b9cf49641&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 블로그 포스트&lt;/a&gt;에 의하면, ML 프로젝트의 진전 상황과 무관하게 앞으로의 상황을 예측하기 어려운 경우가 많다 &lt;em&gt;(상단 그래프 참조)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;문화 차이&lt;/strong&gt; : 엔지니어링과 연구 분야는 서로 크게 다른 문화를 형성하고 있다. 연구 분야는 새롭고, 독창적인 생각을 선호하는 반면, 엔지니어링 분야는 검증된 방법을 선호하기 때문. 이로 인해 ML 조직은 빈번하게 문화 충돌로 인한 갈등을 경험하며, 이와 같은 갈등은 제대로 다뤄지지 않을 시 조직 운영에 치명적인 결과를 초래할 수 있다. 따라서 ML 조직 운영의 주요 과제 중 하나는 ML, 소프트웨어 엔지니어링 분야 간 협업을 이끌어 내는 부분이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;리더십의 도메인 이해 결여&lt;/strong&gt; : 조직의 리더십이 ML 기술을 구체적으로 이해하고 있는 경우는 흔치않다. 따라서 기술을 한계를 명확하게 전달하고, 올바른 기대치를 심어주는 과정에 어려움이 따를 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How to manage ML teams better&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 조직의 관리는 아직 체계가 확립되지 않은 분야지만, 다음과 같은 노력을 통해 개선이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;확률적 계획 수립&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;대부분의 ML 프로젝트는 단계적인 태스크를 명확하게 정의한 후 시작한다. 하지만 이와 같은 엔지니어링적 접근 보다는, 각 태스크에 대한 성공 확률을 부여해 ML 프로젝트는 근본적인 실험성을 동반한다는 점을 사전에 인지하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;다양한 접근 방법 구비&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;제품 개발 계획을 세우는 단계에서 한 개 방법의 성공에 의존하는 것은 위험하기 때문에, 가능한 많은 아이디어와 접근 방법을 포용해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;아웃풋 보다는 인풋을 기반으로한 업무 평가&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;여러 방법을 수행하면서, 성공 여부를 기반으로 팀원의 기여도를 측정하는 것은 적절치 않다. 이와 같은 방법의 평가는 안전하고, 검증된 접근법만을 독려해 전반적인 팀의 상상력, 독창성을 저해할 수 있기 때문. ML 제품의 성공을 위해서는 새로운 아이디어를 높은 수준으로 검증하는 과정이 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;연구자, 엔지니어 간 협업&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;엔지니어링과 연구 부서 간 협업은 수준있는 ML 제품 개발을 위해 필수적이다. 따라서 이들 그룹 간 협업을 독려하고, 이끌 필요가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;빠른 성과 추구&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이와 같은 방법은 리더십에게 프로젝트의 진전도를 보다 효과적이고, 명료하게 전달할 수 있도록 하며, 장기적으로 ML 프로젝트가 성공하는데 도움을 준다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;불확실성에 대한 리더십의 충분한 이해&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;조직의 리더는 타임라인 상 위험요소에 대해 명확하게 이해하고 (understanding timeline risk), 불확실성을 해소할 책임이 있기 때문에 (addressing blind spots) ML 개발의 본질적인 불확실성을 전달하는 과정에서 어려움이 따를 수 있다. 하지만 다음과 같은 접근을 통해 리더십의 ML 이해도를 높이는 것이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 영역에 한정된 KPI 를 지나치게 강조하는 것은 좋지 않은 방법이다 (예. F1 스코어를 0.2 개선해 모델 성능이 상당 부분 개선되었다 등의 코멘트).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대신, 조직 구성원 대부분이 이해할 수 있는 리스크/임팩트 설명을 곁들이는 편이 좋다 (예. 모델 개선으로 인해 약 10% 전환율 상승이 예상되나, 추가적인 demographic 요소를 참조해 지속적으로 성능을 평가하는 과정이 필요).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://a16z.com/2016/06/10/ai-deep-learning-machines/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this a16z primer&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://executive.berkeley.edu/programs/artificial-intelligence&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this class from Prof. Pieter Abbeel&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://pair.withgoogle.com/guidebook&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this Google&amp;rsquo;s People + AI guidebook&lt;/a&gt;&lt;/strong&gt; 등의 리소스 공유를 통해 리더십의 ML 관련 이해도 제고.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ML PMs are well-positioned to educate the organization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML Product Manager 직군은 크게 두 개 타입으로 구분 가능하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Task PM :&lt;/strong&gt; 보다 일반적인 ML PM 모습에 가깝다. 특정 분야에 전문성을 가지고 있고 (예. 안전 정책) 관련해 세부적인 유즈케이스에 많은 경험을 가지고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Platform PM :&lt;/strong&gt; 최근 등장한 PM 직군 형태. Task PM 보다 넓은 영역에서 (우선순위 설정, 워크플로우 관리 등) ML 팀을 지원할 책임을 가지고 있다. ML 에 대한 보다 넓은 이해를 가지고 있고, 조직 전반에 걸쳐 ML 이해도를 높이고, 모델의 아웃풋을 신뢰할 수 있도록 돕는다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 제품의 성공을 위해서는 두 개 타입의 PM 모두 중요한 역할을 수행하며, 특히 Platform PM 은 조직 전반에서 ML 제품 영향력을 키우는 역할을 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What is &amp;ldquo;Agile&amp;rdquo; for ML?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Agile, 소프트웨어 간 관계는 다음 두가지 옵션과 ML 간 관계와 유사하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CRISP-DM, TDSP 모두 구조적이고, 데이터 사이언스 분야에 특화된 프로젝트 관리 방법론이다. 이들 모델을 활용해 프로젝트의 단계, 역할, 산출물 등을 통용/약속된 방식으로 정의할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TDSP&lt;/strong&gt; 는 보다 구조적이며, Agile 방법론에 대한 직접적인 대체제이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CRISP-DM&lt;/strong&gt; 은 보다 상위 레벨의 개념들을 다루며, 프로젝트 관리 체계의 정의가 약한 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;스케일이 큰 프로젝트 진행 시 이러한 프레임워크 적용을 고려해 볼 수 있지만, 그렇지 않은 경우 이를 강제할 필요는 없다. 이들 프레임워크가 머신러닝 보다는 전통적인 데이터 사이언스 문제를 기반으로 하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;design&#34;&gt;Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;대부분의 경우, ML 제품 기획에서 가장 어려운 부분은 제품 구현이 아닌 &lt;strong&gt;유저의 기대치와 실현 가능한 제품의 수준 간 격차를 좁히는 일&lt;/strong&gt;이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ML 시스템을 접한 유저는 대게 고도로 개발된, 실제 가능한 것보다 더 많은 문제를 풀 수 있는 시스템을 기대하기 마련이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;하지만 현실 세계의 ML 시스템이란 특정 작업을 위해 훈련된 강아지와 같다. 집중력에 한계가 존재하고, 학습 받지 않은 작업을 수행하기 어려워 하는 경우가 대부분이기 때문.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_title.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Keys to Good ML Product Design&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;유저는 제품 사용으로 얻을 수 있는 장점과 한계를 명확히 이해했을때 더 높은 만족도를 보인다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;AI-powered&amp;rdquo; 라는 캐치 프레이스를 사용하기 보다는, 실제 모델이 해결하는 문제에 집중할 것.&lt;/li&gt;
&lt;li&gt;시스템 설계를 사람과 같이 느껴지도록 구성하였다면, 유저가 이를 실제 사람과 같이 다룰 것으로 기대할 것.&lt;/li&gt;
&lt;li&gt;Amazon Alexa 와 같이 특정 상황에 ML 이 어떻게 대처할 것인지를 사전에 정의하는 것 또한 검토.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모델이 실행에 실패했을때를 대비한 백업 플랜을 준비할 것.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;지나친 자동화는 오히려 유저 경험의 질을 떨어트릴 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;피드백 룹 구축을 통한 지속적인 모델 개선으로 유저 경험을 개선할 것.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;실패 관리는 ML 시스템 유저의 만족도 제고를 위한 핵심적인 요소이다. 유저가 직접 잘못된 아웃풋을 수정하는 기능을 추가하거나, 특정 임계점을 넘은 경우에만 결과값을 보여주는 등의 Quality Assurance 체계가 필요하다 &lt;em&gt;(예. 페이스북이 사진에 포함된 얼굴을 기반으로 친구 태깅을 추천하지만, 직접적으로 수행하지는 않는 것과 같은 경우)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Types of User Feedback&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 문제 해결을 위해 &lt;strong&gt;유저의 피드백을 깊게 살필 필요&lt;/strong&gt;가 있으며, 피드백은 다음과 같이 구분 가능하다 &lt;em&gt;(x축이 모델 개선 과제 내 유용성, y축이 유저 난이도)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;간접적, 암시적 피드백 (indirect implicit feedback)&lt;/strong&gt; : 유저가 제품 구매 과정에서 이탈했는지 등의 정보.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;직접적, 암시적 피드백 (direct implicit feedback)&lt;/strong&gt; : 유저가 제품 구매 과정의 다음 단계로 이동했는지 등의 정보.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;이항적, 명시적 피드백 (binary explicit feedback)&lt;/strong&gt; : 좋아요/싫어요 등 제품 만족도를 두 개 옵션 중 하나로 특정하는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;범주적, 명시적 피드백 (categorical explicit feedback)&lt;/strong&gt; : 별점 등 제품 만족도를 여러개의 옵션 중 하나로 특정하는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;자유적 피드백 (free text feedback)&lt;/strong&gt; : 유저의 자유로운 텍스트 피드백.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델 보정 (model corrections)&lt;/strong&gt; : 유저의 직접적인 데이터 레이블링.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;이러한 피드백 체계를 구축할 때에는 유저의 이타심에 기대는 것 보다는, 피드백을 제공하는 것이 유저에게 어떤 가치를 제공하는지 적극적으로 설명하는 편이 낫다. 또한, 유저 피드백에 따른 모델 개선이 실제로 빠르고 직접적으로 작동할 수 있도록 구성되어야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 5</title>
        <link>https://meme2515.github.io/mlops/fsdl_5/</link>
        <pubDate>Mon, 05 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_5/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_5_9.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 5" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=W3hKjXg7fXM&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-5-deployment/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1ABdEgVHvOIBtJhfmzy5ps_dMrwFKlgwd/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배포 과정은 좋은 모델 개발에 있어 필수적인 요소이다. &lt;strong&gt;오프라인으로 모든 평가를 진행하면 모델의 작은 실수들을 놓치기 쉽고, 사용자가 정말 필요로 하는 문제 해결 능력이 부재할 수 있기 때문.&lt;/strong&gt; 이러한 요소는 모델 배포를 통해서만 검증이 가능한 경우가 많다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다른 ML 개발 단계와 같이 &lt;strong&gt;최소한의 기능만을 구현한 후, 복잡한 부분들을 순차적으로 추가&lt;/strong&gt;하는 과정을 거치는 편이 좋다. 과정은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프로토타입 설계&lt;/li&gt;
&lt;li&gt;모델/UI 분리&lt;/li&gt;
&lt;li&gt;스케일 문제 해결&lt;/li&gt;
&lt;li&gt;속도 이슈 발생 시, 엣지 디바이스 활용 검토&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;build-a-prototype-to-interact-with&#34;&gt;Build A Prototype To Interact With&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;프로토타입 설계를 위한 툴로는 최근 HuggingFace 가 인수한 &lt;a class=&#34;link&#34; href=&#34;https://gradio.app/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradio&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://streamlit.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Streamlit&lt;/a&gt; 등이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 프로토타입 설계를 위해서는 다음과 같은 기본적인 규칙을 지키자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;심플한 UI&lt;/strong&gt; : 프로토타입의 주된 목적은 실사용 환경에서 모델을 테스트해보고, 타인의 피드백을 얻는 것이다. Gradio, Streamlit 과 같은 앱을 활용하면 많은 코드를 쓰지 않더라도 기본적인 인터페이스 구축이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Web URL 활용&lt;/strong&gt; : URL 은 공유하기 쉬우며, 이를 기준점으로 삼아 더욱 복잡한 배포 방식을 택하면서 발생할 장단점을 생각할 수 있다. Streamlit, HuggingFace 모두 클라우드 배포 기능을 제공.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;공수 최소화&lt;/strong&gt; : 강사진은 프로토타입 설계에 하루 이상을 소비하지 않을 것을 권장.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 프로토타입은 최종 솔루션의 형태가 아니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프론트엔드 구현에 있어 분명한 한계점이 존재한다. 완성된 형태의 서비스 제공을 위해서는 커스텀 UI 제작이 필요.&lt;/li&gt;
&lt;li&gt;스케일링 문제를 안고있다. 유저 수가 증가하게 된다면 스케일업을 위해 백엔드 구축이 필요.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;상단 장표는 일반적인 어플리케이션의 구조를 보여준다. Client 란 유저가 상호작용하는 기기, 즉 브라우저, 차량, 스마트폰 등이며, 이러한 기기는 네트워킹을 통해 서버와 소통한다. 서버는 데이터베이스와의 상호 작용을 통해 어플리케이션을 구동.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이러한 기본적인 어플리케이션 구조에 ML 모델을 배포하는 여러가지 방법이 존재한다. 언급된 프로토타입 접근법은 &lt;strong&gt;model-in-service&lt;/strong&gt; 방식에 해당하며, 웹서버가 패키징된 모델을 품고있는 경우이다 &lt;em&gt;(인스타 등 이미 성숙도가 올라간 서비스에 ML 기능을 추가하는 형태로 생각하면 됨)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 방식의 가장 큰 장점은 모델의 복잡성과 무관하게 기존의 인프라를 사용할 수 있다는 점이다. 하지만 이러한 방식에는 여러가지 단점 또한 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;웹서버가 다른 언어로 작성.&lt;/strong&gt; 파이썬 기반이 아니라면, 이미 구축된 모델을 서버에 통합하는 과정이 까다로울 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델이 서버 코드보다 자주 업데이트 될 수 있음.&lt;/strong&gt; 어플리케이션이 이미 성숙 단계에 접어들었으나 모델이 초기 단계에 있다면, 모델 업데이트 마다 재배포 과정을 겪어야 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;웹서버에 비해 모델의 크기가 지나치게 클 수 있음.&lt;/strong&gt; 이러한 경우 모델을 직접적으로 사용하지 않더라도 전반적인 어플리케이션 사용 경험에 부정적인 영향이 미칠 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;서버 하드웨어는 ML 작업에 최적화되지 않음.&lt;/strong&gt; 이러한 서버 장비에 GPU 가 내장되어 있는 경우는 굉장히 드물다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링 속성의 차이가 발생할 수 있음.&lt;/strong&gt; 따라서 모델과 기존 어플리케이션 간 스케일링 규칙의 차등을 두어야 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;separate-your-model-from-your-ui&#34;&gt;Separate Your Model From Your UI&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;모델을 UI 에서 완전히 분리하는 방법은 크게 &lt;strong&gt;(1) Batch Prediction&lt;/strong&gt;, &lt;strong&gt;(2) Model-as-Service&lt;/strong&gt; 방식으로 나뉜다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 이란 모든 데이터 포인트에 대한 예측치를 사전에 구한 후, 결과값을 데이터베이스에 저장하는 방식&lt;/strong&gt;이다. 경우에 따라 가장 적절한 방식일 수 있는데, 인풋값이 제한된 경우 주기적으로 예측치를 구하는 것만으로 충분히 최신 정보가 반영된 예측치를 사용자에게 전달할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 방식이 적절한 예시는 초기단계의 추천 시스템, 내부 활용을 위한 마케팅 자동화 시스템 등.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주기적으로 예측값을 구하기 위해서는 데이터 처리 자동화 파이프라인 활용이 필요하다. (1) 데이터 처리, (2) 모델 로딩, (3) 예측, (4) 예측값 저장 순의 작업이 필요한데, Dagster, Airflow 등의 DAG 시스템이 처리하기에 적절한 문제이다. 유사한 ML 전용 툴인 &lt;a class=&#34;link&#34; href=&#34;https://metaflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Metaflow&lt;/a&gt; 또한 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;구현이 간단하다.&lt;/strong&gt; 이미 학습에 배치 처리 툴을 활용하고 있다면 이러한 구조를 재사용 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링이 쉽다.&lt;/strong&gt; 데이터베이스는 기본적으로 스케일링에 최적화 되어있는 시스템이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;대형 시스템에서 수년간 검증된 구조.&lt;/strong&gt; 이미 많은 기업들이 이와 같은 예측 파이프라인을 활용해왔고, 예상하지 못한 문제가 발생할 확률이 상대적으로 적다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치 전달이 빠름.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;경우의 수가 많은 인풋을 처리할 수 없음.&lt;/strong&gt; 모든 경우의 수에 대한 모든 예측치를 구하는 것에는 분명한 한계가 존재한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치가 가장 최신의 정보를 반영하지 못함.&lt;/strong&gt; 이러한 정보가 매분, 매초 의미있는 변화를 가진다면, 유저가 보는 예측치는 이미 유의미한 정보를 제공하지 못할 확률이 높다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batch Job 실행 실패를 감지하기 어려움.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 란 모델을 별도의 온라인 서비스로서 운영하는 방식이다.&lt;/strong&gt; 모델은 백엔드, 또는 클라이언트에서 송출한 request 에 대해 response 를 보내는 방식으로 소통하게된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;신뢰성.&lt;/strong&gt; 모델에서 발생한 버그가 전체 웹 어플리케이션을 다운시킬 확률이 감소하게 된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링.&lt;/strong&gt; 목적에 최적화된 하드웨어를 선택하고, 알맞은 방식으로 스케일링을 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;유연성.&lt;/strong&gt; 여러 어플리케이션이 모델 인프라를 공유할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;레이턴시.&lt;/strong&gt; 별도의 서비스인 만큼, 서버/클라이턴트가 모델을 사용할 때 시간적 비용이 발생.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;복잡한 인프라.&lt;/strong&gt; 구축/운영에 대한 새로운 비용이 발생함.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 단점들은 감안하더라도 &lt;strong&gt;model-as-service 구조는 대부분의 ML 제품 배포에 적합한 방식이다&lt;/strong&gt;. 복잡한 어플리케이션의 구조에서 모델 서비스를 개별적으로 스케일링 할 수 있다는 점은 중요하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5주차 강의에선 이러한 모델 서비스를 구축하기 위한 부분들을 설명한다. 이는 &lt;strong&gt;(1) Rest API, (2) 디펜던시 관리, (3) 성능 최적화, (4) 수평 스케일링, (5) 롤아웃&lt;/strong&gt; 등의 개념을 포함한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Rest APIs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 제품의 &lt;strong&gt;Rest API&lt;/strong&gt; 란 약속된 형태의 HTTP 요청에 따라 예측값을 반환하는 형태를 칭한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인프라에 호스팅된 대안적인 프로토콜은 &lt;a class=&#34;link&#34; href=&#34;https://grpc.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gRPC&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://graphql.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GraphQL&lt;/a&gt; &lt;em&gt;(모델 서비스에 적합하지 않을 수 있음)&lt;/em&gt; 이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;아직 모델 서비스 분야에선 Rest API 문법이 통일되지 않은 상태.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google Cloud 는 key, value 페어를 가진 리스트를 인풋으로 정의&lt;/li&gt;
&lt;li&gt;Azure 는 모델 구조에 따라 변동하는 데이터 오브젝트를 다룸&lt;/li&gt;
&lt;li&gt;AWS Sagemaker 는 Google Cloud 와 유사한 형태의 인풋을 기대하지만, 세부적인 형태의 차이 존재.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dependency Management (디펜던시 관리)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;예측값은 코드, 모델 가중치, 그리고 디펜던시에 따라 결정된다.&lt;/strong&gt; 따라서 기대하는 예측값을 얻기 위해서는 웹서버에 개발 환경과 동일한 디펜던시가 세팅되어야 하지만, 이를 항상 보장하는 것은 어려운 작업이다 &lt;em&gt;(개발 환경에서 혹여나 패키지 업데이트가 이루어진다면 서버에서 동일한 업데이트를 매번 진행해야 함, 개발자가 많아지면 관리가 어려워진다)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 디펜던시를 관리하는 방법은 크게 두가지가 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;디펜던시에 무관하게 실행 가능한, &lt;strong&gt;표준화된 모델 개발&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컨테이너 활용&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 모델 표준화&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;모델 표준화는 ONNX (Open Neural Network Exchange) 라이브러리를 활용해 이루어진다. 라이브러리는 &lt;strong&gt;환경에 무관하게 실행 가능한 ML 모델&lt;/strong&gt;을 개발할 수 있도록 돕는데, 언어, 패키지 버전 등과 무관하게 동일한 기능을 제공하는 것을 목표로 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 실사용 환경에선 많은 라이브러리들이 지나치게 빠른 속도로 업데이트되기 때문에 변환 과정에서 버그가 자주 발생하고, 이를 해결하기 위해 오히려 ONNX 를 사용하지 않는 것 보다 더 많은 작업이 발생하는 경우가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;또 torchvision 과 같은 주변 라이브러리는 아예 지원이 안되는 경우가 많다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 컨테이너&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;컨테이너를 설명하기 전, 우선 도커와 가상머신의 개념을 구분해 정리할 필요가 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;가상머신 (VM)&lt;/strong&gt; : &lt;strong&gt;라이브러리, 어플리케이션은 물론 운영체계 (OS) 까지를 하나의 패키지로 묶는 방식&lt;/strong&gt;이다. 용량은 물론 실행에 필요한 자원 소모가 큰 편.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;도커&lt;/strong&gt; : &lt;strong&gt;OS 를 적은 용량/자원으로 가상화하여, 필요한 라이브러리와 어플리케이션 만을 구동&lt;/strong&gt;하는 방식.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇듯 실행이 가벼운 도커는 일반적으로 구분 가능한 작업 마다 개별적으로 생성된다. 예시로 웹앱은 (1) 웹서버, (2) 데이터베이스, (3) Job 관리, (4) Worker 총 4개의 컨테이너가 함께 동작하는 방식으로 운영.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Job 관리 (Job Queue)&lt;/strong&gt; : Airflow, Rundeck 등의 Job Scheduler 에서 유지하는, 앞으로 실행할 Job 에 대한 데이터 구조.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Worker&lt;/strong&gt; : 요청한 태스크를 수행하는 자원 &lt;em&gt;(예. 주문 내역을 파싱 및 데이터베이스로 이동)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;도커 컨테이너는 &lt;strong&gt;도커 파일&lt;/strong&gt;을 통해 생성된다. 각 컨테이너는 서로 다른 도커 파일을 통해 환경을 생성하며, 클라우드나 별도 서버에 저장된 도커 허브를 통해 컨테이너를 공유하는 것 또한 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;도커는 다음과 같은 3가지 요소로 구성되어 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;클라이언트&lt;/strong&gt; : 도커 이미지 구성. 로컬 환경에서 여러 커맨드를 통해 조작이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;도커 호스트&lt;/strong&gt; : 클라이언트에서 입력된 커맨드 실행 및 이미지/컨테이너 생성. 서버 혹은 로컬 환경 모두 구성이 가능함.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;레지스트리&lt;/strong&gt; : 여러 개의 컨테이너 저장. 도커 호스트와 직접 소통.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이와 같은 태스크 분리를 통해 노트북 등의 로컬 자원, 도커 호스트에 저장된 이미지에 등에 의해 도커 활용에 제약이 가해지지 않는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;공개된 여러 퍼블릭 도커 허브엔 다양한 이미지가 호스팅 되어 있으며, 프라이빗 이미지를 저장할 수 있는 기능 또한 제공하고 있다. 최근엔 그 인기가 급상승해 이렇나 도커 허브 활용을 기본 전제로 하는 경우가 잦은 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;도커는 입문 난이도가 다소 높은 편이다. &lt;a class=&#34;link&#34; href=&#34;https://github.com/replicate/cog&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cog&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/bentoml/BentoML&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BentoML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/trussworks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Truss&lt;/a&gt; 와 같은 서비스는 이러한 과정을 간소화 해주며 지정된 모델 호스트 활용, 모델 패키징 등 다양한 기능을 제공한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance Optimization (성능 최적화)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;예측 연산을 효율화하기 위해선 &lt;strong&gt;GPU, concurrency (여러 모델 활용), model distillation (모델 간소화), quantization (파라미터 용량 제한), caching (캐싱), batching (배치 관리), GPU sharing, 관련 라이브러리들&lt;/strong&gt;을 논할 필요가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. GPU&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;호스트 서버에 GPU 자원을 포함시키는 것에서 얻는 장점은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학습이 이루어진 것과 같은 환경에서 예측이 이루어진다면 &lt;strong&gt;환경 관련 이슈가 발생할 염려가 없다&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;많은 트래픽을 더욱 빨리 처리할 수 있다&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 &lt;strong&gt;GPU 자원은 세팅이 보다 어렵고, 트래픽에 의한 비용폭이 크기 때문에 CPU 만을 활용한 초기 모델 서비스 또한 고려해봄직 하다&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하기 테크닉을 통해 보다 적은 비용으로 CPU 자원에서 연산 속도를 개선하는 것 또한 가능함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Concurrency&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;여러개의 CPU, 또는 CPU 코어에서 복수의 모델을 실행하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Thread Tuning&lt;/strong&gt; 과정이 필요하며, 이와 같은 테크닉을 통해 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Nw77sEAn_Js&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;로블록스&lt;/a&gt;는 일일 10억 리퀘스트에 대한 BERT 서비스를 CPU 자원만으로 해결.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. Model Distillation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;학습된 모델의 행동을 모방하는 작은 규모의 모델을 생성하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://heartbeat.comet.ml/research-guide-model-distillation-techniques-for-deep-learning-4a100801c0eb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 글&lt;/a&gt; 에서 관련된 테크닉을 소개하고 있으며, 직접 구현시 성능이 다소 떨어질 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;서비스 환경에서 자주 활용되지는 않지만, &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/transformers/model_doc/distilbert&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistilBERT&lt;/a&gt; 와 같은 예외 경우 또한 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4. Quantization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;모델 전체, 또는 일부분을 보다 작은 용량의 number representation 을 활용해 실행하는 방식이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대게 활용되는 representation 으로는 16-bit floating point, 8-bit integer 가 있으며, 모델 정확도에 부정적인 영향을 끼치게 된다. 속도 개선이 정확도 보다 중요하다고 판단되면 고려할 수 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PyTorch, Tensorflow 등의 패키지는 자체 quantization 라이브러리를 포함하고 있으며, Huggingface 의 사전학습 모델 활용 시 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/optimum/index&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huggingface Optimum&lt;/a&gt; 또한 활용이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습 시 quantization 과정을 감안한 &lt;strong&gt;quantization-aware training&lt;/strong&gt; 이라는 테크닉이 존재하고, 적은 용량으로 representation 변경 시 보다 개선된 정확도를 보인다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5. Caching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;자주 처리되는 인풋을 캐시에 미리 저장해둠으로 처리 속도를 개선시키는 방식. 자원 활용이 큰 연산을 수행하기 전에 인풋이 캐시에 존재하는지 먼저 확인한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;캐싱에는 다양한 방식이 존재하지만, &lt;a class=&#34;link&#34; href=&#34;https://docs.python.org/3/library/functools.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python functools 라이브러리&lt;/a&gt;를 활용하는 것을 추천.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. Batching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배치 처리 시 연산 속도가 개선된다는 점을 활용해 (특히 GPU 활용 시) 일정 수만큼의 인풋을 저장 후 처리하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인풋을 모으는 기간 동안 유저가 레이턴시를 경험할 수 있기 때문에 배치 사이즈 조절이 필요하다. 레이턴시가 너무 길어진다면 이를 별도로 처리해야하며, 구현이 복잡하기 때문에 라이브러리 등을 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;7. GPU Sharing&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;단일 GPU 에 여러개의 모델을 구동시키는 것 또한 가능하다. GPU sharing 기능을 지원하는 패키지 활용.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;8. 라이브러리&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyTorch, Tensorflow, NVIDIA, Ray Serve 등의 옵션이 있다. NVIDIA 쪽이 가장 좋은 성능을 보여주지만 입문장벽이 있는 편이고, &lt;a class=&#34;link&#34; href=&#34;https://docs.ray.io/en/latest/serve/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ray Serve&lt;/a&gt; 의 경우 비교적 난이도가 쉬운 편.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Horizontal Scaling (수평 스케일링)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;트래픽이 증가할 수록 단일 서버보다는 여러대의 서버에서 복제된 모델을 운영할 필요가 생긴다. 이를 &lt;strong&gt;수평 스케일링&lt;/strong&gt;이라 부르며, 한대의 서버에서 처리했을 트래픽을 여러개의 서버로 분산하는 작업을 필요로한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;각 서버엔 서비스되는 모델의 복제본이 저장 되어있으며, &lt;a class=&#34;link&#34; href=&#34;https://www.nginx.com/resources/glossary/nginx/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;nginx&lt;/a&gt; 와 같은 load balancer 라는 툴을 이용해 분산된 트래픽을 처리한다. 모델 서비스의 경우 이를 구현하는 방식으로는 크게 &lt;strong&gt;container orchestration 와 serverless&lt;/strong&gt; 가 존재한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. Container Orchestration&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes&lt;/a&gt; 를 활용해 다수의 도커 컨테이너를 여러대의 서버에서 분산처리 할 수 있도록 돕는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단순히 모델 배포가 목적이라면 굳이 Kubernetes 를 활용할 필요는 없다. &lt;a class=&#34;link&#34; href=&#34;https://www.kubeflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubeflow&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.seldon.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Seldon&lt;/a&gt; 등 관련 작업을 간소화 하는 옵션이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Serverless&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;어플리케이션을 구성하는 코드와 환경을 zip 파일, 또는 도커 컨테이너로 압축한 후 하나의 함수 (model.predict() 등) 를 통해 예측치를 연산하도록 구성.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이와 같이 패키징 된 모델은 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/lambda/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Lambda&lt;/a&gt; 와 같은 서비스를 통해 배포되며, 인프라와 관련된 모든 작업은 클라우드에서 자동적으로 처리된다 &lt;em&gt;(증가한 트래픽에 따른 스케일링 등)&lt;/em&gt;. 유저 입장에서는 제때 비용만 정산하면 됨.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;구체적인 이유로 Kubernetes 를 활용하는 것이 아니라면, Serverless 로 배포를 시작하는 편이 좋다. 단점은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;배포 패키지의 사이즈 제한이 존재한다.&lt;/strong&gt; 용량이 큰 모델은 이와 같은 방식으로 배포가 어려운 편.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;트래픽 미발생으로 서버가 닫혀있는 상태에서 다시 예측치를 내기 까지의 시간 소요가 길다.&lt;/strong&gt; 이를 cold start 문제라 부르며, 초단위에서 분단위 까지의 시간을 필요로 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;파이프라인 등 복잡한 소프트웨어 기능 구현이 어렵다.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;서버 상태 모니터링과 별도 배포 툴 적용이 어렵다.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Serverless 환경은 대체로 GPU 를 포함하지 않으며, 실행 시간에 제한을 둔다.&lt;/strong&gt; 보다 작은 규모의 &lt;a class=&#34;link&#34; href=&#34;https://www.banana.dev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Banana&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.pipeline.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Piepeline&lt;/a&gt; 과 같은 스타트업들은 GPU 를 활용한 서버리스를 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model Rollouts (롤아웃)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이미 배포된 상태의 모델을 업데이트하고, 관리하는 과정을 의미한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;새로운 모델을 효율적으로 배포 하기 위해서는 다음과 같은 배포 방식이 모두 가능해야 한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;점진적 배포&lt;/strong&gt; : 기존 배포 버전에서 새로운 배포 버전으로 트래픽 양을 점진적으로 증가.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;즉각적 배포&lt;/strong&gt; : 문제가 발생한 배포 버전에서 새로운 배포 버전으로 즉각적인 변경.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;배포 버전 관리&lt;/strong&gt; : 두 개의 배포 버전을 두고 트래픽 배분.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;파이프라인 배포&lt;/strong&gt; : 개발된 파이프라인 플로우를 모델과 함께 배포.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 기능들은 직접 구현이 어려우며, 일반적으로 managed service 를 통해 모델 배포에 적용하게 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Managed Options&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_18.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;클라우드 3사 모두 배포 과정을 간소화하는 managed service option 기능을 제공하며, BentoML, Banana 등의 스타트업 또한 관련 기능을 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;가장 인지도 있는 서비스는 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/sagemaker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Sagemaker&lt;/a&gt; 이다. Huggingface class, SciKit-Learn model 등 일반적인 형태의 모델의 경우 적용이 쉬운 편이다. 하지만 일반적인 EC2 인스턴스에 비해 50~100% 가량 비용이 비쌈.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;move-to-the-edge&#34;&gt;Move To The Edge?&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_19.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;웹에서 벗어나 클라이언트 기기 (엣지 디바이스) 내에서 모델 예측을 구현하는 방식 또한 고려해 볼 수 있다. 인터넷 액세스가 불안정한 환경이거나, 민감한 개인정보를 다룰 경우 엣지 디바이스 활용은 필수적.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;엣지 디바이스 활용을 필수적으로 요구하는 환경이 아니라면, 모델의 정확도와 레이턴시 간 유저 경험에 더 중요한 요소를 선택해야한다. &lt;strong&gt;레이턴시를 줄일 수 있는 모든 옵션이 이미 적용되었다면, 엣지 디바이스 활용을 고려할 것&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;엣지 디바이스 inference 는 구현이 복잡하기 때문에 반드시 필요한 경우에만 적용해야 한다. 서버에서 학습된 모델 가중치를 엣지 기기에 불러온 후, 이후 모든 예측 과정을 엣지 기기에서 수행하는 방식으로 진행.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대표적인 장점은 레이턴시 감소이다. 네트워크를 사용할 필요가 없으며, 트래픽에 의한 비용이 발생하지 않는다. 이에 반한 단점은 하드웨어와 소프트웨어의 제약이다. 모델 업데이트 또한 과정이 보다 복잡해지는 문제가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Frameworks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;엣지 배포에 필요한 적절한 프레임워크는 학습 과정과 엣지 기기에 따라 달라질 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developer.nvidia.com/tensorrt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorRT&lt;/a&gt;&lt;/strong&gt; : 엣지 기기가 NVIDIA 하드웨어라면 가장 적절&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developers.google.com/ml-kit&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLKit&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developer.apple.com/documentation/coreml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CoreML&lt;/a&gt;&lt;/strong&gt; : Android, 혹은 iPhone 을 대상으로 한다면 공식 프레임워크 검토&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/mobile/home/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Mobile&lt;/a&gt;&lt;/strong&gt; : iOS 와 Android 환경을 모두 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/lite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TFLite&lt;/a&gt;&lt;/strong&gt; : 핸드폰과 같은 일반적인 기기가 아닌 경우 또한 TF 사용 환경을 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/js&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorFlow JS&lt;/a&gt;&lt;/strong&gt; : 브라우저 배포 전용 프레임워크&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://tvm.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache TVM&lt;/a&gt;&lt;/strong&gt; : 라이브러리, 타깃 기기와 무관하게 활용 가능. 가능한 많은 환경을 지원하고자 한다면 적절함&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외에도 &lt;a class=&#34;link&#34; href=&#34;https://mlir.llvm.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLIR&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://octoml.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OctoML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.tinyml.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TinyML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.modular.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Modular&lt;/a&gt; 과 같은 제품군이 존재함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;엣지 기기의 하드웨어 제약을 뛰어넘는 용량을 가진 모델의 경우, 프레임워크와 무관하게 배포는 불가능하다고 보아야한다. 때문에 가능한 적은 용량과 연산 자원을 사용하면서 최대의 성능을 이끌어내는 모델 구조가 중요.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Quantization, Distillation 등의 기법 또한 활용 가능하나, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MobileNets&lt;/a&gt;&lt;/strong&gt; 와 같이 엣지 기기를 사전에 염두한 모델 구조 또한 존재한다. 모델 성능이 감소하나 많은 경우 실사용에 지장이 없다. 이와 결이 유사한 모델로는 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/huggingface/distilbert-8cf3380435b5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistilBERT&lt;/a&gt;&lt;/strong&gt; 가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mindsets&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;엣지 배포를 검토할 시 다음과 같은 사항을 고려하는 편이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;모델 구조가 아닌 엣지 기기의 환경에 집중할 것.&lt;/strong&gt; 성능이 좋은 모델 구조를 학습 후, 엣지 기기에서 구동이 어렵다면 모델링 과정을 처음부터 다시 시작해야 할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;실행 가능한 모델이 구현되었다면, 계속적으로 엣지 기기를 활용할 것이 아니라 로컬 환경에서 모델을 고도화 할 것.&lt;/strong&gt; 이 경우 모델 용량 등을 Experiment Tracking Metric 으로 추가하는 것이 좋다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;모델 튜닝 과정을 추가적인 리스크로 다룰 것.&lt;/strong&gt; 관련 프레임워크는 아직 성숙하지 못했기 때문에, 작은 하이퍼파라미터 변동으로도 모델이 작동하지 않을 리스크가 존재한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;버저닝을 통한 회귀점을 구비할 것.&lt;/strong&gt; 엣지 배포의 경우 특히 모델을 작동하던 마지막 상태로 복구할 수 있는 시스템이 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 4</title>
        <link>https://meme2515.github.io/mlops/fsdl_4/</link>
        <pubDate>Sun, 04 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_4/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_4_3.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 4" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=Jlm4oqW41vY&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-4-data-management/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/17Ak9mxNBIAv_FHUZsneqSWSud9Dh7F3i/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 분야가 발전되기 시작한 초기 단계에 업계가 잘 이해하지 못했던 부분은 데이터와의 접점이다. 데이터셋을 만들고, 분석하고, 전처리하는 등의 과정은 ML 프로젝트 전반에 걸쳐 필수적이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4주차 강의의 핵심 내용은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;초도 분석에 원하는 것보다 10배 많은 시간을 할애해야 한다.&lt;/li&gt;
&lt;li&gt;데이터를 고치고, 추가하고, 증강하는 것이 대체로 성능 향상에 가장 크게 기여한다.&lt;/li&gt;
&lt;li&gt;데이터를 다루는 과정을 가능한 간단하게 유지할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-sources&#34;&gt;Data Sources&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;이미지, 텍스트, 로그, 데이터베이스&lt;/strong&gt; 등 데이터 원천의 종류는 다양하다. 딥러닝을 위해서는 GPU 자원이 있는 로컬 파일 시스템에 데이터를 옮겨와야하며, 이렇게 학습 데이터를 옮기는 방식은 다루는 데이터 마다 차이가 생긴다.
&lt;ul&gt;
&lt;li&gt;이미지의 경우 S3 등의 &lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;에서 직접 다운로드 받을 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 분산 처리를 통해 데이터를 분석하고, 일부분을 발췌해 로컬 환경으로 옮겨주는 등의 과정이 필요하다 &lt;em&gt;(원문 전달 내용이 조금 불확실함)&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;로그와 데이터베이스의 경우 &lt;strong&gt;데이터 레이크&lt;/strong&gt;를 활용해 데이터를 모으고, 처리할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;파일시스템&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;파일시스템이란 &lt;strong&gt;“파일” 이라는 기초 단위에 기반한 추상화 개념&lt;/strong&gt;이다. 파일이란 흔히 생각하듯 텍스트, 바이너리 등 다양한 형태를 취할 수 있으며, 버전의 개념을 가지지 않는다.&lt;/li&gt;
&lt;li&gt;파일시스템은 보통 사용하는 기기에 연결된 디스크에 저장되며, 연결의 개념은 물리적일 수도, 온프레미스, 클라우드, 혹은 분산시스템에 기반한 원격 연결을 의미할 수도 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;디스크 성능을 평가하는데 가장 중요한 요소는 속도와 대역폭&lt;/strong&gt;이다. 저장장치 포맷은 주로 HDD 와 SSD 로 나뉘어지며, 동일한 SSD 이더라도 SATA 와 NVMe 연결방식 간 약 100배의 속도차이가 발생한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;오브젝트 스토리지란 &lt;strong&gt;파일시스템 활용을 위한 API&lt;/strong&gt; 를 뜻하며, 가장 기본이 되는 단위는 이미지, 오디오, 텍스트 등의 바이너리 형태 “오브젝트” 이다.&lt;/li&gt;
&lt;li&gt;버저닝, 중복 저장 개념이 존재하며, 로컬 파일시스템에 비해서는 속도가 느리지만 클라우드 활용을 위해서는 충분.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터베이스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;지속적이고, 빠르고, 스케일링이 가능한 정형데이터 저장소이다.&lt;/li&gt;
&lt;li&gt;이미지와 같은 바이너리 데이터를 저장하기 보다는 오브젝트 스토리지에 상응하는 URL 을 저장.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.postgresql.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Postgres&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.sqlite.org/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SQLite&lt;/a&gt; 등의 오픈소스가 널리 활용된다.&lt;/li&gt;
&lt;li&gt;프로젝트가 상호 reference 를 같는 객체를 다룬다면 데이터베이스의 도입이 불가피하기 때문에 처음부터 사용하는 편이 개발 시간을 단축시킬 가능성이 높다.&lt;/li&gt;
&lt;li&gt;W&amp;amp;B, HuggingFace Hub, Label Studio 등의 MLOps 툴을 사실 이러한 데이터베이스의 역할을 수행.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 웨어하우스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스가 &lt;strong&gt;온라인 트랜잭션 처리 (OLTP)&lt;/strong&gt; 를 위해 설계되었다면, 데이터 웨어하우스를 &lt;strong&gt;온라인 분석 처리 (OLAP)&lt;/strong&gt; 을 위해 설계된 데이터 처장 체계이다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OLTP&lt;/strong&gt; : &lt;em&gt;네트워크 상의 여러 이용자가 실시간으로 DB 의 데이터를 갱신하거나 조회하는 등의 단위작업 처리 방식. Row-oriented, 즉 개별적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OLAP&lt;/strong&gt; : &lt;em&gt;데이터를 분석하고 유의미한 정보로 치환하거나, 복잡한 모델링을 가능하게끔 하는 분석 방법. Column-oriented, 즉 통계적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;데이터 웨어하우스로 여러 데이터를 끌어오는 작업을 &lt;strong&gt;ETL (Extract-Transform-Load)&lt;/strong&gt; 이라 칭하며, 비즈니스 관점의 의사결정을 위한 정보를 웨어하우스에서 끌어오게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 레이크&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 웨어하우스와 유사하나, 데이터를 사전에 가공하는 ETL 방식과 달리 일단 데이터를 모으고, 사용시 가공하는 &lt;strong&gt;ELT (Extract-Load-Transform)&lt;/strong&gt; 방식을 사용한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;최근 트렌드는 데이터 웨어하우스와 데이터 레이크를 통합하는 솔루션들이다. 정형 데이터와 비정형 데이터가 같은 저장소에서 다뤄질 수 있으며, &lt;a class=&#34;link&#34; href=&#34;https://www.snowflake.com/?lang=ko&amp;amp;utm_source=google&amp;amp;utm_medium=paidsearch&amp;amp;utm_campaign=ap-kr-ko-brand-core-exact&amp;amp;utm_content=go-eta-evg-ss-free-trial&amp;amp;utm_term=c-g-snowflake-e&amp;amp;_bt=579103397662&amp;amp;_bk=snowflake&amp;amp;_bm=e&amp;amp;_bn=g&amp;amp;_bg=128328467463&amp;amp;gclsrc=aw.ds&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUubkoz7BoatiURcPHbxVDF3FAWwLuPcV1hSkAOItZfeqaTMTbDpzxQaAnZXEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snowflake&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://www.databricks.com/p/ebook/the-data-lakehouse-platform-for-dummies?utm_medium=paid&amp;#43;search&amp;amp;utm_source=google&amp;amp;utm_campaign=15849074529&amp;amp;utm_adgroup=130486333845&amp;amp;utm_content=ebook&amp;amp;utm_offer=the-data-lakehouse-platform-for-dummies&amp;amp;utm_ad=587394793834&amp;amp;utm_term=databricks&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUsOVwmdjpvZBvMSSWc1Z-5P83Uc0Y8k7hBQYQjbHZIEF_5Vb0p_3fMaArshEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Databricks&lt;/a&gt; 등의 업체가 분야를 선도하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;분야에 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://dataintensive.net/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Designing Data-Intensive Applications&lt;/a&gt; 라는 책을 추천.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 탐색은 주로 &lt;strong&gt;SQL&lt;/strong&gt; 과 &lt;strong&gt;DataFrame&lt;/strong&gt; 을 활용해 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt; 은 정형 데이터를 다루는 기본적인 인터페이스이며, 수십년간 사용되고 발전되어왔다. RDBMS 등의 트랜잭션 기반 데이터베이스에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pandas&lt;/strong&gt; 는 Python 생태계에서 사용되는 주된 DataFrame 이며 SQL 과 유사한 작업을 수행할 수 있다. OLAP 등의 분석 기반 환경에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://examples.dask.org/dataframe.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DASK DataFrame&lt;/a&gt; 은 Pandas 작업을 여러개의 CPU 코어에서 분산 처리 할 수 있도록 돕는다. &lt;a class=&#34;link&#34; href=&#34;https://rapids.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RAPIDS&lt;/a&gt; 는 동일한 분산 처리 작업을 GPU 에서 수행.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-processing&#34;&gt;Data Processing&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리는 예시와 함께 설명하는 편이 좋다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SNS 플랫폼에 업로드되는 사진을 기반으로, 사진의 인기도를 예측하는 모델을 매일 학습하는 상황이라고 가정하자. 모델러는 다음과 같은 데이터를 활용하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스 내 메타데이터 (업로드 시간, 제목, 장소 등)&lt;/li&gt;
&lt;li&gt;로그 데이터 기반 유저 정보 (로그인 횟수 등)&lt;/li&gt;
&lt;li&gt;별도 분류 모델 기반 사진 정보 (컨텐츠, 스타일 등)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 최종적인 모델 학습이 진행되기 전, 데이터베이스 쿼리 작업, 로그 처리 작업, 모델 예측 작업 등 많은 데이터 처리 작업이 수행되어야 하며, 이러한 &lt;strong&gt;사전 작업을 정해진 순서대로 처리&lt;/strong&gt;해야 할 필요가 생긴다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow&lt;/a&gt; 는 언급된 기능을 수행하는 Python 생태계의 기본 스케줄러 툴이다. &lt;strong&gt;DAG (Directed Acyclic Graph)&lt;/strong&gt; 라는 개념을 활용해 순차적인 작업 설정이 가능하며, 이러한 작업이란 SQL 쿼리, Python 함수 등 다양한 종류가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.prefect.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Prefect&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://dagster.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dagster&lt;/a&gt; 또한 유사한 기능을 수행하는 경쟁 제품이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;feature-store&#34;&gt;Feature Store&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리 과정이 모델 학습과 병렬로 진행될 떄, 모델은 이후 학습에서 어떤 데이터가 신규로 생성되었는지, 어떤 데이터가 이미 학습에 활용되었는지 등을 파악할 필요가 발생할 수 있다 (필수적인 요소는 아님).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 경우 &lt;strong&gt;Feature Store&lt;/strong&gt; 기능을 활용한 데이터 관리가 필요해지게 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feature Store 라는 개념은 Uber 의 ML 플랫폼 &lt;strong&gt;Michalengelo&lt;/strong&gt; 를 소개하는 &lt;a class=&#34;link&#34; href=&#34;https://www.uber.com/en-KR/blog/michelangelo-machine-learning-platform/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 글&lt;/a&gt;에서 처음 등장했다. Uber 의 시스템 특성상 학습은 오프라인, 예측은 온라인으로 진행되기에 두 과정의 싱크를 맞춰줄 필요가 생겼고, 이를 해결하기 위한 수단으로 Feature Store 개념을 사용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;tecton.ai&#34; &gt;Tecton&lt;/a&gt; 은 해당 분야에서 가장 널리 사용되는 SaaS 솔루션이며, 이외에도 &lt;a class=&#34;link&#34; href=&#34;https://feast.dev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Feast&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.featureform.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Featureform&lt;/a&gt; 등의 옵션이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/datasets/index&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HuggingFace Datasets&lt;/a&gt; 는 ML 학습에 특화된 8000+ 데이터셋을 제공하며, 비전, NLP 등 분야가 다양한 편이다. 호스트된 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/datasets/codeparrot/github-code&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github-Code&lt;/a&gt; 데이터를 예시로 들자면 데이터 핸들링을 돕기 위해 Aparche Parquet 형태로 스트림 할 수 있기 떄문에 1TB+ 용량의 전체 데이터를 다운로드 할 필요가 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;또다른 훌륭한 데이터셋의 예시로는 RedCaps 를 들 수 있다. Reddit 에서 수집된 12M 의 이미지-텍스트 페어를 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HuggingFace Datasets 와 유사한 서비스로는 &lt;a class=&#34;link&#34; href=&#34;https://www.activeloop.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Activeloop&lt;/a&gt; 이 있는데, 데이터 다운로드 없이 분석과 기타 데이터 활용이 가능하도록 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-labeling&#34;&gt;Data Labeling&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 레이블링 작업을 시작하기 전, 정말 레이블링이 필요한지를 스스로에게 물어볼 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;자기지도학습 (self-supervised learning)&lt;/strong&gt; 이란 직접적인 레이블링 작업 없이 데이터의 일부분을 레이블로 활용하는 학습 방식을 뜻하며, NLP 과제에서 중요한 요소로 자리매김하고 있다. 마스킹 등의 기법을 통해 데이터의 한 부분을 예측하는 과제이며, &lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/clip/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenAI CLIP&lt;/a&gt; 과 같이 cross-modality 과제에서 (이미지-텍스트 등) 또한 활용이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;이미지 데이터 증강&lt;/strong&gt;은 비전 모델에서 사실상 필수적인 요소이다. &lt;a class=&#34;link&#34; href=&#34;https://github.com/pytorch/vision&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;torchvision&lt;/a&gt; 과 같은 라이브러리를 활용하여 간단하게 구현할 수 있으며, &lt;strong&gt;이미지의 &amp;ldquo;의미&amp;quot;를 변질시키지 않는 선에서 데이터에 변형을 주는 것&lt;/strong&gt;을 목표로 삼는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외 데이터 형태에 대한 증강 방식은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;정형 데이터의 경우 랜덤하게 선택된 셀 정보를 삭제함으로 미입수 데이터를 모방할 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 증강 기법이 상대적으로 부족한 편. 단어의 순서를 변경하거나, 부분적으로 삭제하는 방식이 존재한다.&lt;/li&gt;
&lt;li&gt;오디오 데이터는 속도를 조절하거나, 빈 오디오를 중간에 삽입하는 방식 등이 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Synthetic Data (합성 데이터)&lt;/strong&gt; 또한 고려해볼 필요가 있다. 레이블에 대한 사전 지식을 통해 기존에 존재하지 않는 데이터를 생성할 수 있으며, 적용 예시로는 영수증, 손글씨 이미지 등이 있다. 많은 공수가 필요하기 때문에 다른 방법은 없는지 충분히 검토 후 도입.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;보다 창의성을 발휘해 유저에게 레이블링 작업을 맞기는 것 또한 가능하다. 위 이미지와 같이 Google Photos 는 유저에게 이미지 레이블링 작업을 요구.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;유저의 직접적인 레이블링은 언급된 data flywheel 개념의 적용 예시이다. 유저는 모델 성능 향상에 기여하고, 이로 인해 유저의 제품 경험 또한 개선된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇듯 데이터 레이블링을 우회하는 다양한 방법이 존재하지만, 결국 &lt;strong&gt;모델링 작업을 시작하기 위해서는 어느정도의 레이블링 작업은 불가피&lt;/strong&gt;하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링이란 bounding box 와 같이 &lt;strong&gt;표준적인 형태의 주석을 기록하는 작업&lt;/strong&gt;이다. 주석의 형태보다는 레이블러가 올바른 교육을 받는 것이 가장 중요하며, &lt;strong&gt;이들이 레이블링 표준을 준수하도록 하는 것은 어렵지만 가장 핵심적인 요소&lt;/strong&gt;이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블러 고용 시 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 레이블링을 전문적으로 수행하는 업체.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;레이블러의 &lt;strong&gt;직접적인 고용&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.mturk.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Mechanical Turk&lt;/a&gt; 와 같은 &lt;strong&gt;크라우드 소싱&lt;/strong&gt;. 레이블링 품질을 위해 가능한 피하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링 전문 업체들은 소프트웨어 개발, 인력 관리, 품질 관리 까지의 다양한 작업을 수행한다. 업체 활용이 필요하다면 데잍러를 충분히 이해한 후, 샘플 레이블 등을 통해 여러 경쟁 업체를 비교한 후 의사결정을 내리는 편이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://scale.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Scale AI&lt;/a&gt; 는 업계에서 가장 규모가 큰 데이터 레이블링 솔루션이다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://labelbox.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Labelbox&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://supervise.ly/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Supervisely&lt;/a&gt; 가 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://labelstud.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LabelStudio&lt;/a&gt; 는 가장 널리 알려진 오픈소스 솔루션이며, 직접 레이블링을 수행할 때 활용하게 된다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://diffgram.com/main/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Diffgram&lt;/a&gt; 이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://snorkel.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snorkel&lt;/a&gt; 은 weak supervision 기반 레이블링 툴이며, &amp;ldquo;amazing&amp;rdquo; 이라는 단어가 들어간 모든 문장을 &amp;ldquo;긍정&amp;rdquo; 카테고리로 구분하는 등의 빠른 레이블링 작업을 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-versioning&#34;&gt;Data Versioning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 버전 관리는 단계적으로 구분이 가능하다.
&lt;ul&gt;
&lt;li&gt;Level 0 : &lt;strong&gt;단순한 파일시스템 관리로, 버전 관리가 이루어 지지 않는다.&lt;/strong&gt; 모델이란 코드와 데이터가 합쳐져 만들어진 결과물이기 때문에, 데이터가 바뀌면 동일한 모델을 구현하지 못하게 된다.&lt;/li&gt;
&lt;li&gt;Level 1 : &lt;strong&gt;학습시 데이터에 대한 스냅샷을 저장&lt;/strong&gt;하는 방식. 모델에 활용된 데이터가 특정 가능하지만, 이상적인 방식이라고 보기엔 어렵다.&lt;/li&gt;
&lt;li&gt;Level 2 : &lt;strong&gt;코드 버전 관리와 같은 개념을 도입&lt;/strong&gt;. &lt;a class=&#34;link&#34; href=&#34;https://git-lfs.github.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Git-LFS&lt;/a&gt; 와 같은 툴을 사용하게되며, 적극적으로 권장되는 방식이다.&lt;/li&gt;
&lt;li&gt;Level 3 : 대용량 데이터 관리를 위한 &lt;strong&gt;특별한 솔루션&lt;/strong&gt;을 도입. 합리적인 이유 (데이터 용량이 지나치게 크거나, 데이터에 많은 규제가 붙는 경우 등) 가 없다면 불필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 작업을 위한 툴로는 &lt;a class=&#34;link&#34; href=&#34;https://dvc.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DVC&lt;/a&gt; 가 있다. 데이터를 원격 저장소에 저장하고, 필요시 이전 버전으로 회귀하는 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 3</title>
        <link>https://meme2515.github.io/mlops/fsdl_3/</link>
        <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_3/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_3_title.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 3" /&gt;&lt;h2 id=&#34;testing-software&#34;&gt;Testing Software&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;테스트란 제품의 버그 발생 빈도를 줄여 더 빠른 배포가 가능하도록 도움을 주지만, 모든 버그를 차단할 수는 없다. 즉, 중요하다고 판단되는 부분에 대해서만 테스트를 작성할 것.&lt;/li&gt;
&lt;li&gt;린팅 (linting) 툴 적용은 권장되지만, 모든 스타일 가이드를 맹목적으로 지킬 필요는 없다.&lt;/li&gt;
&lt;li&gt;테스팅, 린팅 워크플로의 자동화 툴 또한 본 강의에서 소개.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;1.1 - Tests Help Us Ship Faster. They Don&amp;rsquo;t Catch All Bugs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image1.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;테스트란 작성한 코드가 실패할 시 이를 탐지하기 위해 작성된 또 다른 코드이다.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;테스트가 존재하더라도 모든 버그를 탐지할순 없다. 특히 파이썬과 같은 하이레벨 코드에선 테스트란 단순히 보조적인 역할을 수행하게 된다.&lt;/li&gt;
&lt;li&gt;또 다른 관점은 테스트를 일종의 분류기로 생각하는 것. 작성된 코드가 버그를 포함하는지 예측하는 모델을 구축한다고 볼 수도 있다.&lt;/li&gt;
&lt;li&gt;분류 문제와 유사하게 테스트란 True Positive / False Positive 간 밸런스를 잡아줄 필요가 있다. 지나치게 많은 False Positive 를 방지하기 위해선 다음과 같은 질문을 해볼 필요가 있다.
&lt;ul&gt;
&lt;li&gt;작성된 test 가 탐지하는 실제 버그는 무엇인가?&lt;/li&gt;
&lt;li&gt;버그가 존재하지 않는 경우 test 가 실패하는 경우는 무엇인가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;위와 같은 질문을 했을때 1번 질문 보다 2번 질문에 대한 답이 더 많다면 테스트 적용을 다시 한번 고민해 보는 것이 필요하다.&lt;/li&gt;
&lt;li&gt;모델의 정확도가 특별히 중요한 경우 또한 고려해야 한다. 의료진단, 자율주행, 금융과 같은 경우를 예시로 들 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image19.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image19.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.2 - Use Testing Tools, But Don&amp;rsquo;t Chase Coverage&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;파이썬 코드 테스팅을 위한 기본 툴은 Pytest 이다. Test Suite 구분, 테스트간 자원 공유, 파라미터 기반 테스팅 등의 기능을 지원.&lt;/li&gt;
&lt;li&gt;단순 텍스트 기반 테스트는 자동화가 어렵기 때문에 유지가 어려운 측면이 있다. 하지만 파이썬의 경우 doctest 모듈을 지원하기 때문에 documentation 내 테스팅이 가능.&lt;/li&gt;
&lt;li&gt;노트북 활용 시, assert 기능과 nbformat 을 활용해 테스팅이 가능하지만, 구현이 지저분한 편.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image17.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;코드베이스 규모가 커질수록 테스팅된 코드와 그렇지 않은 코드를 관리하는 일이 복잡해진다. Codecov 란 이러한 코드 테스팅 현황을 시각화해주는 툴.&lt;/li&gt;
&lt;li&gt;Codecov 는 또한 코드의 일정 비율 이상이 테스팅 되지 않으면 commit 을 reject 하는 등의 개발 편의를 위한 기능들을 제공한다.&lt;/li&gt;
&lt;li&gt;이와 같은 커버리지 타겟팅은 사실 강사진은 추천하지 않는 방식이며, 경험/인터뷰/연구에 의하면 의미있는 테스트는 전체 테스트의 아주 작은 부분에 불과하다.&lt;/li&gt;
&lt;li&gt;엔지니어링 관점에서 가장 효과적인 전략은 의미있는 적은 수의 테스트를 아주 높은 수준으로 구현하는 것. 커버리지 타겟팅을 설정하면 질낮은 테스트를 많이 작성해 커버리지 비율에 집중하게 될 위험성이 높다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image16.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.3 - Use Linting Tools, But Leave Escape Valves&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Clean code is of uniform and standard style&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;통일된 스타일은 pull request 와 코드 리뷰 단계에서 불필요한 논쟁을 줄일 수 있다. 또한 스타일과 관련된 diff 수를 줄여 버전 컨트롤 시스템 활용도를 높인다.&lt;/li&gt;
&lt;li&gt;스탠다드 스타일은 오픈소스 기여 시 마찰을 줄이고, 신규 프로젝트에서 새로운 팀 멤버 합류 과정 또한 더욱 매끄럽게 만들어준다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image18.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image18.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Black :&lt;/strong&gt; whitespace 와 같은 일관된 포맷팅을 위한 툴이다. 기본적으로 자동화가 가능한 영역을 담당하고, 에디터와 자동화 워크플로우에 비교적 문제없이 적용이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flake8 :&lt;/strong&gt; missing docstring 과 같이 자동화가 어려운 영역을 담당하며, docstring completeness, type hinting, security, common bugs 등 영역에서 관련 기능을 제공하는 extension 과 plug-in 을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shellcheck :&lt;/strong&gt; BASH 와 관련된 주요 에러 요인 등을 확인해준다. 실행 속도가 빠르고 에디터에 쉽게 적용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image6.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;스타일의 무지성적인 적용은 바람직하지 않다. 관련한 문제를 방지하기 위해 강사진은 다음과 같은 방식을 추천
&lt;ul&gt;
&lt;li&gt;적용되는 룰을 목적에 부합하는 수준에서 미니멀하게 유지할 것 (스탠다드 유지, 버전 컨트롤 시스템 활용 등).&lt;/li&gt;
&lt;li&gt;선택적인 룰 적용. 단계적인 룰 커버리지 상승 (특히 수정이 많이 필요한 큰 기존 코드베이스에 적용할 시).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.4 - Always Be Automating&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;앞서 설명된 테스팅, 린팅을 업무 환경에 잘 적용하기 위해선 버전 컨트롤 시스템 (VCS) 과의 연동을 통한 자동화가 필요하다.&lt;/li&gt;
&lt;li&gt;VCS 와의 연동은 에러 재현을 가능하게 한다거나, 자동화를 통해 개발자가 본연에 업무에 보다 집중할 수 있다는 등의 장점이 존재한다.&lt;/li&gt;
&lt;li&gt;인기있는 오픈소스 repository 는 관련된 best practice 를 배울 수 있는 최적의 장소이다 (예. PyTorch Github library).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image15.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyTorch 가 활용하는 툴은 GitHub Actions 이며, 해당 툴은 VCS 와 연동된 자동화 기능을 제공.&lt;/li&gt;
&lt;li&gt;Pre-commit.ci, CircleCI, Jenkins 와 같은 유사한 기능의 툴이 존재하지만 GitHub Actions 는 현재 오픈소스 커뮤니티에서 가장 활발하게 활용되는 툴이다.&lt;/li&gt;
&lt;li&gt;버전 관리 내역을 깨끗하게 유지하기 위해선 commit 전 테스팅과 린팅을 로컬 환경에서 구동할 수 있어야 한다. 강사진은 이러한 작업을 위해 pre-commit 을 추천.&lt;/li&gt;
&lt;li&gt;자동화를 위해선 사용하는 툴을 깊게 이해하고 있어야한다. 예를 들어 Docker 를 단순히 사용할 줄 아는 것은 Docker 를 자동화 할 수 있는 것과 다르며, 제대로된 자동화가 아닌 경우 오히려 생산성을 저하시킬 우려가 존재한다.&lt;/li&gt;
&lt;li&gt;따라서 자동화는 보다 높은 직급의 개발자가 담당하는 편이 좋으며, 코드의 오너십, 자동화에 대한 의사결정을 필요로 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-ml-systems&#34;&gt;Testing ML Systems&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;ML 테스팅은 어렵지만, 불가능하진 않다.&lt;/li&gt;
&lt;li&gt;쉬운 작업부터 차근차근 시작할 것.&lt;/li&gt;
&lt;li&gt;배포 환경에서 테스트를 진행하나, 질낮은 코드를 배포하지는 않을 것.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;2.1 - Testing ML Is Hard, But Not Impossible&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;테스팅 개념이 발전된 영역은 소프트웨어 엔지니어링 분야이다. 소프트웨어 엔지니어링은 코드를 배포하는 과정이지만, ML 은 학습을 통해 데이터와 모델을 결합하며, 따라서 다음과 같은 어려움을 동반한다.
&lt;ul&gt;
&lt;li&gt;데이터는 소스 코드 보다 무겁고, 검증이 어렵다.&lt;/li&gt;
&lt;li&gt;데이터는 보다 복잡하고, 명확한 정의를 가지고있지 않다.&lt;/li&gt;
&lt;li&gt;데이터는 컴파일된 프로그램에 비해 빈약한 디버깅, 검증 툴 셋을 가지고있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;본 섹션은 Smoke Testing 개념에 집중하며, 이는 구현이 쉽고 효과적이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.2 - Use Expectation Testing on Data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터에 대한 테스팅은 기본적인 속성에 대한 검증으로부터 시작한다. null 이 존재하지 않는 컬럼, 시작일 이전의 마감일 등 데이터에 대한 기본적인 기대치에 대한 검증을 진행하는 식.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image14.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;강사진은 이와 같은 작업을 위해 great_expectations 라이브러리를 추천한다. 본 툴은 데이터 질에 대한 리포트를 자동으로 생성하며, logging, alerting 등의 기능 또한 지원.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image13.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;원활한 작업 진행을 위해서는, 가능한 모델러와 데이터 간 거리를 좁히는 편이 좋다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;첫째 방안은 프로젝트 시작 시 모델 개발자가 임의로 데이터를 레이블링 하는 것.&lt;/li&gt;
&lt;li&gt;하지만 더 많은 개발자가 팀에 들어오고, 데이터 레이블링을 진행한 개발자가 다른 일에 착수하며 관련된 정보는 필연적으로 유실된다. 이보다 나은 솔루션은 모델 개발자와 주기적으로 소통하는 데이터 레이블링 조직을 운영하는 것.&lt;/li&gt;
&lt;li&gt;최적은 방안은 모델 개발자들이 순차적으로 레이블링 작업을 진행하는 것이다. 이러한 방식을 통해 모델 개발자는 데이터에 대한 이해와 전문성을 높일 수 있다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;2.3 - Use Memorization Testing on Training&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;암기는 가장 단순한 형태의 학습이다. 특히 딥러닝의 경우 데이터를 암기하는 작업을 특히 잘 수행하기 때문에 전체 데이터셋의 일부분을 잘 암기하는지 확인하는 것 만으로 학습이 원활하게 이루어지는지 확인할 수 있다.&lt;/li&gt;
&lt;li&gt;이러한 방식으로 확인 가능한 이슈는 아주 심각할 확률이 높다. 예를 들어 gradient 계산이 제대로 이루어지지 않거나, numerical type 이슈가 존재하거나, 레이블이 섞여있는 등.&lt;/li&gt;
&lt;li&gt;보다 작은 규모의 문제 확인을 위해서는 학습에 소요되는 런타임을 확인하는 것이 좋다. 기대 수준의 성능을 달성하기 까지 소요되는 배치 수가 갑자기 증가한다면, 학습 과정에서 버그가 발생했을 가능성이 있다.&lt;/li&gt;
&lt;li&gt;PyTorch Lightning 은 이러한 작업을 위해 overfit_batches 기능을 제공.&lt;/li&gt;
&lt;li&gt;Memorization 테스팅 개발 시에는 실행 속도를 염두해두어야 한다. 잦은 테스팅을 위해 실행 속도가 빨라야하며, 10분 이내의 테스팅 타음으로 모든 PR, 또는 코드 변경 후 실행하는 편이 좋다.&lt;/li&gt;
&lt;li&gt;실행 속도 개선을 위해서는 다음 이미지 참조 - 이러한 아이디어들은 여러 시나리오에 따른 학습 결과를 사전에 확인할 수 있는 방법이기도 함.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image3.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;또 다른 테스팅 방법은 이전과 동일한 조건의 학습을 새로운 코드로 실행하는 것. 자주 수행이 가능하지는 않지만, 학습 파이프라인에서 예기치 못하게 발생한 문제를 바로 확인할 수 있다.&lt;/li&gt;
&lt;li&gt;이러한 방법의 주된 단점은 학습에 필요한 많은 리소스이다. CircleCI 와 같은 CI (Continuous Integration) 플랫폼은 GPU 활용에 많은 비용을 청구하며, GitHub Actions 는 관련 기기 접근에 많은 제약이 있다.&lt;/li&gt;
&lt;li&gt;가장 좋은 방법은 배포 환경에서 새로 유입되는 데이터를 활용해 주기적인 학습을 진행하는 것. 여전히 많은 리소스가 소요되지만, 실제 모델 개선에 직접적으로 기여하며 관련 작업을 위해 data flywheel 을 필수적으로 구축하게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.4 - Adapt Regression Testing for Models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델은 하나의 함수로 규정할 수 있다 - 기본적으로 인풋에 의한 아웃풋을 출력하기 때문. 따라서 보통의 함수와 같이 regression testing (코드 변경 전후, 동일한 인풋에 대한 아웃풋 출력을 대조하는 방법) 을 통한 코드 검증이 가능하다.&lt;/li&gt;
&lt;li&gt;Regression testing 은 분류기와 같은 보다 단순한 모델에 가장 적합하며, 구조가 복잡한 경우 또한 적용이 조금 어려울순 있지만 배포 과정에서 도움을 줄 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image11.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;보다 우아한 테스팅 방법은 손실값과 모델 지표를 활용한 test suite 작성이다.&lt;/li&gt;
&lt;li&gt;하기 test-driven development (TDD) 코드 작성 패러다임 (테스트 작성 후 코드를 작성하는 방식, 코드에 기인한 테스트 작성을 방지함으로서 테스트가 본연에 역할에 보다 충실할 수 있다) 과 유사한데, 일정 수준의 손실값을 사전에 정의한 후, 모델이 정의된 성능을 보일때 까지 개발을 진행하게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image9.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;하지만 손실값 threshold 기반의 테스팅은 에러 발생의 원인을 특정할 수 없기 때문에 TDD 와 완전한 동일 선상에서 볼 수는 없다.&lt;/li&gt;
&lt;li&gt;이와 같은 문제를 보완하기 위해서 손실값이 가장 크게 발생한 데이터를 면밀히 살펴볼 필요가 있다. 이러한 데이터들을 하나의 세트로 모은 후 해당 세트를 기반으로 별도의 테스팅을 진행할 수도 있는데, 이에 따른 이점은 (1) 모델이 개선 가능한 영역을 확인할 수 있으며 (2) 데이터 자체의 문제 또한 찾을 수 있다는 점 (레이블 오류 등).&lt;/li&gt;
&lt;li&gt;특이 데이터 확인 시에는 타입별로 데이터를 묶는 작업이 필요할 수 있다. 자율운행을 예시로 들자면 주위 환경이 너무 어두운 경우, 앞유리에 빛반사가 발생한 경우 등을 그룹핑.&lt;/li&gt;
&lt;li&gt;이러한 방법을 통해 모델 개선시 동일한 문제가 발생하지 않는지 확인하는 작업이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image8.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;꽤나 손이 많이 가는 작업인데, 별도 레이블링 팀과의 협업 등을 통해 효율 개선이 가능한 부분. Domino, Checklist 와 같이 이러한 문제를 별도 ML 모델로 해결하는 방법 또한 존재한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.5 - Test in Production, But Don&amp;rsquo;t YOLO&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;테스트는 실제 배포 환경에서 진행되어야 한다. 특히 ML 분야의 경우 배포 환경과 개발 환경 간 데이터 유사성을 담보하기 어렵기 때문에 배포 환경 내 테스팅이 중요.&lt;/li&gt;
&lt;li&gt;또한 배포 환경 테스팅을 위해서 구축하게 되는 툴과 인프라는 실제 배포 문제가 발생했을때 이를 해결하는데 활용될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image7.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.6 - ML Test Score&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;코드베이스가 커지고, 팀이 성숙해가며 단순한 smoke testing 보다 완전한 형태의 테스팅이 필요해질 수 있다. 이러한 예시 중 하나가 ML Test Score.&lt;/li&gt;
&lt;li&gt;ML Test Score 는 구글 ML 개발팀에서 발전한 평가기준인데, 데이터, 모델, 학습, 인프라, 배포 모니터링 등의 영역을 객관적으로 평가할 수 있도록 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image2.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;해당 방법은 기준치가 매우 높고, 영역이 광범위하다. 강사진이 개발한 모델 조차 몇개의 영역에서 기준에 미치지 못하기 때문에 일종의 참고 자료로 활용하는 것이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image5.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting-models&#34;&gt;Troubleshooting Models&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;테스팅은 잘못된 부분을 찾도록 돕지만, 트러블슈팅은 실제 잘못된 부분을 고치는 과정이다. ML 트러블슈팅이란 다음과 같은 순차적 방법론으로 정의할 수 있다.
&lt;ol&gt;
&lt;li&gt;Make It Run - 자주 발생하는 에러를 방지해 모델이 작동하도록 할 것.&lt;/li&gt;
&lt;li&gt;Make It Fast - 비효율성을 개선해 모델이 빠르게 동작하도록 할 것.&lt;/li&gt;
&lt;li&gt;Make It Right - 검증된 구조와 보다 방대한 데이터 활용으로 올바른 모델을 구축할 것.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.1 - Make It Run&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;세단계의 과정 중 가장 쉬운 단계이다. 모델 실행을 막는 버그는 아주 일부분에 불과한데, 이러한 버그들은 미리 내용을 숙지한 후 사전에 방지하는 편이 좋다.&lt;/li&gt;
&lt;li&gt;첫번째 타입은 shape error, 즉 행렬 연산 과정에서 행렬의 크기가 맞지 않는 경우이다. 이러한 에러를 방지하기 위해 개발 과정에서 예상되는 텐서의 크기를 중간 중간 코드 내에 적어주는 것이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image10.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;두번째 타입은 메모리 에러이다. GPU 에 비해 지나치게 큰 용량의 텐서를 처리할 시 발생되며, 이를 예방하기 위해서는 가능한 낮은 precision 을 활용할 것 (주로 16비트 precision).&lt;/li&gt;
&lt;li&gt;다른 원인은 지나치게 많은 데이터, 혹은 배치 사이즈. PyTorch Lightning 내 autoscale batch size 기능을 활용해 방지 가능하며, 이로도 해결이 어렵다면 tensor parallelism, gradient checkpoint 등의 옵션을 검토.&lt;/li&gt;
&lt;li&gt;NaN, Infinite 등의 값이 텐서 내 발생하는 경우 또한 학습 실패로 이어질 수 있다. 주로 gradient 발생 후, 모델에 전파되는 형태이며 PyTorch Lightning 은 이러한 이슈 트래킹을 위한 기능을 제공.&lt;/li&gt;
&lt;li&gt;주로 Normalization Layer 에서 발생하며, 64 비트 float 적용 시 문제가 해결될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.2 - Make It Fast&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image4.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델이 정상적으로 작동한다면, 이후 실행 속도 개선이 필요하다.&lt;/li&gt;
&lt;li&gt;DNN 의 경우 실행 속도와 관련해 직관적이지 않은 부분이 다소 존재하는데, 예시적으로 트랜스포머 모델 내 MLP 레이어 실행 속도가 Attention 레이어 실행 속도보다 느리거나, 데이터 로딩 등에 상당한 시간이 소요될 수 있다.&lt;/li&gt;
&lt;li&gt;이러한 이슈를 해결하기 위해서 가장 좋은 방법은 단순히 코드를 재점검하는 것. 관련해 아주 작은 코드 변화도 큰 효과를 가져올 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.3 - Make It Right&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;기존 소프트웨어와는 다르게 ML 모델은 태생적으로 완벽할 수 없다.&lt;/li&gt;
&lt;li&gt;하지만 모델/데이터 스케일링을 통해 모델은 상당한 성능 개선을 보일 수 있는데, OpenAI 리서치에 의하면 스케일링에 의한 장점은 명확히 측정될 수 있고, 리소스, 데이터 사이즈, 파라미터 수 등에 기반해 예측될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/media/image12.png&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;직접적인 스케일링이 어렵다면, finetuning 을 검토.&lt;/li&gt;
&lt;li&gt;언급된 조언보다 세부적인 사항들은 모델과 관련 과제 마다 많은 차이가 있을 것. 가능하면 이미 존재하는 모델 구조와 하이퍼파라미터 등을 활용하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 2</title>
        <link>https://meme2515.github.io/mlops/fsdl_2/</link>
        <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_2/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_2_7.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 2" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=BPYOsDCZbno&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-2-development-infrastructure-and-tooling/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/16pEG5GesO4_UAWiD5jrIReMGzoyn165M/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;이상적인 ML 환경이란 &lt;strong&gt;정의된 프로젝트 목표와 샘플 데이터를 기반으로, 지속적으로 개선되는 예측 시스템을 큰 규모로 운영&lt;/strong&gt;하는 것이다.&lt;/li&gt;
&lt;li&gt;현실은 이와는 다를 수 밖에 없다. 데이터에 대한 &lt;strong&gt;수집, 처리, 레이블, 버저닝&lt;/strong&gt;이 필요하며, &lt;strong&gt;적합한 모델 구조와 사전 학습된 가중치&lt;/strong&gt;를 찾아야하고, 프로젝트에 적합하게 &lt;strong&gt;디버깅&lt;/strong&gt;해야 한다. 또한 여러 &lt;strong&gt;학습 과정을 기록 및 리뷰&lt;/strong&gt;해야하며, 모델 배포 후에도 끊임없이 생성되는 데이터를 기반으로 모델을 개선해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 환경의 3가지 주요한 컴포넌트는 &lt;strong&gt;데이터, 개발, 배포&lt;/strong&gt;이다. 각각의 컴포넌트는 방대한 툴을 가지고 있고, 3주간 강의를 통해 이들 모두를 전반적으로 살핀다. 본 강의의 주제는 개발이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;software-engineering&#34;&gt;Software Engineering&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;개발 언어의 경우 데이터 컴퓨팅 분야에선 현재 &lt;strong&gt;Python&lt;/strong&gt; 이 절대적인 우위를 점하고 있다. 너무나 많은 부속 라이브러리들이 개발되었기 때문이며, Julia, C/C++ 와 같은 경쟁자가 존재했지만 사실상 Python 이 생태계를 독점하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파이썬 코드를 작성하기 위해서는 에디터를 사용해야 한다. Vim, Emacs, Jupyter Notebook/Lab, PyCharm 등 수많은 옵션이 있지만 FSDL 팀이 제안하는 에디터는 &lt;strong&gt;VS Code&lt;/strong&gt; 이다. 내장된 Git 버전 컨트롤, docs peeking, 원격 접속, 린터, 디버깅 기능 등을 제공하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;수많은 현업들이 Jupyter Notebook 환경을 사용하지만, 에디터가 별다른 기능을 제공하지 못하고, 코드의 작성 순서가 중요하지 않으며, 버전 컨트롤, 테스팅이 어렵다는 문제를 가지고 있다. &lt;a class=&#34;link&#34; href=&#34;https://nbdev.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Nbdev&lt;/a&gt; 패키지를 활용하면 이러한 문제들은 어느 정도 해결은 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deep-learning-frameworks&#34;&gt;Deep Learning Frameworks&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;딥러닝의 본질적인 요소인 행렬 연산은 사실 Numpy 정도의 라이브러리만으로 해결 가능하다. 하지만 CUDA 를 통한 GPU 자원 활용, 전통적이지 않은 형태의 레이어 구축, 옵티마이저/데이터 인터페이스 활용 등을 위해서는 딥러닝 프레임워크가 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PyTorch, TensorFlow, Jax 등 다양한 프레임워크들이 존재하며, 모델을 구축 한 후 배포 환경에 따라 최적화된 execution graph 를 찾는다는 점에서 근본적인 작동 원리는 서로 유사하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;강사진은 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch&lt;/a&gt; 를 선호하는데, 구현된 모델 수, 연관 논문 수, 대회 수상 모델 수 등에서 압도적인 우세를 보이기 때문이다. 2021년도만 하더라도 ML 대회 우승 모델의 약 77%가 PyTorch 를 사용했다.&lt;/li&gt;
&lt;li&gt;PyTorch 의 경우 TorchScript 등의 파생 제품을 이용하면 실행 속도가 더욱 빨라지며, 분산 처리, 비전, 오디오, 모바일 배포 환경등의 생태계를 이루고 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.pytorchlightning.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Lightning&lt;/a&gt; 을 PyTorch 와 함께 사용하면 코드를 보다 구조적으로 유지할 수 있으며, 어떠한 하드웨어에서도 코드를 실행할 수 있다. 모델 체크포인팅 등 추가적인 기능 또한 제공.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/?gclid=CjwKCAiAhKycBhAQEiwAgf19euf21xRE6IFNBHwFXUSdIUSJu5-q_H8dscz8q1AeULry-_1pOeBGyBoCWO8QAvD_BwE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorFlow&lt;/a&gt; 의 경우 브라우저에서 딥러닝을 실행할 수 있는 TensorFlow.js, 쉽게 딥러닝 개발이 가능한 Keras 등의 파생 제품을 가지고있다.&lt;/li&gt;
&lt;li&gt;이외의 옵션으로는 &lt;a class=&#34;link&#34; href=&#34;https://www.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FasiAI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/google/jax&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JAX&lt;/a&gt; 등이 있으며, 이들 라이브러리를 사용할 구체적인 이유가 있지않다면 비추천.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대부분의 ML 프로젝트는 이미 배포/개발된 모델 구조를 기반으로 시작하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://onnx.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ONNX&lt;/a&gt; 는 딥러닝 모델을 저장하는 표준 방식을 제공하는 패키지이며, PyTorch 에서 Tensorflow 등으로의 모델 변환을 가능하게 한다. 잘 작동하는 경우도 있지만, 모든 경우의 수를 감안하지는 못한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huggingface&lt;/a&gt; 는 최근 가장 떠오르는 모델 저장소이다. NLP 라이브러리로 시작했지만, 오디오/이미지 분류 등의 다양한 분야로 확장했으며 약 60,000 개의 사전 학습 모델, 7,500 개의 데이터셋을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://timm.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TIMM&lt;/a&gt; 은 최신 비전 모델을 중점적으로 제공하는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;distributed-training&#34;&gt;Distributed Training&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;다수의 GPU 를 내장한, 다수의 PC 에서 모델 학습이 가능한 환경에 있다고 가정하자. &lt;strong&gt;(1) 데이터 배치&lt;/strong&gt;와 &lt;strong&gt;(2) 모델 파라미터&lt;/strong&gt; 를 GPU 에 분산하여 처리하게 되며, 데이터 배치가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도, 모델 파라미터가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도 있다.&lt;/li&gt;
&lt;li&gt;베스트 케이스는 데이터 배치와 모델 파라미터가 모두 한 개의 GPU 에 담길 수 있는 경우이다. 이와 같은 경우를 &lt;strong&gt;Trivial Parallelism&lt;/strong&gt; 이라 부르며, 다른 GPU/PC 에서 독립적인 학습을 수행할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델 파라미터가 한 개 GPU 에 담기나, 데이터 배치가 담기지 않는 경우 &lt;strong&gt;Data Parallelism&lt;/strong&gt; 을 수행할 수 있다. 즉, 단일 배치의 데이터를 여러대의 GPU 에 분산한 후 모델에 의해 연산된 gradient 의 평균값을 구하는 것이다.&lt;/li&gt;
&lt;li&gt;A100 등의 서버 카드를 활용한다며 연산 속도가 선형적으로 증가하며, 3090 과 같은 소비자용 카드 활용시 이보다 효율성이 떨어진다.&lt;/li&gt;
&lt;li&gt;PyTorch 라이브러리는 Data Parallelism 을 구현한 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistributedDataParallel&lt;/a&gt; 라이브러리를 제공한다. 써드파티 라이브러리로는 &lt;a class=&#34;link&#34; href=&#34;https://horovod.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Horovod&lt;/a&gt; 같은 옵션이 있으며, PyTorch Lightning 을 활용한다면 이 두 라이브러리 활용이 더욱 쉬워진다. 두 개 라이브러리의 성능은 서로 유사한 편이다.&lt;/li&gt;
&lt;li&gt;이보다 복잡한 경우는 모델 파라미터가 한 개 GPU 에 담기지 않는 경우인데, 이 경우 대표적으로 세가지의 솔루션, (1) Sharded Data Parallelism, (2) Pipelined Model Parallelism, (3) Tensor Parallelism, 이 존재한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sharded Data Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sharded 데이터 분산 처리는 GPU 메모리를 차지하는 요소인 (1) 모델 파라미터, (2) 미분값, (3) 옵티마이저 기록, (4) 데이터 배치를 모두 분산하여 다수의 GPU 메모리를 효율적으로 운영하는 방법이다.&lt;/li&gt;
&lt;li&gt;Microsoft 의 ZeRO 라는 방법론으로 처음 고안되었고, 기존 방식과 대비해 약 10배 큰 배치 사이즈를 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;Microsoft DeepSpeed, Facebook FairScale 등의 라이브러리가 존재하며, PyTorch 또한 기본적으로 Fully Sharded DataParallel 기능을 제공한다.&lt;/li&gt;
&lt;li&gt;ZeRO 접근법은 한 대의 GPU 에 적용될 수 있다 (분산된 데이터를 순차적으로 처리).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pipelined Model Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델의 각 레이어를 개별적인 GPU 에 분산시키는 방식이다. 어렵지 않게 구현이 가능하지만 별도의 패키지를 활용하지 않는다면 각 단계에서 하나의 GPU 만 활용하게 되기에 효율적이지 않다.&lt;/li&gt;
&lt;li&gt;DeepSpeed 와 FairScale 같은 라이브러리는 연산 스케줄링을 통해 모든 GPU 가 한꺼번에 동작하도록 설정이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tensor Parallelism 은 연산 대상 행렬을 다수의 GPU 에 분산하는 접근법이다. NVIDIA 에서 배포한 Megatron-LM repo 는 이러한 분산 방식을 Transformer 모델에 적용했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT3 규모의 모델을 핸들링해야 한다면 언급한 3가지의 분산 처리 기법을 함께 사용하는 것 또한 가능하다. 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/bloom-megatron-deepspeed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BLOOM 학습&lt;/a&gt; 관련 자료를 참고.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;compute&#34;&gt;Compute&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지난 10년 간 발전된 ML 모델이 요구하는 연산 자원은 빠른 속도로 성장했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모델의 효율적인 학습을 위해선 GPU 활용은 필수적이다. 제조사 중 가장 큰 영향력을 행사하는 기업은 NVIDIA 이지만, Google 또한 자체적으로 설계/생산한 TPU 를 Google Cloud 를 통해 제공한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 선택할땐 다음의 3가지 고민이 필요하다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;한번에 얼마나 많은 데이터를 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;데이터를 얼마나 빠르게 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;CPU 와 GPU 간 통신 속도는 어느정도인가? 다수의 GPU 간 통신 속도는 어느정도인가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;개선된 성능의 최신 GPU 구조는 거의 매년 소개되고 있다. 이러한 GPU 들은 소비자용과 기업용으로 나눌 수 있는데, 기업 환경에서는 항상 서버 카드를 사용해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 평가하는 2가지 중요한 지표는 RAM 과 Tensor TFlops 이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RAM 이 더 큰 GPU 는 상대적으로 더 많은 모델 파라미터와 데이터를 처리할 수 있다.&lt;/li&gt;
&lt;li&gt;Tensor TFlops 란 NVIDIA 에서 개발한 딥러닝 전용 GPU 코어를 뜻한다. Mixed Precision 연산, 즉 연산 성격에 따라 16bit 와 32bit 부동소수점 (floating point) 타입을 적절히 혼용하여 연산 속도와 사용 용량을 개선하는 작업에 최적화 되어있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/gpu-benchmarks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.aime.info/en/blog/deep-learning-gpu-benchmarks-2021/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AIME&lt;/a&gt; 과 같은 업체는 실사용 환경에 기반한 벤치마크 자료를 제공한다. NVIDIA A100 은 기존 V100 보다 2.5 배 정도 빠르며, RTX 칩 또한 V100 을 상회하는 성능을 보여준다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대형 클라우드 서비스인 Microsoft Azure, Google Cloud Platfrom, Amazon Web Services 등이 이러한 GPU 연산 자원을 이용할 수 있는 가장 기본적인 장소이며, 유사한 스타트업 서비스인 &lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.coreweave.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CoreWeave&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt; 또한 참고할 만 하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TPU 의 경우 현재 4세대 까지 발전한 상태이며, 딥러닝을 위한 최적의 하드웨어이다. 상단의 그래프는 TPU 와 NVIDIA A100 의 성능을 비교한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;클라우드 서비스를 활용한 GPU 가용 비용은 미리 계산하기 까다로운 측면이 있기에 FSDL 팀은 이러한 문제를 해결하기 위한 &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/cloud-gpus/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GPU Cost Metric&lt;/a&gt; 툴을 공개했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;성능/비용을 함께 고려했을때 고성능 GPU 는 시간당 비용이 비싸더라도 전체 학습 관점에서 비용을 절감하는 효과를 가질 수 있다. 예를 들어 동일한 트랜스포머 학습 시 4개의 V100 GPU 에서 72시간 동안 1,750 달러의 비용이 발생하지만, 4개의 A100 GPU 에선 8시간 동안 250 달러의 비용만 발생한다. 때문에 무조건 단가가 싼 GPU 를 활용하기 보다는 이러한 비용 절감 요소를 고려해 자원을 선택할 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음과 같은 룰이 이러한 자원 선택 과정에 도움을 줄 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;가장 저렴한 클라우드 서비스에서 시간당 비용이 가장 비싼 GPU 활용&lt;/strong&gt;할 것.&lt;/li&gt;
&lt;li&gt;Paperspace 와 같은 &lt;strong&gt;스타트업은 메이저 클라우드 사업자 대비 저렴한 비용으로 GPU 자원 제공&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 자원을 활용한다면 조립 PC 를 구축하거나, NVIDIA 와 같은 제조사에서 판매하는 딥러닝용 PC 를 구매할 수 있다. 128 GB 램, 2개의 RTX 3090 이 탑재된 PC 를 약 7,000 달러 정도에 구축할 수 있으며, 이보다 향상된 성능이 필요하다면 Lambda Labs 에서 판매하는 60,000 달러 학습용 PC 와 같은 옵션이 있다 (8개의 A100 탑재).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 vs. 클라우드&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU 자원을 소유하고 있다면 &lt;strong&gt;비용을 최소화한다는 관점보다는 활용도를 최대화한다는 관점에서 문제 접근이 가능&lt;/strong&gt;하다.&lt;/li&gt;
&lt;li&gt;스케일 아웃을 지향한다면, 가장 저렴한 클라우드 사업자를 이용하는 편이 맞다.&lt;/li&gt;
&lt;li&gt;연산 부담이 큰 작업이라면 TPU 활용을 진지하게 고려해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;resource-management&#34;&gt;Resource Management&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;다수의 연산 자원이 확보되었다면 해당 자원들을 어떻게 관리/운영 할 것인지에 대한 고민 또한 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단일 자원 환경에선 &lt;a class=&#34;link&#34; href=&#34;https://python-poetry.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;poetry&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://docs.conda.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;conda&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://pypi.org/project/pip-tools/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;pip-tools&lt;/a&gt; 와 같은 패키지 매니저 / 가상환경을 활용해 쉽게 분석 환경을 설정할 수 있다. 이에 반해 다수의 자원을 활용할 때에는 &lt;a class=&#34;link&#34; href=&#34;https://slurm.schedmd.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SLURM&lt;/a&gt; 과 같은 리소스 매니저 활용이 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;휴대성/이식성을 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://www.docker.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker&lt;/a&gt; 를 통해 가볍게 모든 디펜던시 스택을 패키징할 수 있다. 자원 클러스터에서 다수의 Docker 컨테이너를 운영하기 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes&lt;/a&gt; 와 같은 툴이 필요하며, &lt;a class=&#34;link&#34; href=&#34;https://www.kubeflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubeflow&lt;/a&gt; 는 Kubernetes 에 기반한 ML 프로젝트 운영을 돕는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;자원 클러스터 구축을 위한 옵션은 다음과 같다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS 를 활용한다면 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/pm/sagemaker/?trk=83e980bd-feef-4dc8-827c-21089d3b5592&amp;amp;sc_channel=ps&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&amp;amp;ef_id=Cj0KCQiA7bucBhCeARIsAIOwr-8hHn1JQyePYZvkT7YpagXav6_7hAP7L8afpmbCQJ-oRYxKnSnwpooaArmfEALw_wcB:G:s&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sagemaker&lt;/a&gt; 를 통해 데이터 레이블링 부터 모델 배포 까지의 과정을 모두 마칠 수 있다. Sagemaker 는 AWS 에만 존재하는 많은 설정값을 가진다는 단점이 있지만, 학습을 위한 수많은 학습 알고리즘을 제공하고 있다. 약간의 추가 비용이 발생하지만, PyTorch 또한 점차 지원하고 있는 추세이다.&lt;/li&gt;
&lt;li&gt;Anyscale 의 &lt;a class=&#34;link&#34; href=&#34;https://docs.ray.io/en/latest/train/train.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ray Train&lt;/a&gt; 은 Sagemaker 와 유사한 형태의 자원 클러스터 구축 도구이다. 하지만 비용이 다소 비싸다는 단점이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined.AI&lt;/a&gt; 는 온프레미스와 클라우드 클러스터를 관리하는 툴이다. 분산 학습 등의 기능을 지원하며, 계속 개발이 진행되고 있는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다양한 클라우드 자원을 관리하는 작업은 난이도가 있고, 아직 개선의 여지가 존재하는 영역이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiment-and-model-management&#34;&gt;Experiment and Model Management&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;연산 자원 관리와는 달리, 학습 모니터링은 체계확립이 거의 완료된 영역이다. 학습 모니터링이란 모델 개발과정에서 변동하는 코드, 모델 파라미터, 데이터 셋에 대한 관리를 뜻하며, 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/tensorboard&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorBoard&lt;/a&gt; : 구글이 개발한 단발적인 학습 모니터링 툴이며, 다수의 학습을 체계적으로 관리하기 어려운 측면이 존재.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mlflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLFlow&lt;/a&gt; : Databricks 에서 개발한 모델 패키징, 학습 모니터링 툴이며, self-hosting 이 필수적이다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=Performance-Max&amp;amp;utm_content=site&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=%7bcampaign%7d&amp;amp;utm_term=&amp;amp;utm_content=%7bcontent%7d&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr-9FBRDAmcSqE8zwkd1LTzevHny63DrOR_97Q19FVD_PdFLTC07m5SAaAiXHEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Weights and Biases&lt;/a&gt; : 개인적, 학업적 사용은 무료이며, &amp;ldquo;experiemnt config&amp;rdquo; 커맨드를 통해 학습 내용을 로그에 기록할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://neptune.ai/?utm_source=googleads&amp;amp;utm_medium=googleads&amp;amp;utm_campaign=[SG][HI][brand][rsa][all]&amp;amp;utm_term=neptune%20ai&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr--0uGPxuUEQLd9BHDlEAYPhIiF0-C-HvyadckWhW_3GCfg3ZCyeC0oaAsJxEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Neptune AI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.comet.com/site/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Comet ML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined AI&lt;/a&gt; 또한 연관 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;상단에 언급된 다수의 툴은 Hyperparameter Optimization 기능을 제공한다. 모델 튜닝을 효율적으로 수행하는데 도움을 주는데, 예를 들어 Weights and Biases 의 &lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site/sweeps&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sweeps&lt;/a&gt; 같은 기능이 이 역할을 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;all-in-one&#34;&gt;&amp;ldquo;All-In-One&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;학습 모니터링, 분산 처리, 배포, 스케일링 등 언급된 모든 기능을 수행하는 인프라 솔루션 또한 존재하는데, 그 가격이 상당한 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/gradient&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradient by Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.dominodatalab.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Domino Data Lab&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/sagemaker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Sagemaker&lt;/a&gt; 와 같은 옵션이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Week 1</title>
        <link>https://meme2515.github.io/mlops/fsdl_1/</link>
        <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl_1/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_4.png" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Week 1" /&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=-Iob-FW5jVM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-1-course-vision-and-when-to-use-ml/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/18EVuJpnJ9z5Pz7oRYcgax_IzRVhbuAMC/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;course-vision&#34;&gt;Course Vision&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;FSDL 과정이 처음 시작한 2018년에는 규모가 큰 기업들만 ML 제품을 내놓고 있는 상태였으며, 이들 이외의 기업들은 ML로 부터 부가가치를 창출하기 어렵다는 생각이 업계 전반에 있었다.&lt;/li&gt;
&lt;li&gt;2022년 현재에는 트랜스포머의 등장으로 인해 NLP 분야가 더 많은 적용 사례들을 찾아내고 있고, 이외에도 많은 ML 제품들의 등장으로 MLOps 라는 단어가 사용되기 시작했다.&lt;/li&gt;
&lt;li&gt;물론 업계 전반이 더 성숙해졌고, 주요한 연구 실적 또한 있었지만, ML 제품 개발이 더욱 활성화된 주요한 이유는 &lt;strong&gt;선행학습이 완료된 모델이 점차 상품화되고 있다는 점&lt;/strong&gt;이다.
&lt;ul&gt;
&lt;li&gt;이제 HuggingFace 와 같은 툴을 이용하면 최신 NLP, 비전 모델을 코드 한두줄로 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;회사들은 학습된 모델을 네트워크를 통해 제공하기 시작했다.&lt;/li&gt;
&lt;li&gt;Keras, PyTorch Lightning 을 중심으로 유관한 프레임워크들이 표준화되기 시작했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI 분야는 항상 대중의 관심 속에 있어왔지만, 기대에 부흥하지 못한 실용성으로 지난 수십년간 굴곡을 겪어왔다. 분야가 다시 성장하고 있는 지금, 또다른 혹한기를 피하기 위해 관련 연구를 real-world 제품으로 승화시켜야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학계에서 다루는 ML 은 단차원적이다. 문제를 정의하고, 데이터를 수집하고, 정제한 다음 모델 개발 과정을 거쳐 잘 작동하는 ML 모델을 평가/보고함으로 과정이 끝난다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이에 반해 ML 제품은 배포 후 관리를 필요로한다. 실제 사용자들이 제품을 어떻게 경험하는지 관찰/측정한 후, 사용자들의 데이터에 기반한 data flywheel 을 만들어 모델을 고도화하게 된다.&lt;/li&gt;
&lt;li&gt;본 과정은 모델 학습을 넘어 &lt;strong&gt;좋은 ML 제품을 만들기 위해 필요한 지식과 노하우를 전달한다&lt;/strong&gt;. 이러한 제품에 어떤 부분들이 있어야 하는지, 제품 개발에서 발생하는 문제 해결을 위한 접근법은 어떠한 것들이 있는지 등을 가르친다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;MLOps 란 지난 몇년간 새로 등장한 분야이며, ML 시스템에 대한 배포, 유지, 운영에 관한 개념을 다룬다. 통제/반복 가능한 환경에서 모델을 구축하는 법, high scale 세팅에서 시스템을 운영하는 법, 시스템 유지를 위해 팀이 협업하는 법 등을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 기반 제품&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ML 기반 제품이란 이와 유사성을 가진 개념이나, 완전히 같다고 볼 수 없다. 좋은 제품 개발은 운영 이외의 분야에 대한 깊은 생각을 필요로하고, 최종 제품에서 ML 이 어떠한 역할을 하는지에 집중하게 된다. 유저가 제품을 사용하면서 어떠한 경험을 가지는지, 조직과 효율적으로 협업하는 방법은 무엇인지, ML 분야의 프로덕트 매니징은 어떻게 이루어지는지 등의 개념을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;본 과정은 좋은 ML 기반 제품을 만들기 위한 end-to-end 과정을 가르치며, 이에 필요한 기본적인 MLOps 개념만을 전달한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;when-to-use-machine-learning&#34;&gt;When To Use Machine Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML 프로젝트는 일반적인 소프트웨어 개발보다 높은 실패율을 보인다.&lt;/strong&gt; 많은 적용 분야에서 ML 이란 아직 연구 단계에 있기 때문이며, 때문에 100% 성공을 목표로 할 수는 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외에도 ML 프로젝트가 실패하는 이유 중 대표적인 예시는 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;기술적으로 불가능하거나 스코프 설정이 잘못되었기 때문&lt;/li&gt;
&lt;li&gt;제품화로의 도약을 이루지 못하기 때문&lt;/li&gt;
&lt;li&gt;조직적으로 ML 프로젝트 성공의 기준을 정하지 못했기 때문&lt;/li&gt;
&lt;li&gt;문제 해결을 이루어냈으나, 복잡성에 비례한 정당성을 가지지 못했기 때문&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 ML 프로젝트를 시작하기 전, 다음과 같은 질문을 할 필요가 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML을 활용할 준비가 되었는가?&lt;/strong&gt; 구체적으로는 적용할 제품이 있는가? 이미 데이터를 활용 가능한 방식으로 수집하고 있는가? 적절한 인력을 보유하고 있는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제를 해결하기 위해 정말 ML이 필요한가?&lt;/strong&gt; 문제는 애초에 해결되어야 하는 것인가? 룰베이스 혹은 간단한 통계학을 통한 문제 해결이 가능하진 않은가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML의 활용이 윤리적으로 올바른가?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모든 분야의 프로젝트와 같이, 적절한 ML 프로젝트 선정을 위해선 &lt;strong&gt;큰 임팩트&lt;/strong&gt;와 &lt;strong&gt;적은 비용&lt;/strong&gt;을 가진 유즈케이스 선정이 필요하다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;큰 임팩트란 ML 이 서비스 파이프라인의 복잡한 구조를 해결하거나, 간단한 예측이 큰 의미를 가지는 경우를 뜻한다. 업계에서 ML 을 어떻게 활용하고 있는지 또한 좋은 지표가 될 수 있다.&lt;/li&gt;
&lt;li&gt;적은 비용이란 데이터의 이미 존재하거나, 잘못된 예측이 어느정도 허용되는 경우를 말한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;큰 임팩트를 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML 활용이 상대적 경제성을 가지는 경우.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;제품이 필요로 하는 것이 무엇인지를 고민해야 한다.&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://spotify.design/article/three-principles-for-designing-ml-powered-products&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spotify - Discover Weekly 를 구현하면서 세운 3가지 원칙&lt;/a&gt; 참조.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 이 특히 잘하는 것이 무엇인가를 생각.&lt;/strong&gt; 시스템에 복잡하고 수동적으로 정의된 부분이 있다면 ML 적용이 큰 도움이 될 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;업계에서 ML 이 어떤 문제를 해결하고 있는지를 참고.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;적은 비용을 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;데이터 유무를 파악.&lt;/strong&gt; 새로운 데이터를 확보하는 것은 얼마나 어려운지, 데이터 레이블링은 어느정도의 비용이 드는지, 얼마나 많은 데이터가 필요할 것인지, 데이터는 얼마나 정적인지, 어떠한 보안 규제가 존재하는지 등.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델 정확도의 중요성을 고려.&lt;/strong&gt; 잘못된 예측으로 인한 비용은 어느정도인지, 실용성을 위해 모델의 정확도는 어느 정도여야 하는지를 파악해야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제의 난이도에 대한 고민.&lt;/strong&gt; ML 활용으로 해결될 문제는 얼마나 잘 정의되었는지, 관련 주제에 대한 논의가 충분히 존재하는지, 연산 자원은 얼마나 필요한지 등.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML이 어려워하는 대표적 문제들&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;결과값이 복잡한 경우.&lt;/strong&gt; 예측치의 정의가 불확실하거나, 고차원의 형상을 다루는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;높은 정확도를 요구하는 경우.&lt;/strong&gt; ML 모델은 예상치 못한 부분에서 실패하기 때문에, 일정 수준 이상의 정확도를 요구하는 경우 ML 적용이 적절하지 않을 수 있음.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;일반화가 필요한 경우.&lt;/strong&gt; 통계치에서 벗어난 데이터에 대한 예측을 요구하거나, 논리/계획을 세우거나 인과관계를 판단하는 작업을 요구하는 경우.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;같은 ML 프로젝트라 할지라도 프로젝트의 성격에 따라 계획 과정은 판이하게 달라진다. 관련한 방법론을 수립하기 위해 강사진은 다음과 같은 3가지 카테고리로 ML 제품을 구분한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Software 2.0&lt;/strong&gt; : 전통적인 소프트웨어에 머신러닝을 적용하는 경우이다. 코드 작성 AI 인 Github Copilot 을 예시로 들 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human-in-the-loop&lt;/strong&gt; : ML 시스템이 사람의 의사결정 체계를 돕거나, 효율성을 향상시키는 경우를 말한다. 단순한 스케치를 기반으로 PPT 슬라이드를 생성하는 등의 예시를 들 수 있으며, 이 경우 모델 아웃풋의 품질을 사람이 확인하는 과정이 수반된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autonomous Systems&lt;/strong&gt; : ML 을 활용해 사람이 개입할 필요가 없는 완전한 자동화 시스템을 구축하는 경우이다. 자율주행 등을 예시로 들 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 의 경우, &lt;strong&gt;ML 적용이 실제 성능 개선에 도움이 되는지&lt;/strong&gt;를 꼼꼼하게 점검해 볼 필요가 있다. 또한 서비스 배포 후 data flywheel, 즉 신규 데이터를 기반으로 모델을 개선시킬 수 있는 사이클이 구축될 수 있는지 또한 검토가 필요하다.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 &lt;strong&gt;사용자가 어떠한 배경, 환경을 가지고 모델을 활용하는지&lt;/strong&gt;를 염두해야 하며, &lt;strong&gt;그들의 니즈 또한 파악&lt;/strong&gt;할 필요가 있다. 유저에게 실질적인 도움을 제공하려면 어느 정도 수준의 성능을 보여야 하는지 등을 고려해야 한다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 &lt;strong&gt;실패율과 그에 따른 결과&lt;/strong&gt;에 집중할 필요가 있다. 사람이 개입할 여지가 없다면 실패 케이스들을 면밀하게 주시해야 하며, 자율주행이 이에 대한 좋은 예시라고 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;언급했듯 Software 2.0 프로젝트 내에선 data flywheel 개념을 곱씹을 필요가 있다. 경우에 따라 차이가 존재할 수 있지만, 대체로 유저의 데이터를 수집하여 모델 개선에 활용한다면 성능이 서비스 기간이 지남에 따라 개선될 가능성이 높다.&lt;/li&gt;
&lt;li&gt;data flywheel 을 구축하기 전, 다음과 같은 3가지 질문에 대한 답이 필요하다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 loop 이 존재하는가?&lt;/strong&gt; Data flywheel 을 구축하기 위해서는 정제된 데이터를 스케일링이 가능한 방식으로 유저로 부터 수집할 수 있어야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;더 많은 데이터가 더 나은 모델과 상응하는가?&lt;/strong&gt; 모델러의 역량과는 별개로 문제 특성상 더 많은 데이터가 더 나은 모델을 의미하지 않는 경우가 발생할 수 있다. data flywheel 시스템 구축 전 더 많은 데이터가 가치를 전달하는지를 확실히 해 둘 필요가 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델의 성능이 제품 활용성에 기여하는가?&lt;/strong&gt; 보다 근본적인 질문인데, 모델의 성능 개선이 유저의 경험에 긍정적으로 기여할 수 있는지 또한 짚고 넘어가야 할 부분이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;상단 이미지는 &lt;strong&gt;영향성 vs. 실현 가능성&lt;/strong&gt; 그래프에서 정의된 3가지 타입의 과제가 상대적으로 어디에 위치해 있는지를 보여준다. 대체로 &lt;strong&gt;모델을 구축하기 힘들수록 더 큰 영향을 끼친다&lt;/strong&gt;라는 규칙이 통용된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 는 data flywheel 구축을 통해 더 큰 영향력을 가질 수 있다. 모델의 성능이 증가하며, 이로 인한 사용자의 경험이 계속 개선되기 때문.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 충분한 고민이 반영된 설계 과정, 혹은 적절한 단계에서 배포 후 점차 성능을 개선시킨다는 &amp;ldquo;good enough&amp;rdquo; 마인드 셋이 제품에 대한 기대치와 목표 성능을 낮추는데 도움을 줄 수 있다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 사람의 개입을 유도해 모델의 실패에 대비하는 체계가 도움을 줄 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 결국 엔지니어링의 가장 중요한 측면은 &lt;strong&gt;무언가를 만드는 일&lt;/strong&gt;이다. 우리는 Google, Uber 와 항상 같은 환경을 구축할 필요가 없으며, 최신 툴과 완벽한 체계를 추구하기 전 먼저 문제에 대한 해결책을 찾는 것이 핵심이라는 점을 상기해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lifecycle&#34;&gt;Lifecycle&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 프로젝트가 계획적/단계적으로 진행되기엔 현실적으로 어려운 부분이 많으며, 중간 과정에서 발견된 인사이트로 인해 이전 단계의 작업을 번복하거나, 성능 요건을 재정의 하는 등 단계 별 작업이 병렬적으로 진행되는 경향이 있다.&lt;/li&gt;
&lt;li&gt;본 부트캠프는 이러한 프로젝트 lifecycle 의 각 단계를 가급적 성공적으로 수행하는 방법을 전달하고, 채용, 인프라 등 프로젝트 외 요소들 또한 어떻게 다루어야 하는지 공유한다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Full Stack Deep Learning 2022 부트캠프 - Overview</title>
        <link>https://meme2515.github.io/mlops/fsdl/</link>
        <pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_title.jpg" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프 - Overview" /&gt;&lt;h2 id=&#34;부트캠프-소개-및-전반적인-느낌&#34;&gt;부트캠프 소개 및 전반적인 느낌&lt;/h2&gt;
&lt;p&gt;회사분의 소개로 2022년 코호트의 일환이 되었다. Early Registration 으로 495 달러인 참가비보다 약간 저렴한 300 달러를 지불했고, 돈을 내면서 까지 참가하고 싶다는 생각이 들기까지는 카일님의 블로그에 올라온 &lt;a class=&#34;link&#34; href=&#34;https://zzsza.github.io/mlops/2019/10/06/fullstack-deeplearning-bootcamp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;긍정적인 리뷰&lt;/a&gt;가 중요한 역할을 했던 것 같다.&lt;/p&gt;
&lt;p&gt;실용적인 ML을 추구하기 때문에 강사진의 업계 경험 및 배경 또한 중요하다고 생각했다. 강사진은 버클리 대학에서 박사과정을 마친 이력을 공유하고 있고, Weights &amp;amp; Biases, OpenAI 등의 기업에서의 실무 경험을 가지고있다. 개별적인 강사진의 공개된 이력은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/charles-frye-38654abb/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Charles Frye&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Chicago 학부 졸업 (Computational Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;Weights &amp;amp; Biases 2년 근무&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/sergeykarayev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sergey Karayev&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Washington 학부 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;Turnitin 2년 근무 (교육 관련 소프트웨어 개발사)&lt;/li&gt;
&lt;li&gt;GSV Ventures 3년 근무 (벤처 캐피탈)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/josh-tobin-4b3b10a9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Josh Tobin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Columbia University 학부 졸업 (Mathematics 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;McKinsey &amp;amp; Company 2년 근무&lt;/li&gt;
&lt;li&gt;OpenAI 3년 근무&lt;/li&gt;
&lt;li&gt;Gantry 창업 (ML 스타트업)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://meme2515.github.io/mlops/fsdl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FSDL 2022 Course Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_1/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 1 - When to Use ML and Course Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 2 - Development Infrastureture &amp;amp; Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_4/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 4 - Data Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 5 - Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_6/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 6 - Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_7/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 7 - Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 8 - ML Teams and Project Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://meme2515.github.io/mlops/fsdl_9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture 9 - Ethics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
