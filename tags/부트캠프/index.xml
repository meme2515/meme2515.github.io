<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>부트캠프 on Soon Hyung Kwon</title>
        <link>https://meme2515.github.io/tags/%EB%B6%80%ED%8A%B8%EC%BA%A0%ED%94%84/</link>
        <description>Recent content in 부트캠프 on Soon Hyung Kwon</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 27 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://meme2515.github.io/tags/%EB%B6%80%ED%8A%B8%EC%BA%A0%ED%94%84/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Full Stack Deep Learning 2022 부트캠프</title>
        <link>https://meme2515.github.io/mlops/fsdl/</link>
        <pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_title.jpg" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프" /&gt;&lt;h2 id=&#34;부트캠프-소개-및-전반적인-느낌&#34;&gt;부트캠프 소개 및 전반적인 느낌&lt;/h2&gt;
&lt;p&gt;회사분의 소개로 2022년 코호트의 일환이 되었다. Early Registration 으로 495 달러인 참가비보다 약간 저렴한 300 달러를 지불했고, 돈을 내면서 까지 참가하고 싶다는 생각이 들기까지는 카일님의 블로그에 올라온 &lt;a class=&#34;link&#34; href=&#34;https://zzsza.github.io/mlops/2019/10/06/fullstack-deeplearning-bootcamp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;긍정적인 리뷰&lt;/a&gt;가 중요한 역할을 했던 것 같다.&lt;/p&gt;
&lt;p&gt;실용적인 ML을 추구하기 때문에 강사진의 업계 경험 및 배경 또한 중요하다고 생각했다. 강사진은 버클리 대학에서 박사과정을 마친 이력을 공유하고 있고, Weights &amp;amp; Biases, OpenAI 등의 기업에서의 실무 경험을 가지고있다. 개별적인 강사진의 공개된 이력은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/charles-frye-38654abb/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Charles Frye&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Chicago 학부 졸업 (Computational Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;Weights &amp;amp; Biases 2년 근무&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/sergeykarayev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sergey Karayev&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Washington 학부 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;Turnitin 2년 근무 (교육 관련 소프트웨어 개발사)&lt;/li&gt;
&lt;li&gt;GSV Ventures 3년 근무 (벤처 캐피탈)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/josh-tobin-4b3b10a9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Josh Tobin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Columbia University 학부 졸업 (Mathematics 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;McKinsey &amp;amp; Company 2년 근무&lt;/li&gt;
&lt;li&gt;OpenAI 3년 근무&lt;/li&gt;
&lt;li&gt;Gantry 창업 (ML 스타트업)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;h3 id=&#34;lecture-1---when-to-use-ml-and-course-vision&#34;&gt;Lecture 1 - When to Use ML and Course Vision&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=-Iob-FW5jVM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-1-course-vision-and-when-to-use-ml/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/18EVuJpnJ9z5Pz7oRYcgax_IzRVhbuAMC/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;course-vision&#34;&gt;Course Vision&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;FSDL 과정이 처음 시작한 2018년에는 규모가 큰 기업들만 ML 제품을 내놓고 있는 상태였으며, 이들 이외의 기업들은 ML로 부터 부가가치를 창출하기 어렵다는 생각이 업계 전반에 있었다.&lt;/li&gt;
&lt;li&gt;2022년 현재에는 트랜스포머의 등장으로 인해 NLP 분야가 더 많은 적용 사례들을 찾아내고 있고, 이외에도 많은 ML 제품들의 등장으로 MLOps 라는 단어가 사용되기 시작했다.&lt;/li&gt;
&lt;li&gt;물론 업계 전반이 더 성숙해졌고, 주요한 연구 실적 또한 있었지만, ML 제품 개발이 더욱 활성화된 주요한 이유는 &lt;strong&gt;선행학습이 완료된 모델이 점차 상품화되고 있다는 점&lt;/strong&gt;이다.
&lt;ul&gt;
&lt;li&gt;이제 HuggingFace 와 같은 툴을 이용하면 최신 NLP, 비전 모델을 코드 한두줄로 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;회사들은 학습된 모델을 네트워크를 통해 제공하기 시작했다.&lt;/li&gt;
&lt;li&gt;Keras, PyTorch Lightning 을 중심으로 유관한 프레임워크들이 표준화되기 시작했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI 분야는 항상 대중의 관심 속에 있어왔지만, 기대에 부흥하지 못한 실용성으로 지난 수십년간 굴곡을 겪어왔다. 분야가 다시 성장하고 있는 지금, 또다른 혹한기를 피하기 위해 관련 연구를 real-world 제품으로 승화시켜야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학계에서 다루는 ML 은 단차원적이다. 문제를 정의하고, 데이터를 수집하고, 정제한 다음 모델 개발 과정을 거쳐 잘 작동하는 ML 모델을 평가/보고함으로 과정이 끝난다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이에 반해 ML 제품은 배포 후 관리를 필요로한다. 실제 사용자들이 제품을 어떻게 경험하는지 관찰/측정한 후, 사용자들의 데이터에 기반한 data flywheel 을 만들어 모델을 고도화하게 된다.&lt;/li&gt;
&lt;li&gt;본 과정은 모델 학습을 넘어 &lt;strong&gt;좋은 ML 제품을 만들기 위해 필요한 지식과 노하우를 전달한다&lt;/strong&gt;. 이러한 제품에 어떤 부분들이 있어야 하는지, 제품 개발에서 발생하는 문제 해결을 위한 접근법은 어떠한 것들이 있는지 등을 가르친다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;MLOps 란 지난 몇년간 새로 등장한 분야이며, ML 시스템에 대한 배포, 유지, 운영에 관한 개념을 다룬다. 통제/반복 가능한 환경에서 모델을 구축하는 법, high scale 세팅에서 시스템을 운영하는 법, 시스템 유지를 위해 팀이 협업하는 법 등을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 기반 제품&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ML 기반 제품이란 이와 유사성을 가진 개념이나, 완전히 같다고 볼 수 없다. 좋은 제품 개발은 운영 이외의 분야에 대한 깊은 생각을 필요로하고, 최종 제품에서 ML 이 어떠한 역할을 하는지에 집중하게 된다. 유저가 제품을 사용하면서 어떠한 경험을 가지는지, 조직과 효율적으로 협업하는 방법은 무엇인지, ML 분야의 프로덕트 매니징은 어떻게 이루어지는지 등의 개념을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;본 과정은 좋은 ML 기반 제품을 만들기 위한 end-to-end 과정을 가르치며, 이에 필요한 기본적인 MLOps 개념만을 전달한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;when-to-use-machine-learning&#34;&gt;When To Use Machine Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML 프로젝트는 일반적인 소프트웨어 개발보다 높은 실패율을 보인다.&lt;/strong&gt; 많은 적용 분야에서 ML 이란 아직 연구 단계에 있기 때문이며, 때문에 100% 성공을 목표로 할 수는 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외에도 ML 프로젝트가 실패하는 이유 중 대표적인 예시는 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;기술적으로 불가능하거나 스코프 설정이 잘못되었기 때문&lt;/li&gt;
&lt;li&gt;제품화로의 도약을 이루지 못하기 때문&lt;/li&gt;
&lt;li&gt;조직적으로 ML 프로젝트 성공의 기준을 정하지 못했기 때문&lt;/li&gt;
&lt;li&gt;문제 해결을 이루어냈으나, 복잡성에 비례한 정당성을 가지지 못했기 때문&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 ML 프로젝트를 시작하기 전, 다음과 같은 질문을 할 필요가 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML을 활용할 준비가 되었는가?&lt;/strong&gt; 구체적으로는 적용할 제품이 있는가? 이미 데이터를 활용 가능한 방식으로 수집하고 있는가? 적절한 인력을 보유하고 있는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제를 해결하기 위해 정말 ML이 필요한가?&lt;/strong&gt; 문제는 애초에 해결되어야 하는 것인가? 룰베이스 혹은 간단한 통계학을 통한 문제 해결이 가능하진 않은가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML의 활용이 윤리적으로 올바른가?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모든 분야의 프로젝트와 같이, 적절한 ML 프로젝트 선정을 위해선 &lt;strong&gt;큰 임팩트&lt;/strong&gt;와 &lt;strong&gt;적은 비용&lt;/strong&gt;을 가진 유즈케이스 선정이 필요하다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;큰 임팩트란 ML 이 서비스 파이프라인의 복잡한 구조를 해결하거나, 간단한 예측이 큰 의미를 가지는 경우를 뜻한다. 업계에서 ML 을 어떻게 활용하고 있는지 또한 좋은 지표가 될 수 있다.&lt;/li&gt;
&lt;li&gt;적은 비용이란 데이터의 이미 존재하거나, 잘못된 예측이 어느정도 허용되는 경우를 말한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;큰 임팩트를 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML 활용이 상대적 경제성을 가지는 경우.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;제품이 필요로 하는 것이 무엇인지를 고민해야 한다.&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://spotify.design/article/three-principles-for-designing-ml-powered-products&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spotify - Discover Weekly 를 구현하면서 세운 3가지 원칙&lt;/a&gt; 참조.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 이 특히 잘하는 것이 무엇인가를 생각.&lt;/strong&gt; 시스템에 복잡하고 수동적으로 정의된 부분이 있다면 ML 적용이 큰 도움이 될 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;업계에서 ML 이 어떤 문제를 해결하고 있는지를 참고.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;적은 비용을 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;데이터 유무를 파악.&lt;/strong&gt; 새로운 데이터를 확보하는 것은 얼마나 어려운지, 데이터 레이블링은 어느정도의 비용이 드는지, 얼마나 많은 데이터가 필요할 것인지, 데이터는 얼마나 정적인지, 어떠한 보안 규제가 존재하는지 등.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델 정확도의 중요성을 고려.&lt;/strong&gt; 잘못된 예측으로 인한 비용은 어느정도인지, 실용성을 위해 모델의 정확도는 어느 정도여야 하는지를 파악해야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제의 난이도에 대한 고민.&lt;/strong&gt; ML 활용으로 해결될 문제는 얼마나 잘 정의되었는지, 관련 주제에 대한 논의가 충분히 존재하는지, 연산 자원은 얼마나 필요한지 등.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML이 어려워하는 대표적 문제들&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;결과값이 복잡한 경우.&lt;/strong&gt; 예측치의 정의가 불확실하거나, 고차원의 형상을 다루는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;높은 정확도를 요구하는 경우.&lt;/strong&gt; ML 모델은 예상치 못한 부분에서 실패하기 때문에, 일정 수준 이상의 정확도를 요구하는 경우 ML 적용이 적절하지 않을 수 있음.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;일반화가 필요한 경우.&lt;/strong&gt; 통계치에서 벗어난 데이터에 대한 예측을 요구하거나, 논리/계획을 세우거나 인과관계를 판단하는 작업을 요구하는 경우.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;같은 ML 프로젝트라 할지라도 프로젝트의 성격에 따라 계획 과정은 판이하게 달라진다. 관련한 방법론을 수립하기 위해 강사진은 다음과 같은 3가지 카테고리로 ML 제품을 구분한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Software 2.0&lt;/strong&gt; : 전통적인 소프트웨어에 머신러닝을 적용하는 경우이다. 코드 작성 AI 인 Github Copilot 을 예시로 들 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human-in-the-loop&lt;/strong&gt; : ML 시스템이 사람의 의사결정 체계를 돕거나, 효율성을 향상시키는 경우를 말한다. 단순한 스케치를 기반으로 PPT 슬라이드를 생성하는 등의 예시를 들 수 있으며, 이 경우 모델 아웃풋의 품질을 사람이 확인하는 과정이 수반된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autonomous Systems&lt;/strong&gt; : ML 을 활용해 사람이 개입할 필요가 없는 완전한 자동화 시스템을 구축하는 경우이다. 자율주행 등을 예시로 들 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 의 경우, &lt;strong&gt;ML 적용이 실제 성능 개선에 도움이 되는지&lt;/strong&gt;를 꼼꼼하게 점검해 볼 필요가 있다. 또한 서비스 배포 후 data flywheel, 즉 신규 데이터를 기반으로 모델을 개선시킬 수 있는 사이클이 구축될 수 있는지 또한 검토가 필요하다.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 &lt;strong&gt;사용자가 어떠한 배경, 환경을 가지고 모델을 활용하는지&lt;/strong&gt;를 염두해야 하며, &lt;strong&gt;그들의 니즈 또한 파악&lt;/strong&gt;할 필요가 있다. 유저에게 실질적인 도움을 제공하려면 어느 정도 수준의 성능을 보여야 하는지 등을 고려해야 한다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 &lt;strong&gt;실패율과 그에 따른 결과&lt;/strong&gt;에 집중할 필요가 있다. 사람이 개입할 여지가 없다면 실패 케이스들을 면밀하게 주시해야 하며, 자율주행이 이에 대한 좋은 예시라고 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;언급했듯 Software 2.0 프로젝트 내에선 data flywheel 개념을 곱씹을 필요가 있다. 경우에 따라 차이가 존재할 수 있지만, 대체로 유저의 데이터를 수집하여 모델 개선에 활용한다면 성능이 서비스 기간이 지남에 따라 개선될 가능성이 높다.&lt;/li&gt;
&lt;li&gt;data flywheel 을 구축하기 전, 다음과 같은 3가지 질문에 대한 답이 필요하다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 loop 이 존재하는가?&lt;/strong&gt; Data flywheel 을 구축하기 위해서는 정제된 데이터를 스케일링이 가능한 방식으로 유저로 부터 수집할 수 있어야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;더 많은 데이터가 더 나은 모델과 상응하는가?&lt;/strong&gt; 모델러의 역량과는 별개로 문제 특성상 더 많은 데이터가 더 나은 모델을 의미하지 않는 경우가 발생할 수 있다. data flywheel 시스템 구축 전 더 많은 데이터가 가치를 전달하는지를 확실히 해 둘 필요가 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델의 성능이 제품 활용성에 기여하는가?&lt;/strong&gt; 보다 근본적인 질문인데, 모델의 성능 개선이 유저의 경험에 긍정적으로 기여할 수 있는지 또한 짚고 넘어가야 할 부분이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;상단 이미지는 &lt;strong&gt;영향성 vs. 실현 가능성&lt;/strong&gt; 그래프에서 정의된 3가지 타입의 과제가 상대적으로 어디에 위치해 있는지를 보여준다. 대체로 &lt;strong&gt;모델을 구축하기 힘들수록 더 큰 영향을 끼친다&lt;/strong&gt;라는 규칙이 통용된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 는 data flywheel 구축을 통해 더 큰 영향력을 가질 수 있다. 모델의 성능이 증가하며, 이로 인한 사용자의 경험이 계속 개선되기 때문.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 충분한 고민이 반영된 설계 과정, 혹은 적절한 단계에서 배포 후 점차 성능을 개선시킨다는 &amp;ldquo;good enough&amp;rdquo; 마인드 셋이 제품에 대한 기대치와 목표 성능을 낮추는데 도움을 줄 수 있다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 사람의 개입을 유도해 모델의 실패에 대비하는 체계가 도움을 줄 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 결국 엔지니어링의 가장 중요한 측면은 &lt;strong&gt;무언가를 만드는 일&lt;/strong&gt;이다. 우리는 Google, Uber 와 항상 같은 환경을 구축할 필요가 없으며, 최신 툴과 완벽한 체계를 추구하기 전 먼저 문제에 대한 해결책을 찾는 것이 핵심이라는 점을 상기해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;lifecycle&#34;&gt;Lifecycle&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 프로젝트가 계획적/단계적으로 진행되기엔 현실적으로 어려운 부분이 많으며, 중간 과정에서 발견된 인사이트로 인해 이전 단계의 작업을 번복하거나, 성능 요건을 재정의 하는 등 단계 별 작업이 병렬적으로 진행되는 경향이 있다.&lt;/li&gt;
&lt;li&gt;본 부트캠프는 이러한 프로젝트 lifecycle 의 각 단계를 가급적 성공적으로 수행하는 방법을 전달하고, 채용, 인프라 등 프로젝트 외 요소들 또한 어떻게 다루어야 하는지 공유한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-2---development-infrastructure--tooling&#34;&gt;Lecture 2 - Development Infrastructure &amp;amp; Tooling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=BPYOsDCZbno&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-2-development-infrastructure-and-tooling/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/16pEG5GesO4_UAWiD5jrIReMGzoyn165M/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;이상적인 ML 환경이란 &lt;strong&gt;정의된 프로젝트 목표와 샘플 데이터를 기반으로, 지속적으로 개선되는 예측 시스템을 큰 규모로 운영&lt;/strong&gt;하는 것이다.&lt;/li&gt;
&lt;li&gt;현실은 이와는 다를 수 밖에 없다. 데이터에 대한 &lt;strong&gt;수집, 처리, 레이블, 버저닝&lt;/strong&gt;이 필요하며, &lt;strong&gt;적합한 모델 구조와 사전 학습된 가중치&lt;/strong&gt;를 찾아야하고, 프로젝트에 적합하게 &lt;strong&gt;디버깅&lt;/strong&gt;해야 한다. 또한 여러 &lt;strong&gt;학습 과정을 기록 및 리뷰&lt;/strong&gt;해야하며, 모델 배포 후에도 끊임없이 생성되는 데이터를 기반으로 모델을 개선해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 환경의 3가지 주요한 컴포넌트는 &lt;strong&gt;데이터, 개발, 배포&lt;/strong&gt;이다. 각각의 컴포넌트는 방대한 툴을 가지고 있고, 3주간 강의를 통해 이들 모두를 전반적으로 살핀다. 본 강의의 주제는 개발이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;software-engineering&#34;&gt;Software Engineering&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;개발 언어의 경우 데이터 컴퓨팅 분야에선 현재 &lt;strong&gt;Python&lt;/strong&gt; 이 절대적인 우위를 점하고 있다. 너무나 많은 부속 라이브러리들이 개발되었기 때문이며, Julia, C/C++ 와 같은 경쟁자가 존재했지만 사실상 Python 이 생태계를 독점하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파이썬 코드를 작성하기 위해서는 에디터를 사용해야 한다. Vim, Emacs, Jupyter Notebook/Lab, PyCharm 등 수많은 옵션이 있지만 FSDL 팀이 제안하는 에디터는 &lt;strong&gt;VS Code&lt;/strong&gt; 이다. 내장된 Git 버전 컨트롤, docs peeking, 원격 접속, 린터, 디버깅 기능 등을 제공하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;수많은 현업들이 Jupyter Notebook 환경을 사용하지만, 에디터가 별다른 기능을 제공하지 못하고, 코드의 작성 순서가 중요하지 않으며, 버전 컨트롤, 테스팅이 어렵다는 문제를 가지고 있다. &lt;a class=&#34;link&#34; href=&#34;https://nbdev.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Nbdev&lt;/a&gt; 패키지를 활용하면 이러한 문제들은 어느 정도 해결은 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;deep-learning-frameworks&#34;&gt;Deep Learning Frameworks&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;딥러닝의 본질적인 요소인 행렬 연산은 사실 Numpy 정도의 라이브러리만으로 해결 가능하다. 하지만 CUDA 를 통한 GPU 자원 활용, 전통적이지 않은 형태의 레이어 구축, 옵티마이저/데이터 인터페이스 활용 등을 위해서는 딥러닝 프레임워크가 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PyTorch, TensorFlow, Jax 등 다양한 프레임워크들이 존재하며, 모델을 구축 한 후 배포 환경에 따라 최적화된 execution graph 를 찾는다는 점에서 근본적인 작동 원리는 서로 유사하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;강사진은 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch&lt;/a&gt; 를 선호하는데, 구현된 모델 수, 연관 논문 수, 대회 수상 모델 수 등에서 압도적인 우세를 보이기 때문이다. 2021년도만 하더라도 ML 대회 우승 모델의 약 77%가 PyTorch 를 사용했다.&lt;/li&gt;
&lt;li&gt;PyTorch 의 경우 TorchScript 등의 파생 제품을 이용하면 실행 속도가 더욱 빨라지며, 분산 처리, 비전, 오디오, 모바일 배포 환경등의 생태계를 이루고 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.pytorchlightning.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Lightning&lt;/a&gt; 을 PyTorch 와 함께 사용하면 코드를 보다 구조적으로 유지할 수 있으며, 어떠한 하드웨어에서도 코드를 실행할 수 있다. 모델 체크포인팅 등 추가적인 기능 또한 제공.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/?gclid=CjwKCAiAhKycBhAQEiwAgf19euf21xRE6IFNBHwFXUSdIUSJu5-q_H8dscz8q1AeULry-_1pOeBGyBoCWO8QAvD_BwE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorFlow&lt;/a&gt; 의 경우 브라우저에서 딥러닝을 실행할 수 있는 TensorFlow.js, 쉽게 딥러닝 개발이 가능한 Keras 등의 파생 제품을 가지고있다.&lt;/li&gt;
&lt;li&gt;이외의 옵션으로는 &lt;a class=&#34;link&#34; href=&#34;https://www.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FasiAI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/google/jax&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JAX&lt;/a&gt; 등이 있으며, 이들 라이브러리를 사용할 구체적인 이유가 있지않다면 비추천.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대부분의 ML 프로젝트는 이미 배포/개발된 모델 구조를 기반으로 시작하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://onnx.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ONNX&lt;/a&gt; 는 딥러닝 모델을 저장하는 표준 방식을 제공하는 패키지이며, PyTorch 에서 Tensorflow 등으로의 모델 변환을 가능하게 한다. 잘 작동하는 경우도 있지만, 모든 경우의 수를 감안하지는 못한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huggingface&lt;/a&gt; 는 최근 가장 떠오르는 모델 저장소이다. NLP 라이브러리로 시작했지만, 오디오/이미지 분류 등의 다양한 분야로 확장했으며 약 60,000 개의 사전 학습 모델, 7,500 개의 데이터셋을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://timm.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TIMM&lt;/a&gt; 은 최신 비전 모델을 중점적으로 제공하는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distributed-training&#34;&gt;Distributed Training&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;다수의 GPU 를 내장한, 다수의 PC 에서 모델 학습이 가능한 환경에 있다고 가정하자. &lt;strong&gt;(1) 데이터 배치&lt;/strong&gt;와 &lt;strong&gt;(2) 모델 파라미터&lt;/strong&gt; 를 GPU 에 분산하여 처리하게 되며, 데이터 배치가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도, 모델 파라미터가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도 있다.&lt;/li&gt;
&lt;li&gt;베스트 케이스는 데이터 배치와 모델 파라미터가 모두 한 개의 GPU 에 담길 수 있는 경우이다. 이와 같은 경우를 &lt;strong&gt;Trivial Parallelism&lt;/strong&gt; 이라 부르며, 다른 GPU/PC 에서 독립적인 학습을 수행할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델 파라미터가 한 개 GPU 에 담기나, 데이터 배치가 담기지 않는 경우 &lt;strong&gt;Data Parallelism&lt;/strong&gt; 을 수행할 수 있다. 즉, 단일 배치의 데이터를 여러대의 GPU 에 분산한 후 모델에 의해 연산된 gradient 의 평균값을 구하는 것이다.&lt;/li&gt;
&lt;li&gt;A100 등의 서버 카드를 활용한다며 연산 속도가 선형적으로 증가하며, 3090 과 같은 소비자용 카드 활용시 이보다 효율성이 떨어진다.&lt;/li&gt;
&lt;li&gt;PyTorch 라이브러리는 Data Parallelism 을 구현한 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistributedDataParallel&lt;/a&gt; 라이브러리를 제공한다. 써드파티 라이브러리로는 &lt;a class=&#34;link&#34; href=&#34;https://horovod.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Horovod&lt;/a&gt; 같은 옵션이 있으며, PyTorch Lightning 을 활용한다면 이 두 라이브러리 활용이 더욱 쉬워진다. 두 개 라이브러리의 성능은 서로 유사한 편이다.&lt;/li&gt;
&lt;li&gt;이보다 복잡한 경우는 모델 파라미터가 한 개 GPU 에 담기지 않는 경우인데, 이 경우 대표적으로 세가지의 솔루션, (1) Sharded Data Parallelism, (2) Pipelined Model Parallelism, (3) Tensor Parallelism, 이 존재한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sharded Data Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sharded 데이터 분산 처리는 GPU 메모리를 차지하는 요소인 (1) 모델 파라미터, (2) 미분값, (3) 옵티마이저 기록, (4) 데이터 배치를 모두 분산하여 다수의 GPU 메모리를 효율적으로 운영하는 방법이다.&lt;/li&gt;
&lt;li&gt;Microsoft 의 ZeRO 라는 방법론으로 처음 고안되었고, 기존 방식과 대비해 약 10배 큰 배치 사이즈를 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;Microsoft DeepSpeed, Facebook FairScale 등의 라이브러리가 존재하며, PyTorch 또한 기본적으로 Fully Sharded DataParallel 기능을 제공한다.&lt;/li&gt;
&lt;li&gt;ZeRO 접근법은 한 대의 GPU 에 적용될 수 있다 (분산된 데이터를 순차적으로 처리).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pipelined Model Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델의 각 레이어를 개별적인 GPU 에 분산시키는 방식이다. 어렵지 않게 구현이 가능하지만 별도의 패키지를 활용하지 않는다면 각 단계에서 하나의 GPU 만 활용하게 되기에 효율적이지 않다.&lt;/li&gt;
&lt;li&gt;DeepSpeed 와 FairScale 같은 라이브러리는 연산 스케줄링을 통해 모든 GPU 가 한꺼번에 동작하도록 설정이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tensor Parallelism 은 연산 대상 행렬을 다수의 GPU 에 분산하는 접근법이다. NVIDIA 에서 배포한 Megatron-LM repo 는 이러한 분산 방식을 Transformer 모델에 적용했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT3 규모의 모델을 핸들링해야 한다면 언급한 3가지의 분산 처리 기법을 함께 사용하는 것 또한 가능하다. 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/bloom-megatron-deepspeed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BLOOM 학습&lt;/a&gt; 관련 자료를 참고.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;compute&#34;&gt;Compute&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지난 10년 간 발전된 ML 모델이 요구하는 연산 자원은 빠른 속도로 성장했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모델의 효율적인 학습을 위해선 GPU 활용은 필수적이다. 제조사 중 가장 큰 영향력을 행사하는 기업은 NVIDIA 이지만, Google 또한 자체적으로 설계/생산한 TPU 를 Google Cloud 를 통해 제공한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 선택할땐 다음의 3가지 고민이 필요하다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;한번에 얼마나 많은 데이터를 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;데이터를 얼마나 빠르게 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;CPU 와 GPU 간 통신 속도는 어느정도인가? 다수의 GPU 간 통신 속도는 어느정도인가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;개선된 성능의 최신 GPU 구조는 거의 매년 소개되고 있다. 이러한 GPU 들은 소비자용과 기업용으로 나눌 수 있는데, 기업 환경에서는 항상 서버 카드를 사용해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 평가하는 2가지 중요한 지표는 RAM 과 Tensor TFlops 이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RAM 이 더 큰 GPU 는 상대적으로 더 많은 모델 파라미터와 데이터를 처리할 수 있다.&lt;/li&gt;
&lt;li&gt;Tensor TFlops 란 NVIDIA 에서 개발한 딥러닝 전용 GPU 코어를 뜻한다. Mixed Precision 연산, 즉 연산 성격에 따라 16bit 와 32bit 부동소수점 (floating point) 타입을 적절히 혼용하여 연산 속도와 사용 용량을 개선하는 작업에 최적화 되어있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/gpu-benchmarks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.aime.info/en/blog/deep-learning-gpu-benchmarks-2021/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AIME&lt;/a&gt; 과 같은 업체는 실사용 환경에 기반한 벤치마크 자료를 제공한다. NVIDIA A100 은 기존 V100 보다 2.5 배 정도 빠르며, RTX 칩 또한 V100 을 상회하는 성능을 보여준다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대형 클라우드 서비스인 Microsoft Azure, Google Cloud Platfrom, Amazon Web Services 등이 이러한 GPU 연산 자원을 이용할 수 있는 가장 기본적인 장소이며, 유사한 스타트업 서비스인 &lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.coreweave.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CoreWeave&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt; 또한 참고할 만 하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TPU 의 경우 현재 4세대 까지 발전한 상태이며, 딥러닝을 위한 최적의 하드웨어이다. 상단의 그래프는 TPU 와 NVIDIA A100 의 성능을 비교한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;클라우드 서비스를 활용한 GPU 가용 비용은 미리 계산하기 까다로운 측면이 있기에 FSDL 팀은 이러한 문제를 해결하기 위한 &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/cloud-gpus/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GPU Cost Metric&lt;/a&gt; 툴을 공개했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;성능/비용을 함께 고려했을때 고성능 GPU 는 시간당 비용이 비싸더라도 전체 학습 관점에서 비용을 절감하는 효과를 가질 수 있다. 예를 들어 동일한 트랜스포머 학습 시 4개의 V100 GPU 에서 72시간 동안 1,750 달러의 비용이 발생하지만, 4개의 A100 GPU 에선 8시간 동안 250 달러의 비용만 발생한다. 때문에 무조건 단가가 싼 GPU 를 활용하기 보다는 이러한 비용 절감 요소를 고려해 자원을 선택할 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음과 같은 룰이 이러한 자원 선택 과정에 도움을 줄 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;가장 저렴한 클라우드 서비스에서 시간당 비용이 가장 비싼 GPU 활용&lt;/strong&gt;할 것.&lt;/li&gt;
&lt;li&gt;Paperspace 와 같은 &lt;strong&gt;스타트업은 메이저 클라우드 사업자 대비 저렴한 비용으로 GPU 자원 제공&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 자원을 활용한다면 조립 PC 를 구축하거나, NVIDIA 와 같은 제조사에서 판매하는 딥러닝용 PC 를 구매할 수 있다. 128 GB 램, 2개의 RTX 3090 이 탑재된 PC 를 약 7,000 달러 정도에 구축할 수 있으며, 이보다 향상된 성능이 필요하다면 Lambda Labs 에서 판매하는 60,000 달러 학습용 PC 와 같은 옵션이 있다 (8개의 A100 탑재).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 vs. 클라우드&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU 자원을 소유하고 있다면 &lt;strong&gt;비용을 최소화한다는 관점보다는 활용도를 최대화한다는 관점에서 문제 접근이 가능&lt;/strong&gt;하다.&lt;/li&gt;
&lt;li&gt;스케일 아웃을 지향한다면, 가장 저렴한 클라우드 사업자를 이용하는 편이 맞다.&lt;/li&gt;
&lt;li&gt;연산 부담이 큰 작업이라면 TPU 활용을 진지하게 고려해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;resource-management&#34;&gt;Resource Management&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;다수의 연산 자원이 확보되었다면 해당 자원들을 어떻게 관리/운영 할 것인지에 대한 고민 또한 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단일 자원 환경에선 &lt;a class=&#34;link&#34; href=&#34;https://python-poetry.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;poetry&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://docs.conda.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;conda&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://pypi.org/project/pip-tools/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;pip-tools&lt;/a&gt; 와 같은 패키지 매니저 / 가상환경을 활용해 쉽게 분석 환경을 설정할 수 있다. 이에 반해 다수의 자원을 활용할 때에는 &lt;a class=&#34;link&#34; href=&#34;https://slurm.schedmd.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SLURM&lt;/a&gt; 과 같은 리소스 매니저 활용이 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;휴대성/이식성을 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://www.docker.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker&lt;/a&gt; 를 통해 가볍게 모든 디펜던시 스택을 패키징할 수 있다. 자원 클러스터에서 다수의 Docker 컨테이너를 운영하기 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes&lt;/a&gt; 와 같은 툴이 필요하며, &lt;a class=&#34;link&#34; href=&#34;https://www.kubeflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubeflow&lt;/a&gt; 는 Kubernetes 에 기반한 ML 프로젝트 운영을 돕는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;자원 클러스터 구축을 위한 옵션은 다음과 같다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS 를 활용한다면 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/pm/sagemaker/?trk=83e980bd-feef-4dc8-827c-21089d3b5592&amp;amp;sc_channel=ps&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&amp;amp;ef_id=Cj0KCQiA7bucBhCeARIsAIOwr-8hHn1JQyePYZvkT7YpagXav6_7hAP7L8afpmbCQJ-oRYxKnSnwpooaArmfEALw_wcB:G:s&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sagemaker&lt;/a&gt; 를 통해 데이터 레이블링 부터 모델 배포 까지의 과정을 모두 마칠 수 있다. Sagemaker 는 AWS 에만 존재하는 많은 설정값을 가진다는 단점이 있지만, 학습을 위한 수많은 학습 알고리즘을 제공하고 있다. 약간의 추가 비용이 발생하지만, PyTorch 또한 점차 지원하고 있는 추세이다.&lt;/li&gt;
&lt;li&gt;Anyscale 의 &lt;a class=&#34;link&#34; href=&#34;https://docs.ray.io/en/latest/train/train.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ray Train&lt;/a&gt; 은 Sagemaker 와 유사한 형태의 자원 클러스터 구축 도구이다. 하지만 비용이 다소 비싸다는 단점이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined.AI&lt;/a&gt; 는 온프레미스와 클라우드 클러스터를 관리하는 툴이다. 분산 학습 등의 기능을 지원하며, 계속 개발이 진행되고 있는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다양한 클라우드 자원을 관리하는 작업은 난이도가 있고, 아직 개선의 여지가 존재하는 영역이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;experiment-and-model-management&#34;&gt;Experiment and Model Management&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;연산 자원 관리와는 달리, 학습 모니터링은 체계확립이 거의 완료된 영역이다. 학습 모니터링이란 모델 개발과정에서 변동하는 코드, 모델 파라미터, 데이터 셋에 대한 관리를 뜻하며, 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/tensorboard&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorBoard&lt;/a&gt; : 구글이 개발한 단발적인 학습 모니터링 툴이며, 다수의 학습을 체계적으로 관리하기 어려운 측면이 존재.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mlflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLFlow&lt;/a&gt; : Databricks 에서 개발한 모델 패키징, 학습 모니터링 툴이며, self-hosting 이 필수적이다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=Performance-Max&amp;amp;utm_content=site&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=%7bcampaign%7d&amp;amp;utm_term=&amp;amp;utm_content=%7bcontent%7d&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr-9FBRDAmcSqE8zwkd1LTzevHny63DrOR_97Q19FVD_PdFLTC07m5SAaAiXHEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Weights and Biases&lt;/a&gt; : 개인적, 학업적 사용은 무료이며, &amp;ldquo;experiemnt config&amp;rdquo; 커맨드를 통해 학습 내용을 로그에 기록할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://neptune.ai/?utm_source=googleads&amp;amp;utm_medium=googleads&amp;amp;utm_campaign=[SG][HI][brand][rsa][all]&amp;amp;utm_term=neptune%20ai&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr--0uGPxuUEQLd9BHDlEAYPhIiF0-C-HvyadckWhW_3GCfg3ZCyeC0oaAsJxEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Neptune AI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.comet.com/site/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Comet ML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined AI&lt;/a&gt; 또한 연관 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;상단에 언급된 다수의 툴은 Hyperparameter Optimization 기능을 제공한다. 모델 튜닝을 효율적으로 수행하는데 도움을 주는데, 예를 들어 Weights and Biases 의 &lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site/sweeps&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sweeps&lt;/a&gt; 같은 기능이 이 역할을 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;all-in-one&#34;&gt;&amp;ldquo;All-In-One&amp;rdquo;&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;학습 모니터링, 분산 처리, 배포, 스케일링 등 언급된 모든 기능을 수행하는 인프라 솔루션 또한 존재하는데, 그 가격이 상당한 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/gradient&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradient by Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.dominodatalab.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Domino Data Lab&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/sagemaker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Sagemaker&lt;/a&gt; 와 같은 옵션이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-3---troubleshooting--testing&#34;&gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=RLemHNAO5Lw&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/13UAHw1A7hM-O0jYGdGStN5gFCUb5XzLv/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-4---data-management&#34;&gt;Lecture 4 - Data Management&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=Jlm4oqW41vY&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-4-data-management/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/17Ak9mxNBIAv_FHUZsneqSWSud9Dh7F3i/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 분야가 발전되기 시작한 초기 단계에 업계가 잘 이해하지 못했던 부분은 데이터와의 접점이다. 데이터셋을 만들고, 분석하고, 전처리하는 등의 과정은 ML 프로젝트 전반에 걸쳐 필수적이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4주차 강의의 핵심 내용은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;초도 분석에 원하는 것보다 10배 많은 시간을 할애해야 한다.&lt;/li&gt;
&lt;li&gt;데이터를 고치고, 추가하고, 증강하는 것이 대체로 성능 향상에 가장 크게 기여한다.&lt;/li&gt;
&lt;li&gt;데이터를 다루는 과정을 가능한 간단하게 유지할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-sources&#34;&gt;Data Sources&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;이미지, 텍스트, 로그, 데이터베이스&lt;/strong&gt; 등 데이터 원천의 종류는 다양하다. 딥러닝을 위해서는 GPU 자원이 있는 로컬 파일 시스템에 데이터를 옮겨와야하며, 이렇게 학습 데이터를 옮기는 방식은 다루는 데이터 마다 차이가 생긴다.
&lt;ul&gt;
&lt;li&gt;이미지의 경우 S3 등의 &lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;에서 직접 다운로드 받을 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 분산 처리를 통해 데이터를 분석하고, 일부분을 발췌해 로컬 환경으로 옮겨주는 등의 과정이 필요하다 &lt;em&gt;(원문 전달 내용이 조금 불확실함)&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;로그와 데이터베이스의 경우 &lt;strong&gt;데이터 레이크&lt;/strong&gt;를 활용해 데이터를 모으고, 처리할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;파일시스템&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;파일시스템이란 &lt;strong&gt;“파일” 이라는 기초 단위에 기반한 추상화 개념&lt;/strong&gt;이다. 파일이란 흔히 생각하듯 텍스트, 바이너리 등 다양한 형태를 취할 수 있으며, 버전의 개념을 가지지 않는다.&lt;/li&gt;
&lt;li&gt;파일시스템은 보통 사용하는 기기에 연결된 디스크에 저장되며, 연결의 개념은 물리적일 수도, 온프레미스, 클라우드, 혹은 분산시스템에 기반한 원격 연결을 의미할 수도 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;디스크 성능을 평가하는데 가장 중요한 요소는 속도와 대역폭&lt;/strong&gt;이다. 저장장치 포맷은 주로 HDD 와 SSD 로 나뉘어지며, 동일한 SSD 이더라도 SATA 와 NVMe 연결방식 간 약 100배의 속도차이가 발생한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;오브젝트 스토리지란 &lt;strong&gt;파일시스템 활용을 위한 API&lt;/strong&gt; 를 뜻하며, 가장 기본이 되는 단위는 이미지, 오디오, 텍스트 등의 바이너리 형태 “오브젝트” 이다.&lt;/li&gt;
&lt;li&gt;버저닝, 중복 저장 개념이 존재하며, 로컬 파일시스템에 비해서는 속도가 느리지만 클라우드 활용을 위해서는 충분.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터베이스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;지속적이고, 빠르고, 스케일링이 가능한 정형데이터 저장소이다.&lt;/li&gt;
&lt;li&gt;이미지와 같은 바이너리 데이터를 저장하기 보다는 오브젝트 스토리지에 상응하는 URL 을 저장.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.postgresql.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Postgres&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.sqlite.org/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SQLite&lt;/a&gt; 등의 오픈소스가 널리 활용된다.&lt;/li&gt;
&lt;li&gt;프로젝트가 상호 reference 를 같는 객체를 다룬다면 데이터베이스의 도입이 불가피하기 때문에 처음부터 사용하는 편이 개발 시간을 단축시킬 가능성이 높다.&lt;/li&gt;
&lt;li&gt;W&amp;amp;B, HuggingFace Hub, Label Studio 등의 MLOps 툴을 사실 이러한 데이터베이스의 역할을 수행.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 웨어하우스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스가 &lt;strong&gt;온라인 트랜잭션 처리 (OLTP)&lt;/strong&gt; 를 위해 설계되었다면, 데이터 웨어하우스를 &lt;strong&gt;온라인 분석 처리 (OLAP)&lt;/strong&gt; 을 위해 설계된 데이터 처장 체계이다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OLTP&lt;/strong&gt; : &lt;em&gt;네트워크 상의 여러 이용자가 실시간으로 DB 의 데이터를 갱신하거나 조회하는 등의 단위작업 처리 방식. Row-oriented, 즉 개별적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OLAP&lt;/strong&gt; : &lt;em&gt;데이터를 분석하고 유의미한 정보로 치환하거나, 복잡한 모델링을 가능하게끔 하는 분석 방법. Column-oriented, 즉 통계적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;데이터 웨어하우스로 여러 데이터를 끌어오는 작업을 &lt;strong&gt;ETL (Extract-Transform-Load)&lt;/strong&gt; 이라 칭하며, 비즈니스 관점의 의사결정을 위한 정보를 웨어하우스에서 끌어오게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 레이크&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 웨어하우스와 유사하나, 데이터를 사전에 가공하는 ETL 방식과 달리 일단 데이터를 모으고, 사용시 가공하는 &lt;strong&gt;ELT (Extract-Load-Transform)&lt;/strong&gt; 방식을 사용한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;최근 트렌드는 데이터 웨어하우스와 데이터 레이크를 통합하는 솔루션들이다. 정형 데이터와 비정형 데이터가 같은 저장소에서 다뤄질 수 있으며, &lt;a class=&#34;link&#34; href=&#34;https://www.snowflake.com/?lang=ko&amp;amp;utm_source=google&amp;amp;utm_medium=paidsearch&amp;amp;utm_campaign=ap-kr-ko-brand-core-exact&amp;amp;utm_content=go-eta-evg-ss-free-trial&amp;amp;utm_term=c-g-snowflake-e&amp;amp;_bt=579103397662&amp;amp;_bk=snowflake&amp;amp;_bm=e&amp;amp;_bn=g&amp;amp;_bg=128328467463&amp;amp;gclsrc=aw.ds&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUubkoz7BoatiURcPHbxVDF3FAWwLuPcV1hSkAOItZfeqaTMTbDpzxQaAnZXEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snowflake&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://www.databricks.com/p/ebook/the-data-lakehouse-platform-for-dummies?utm_medium=paid&amp;#43;search&amp;amp;utm_source=google&amp;amp;utm_campaign=15849074529&amp;amp;utm_adgroup=130486333845&amp;amp;utm_content=ebook&amp;amp;utm_offer=the-data-lakehouse-platform-for-dummies&amp;amp;utm_ad=587394793834&amp;amp;utm_term=databricks&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUsOVwmdjpvZBvMSSWc1Z-5P83Uc0Y8k7hBQYQjbHZIEF_5Vb0p_3fMaArshEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Databricks&lt;/a&gt; 등의 업체가 분야를 선도하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;분야에 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://dataintensive.net/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Designing Data-Intensive Applications&lt;/a&gt; 라는 책을 추천.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 탐색은 주로 &lt;strong&gt;SQL&lt;/strong&gt; 과 &lt;strong&gt;DataFrame&lt;/strong&gt; 을 활용해 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt; 은 정형 데이터를 다루는 기본적인 인터페이스이며, 수십년간 사용되고 발전되어왔다. RDBMS 등의 트랜잭션 기반 데이터베이스에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pandas&lt;/strong&gt; 는 Python 생태계에서 사용되는 주된 DataFrame 이며 SQL 과 유사한 작업을 수행할 수 있다. OLAP 등의 분석 기반 환경에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://examples.dask.org/dataframe.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DASK DataFrame&lt;/a&gt; 은 Pandas 작업을 여러개의 CPU 코어에서 분산 처리 할 수 있도록 돕는다. &lt;a class=&#34;link&#34; href=&#34;https://rapids.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RAPIDS&lt;/a&gt; 는 동일한 분산 처리 작업을 GPU 에서 수행.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-processing&#34;&gt;Data Processing&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리는 예시와 함께 설명하는 편이 좋다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SNS 플랫폼에 업로드되는 사진을 기반으로, 사진의 인기도를 예측하는 모델을 매일 학습하는 상황이라고 가정하자. 모델러는 다음과 같은 데이터를 활용하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스 내 메타데이터 (업로드 시간, 제목, 장소 등)&lt;/li&gt;
&lt;li&gt;로그 데이터 기반 유저 정보 (로그인 횟수 등)&lt;/li&gt;
&lt;li&gt;별도 분류 모델 기반 사진 정보 (컨텐츠, 스타일 등)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 최종적인 모델 학습이 진행되기 전, 데이터베이스 쿼리 작업, 로그 처리 작업, 모델 예측 작업 등 많은 데이터 처리 작업이 수행되어야 하며, 이러한 &lt;strong&gt;사전 작업을 정해진 순서대로 처리&lt;/strong&gt;해야 할 필요가 생긴다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow&lt;/a&gt; 는 언급된 기능을 수행하는 Python 생태계의 기본 스케줄러 툴이다. &lt;strong&gt;DAG (Directed Acyclic Graph)&lt;/strong&gt; 라는 개념을 활용해 순차적인 작업 설정이 가능하며, 이러한 작업이란 SQL 쿼리, Python 함수 등 다양한 종류가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.prefect.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Prefect&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://dagster.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dagster&lt;/a&gt; 또한 유사한 기능을 수행하는 경쟁 제품이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;feature-store&#34;&gt;Feature Store&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리 과정이 모델 학습과 병렬로 진행될 떄, 모델은 이후 학습에서 어떤 데이터가 신규로 생성되었는지, 어떤 데이터가 이미 학습에 활용되었는지 등을 파악할 필요가 발생할 수 있다 (필수적인 요소는 아님).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 경우 &lt;strong&gt;Feature Store&lt;/strong&gt; 기능을 활용한 데이터 관리가 필요해지게 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feature Store 라는 개념은 Uber 의 ML 플랫폼 &lt;strong&gt;Michalengelo&lt;/strong&gt; 를 소개하는 &lt;a class=&#34;link&#34; href=&#34;https://www.uber.com/en-KR/blog/michelangelo-machine-learning-platform/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 글&lt;/a&gt;에서 처음 등장했다. Uber 의 시스템 특성상 학습은 오프라인, 예측은 온라인으로 진행되기에 두 과정의 싱크를 맞춰줄 필요가 생겼고, 이를 해결하기 위한 수단으로 Feature Store 개념을 사용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;tecton.ai&#34; &gt;Tecton&lt;/a&gt; 은 해당 분야에서 가장 널리 사용되는 SaaS 솔루션이며, 이외에도 &lt;a class=&#34;link&#34; href=&#34;https://feast.dev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Feast&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.featureform.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Featureform&lt;/a&gt; 등의 옵션이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;datasets&#34;&gt;Datasets&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/datasets/index&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HuggingFace Datasets&lt;/a&gt; 는 ML 학습에 특화된 8000+ 데이터셋을 제공하며, 비전, NLP 등 분야가 다양한 편이다. 호스트된 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/datasets/codeparrot/github-code&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github-Code&lt;/a&gt; 데이터를 예시로 들자면 데이터 핸들링을 돕기 위해 Aparche Parquet 형태로 스트림 할 수 있기 떄문에 1TB+ 용량의 전체 데이터를 다운로드 할 필요가 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;또다른 훌륭한 데이터셋의 예시로는 RedCaps 를 들 수 있다. Reddit 에서 수집된 12M 의 이미지-텍스트 페어를 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HuggingFace Datasets 와 유사한 서비스로는 &lt;a class=&#34;link&#34; href=&#34;https://www.activeloop.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Activeloop&lt;/a&gt; 이 있는데, 데이터 다운로드 없이 분석과 기타 데이터 활용이 가능하도록 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-labeling&#34;&gt;Data Labeling&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 레이블링 작업을 시작하기 전, 정말 레이블링이 필요한지를 스스로에게 물어볼 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;자기지도학습 (self-supervised learning)&lt;/strong&gt; 이란 직접적인 레이블링 작업 없이 데이터의 일부분을 레이블로 활용하는 학습 방식을 뜻하며, NLP 과제에서 중요한 요소로 자리매김하고 있다. 마스킹 등의 기법을 통해 데이터의 한 부분을 예측하는 과제이며, &lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/clip/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenAI CLIP&lt;/a&gt; 과 같이 cross-modality 과제에서 (이미지-텍스트 등) 또한 활용이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;이미지 데이터 증강&lt;/strong&gt;은 비전 모델에서 사실상 필수적인 요소이다. &lt;a class=&#34;link&#34; href=&#34;https://github.com/pytorch/vision&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;torchvision&lt;/a&gt; 과 같은 라이브러리를 활용하여 간단하게 구현할 수 있으며, &lt;strong&gt;이미지의 &amp;ldquo;의미&amp;quot;를 변질시키지 않는 선에서 데이터에 변형을 주는 것&lt;/strong&gt;을 목표로 삼는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외 데이터 형태에 대한 증강 방식은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;정형 데이터의 경우 랜덤하게 선택된 셀 정보를 삭제함으로 미입수 데이터를 모방할 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 증강 기법이 상대적으로 부족한 편. 단어의 순서를 변경하거나, 부분적으로 삭제하는 방식이 존재한다.&lt;/li&gt;
&lt;li&gt;오디오 데이터는 속도를 조절하거나, 빈 오디오를 중간에 삽입하는 방식 등이 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Synthetic Data (합성 데이터)&lt;/strong&gt; 또한 고려해볼 필요가 있다. 레이블에 대한 사전 지식을 통해 기존에 존재하지 않는 데이터를 생성할 수 있으며, 적용 예시로는 영수증, 손글씨 이미지 등이 있다. 많은 공수가 필요하기 때문에 다른 방법은 없는지 충분히 검토 후 도입.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;보다 창의성을 발휘해 유저에게 레이블링 작업을 맞기는 것 또한 가능하다. 위 이미지와 같이 Google Photos 는 유저에게 이미지 레이블링 작업을 요구.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;유저의 직접적인 레이블링은 언급된 data flywheel 개념의 적용 예시이다. 유저는 모델 성능 향상에 기여하고, 이로 인해 유저의 제품 경험 또한 개선된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇듯 데이터 레이블링을 우회하는 다양한 방법이 존재하지만, 결국 &lt;strong&gt;모델링 작업을 시작하기 위해서는 어느정도의 레이블링 작업은 불가피&lt;/strong&gt;하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링이란 bounding box 와 같이 &lt;strong&gt;표준적인 형태의 주석을 기록하는 작업&lt;/strong&gt;이다. 주석의 형태보다는 레이블러가 올바른 교육을 받는 것이 가장 중요하며, &lt;strong&gt;이들이 레이블링 표준을 준수하도록 하는 것은 어렵지만 가장 핵심적인 요소&lt;/strong&gt;이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블러 고용 시 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 레이블링을 전문적으로 수행하는 업체.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;레이블러의 &lt;strong&gt;직접적인 고용&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.mturk.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Mechanical Turk&lt;/a&gt; 와 같은 &lt;strong&gt;크라우드 소싱&lt;/strong&gt;. 레이블링 품질을 위해 가능한 피하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링 전문 업체들은 소프트웨어 개발, 인력 관리, 품질 관리 까지의 다양한 작업을 수행한다. 업체 활용이 필요하다면 데잍러를 충분히 이해한 후, 샘플 레이블 등을 통해 여러 경쟁 업체를 비교한 후 의사결정을 내리는 편이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://scale.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Scale AI&lt;/a&gt; 는 업계에서 가장 규모가 큰 데이터 레이블링 솔루션이다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://labelbox.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Labelbox&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://supervise.ly/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Supervisely&lt;/a&gt; 가 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://labelstud.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LabelStudio&lt;/a&gt; 는 가장 널리 알려진 오픈소스 솔루션이며, 직접 레이블링을 수행할 때 활용하게 된다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://diffgram.com/main/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Diffgram&lt;/a&gt; 이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://snorkel.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snorkel&lt;/a&gt; 은 weak supervision 기반 레이블링 툴이며, &amp;ldquo;amazing&amp;rdquo; 이라는 단어가 들어간 모든 문장을 &amp;ldquo;긍정&amp;rdquo; 카테고리로 구분하는 등의 빠른 레이블링 작업을 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-versioning&#34;&gt;Data Versioning&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 버전 관리는 단계적으로 구분이 가능하다.
&lt;ul&gt;
&lt;li&gt;Level 0 : &lt;strong&gt;단순한 파일시스템 관리로, 버전 관리가 이루어 지지 않는다.&lt;/strong&gt; 모델이란 코드와 데이터가 합쳐져 만들어진 결과물이기 때문에, 데이터가 바뀌면 동일한 모델을 구현하지 못하게 된다.&lt;/li&gt;
&lt;li&gt;Level 1 : &lt;strong&gt;학습시 데이터에 대한 스냅샷을 저장&lt;/strong&gt;하는 방식. 모델에 활용된 데이터가 특정 가능하지만, 이상적인 방식이라고 보기엔 어렵다.&lt;/li&gt;
&lt;li&gt;Level 2 : &lt;strong&gt;코드 버전 관리와 같은 개념을 도입&lt;/strong&gt;. &lt;a class=&#34;link&#34; href=&#34;https://git-lfs.github.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Git-LFS&lt;/a&gt; 와 같은 툴을 사용하게되며, 적극적으로 권장되는 방식이다.&lt;/li&gt;
&lt;li&gt;Level 3 : 대용량 데이터 관리를 위한 &lt;strong&gt;특별한 솔루션&lt;/strong&gt;을 도입. 합리적인 이유 (데이터 용량이 지나치게 크거나, 데이터에 많은 규제가 붙는 경우 등) 가 없다면 불필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 작업을 위한 툴로는 &lt;a class=&#34;link&#34; href=&#34;https://dvc.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DVC&lt;/a&gt; 가 있다. 데이터를 원격 저장소에 저장하고, 필요시 이전 버전으로 회귀하는 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-5---deployment&#34;&gt;Lecture 5 - Deployment&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=W3hKjXg7fXM&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-5-deployment/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1ABdEgVHvOIBtJhfmzy5ps_dMrwFKlgwd/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배포 과정은 좋은 모델 개발에 있어 필수적인 요소이다. &lt;strong&gt;오프라인으로 모든 평가를 진행하면 모델의 작은 실수들을 놓치기 쉽고, 사용자가 정말 필요로 하는 문제 해결 능력이 부재할 수 있기 때문.&lt;/strong&gt; 이러한 요소는 모델 배포를 통해서만 검증이 가능한 경우가 많다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다른 ML 개발 단계와 같이 &lt;strong&gt;최소한의 기능만을 구현한 후, 복잡한 부분들을 순차적으로 추가&lt;/strong&gt;하는 과정을 거치는 편이 좋다. 과정은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프로토타입 설계&lt;/li&gt;
&lt;li&gt;모델/UI 분리&lt;/li&gt;
&lt;li&gt;스케일 문제 해결&lt;/li&gt;
&lt;li&gt;속도 이슈 발생 시, 엣지 디바이스 활용 검토&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;build-a-prototype-to-interact-with&#34;&gt;Build A Prototype To Interact With&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;프로토타입 설계를 위한 툴로는 최근 HuggingFace 가 인수한 &lt;a class=&#34;link&#34; href=&#34;https://gradio.app/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradio&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://streamlit.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Streamlit&lt;/a&gt; 등이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 프로토타입 설계를 위해서는 다음과 같은 기본적인 규칙을 지키자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;심플한 UI&lt;/strong&gt; : 프로토타입의 주된 목적은 실사용 환경에서 모델을 테스트해보고, 타인의 피드백을 얻는 것이다. Gradio, Streamlit 과 같은 앱을 활용하면 많은 코드를 쓰지 않더라도 기본적인 인터페이스 구축이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Web URL 활용&lt;/strong&gt; : URL 은 공유하기 쉬우며, 이를 기준점으로 삼아 더욱 복잡한 배포 방식을 택하면서 발생할 장단점을 생각할 수 있다. Streamlit, HuggingFace 모두 클라우드 배포 기능을 제공.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;공수 최소화&lt;/strong&gt; : 강사진은 프로토타입 설계에 하루 이상을 소비하지 않을 것을 권장.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 프로토타입은 최종 솔루션의 형태가 아니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프론트엔드 구현에 있어 분명한 한계점이 존재한다. 완성된 형태의 서비스 제공을 위해서는 커스텀 UI 제작이 필요.&lt;/li&gt;
&lt;li&gt;스케일링 문제를 안고있다. 유저 수가 증가하게 된다면 스케일업을 위해 백엔드 구축이 필요.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;상단 장표는 일반적인 어플리케이션의 구조를 보여준다. Client 란 유저가 상호작용하는 기기, 즉 브라우저, 차량, 스마트폰 등이며, 이러한 기기는 네트워킹을 통해 서버와 소통한다. 서버는 데이터베이스와의 상호 작용을 통해 어플리케이션을 구동.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이러한 기본적인 어플리케이션 구조에 ML 모델을 배포하는 여러가지 방법이 존재한다. 언급된 프로토타입 접근법은 &lt;strong&gt;model-in-service&lt;/strong&gt; 방식에 해당하며, 웹서버가 패키징된 모델을 품고있는 경우이다 &lt;em&gt;(인스타 등 이미 성숙도가 올라간 서비스에 ML 기능을 추가하는 형태로 생각하면 됨)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 방식의 가장 큰 장점은 모델의 복잡성과 무관하게 기존의 인프라를 사용할 수 있다는 점이다. 하지만 이러한 방식에는 여러가지 단점 또한 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;웹서버가 다른 언어로 작성.&lt;/strong&gt; 파이썬 기반이 아니라면, 이미 구축된 모델을 서버에 통합하는 과정이 까다로울 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델이 서버 코드보다 자주 업데이트 될 수 있음.&lt;/strong&gt; 어플리케이션이 이미 성숙 단계에 접어들었으나 모델이 초기 단계에 있다면, 모델 업데이트 마다 재배포 과정을 겪어야 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;웹서버에 비해 모델의 크기가 지나치게 클 수 있음.&lt;/strong&gt; 이러한 경우 모델을 직접적으로 사용하지 않더라도 전반적인 어플리케이션 사용 경험에 부정적인 영향이 미칠 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;서버 하드웨어는 ML 작업에 최적화되지 않음.&lt;/strong&gt; 이러한 서버 장비에 GPU 가 내장되어 있는 경우는 굉장히 드물다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링 속성의 차이가 발생할 수 있음.&lt;/strong&gt; 따라서 모델과 기존 어플리케이션 간 스케일링 규칙의 차등을 두어야 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;separate-your-model-from-your-ui&#34;&gt;Separate Your Model From Your UI&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;모델을 UI 에서 완전히 분리하는 방법은 크게 &lt;strong&gt;(1) Batch Prediction&lt;/strong&gt;, &lt;strong&gt;(2) Model-as-Service&lt;/strong&gt; 방식으로 나뉜다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 이란 모든 데이터 포인트에 대한 예측치를 사전에 구한 후, 결과값을 데이터베이스에 저장하는 방식&lt;/strong&gt;이다. 경우에 따라 가장 적절한 방식일 수 있는데, 인풋값이 제한된 경우 주기적으로 예측치를 구하는 것만으로 충분히 최신 정보가 반영된 예측치를 사용자에게 전달할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 방식이 적절한 예시는 초기단계의 추천 시스템, 내부 활용을 위한 마케팅 자동화 시스템 등.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주기적으로 예측값을 구하기 위해서는 데이터 처리 자동화 파이프라인 활용이 필요하다. (1) 데이터 처리, (2) 모델 로딩, (3) 예측, (4) 예측값 저장 순의 작업이 필요한데, Dagster, Airflow 등의 DAG 시스템이 처리하기에 적절한 문제이다. 유사한 ML 전용 툴인 &lt;a class=&#34;link&#34; href=&#34;https://metaflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Metaflow&lt;/a&gt; 또한 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;구현이 간단하다.&lt;/strong&gt; 이미 학습에 배치 처리 툴을 활용하고 있다면 이러한 구조를 재사용 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링이 쉽다.&lt;/strong&gt; 데이터베이스는 기본적으로 스케일링에 최적화 되어있는 시스템이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;대형 시스템에서 수년간 검증된 구조.&lt;/strong&gt; 이미 많은 기업들이 이와 같은 예측 파이프라인을 활용해왔고, 예상하지 못한 문제가 발생할 확률이 상대적으로 적다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치 전달이 빠름.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;경우의 수가 많은 인풋을 처리할 수 없음.&lt;/strong&gt; 모든 경우의 수에 대한 모든 예측치를 구하는 것에는 분명한 한계가 존재한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치가 가장 최신의 정보를 반영하지 못함.&lt;/strong&gt; 이러한 정보가 매분, 매초 의미있는 변화를 가진다면, 유저가 보는 예측치는 이미 유의미한 정보를 제공하지 못할 확률이 높다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batch Job 실행 실패를 감지하기 어려움.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 란 모델을 별도의 온라인 서비스로서 운영하는 방식이다.&lt;/strong&gt; 모델은 백엔드, 또는 클라이언트에서 송출한 request 에 대해 response 를 보내는 방식으로 소통하게된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;신뢰성.&lt;/strong&gt; 모델에서 발생한 버그가 전체 웹 어플리케이션을 다운시킬 확률이 감소하게 된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링.&lt;/strong&gt; 목적에 최적화된 하드웨어를 선택하고, 알맞은 방식으로 스케일링을 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;유연성.&lt;/strong&gt; 여러 어플리케이션이 모델 인프라를 공유할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;레이턴시.&lt;/strong&gt; 별도의 서비스인 만큼, 서버/클라이턴트가 모델을 사용할 때 시간적 비용이 발생.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;복잡한 인프라.&lt;/strong&gt; 구축/운영에 대한 새로운 비용이 발생함.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 단점들은 감안하더라도 &lt;strong&gt;model-as-service 구조는 대부분의 ML 제품 배포에 적합한 방식이다&lt;/strong&gt;. 복잡한 어플리케이션의 구조에서 모델 서비스를 개별적으로 스케일링 할 수 있다는 점은 중요하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5주차 강의에선 이러한 모델 서비스를 구축하기 위한 부분들을 설명한다. 이는 &lt;strong&gt;(1) Rest API, (2) 디펜던시 관리, (3) 성능 최적화, (4) 수평 스케일링, (5) 롤아웃&lt;/strong&gt; 등의 개념을 포함한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Rest APIs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dependency Management&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Horizontal Scaling&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Model Rollouts&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Managed Options&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;move-to-the-edge&#34;&gt;Move To The Edge?&lt;/h4&gt;
&lt;h3 id=&#34;lecture-6---continual-learning&#34;&gt;Lecture 6 - Continual Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=nra0Tt3a-Oc&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-6-continual-learning/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/10fDYIEELIeT3Nju001GTAxM_YYUDFMpB/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-7---foundation-models&#34;&gt;Lecture 7 - Foundation Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Rm11UeGwGgk&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-7-foundation-models/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/17ZAj6izyYhV-SXA_UKNWjYo0adbL2E8n/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-8---ml-teams-and-project-management&#34;&gt;Lecture 8 - ML Teams and Project Management&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=a54xH6nT4Sw&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-8-teams-and-pm/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1o2x8ywivp555__AEbLLI28BsiQmHobOh/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-9---ethics&#34;&gt;Lecture 9 - Ethics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=7FQpbYTqjAA&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-9-ethics/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1ytLW4fOSef1PkWmSsoFdWdrFG5d0oCKh/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
