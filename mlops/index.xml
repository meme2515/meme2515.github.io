<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Mlops on Soon Hyung Kwon</title>
        <link>https://meme2515.github.io/mlops/</link>
        <description>Recent content in Mlops on Soon Hyung Kwon</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 27 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://meme2515.github.io/mlops/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Full Stack Deep Learning 2022 부트캠프</title>
        <link>https://meme2515.github.io/mlops/fsdl/</link>
        <pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/fsdl/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/fsdl_title.jpg" alt="Featured image of post Full Stack Deep Learning 2022 부트캠프" /&gt;&lt;h2 id=&#34;부트캠프-소개-및-전반적인-느낌&#34;&gt;부트캠프 소개 및 전반적인 느낌&lt;/h2&gt;
&lt;p&gt;회사분의 소개로 2022년 코호트의 일환이 되었다. Early Registration 으로 495 달러인 참가비보다 약간 저렴한 300 달러를 지불했고, 돈을 내면서 까지 참가하고 싶다는 생각이 들기까지는 카일님의 블로그에 올라온 &lt;a class=&#34;link&#34; href=&#34;https://zzsza.github.io/mlops/2019/10/06/fullstack-deeplearning-bootcamp/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;긍정적인 리뷰&lt;/a&gt;가 중요한 역할을 했던 것 같다.&lt;/p&gt;
&lt;p&gt;실용적인 ML을 추구하기 때문에 강사진의 업계 경험 및 배경 또한 중요하다고 생각했다. 강사진은 버클리 대학에서 박사과정을 마친 이력을 공유하고 있고, Weights &amp;amp; Biases, OpenAI 등의 기업에서의 실무 경험을 가지고있다. 개별적인 강사진의 공개된 이력은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/charles-frye-38654abb/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Charles Frye&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Chicago 학부 졸업 (Computational Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Neuroscience 전공)&lt;/li&gt;
&lt;li&gt;Weights &amp;amp; Biases 2년 근무&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/sergeykarayev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sergey Karayev&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;University of Washington 학부 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;Turnitin 2년 근무 (교육 관련 소프트웨어 개발사)&lt;/li&gt;
&lt;li&gt;GSV Ventures 3년 근무 (벤처 캐피탈)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/josh-tobin-4b3b10a9/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Josh Tobin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Columbia University 학부 졸업 (Mathematics 전공)&lt;/li&gt;
&lt;li&gt;University of California, Berkeley 박사 졸업 (Computer Science 전공)&lt;/li&gt;
&lt;li&gt;McKinsey &amp;amp; Company 2년 근무&lt;/li&gt;
&lt;li&gt;OpenAI 3년 근무&lt;/li&gt;
&lt;li&gt;Gantry 창업 (ML 스타트업)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-내용-요약&#34;&gt;Lecture 내용 요약&lt;/h2&gt;
&lt;h3 id=&#34;lecture-1---when-to-use-ml-and-course-vision&#34;&gt;Lecture 1 - When to Use ML and Course Vision&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=-Iob-FW5jVM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-1-course-vision-and-when-to-use-ml/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/18EVuJpnJ9z5Pz7oRYcgax_IzRVhbuAMC/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;course-vision&#34;&gt;Course Vision&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;FSDL 과정이 처음 시작한 2018년에는 규모가 큰 기업들만 ML 제품을 내놓고 있는 상태였으며, 이들 이외의 기업들은 ML로 부터 부가가치를 창출하기 어렵다는 생각이 업계 전반에 있었다.&lt;/li&gt;
&lt;li&gt;2022년 현재에는 트랜스포머의 등장으로 인해 NLP 분야가 더 많은 적용 사례들을 찾아내고 있고, 이외에도 많은 ML 제품들의 등장으로 MLOps 라는 단어가 사용되기 시작했다.&lt;/li&gt;
&lt;li&gt;물론 업계 전반이 더 성숙해졌고, 주요한 연구 실적 또한 있었지만, ML 제품 개발이 더욱 활성화된 주요한 이유는 &lt;strong&gt;선행학습이 완료된 모델이 점차 상품화되고 있다는 점&lt;/strong&gt;이다.
&lt;ul&gt;
&lt;li&gt;이제 HuggingFace 와 같은 툴을 이용하면 최신 NLP, 비전 모델을 코드 한두줄로 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;회사들은 학습된 모델을 네트워크를 통해 제공하기 시작했다.&lt;/li&gt;
&lt;li&gt;Keras, PyTorch Lightning 을 중심으로 유관한 프레임워크들이 표준화되기 시작했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI 분야는 항상 대중의 관심 속에 있어왔지만, 기대에 부흥하지 못한 실용성으로 지난 수십년간 굴곡을 겪어왔다. 분야가 다시 성장하고 있는 지금, 또다른 혹한기를 피하기 위해 관련 연구를 real-world 제품으로 승화시켜야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학계에서 다루는 ML 은 단차원적이다. 문제를 정의하고, 데이터를 수집하고, 정제한 다음 모델 개발 과정을 거쳐 잘 작동하는 ML 모델을 평가/보고함으로 과정이 끝난다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이에 반해 ML 제품은 배포 후 관리를 필요로한다. 실제 사용자들이 제품을 어떻게 경험하는지 관찰/측정한 후, 사용자들의 데이터에 기반한 data flywheel 을 만들어 모델을 고도화하게 된다.&lt;/li&gt;
&lt;li&gt;본 과정은 모델 학습을 넘어 &lt;strong&gt;좋은 ML 제품을 만들기 위해 필요한 지식과 노하우를 전달한다&lt;/strong&gt;. 이러한 제품에 어떤 부분들이 있어야 하는지, 제품 개발에서 발생하는 문제 해결을 위한 접근법은 어떠한 것들이 있는지 등을 가르친다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MLOps&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;MLOps 란 지난 몇년간 새로 등장한 분야이며, ML 시스템에 대한 배포, 유지, 운영에 관한 개념을 다룬다. 통제/반복 가능한 환경에서 모델을 구축하는 법, high scale 세팅에서 시스템을 운영하는 법, 시스템 유지를 위해 팀이 협업하는 법 등을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 기반 제품&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;ML 기반 제품이란 이와 유사성을 가진 개념이나, 완전히 같다고 볼 수 없다. 좋은 제품 개발은 운영 이외의 분야에 대한 깊은 생각을 필요로하고, 최종 제품에서 ML 이 어떠한 역할을 하는지에 집중하게 된다. 유저가 제품을 사용하면서 어떠한 경험을 가지는지, 조직과 효율적으로 협업하는 방법은 무엇인지, ML 분야의 프로덕트 매니징은 어떻게 이루어지는지 등의 개념을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;본 과정은 좋은 ML 기반 제품을 만들기 위한 end-to-end 과정을 가르치며, 이에 필요한 기본적인 MLOps 개념만을 전달한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;when-to-use-machine-learning&#34;&gt;When To Use Machine Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML 프로젝트는 일반적인 소프트웨어 개발보다 높은 실패율을 보인다.&lt;/strong&gt; 많은 적용 분야에서 ML 이란 아직 연구 단계에 있기 때문이며, 때문에 100% 성공을 목표로 할 수는 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외에도 ML 프로젝트가 실패하는 이유 중 대표적인 예시는 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;기술적으로 불가능하거나 스코프 설정이 잘못되었기 때문&lt;/li&gt;
&lt;li&gt;제품화로의 도약을 이루지 못하기 때문&lt;/li&gt;
&lt;li&gt;조직적으로 ML 프로젝트 성공의 기준을 정하지 못했기 때문&lt;/li&gt;
&lt;li&gt;문제 해결을 이루어냈으나, 복잡성에 비례한 정당성을 가지지 못했기 때문&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 ML 프로젝트를 시작하기 전, 다음과 같은 질문을 할 필요가 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML을 활용할 준비가 되었는가?&lt;/strong&gt; 구체적으로는 적용할 제품이 있는가? 이미 데이터를 활용 가능한 방식으로 수집하고 있는가? 적절한 인력을 보유하고 있는가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제를 해결하기 위해 정말 ML이 필요한가?&lt;/strong&gt; 문제는 애초에 해결되어야 하는 것인가? 룰베이스 혹은 간단한 통계학을 통한 문제 해결이 가능하진 않은가?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML의 활용이 윤리적으로 올바른가?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모든 분야의 프로젝트와 같이, 적절한 ML 프로젝트 선정을 위해선 &lt;strong&gt;큰 임팩트&lt;/strong&gt;와 &lt;strong&gt;적은 비용&lt;/strong&gt;을 가진 유즈케이스 선정이 필요하다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;큰 임팩트란 ML 이 서비스 파이프라인의 복잡한 구조를 해결하거나, 간단한 예측이 큰 의미를 가지는 경우를 뜻한다. 업계에서 ML 을 어떻게 활용하고 있는지 또한 좋은 지표가 될 수 있다.&lt;/li&gt;
&lt;li&gt;적은 비용이란 데이터의 이미 존재하거나, 잘못된 예측이 어느정도 허용되는 경우를 말한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;큰 임팩트를 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ML 활용이 상대적 경제성을 가지는 경우.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;제품이 필요로 하는 것이 무엇인지를 고민해야 한다.&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://spotify.design/article/three-principles-for-designing-ml-powered-products&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spotify - Discover Weekly 를 구현하면서 세운 3가지 원칙&lt;/a&gt; 참조.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML 이 특히 잘하는 것이 무엇인가를 생각.&lt;/strong&gt; 시스템에 복잡하고 수동적으로 정의된 부분이 있다면 ML 적용이 큰 도움이 될 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;업계에서 ML 이 어떤 문제를 해결하고 있는지를 참고.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;적은 비용을 가진 프로젝트&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;데이터 유무를 파악.&lt;/strong&gt; 새로운 데이터를 확보하는 것은 얼마나 어려운지, 데이터 레이블링은 어느정도의 비용이 드는지, 얼마나 많은 데이터가 필요할 것인지, 데이터는 얼마나 정적인지, 어떠한 보안 규제가 존재하는지 등.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델 정확도의 중요성을 고려.&lt;/strong&gt; 잘못된 예측으로 인한 비용은 어느정도인지, 실용성을 위해 모델의 정확도는 어느 정도여야 하는지를 파악해야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;문제의 난이도에 대한 고민.&lt;/strong&gt; ML 활용으로 해결될 문제는 얼마나 잘 정의되었는지, 관련 주제에 대한 논의가 충분히 존재하는지, 연산 자원은 얼마나 필요한지 등.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ML이 어려워하는 대표적 문제들&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;결과값이 복잡한 경우.&lt;/strong&gt; 예측치의 정의가 불확실하거나, 고차원의 형상을 다루는 경우.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;높은 정확도를 요구하는 경우.&lt;/strong&gt; ML 모델은 예상치 못한 부분에서 실패하기 때문에, 일정 수준 이상의 정확도를 요구하는 경우 ML 적용이 적절하지 않을 수 있음.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;일반화가 필요한 경우.&lt;/strong&gt; 통계치에서 벗어난 데이터에 대한 예측을 요구하거나, 논리/계획을 세우거나 인과관계를 판단하는 작업을 요구하는 경우.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;같은 ML 프로젝트라 할지라도 프로젝트의 성격에 따라 계획 과정은 판이하게 달라진다. 관련한 방법론을 수립하기 위해 강사진은 다음과 같은 3가지 카테고리로 ML 제품을 구분한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Software 2.0&lt;/strong&gt; : 전통적인 소프트웨어에 머신러닝을 적용하는 경우이다. 코드 작성 AI 인 Github Copilot 을 예시로 들 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human-in-the-loop&lt;/strong&gt; : ML 시스템이 사람의 의사결정 체계를 돕거나, 효율성을 향상시키는 경우를 말한다. 단순한 스케치를 기반으로 PPT 슬라이드를 생성하는 등의 예시를 들 수 있으며, 이 경우 모델 아웃풋의 품질을 사람이 확인하는 과정이 수반된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autonomous Systems&lt;/strong&gt; : ML 을 활용해 사람이 개입할 필요가 없는 완전한 자동화 시스템을 구축하는 경우이다. 자율주행 등을 예시로 들 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 의 경우, &lt;strong&gt;ML 적용이 실제 성능 개선에 도움이 되는지&lt;/strong&gt;를 꼼꼼하게 점검해 볼 필요가 있다. 또한 서비스 배포 후 data flywheel, 즉 신규 데이터를 기반으로 모델을 개선시킬 수 있는 사이클이 구축될 수 있는지 또한 검토가 필요하다.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 &lt;strong&gt;사용자가 어떠한 배경, 환경을 가지고 모델을 활용하는지&lt;/strong&gt;를 염두해야 하며, &lt;strong&gt;그들의 니즈 또한 파악&lt;/strong&gt;할 필요가 있다. 유저에게 실질적인 도움을 제공하려면 어느 정도 수준의 성능을 보여야 하는지 등을 고려해야 한다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 &lt;strong&gt;실패율과 그에 따른 결과&lt;/strong&gt;에 집중할 필요가 있다. 사람이 개입할 여지가 없다면 실패 케이스들을 면밀하게 주시해야 하며, 자율주행이 이에 대한 좋은 예시라고 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;언급했듯 Software 2.0 프로젝트 내에선 data flywheel 개념을 곱씹을 필요가 있다. 경우에 따라 차이가 존재할 수 있지만, 대체로 유저의 데이터를 수집하여 모델 개선에 활용한다면 성능이 서비스 기간이 지남에 따라 개선될 가능성이 높다.&lt;/li&gt;
&lt;li&gt;data flywheel 을 구축하기 전, 다음과 같은 3가지 질문에 대한 답이 필요하다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 loop 이 존재하는가?&lt;/strong&gt; Data flywheel 을 구축하기 위해서는 정제된 데이터를 스케일링이 가능한 방식으로 유저로 부터 수집할 수 있어야 한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;더 많은 데이터가 더 나은 모델과 상응하는가?&lt;/strong&gt; 모델러의 역량과는 별개로 문제 특성상 더 많은 데이터가 더 나은 모델을 의미하지 않는 경우가 발생할 수 있다. data flywheel 시스템 구축 전 더 많은 데이터가 가치를 전달하는지를 확실히 해 둘 필요가 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델의 성능이 제품 활용성에 기여하는가?&lt;/strong&gt; 보다 근본적인 질문인데, 모델의 성능 개선이 유저의 경험에 긍정적으로 기여할 수 있는지 또한 짚고 넘어가야 할 부분이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;상단 이미지는 &lt;strong&gt;영향성 vs. 실현 가능성&lt;/strong&gt; 그래프에서 정의된 3가지 타입의 과제가 상대적으로 어디에 위치해 있는지를 보여준다. 대체로 &lt;strong&gt;모델을 구축하기 힘들수록 더 큰 영향을 끼친다&lt;/strong&gt;라는 규칙이 통용된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software 2.0 는 data flywheel 구축을 통해 더 큰 영향력을 가질 수 있다. 모델의 성능이 증가하며, 이로 인한 사용자의 경험이 계속 개선되기 때문.&lt;/li&gt;
&lt;li&gt;Human-in-the-loop 시스템의 경우 충분한 고민이 반영된 설계 과정, 혹은 적절한 단계에서 배포 후 점차 성능을 개선시킨다는 &amp;ldquo;good enough&amp;rdquo; 마인드 셋이 제품에 대한 기대치와 목표 성능을 낮추는데 도움을 줄 수 있다.&lt;/li&gt;
&lt;li&gt;Autonomous 시스템은 사람의 개입을 유도해 모델의 실패에 대비하는 체계가 도움을 줄 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 결국 엔지니어링의 가장 중요한 측면은 &lt;strong&gt;무언가를 만드는 일&lt;/strong&gt;이다. 우리는 Google, Uber 와 항상 같은 환경을 구축할 필요가 없으며, 최신 툴과 완벽한 체계를 추구하기 전 먼저 문제에 대한 해결책을 찾는 것이 핵심이라는 점을 상기해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;lifecycle&#34;&gt;Lifecycle&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML 프로젝트가 계획적/단계적으로 진행되기엔 현실적으로 어려운 부분이 많으며, 중간 과정에서 발견된 인사이트로 인해 이전 단계의 작업을 번복하거나, 성능 요건을 재정의 하는 등 단계 별 작업이 병렬적으로 진행되는 경향이 있다.&lt;/li&gt;
&lt;li&gt;본 부트캠프는 이러한 프로젝트 lifecycle 의 각 단계를 가급적 성공적으로 수행하는 방법을 전달하고, 채용, 인프라 등 프로젝트 외 요소들 또한 어떻게 다루어야 하는지 공유한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-2---development-infrastructure--tooling&#34;&gt;Lecture 2 - Development Infrastructure &amp;amp; Tooling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=BPYOsDCZbno&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-2-development-infrastructure-and-tooling/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/16pEG5GesO4_UAWiD5jrIReMGzoyn165M/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;이상적인 ML 환경이란 &lt;strong&gt;정의된 프로젝트 목표와 샘플 데이터를 기반으로, 지속적으로 개선되는 예측 시스템을 큰 규모로 운영&lt;/strong&gt;하는 것이다.&lt;/li&gt;
&lt;li&gt;현실은 이와는 다를 수 밖에 없다. 데이터에 대한 &lt;strong&gt;수집, 처리, 레이블, 버저닝&lt;/strong&gt;이 필요하며, &lt;strong&gt;적합한 모델 구조와 사전 학습된 가중치&lt;/strong&gt;를 찾아야하고, 프로젝트에 적합하게 &lt;strong&gt;디버깅&lt;/strong&gt;해야 한다. 또한 여러 &lt;strong&gt;학습 과정을 기록 및 리뷰&lt;/strong&gt;해야하며, 모델 배포 후에도 끊임없이 생성되는 데이터를 기반으로 모델을 개선해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 환경의 3가지 주요한 컴포넌트는 &lt;strong&gt;데이터, 개발, 배포&lt;/strong&gt;이다. 각각의 컴포넌트는 방대한 툴을 가지고 있고, 3주간 강의를 통해 이들 모두를 전반적으로 살핀다. 본 강의의 주제는 개발이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;software-engineering&#34;&gt;Software Engineering&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;개발 언어의 경우 데이터 컴퓨팅 분야에선 현재 &lt;strong&gt;Python&lt;/strong&gt; 이 절대적인 우위를 점하고 있다. 너무나 많은 부속 라이브러리들이 개발되었기 때문이며, Julia, C/C++ 와 같은 경쟁자가 존재했지만 사실상 Python 이 생태계를 독점하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파이썬 코드를 작성하기 위해서는 에디터를 사용해야 한다. Vim, Emacs, Jupyter Notebook/Lab, PyCharm 등 수많은 옵션이 있지만 FSDL 팀이 제안하는 에디터는 &lt;strong&gt;VS Code&lt;/strong&gt; 이다. 내장된 Git 버전 컨트롤, docs peeking, 원격 접속, 린터, 디버깅 기능 등을 제공하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;수많은 현업들이 Jupyter Notebook 환경을 사용하지만, 에디터가 별다른 기능을 제공하지 못하고, 코드의 작성 순서가 중요하지 않으며, 버전 컨트롤, 테스팅이 어렵다는 문제를 가지고 있다. &lt;a class=&#34;link&#34; href=&#34;https://nbdev.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Nbdev&lt;/a&gt; 패키지를 활용하면 이러한 문제들은 어느 정도 해결은 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;deep-learning-frameworks&#34;&gt;Deep Learning Frameworks&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;딥러닝의 본질적인 요소인 행렬 연산은 사실 Numpy 정도의 라이브러리만으로 해결 가능하다. 하지만 CUDA 를 통한 GPU 자원 활용, 전통적이지 않은 형태의 레이어 구축, 옵티마이저/데이터 인터페이스 활용 등을 위해서는 딥러닝 프레임워크가 필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PyTorch, TensorFlow, Jax 등 다양한 프레임워크들이 존재하며, 모델을 구축 한 후 배포 환경에 따라 최적화된 execution graph 를 찾는다는 점에서 근본적인 작동 원리는 서로 유사하다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;강사진은 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch&lt;/a&gt; 를 선호하는데, 구현된 모델 수, 연관 논문 수, 대회 수상 모델 수 등에서 압도적인 우세를 보이기 때문이다. 2021년도만 하더라도 ML 대회 우승 모델의 약 77%가 PyTorch 를 사용했다.&lt;/li&gt;
&lt;li&gt;PyTorch 의 경우 TorchScript 등의 파생 제품을 이용하면 실행 속도가 더욱 빨라지며, 분산 처리, 비전, 오디오, 모바일 배포 환경등의 생태계를 이루고 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.pytorchlightning.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Lightning&lt;/a&gt; 을 PyTorch 와 함께 사용하면 코드를 보다 구조적으로 유지할 수 있으며, 어떠한 하드웨어에서도 코드를 실행할 수 있다. 모델 체크포인팅 등 추가적인 기능 또한 제공.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/?gclid=CjwKCAiAhKycBhAQEiwAgf19euf21xRE6IFNBHwFXUSdIUSJu5-q_H8dscz8q1AeULry-_1pOeBGyBoCWO8QAvD_BwE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorFlow&lt;/a&gt; 의 경우 브라우저에서 딥러닝을 실행할 수 있는 TensorFlow.js, 쉽게 딥러닝 개발이 가능한 Keras 등의 파생 제품을 가지고있다.&lt;/li&gt;
&lt;li&gt;이외의 옵션으로는 &lt;a class=&#34;link&#34; href=&#34;https://www.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FasiAI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/google/jax&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;JAX&lt;/a&gt; 등이 있으며, 이들 라이브러리를 사용할 구체적인 이유가 있지않다면 비추천.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대부분의 ML 프로젝트는 이미 배포/개발된 모델 구조를 기반으로 시작하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://onnx.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ONNX&lt;/a&gt; 는 딥러닝 모델을 저장하는 표준 방식을 제공하는 패키지이며, PyTorch 에서 Tensorflow 등으로의 모델 변환을 가능하게 한다. 잘 작동하는 경우도 있지만, 모든 경우의 수를 감안하지는 못한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huggingface&lt;/a&gt; 는 최근 가장 떠오르는 모델 저장소이다. NLP 라이브러리로 시작했지만, 오디오/이미지 분류 등의 다양한 분야로 확장했으며 약 60,000 개의 사전 학습 모델, 7,500 개의 데이터셋을 제공한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://timm.fast.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TIMM&lt;/a&gt; 은 최신 비전 모델을 중점적으로 제공하는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distributed-training&#34;&gt;Distributed Training&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;다수의 GPU 를 내장한, 다수의 PC 에서 모델 학습이 가능한 환경에 있다고 가정하자. &lt;strong&gt;(1) 데이터 배치&lt;/strong&gt;와 &lt;strong&gt;(2) 모델 파라미터&lt;/strong&gt; 를 GPU 에 분산하여 처리하게 되며, 데이터 배치가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도, 모델 파라미터가 한 개의 GPU 에 저장 가능하거나 그렇지 않을 수도 있다.&lt;/li&gt;
&lt;li&gt;베스트 케이스는 데이터 배치와 모델 파라미터가 모두 한 개의 GPU 에 담길 수 있는 경우이다. 이와 같은 경우를 &lt;strong&gt;Trivial Parallelism&lt;/strong&gt; 이라 부르며, 다른 GPU/PC 에서 독립적인 학습을 수행할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델 파라미터가 한 개 GPU 에 담기나, 데이터 배치가 담기지 않는 경우 &lt;strong&gt;Data Parallelism&lt;/strong&gt; 을 수행할 수 있다. 즉, 단일 배치의 데이터를 여러대의 GPU 에 분산한 후 모델에 의해 연산된 gradient 의 평균값을 구하는 것이다.&lt;/li&gt;
&lt;li&gt;A100 등의 서버 카드를 활용한다며 연산 속도가 선형적으로 증가하며, 3090 과 같은 소비자용 카드 활용시 이보다 효율성이 떨어진다.&lt;/li&gt;
&lt;li&gt;PyTorch 라이브러리는 Data Parallelism 을 구현한 &lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistributedDataParallel&lt;/a&gt; 라이브러리를 제공한다. 써드파티 라이브러리로는 &lt;a class=&#34;link&#34; href=&#34;https://horovod.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Horovod&lt;/a&gt; 같은 옵션이 있으며, PyTorch Lightning 을 활용한다면 이 두 라이브러리 활용이 더욱 쉬워진다. 두 개 라이브러리의 성능은 서로 유사한 편이다.&lt;/li&gt;
&lt;li&gt;이보다 복잡한 경우는 모델 파라미터가 한 개 GPU 에 담기지 않는 경우인데, 이 경우 대표적으로 세가지의 솔루션, (1) Sharded Data Parallelism, (2) Pipelined Model Parallelism, (3) Tensor Parallelism, 이 존재한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sharded Data Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sharded 데이터 분산 처리는 GPU 메모리를 차지하는 요소인 (1) 모델 파라미터, (2) 미분값, (3) 옵티마이저 기록, (4) 데이터 배치를 모두 분산하여 다수의 GPU 메모리를 효율적으로 운영하는 방법이다.&lt;/li&gt;
&lt;li&gt;Microsoft 의 ZeRO 라는 방법론으로 처음 고안되었고, 기존 방식과 대비해 약 10배 큰 배치 사이즈를 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;Microsoft DeepSpeed, Facebook FairScale 등의 라이브러리가 존재하며, PyTorch 또한 기본적으로 Fully Sharded DataParallel 기능을 제공한다.&lt;/li&gt;
&lt;li&gt;ZeRO 접근법은 한 대의 GPU 에 적용될 수 있다 (분산된 데이터를 순차적으로 처리).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pipelined Model Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;모델의 각 레이어를 개별적인 GPU 에 분산시키는 방식이다. 어렵지 않게 구현이 가능하지만 별도의 패키지를 활용하지 않는다면 각 단계에서 하나의 GPU 만 활용하게 되기에 효율적이지 않다.&lt;/li&gt;
&lt;li&gt;DeepSpeed 와 FairScale 같은 라이브러리는 연산 스케줄링을 통해 모든 GPU 가 한꺼번에 동작하도록 설정이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tensor Parallelism 은 연산 대상 행렬을 다수의 GPU 에 분산하는 접근법이다. NVIDIA 에서 배포한 Megatron-LM repo 는 이러한 분산 방식을 Transformer 모델에 적용했다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT3 규모의 모델을 핸들링해야 한다면 언급한 3가지의 분산 처리 기법을 함께 사용하는 것 또한 가능하다. 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/bloom-megatron-deepspeed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BLOOM 학습&lt;/a&gt; 관련 자료를 참고.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;compute&#34;&gt;Compute&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;지난 10년 간 발전된 ML 모델이 요구하는 연산 자원은 빠른 속도로 성장했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;모델의 효율적인 학습을 위해선 GPU 활용은 필수적이다. 제조사 중 가장 큰 영향력을 행사하는 기업은 NVIDIA 이지만, Google 또한 자체적으로 설계/생산한 TPU 를 Google Cloud 를 통해 제공한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 선택할땐 다음의 3가지 고민이 필요하다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;한번에 얼마나 많은 데이터를 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;데이터를 얼마나 빠르게 처리할 수 있는가?&lt;/li&gt;
&lt;li&gt;CPU 와 GPU 간 통신 속도는 어느정도인가? 다수의 GPU 간 통신 속도는 어느정도인가?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;개선된 성능의 최신 GPU 구조는 거의 매년 소개되고 있다. 이러한 GPU 들은 소비자용과 기업용으로 나눌 수 있는데, 기업 환경에서는 항상 서버 카드를 사용해야 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPU 를 평가하는 2가지 중요한 지표는 RAM 과 Tensor TFlops 이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RAM 이 더 큰 GPU 는 상대적으로 더 많은 모델 파라미터와 데이터를 처리할 수 있다.&lt;/li&gt;
&lt;li&gt;Tensor TFlops 란 NVIDIA 에서 개발한 딥러닝 전용 GPU 코어를 뜻한다. Mixed Precision 연산, 즉 연산 성격에 따라 16bit 와 32bit 부동소수점 (floating point) 타입을 적절히 혼용하여 연산 속도와 사용 용량을 개선하는 작업에 최적화 되어있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/gpu-benchmarks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.aime.info/en/blog/deep-learning-gpu-benchmarks-2021/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AIME&lt;/a&gt; 과 같은 업체는 실사용 환경에 기반한 벤치마크 자료를 제공한다. NVIDIA A100 은 기존 V100 보다 2.5 배 정도 빠르며, RTX 칩 또한 V100 을 상회하는 성능을 보여준다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대형 클라우드 서비스인 Microsoft Azure, Google Cloud Platfrom, Amazon Web Services 등이 이러한 GPU 연산 자원을 이용할 수 있는 가장 기본적인 장소이며, 유사한 스타트업 서비스인 &lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.coreweave.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CoreWeave&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://lambdalabs.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lambda Labs&lt;/a&gt; 또한 참고할 만 하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TPU 의 경우 현재 4세대 까지 발전한 상태이며, 딥러닝을 위한 최적의 하드웨어이다. 상단의 그래프는 TPU 와 NVIDIA A100 의 성능을 비교한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;클라우드 서비스를 활용한 GPU 가용 비용은 미리 계산하기 까다로운 측면이 있기에 FSDL 팀은 이러한 문제를 해결하기 위한 &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/cloud-gpus/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GPU Cost Metric&lt;/a&gt; 툴을 공개했다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;성능/비용을 함께 고려했을때 고성능 GPU 는 시간당 비용이 비싸더라도 전체 학습 관점에서 비용을 절감하는 효과를 가질 수 있다. 예를 들어 동일한 트랜스포머 학습 시 4개의 V100 GPU 에서 72시간 동안 1,750 달러의 비용이 발생하지만, 4개의 A100 GPU 에선 8시간 동안 250 달러의 비용만 발생한다. 때문에 무조건 단가가 싼 GPU 를 활용하기 보다는 이러한 비용 절감 요소를 고려해 자원을 선택할 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음과 같은 룰이 이러한 자원 선택 과정에 도움을 줄 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;가장 저렴한 클라우드 서비스에서 시간당 비용이 가장 비싼 GPU 활용&lt;/strong&gt;할 것.&lt;/li&gt;
&lt;li&gt;Paperspace 와 같은 &lt;strong&gt;스타트업은 메이저 클라우드 사업자 대비 저렴한 비용으로 GPU 자원 제공&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 자원을 활용한다면 조립 PC 를 구축하거나, NVIDIA 와 같은 제조사에서 판매하는 딥러닝용 PC 를 구매할 수 있다. 128 GB 램, 2개의 RTX 3090 이 탑재된 PC 를 약 7,000 달러 정도에 구축할 수 있으며, 이보다 향상된 성능이 필요하다면 Lambda Labs 에서 판매하는 60,000 달러 학습용 PC 와 같은 옵션이 있다 (8개의 A100 탑재).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;온프레미스 vs. 클라우드&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU 자원을 소유하고 있다면 &lt;strong&gt;비용을 최소화한다는 관점보다는 활용도를 최대화한다는 관점에서 문제 접근이 가능&lt;/strong&gt;하다.&lt;/li&gt;
&lt;li&gt;스케일 아웃을 지향한다면, 가장 저렴한 클라우드 사업자를 이용하는 편이 맞다.&lt;/li&gt;
&lt;li&gt;연산 부담이 큰 작업이라면 TPU 활용을 진지하게 고려해야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;resource-management&#34;&gt;Resource Management&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;다수의 연산 자원이 확보되었다면 해당 자원들을 어떻게 관리/운영 할 것인지에 대한 고민 또한 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단일 자원 환경에선 &lt;a class=&#34;link&#34; href=&#34;https://python-poetry.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;poetry&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://docs.conda.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;conda&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://pypi.org/project/pip-tools/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;pip-tools&lt;/a&gt; 와 같은 패키지 매니저 / 가상환경을 활용해 쉽게 분석 환경을 설정할 수 있다. 이에 반해 다수의 자원을 활용할 때에는 &lt;a class=&#34;link&#34; href=&#34;https://slurm.schedmd.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SLURM&lt;/a&gt; 과 같은 리소스 매니저 활용이 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;휴대성/이식성을 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://www.docker.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker&lt;/a&gt; 를 통해 가볍게 모든 디펜던시 스택을 패키징할 수 있다. 자원 클러스터에서 다수의 Docker 컨테이너를 운영하기 위해서는 &lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes&lt;/a&gt; 와 같은 툴이 필요하며, &lt;a class=&#34;link&#34; href=&#34;https://www.kubeflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubeflow&lt;/a&gt; 는 Kubernetes 에 기반한 ML 프로젝트 운영을 돕는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;자원 클러스터 구축을 위한 옵션은 다음과 같다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS 를 활용한다면 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/pm/sagemaker/?trk=83e980bd-feef-4dc8-827c-21089d3b5592&amp;amp;sc_channel=ps&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&amp;amp;ef_id=Cj0KCQiA7bucBhCeARIsAIOwr-8hHn1JQyePYZvkT7YpagXav6_7hAP7L8afpmbCQJ-oRYxKnSnwpooaArmfEALw_wcB:G:s&amp;amp;s_kwcid=AL!4422!3!532438441650!e!!g!!sagemaker&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sagemaker&lt;/a&gt; 를 통해 데이터 레이블링 부터 모델 배포 까지의 과정을 모두 마칠 수 있다. Sagemaker 는 AWS 에만 존재하는 많은 설정값을 가진다는 단점이 있지만, 학습을 위한 수많은 학습 알고리즘을 제공하고 있다. 약간의 추가 비용이 발생하지만, PyTorch 또한 점차 지원하고 있는 추세이다.&lt;/li&gt;
&lt;li&gt;Anyscale 의 &lt;a class=&#34;link&#34; href=&#34;https://docs.ray.io/en/latest/train/train.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ray Train&lt;/a&gt; 은 Sagemaker 와 유사한 형태의 자원 클러스터 구축 도구이다. 하지만 비용이 다소 비싸다는 단점이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined.AI&lt;/a&gt; 는 온프레미스와 클라우드 클러스터를 관리하는 툴이다. 분산 학습 등의 기능을 지원하며, 계속 개발이 진행되고 있는 서비스이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다양한 클라우드 자원을 관리하는 작업은 난이도가 있고, 아직 개선의 여지가 존재하는 영역이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;experiment-and-model-management&#34;&gt;Experiment and Model Management&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;연산 자원 관리와는 달리, 학습 모니터링은 체계확립이 거의 완료된 영역이다. 학습 모니터링이란 모델 개발과정에서 변동하는 코드, 모델 파라미터, 데이터 셋에 대한 관리를 뜻하며, 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/tensorboard&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorBoard&lt;/a&gt; : 구글이 개발한 단발적인 학습 모니터링 툴이며, 다수의 학습을 체계적으로 관리하기 어려운 측면이 존재.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://mlflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLFlow&lt;/a&gt; : Databricks 에서 개발한 모델 패키징, 학습 모니터링 툴이며, self-hosting 이 필수적이다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=Performance-Max&amp;amp;utm_content=site&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=%7bcampaign%7d&amp;amp;utm_term=&amp;amp;utm_content=%7bcontent%7d&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr-9FBRDAmcSqE8zwkd1LTzevHny63DrOR_97Q19FVD_PdFLTC07m5SAaAiXHEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Weights and Biases&lt;/a&gt; : 개인적, 학업적 사용은 무료이며, &amp;ldquo;experiemnt config&amp;rdquo; 커맨드를 통해 학습 내용을 로그에 기록할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://neptune.ai/?utm_source=googleads&amp;amp;utm_medium=googleads&amp;amp;utm_campaign=[SG][HI][brand][rsa][all]&amp;amp;utm_term=neptune%20ai&amp;amp;gclid=Cj0KCQiA7bucBhCeARIsAIOwr--0uGPxuUEQLd9BHDlEAYPhIiF0-C-HvyadckWhW_3GCfg3ZCyeC0oaAsJxEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Neptune AI&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.comet.com/site/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Comet ML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.determined.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Determined AI&lt;/a&gt; 또한 연관 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;상단에 언급된 다수의 툴은 Hyperparameter Optimization 기능을 제공한다. 모델 튜닝을 효율적으로 수행하는데 도움을 주는데, 예를 들어 Weights and Biases 의 &lt;a class=&#34;link&#34; href=&#34;https://wandb.ai/site/sweeps&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sweeps&lt;/a&gt; 같은 기능이 이 역할을 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;all-in-one&#34;&gt;&amp;ldquo;All-In-One&amp;rdquo;&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_2_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;학습 모니터링, 분산 처리, 배포, 스케일링 등 언급된 모든 기능을 수행하는 인프라 솔루션 또한 존재하는데, 그 가격이 상당한 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.paperspace.com/gradient&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradient by Paperspace&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.dominodatalab.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Domino Data Lab&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/sagemaker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Sagemaker&lt;/a&gt; 와 같은 옵션이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-3---troubleshooting--testing&#34;&gt;Lecture 3 - Troubleshooting &amp;amp; Testing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=RLemHNAO5Lw&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/13UAHw1A7hM-O0jYGdGStN5gFCUb5XzLv/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-4---data-management&#34;&gt;Lecture 4 - Data Management&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=Jlm4oqW41vY&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-4-data-management/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/17Ak9mxNBIAv_FHUZsneqSWSud9Dh7F3i/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 분야가 발전되기 시작한 초기 단계에 업계가 잘 이해하지 못했던 부분은 데이터와의 접점이다. 데이터셋을 만들고, 분석하고, 전처리하는 등의 과정은 ML 프로젝트 전반에 걸쳐 필수적이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4주차 강의의 핵심 내용은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;초도 분석에 원하는 것보다 10배 많은 시간을 할애해야 한다.&lt;/li&gt;
&lt;li&gt;데이터를 고치고, 추가하고, 증강하는 것이 대체로 성능 향상에 가장 크게 기여한다.&lt;/li&gt;
&lt;li&gt;데이터를 다루는 과정을 가능한 간단하게 유지할 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-sources&#34;&gt;Data Sources&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;
&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;이미지, 텍스트, 로그, 데이터베이스&lt;/strong&gt; 등 데이터 원천의 종류는 다양하다. 딥러닝을 위해서는 GPU 자원이 있는 로컬 파일 시스템에 데이터를 옮겨와야하며, 이렇게 학습 데이터를 옮기는 방식은 다루는 데이터 마다 차이가 생긴다.
&lt;ul&gt;
&lt;li&gt;이미지의 경우 S3 등의 &lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;에서 직접 다운로드 받을 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 분산 처리를 통해 데이터를 분석하고, 일부분을 발췌해 로컬 환경으로 옮겨주는 등의 과정이 필요하다 &lt;em&gt;(원문 전달 내용이 조금 불확실함)&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;로그와 데이터베이스의 경우 &lt;strong&gt;데이터 레이크&lt;/strong&gt;를 활용해 데이터를 모으고, 처리할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;파일시스템&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;파일시스템이란 &lt;strong&gt;“파일” 이라는 기초 단위에 기반한 추상화 개념&lt;/strong&gt;이다. 파일이란 흔히 생각하듯 텍스트, 바이너리 등 다양한 형태를 취할 수 있으며, 버전의 개념을 가지지 않는다.&lt;/li&gt;
&lt;li&gt;파일시스템은 보통 사용하는 기기에 연결된 디스크에 저장되며, 연결의 개념은 물리적일 수도, 온프레미스, 클라우드, 혹은 분산시스템에 기반한 원격 연결을 의미할 수도 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;디스크 성능을 평가하는데 가장 중요한 요소는 속도와 대역폭&lt;/strong&gt;이다. 저장장치 포맷은 주로 HDD 와 SSD 로 나뉘어지며, 동일한 SSD 이더라도 SATA 와 NVMe 연결방식 간 약 100배의 속도차이가 발생한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;오브젝트 스토리지&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;오브젝트 스토리지란 &lt;strong&gt;파일시스템 활용을 위한 API&lt;/strong&gt; 를 뜻하며, 가장 기본이 되는 단위는 이미지, 오디오, 텍스트 등의 바이너리 형태 “오브젝트” 이다.&lt;/li&gt;
&lt;li&gt;버저닝, 중복 저장 개념이 존재하며, 로컬 파일시스템에 비해서는 속도가 느리지만 클라우드 활용을 위해서는 충분.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터베이스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;지속적이고, 빠르고, 스케일링이 가능한 정형데이터 저장소이다.&lt;/li&gt;
&lt;li&gt;이미지와 같은 바이너리 데이터를 저장하기 보다는 오브젝트 스토리지에 상응하는 URL 을 저장.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.postgresql.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Postgres&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.sqlite.org/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SQLite&lt;/a&gt; 등의 오픈소스가 널리 활용된다.&lt;/li&gt;
&lt;li&gt;프로젝트가 상호 reference 를 같는 객체를 다룬다면 데이터베이스의 도입이 불가피하기 때문에 처음부터 사용하는 편이 개발 시간을 단축시킬 가능성이 높다.&lt;/li&gt;
&lt;li&gt;W&amp;amp;B, HuggingFace Hub, Label Studio 등의 MLOps 툴을 사실 이러한 데이터베이스의 역할을 수행.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 웨어하우스&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스가 &lt;strong&gt;온라인 트랜잭션 처리 (OLTP)&lt;/strong&gt; 를 위해 설계되었다면, 데이터 웨어하우스를 &lt;strong&gt;온라인 분석 처리 (OLAP)&lt;/strong&gt; 을 위해 설계된 데이터 처장 체계이다.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OLTP&lt;/strong&gt; : &lt;em&gt;네트워크 상의 여러 이용자가 실시간으로 DB 의 데이터를 갱신하거나 조회하는 등의 단위작업 처리 방식. Row-oriented, 즉 개별적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OLAP&lt;/strong&gt; : &lt;em&gt;데이터를 분석하고 유의미한 정보로 치환하거나, 복잡한 모델링을 가능하게끔 하는 분석 방법. Column-oriented, 즉 통계적인 정보에 중점을 둠.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;데이터 웨어하우스로 여러 데이터를 끌어오는 작업을 &lt;strong&gt;ETL (Extract-Transform-Load)&lt;/strong&gt; 이라 칭하며, 비즈니스 관점의 의사결정을 위한 정보를 웨어하우스에서 끌어오게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;데이터 레이크&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 웨어하우스와 유사하나, 데이터를 사전에 가공하는 ETL 방식과 달리 일단 데이터를 모으고, 사용시 가공하는 &lt;strong&gt;ELT (Extract-Load-Transform)&lt;/strong&gt; 방식을 사용한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;최근 트렌드는 데이터 웨어하우스와 데이터 레이크를 통합하는 솔루션들이다. 정형 데이터와 비정형 데이터가 같은 저장소에서 다뤄질 수 있으며, &lt;a class=&#34;link&#34; href=&#34;https://www.snowflake.com/?lang=ko&amp;amp;utm_source=google&amp;amp;utm_medium=paidsearch&amp;amp;utm_campaign=ap-kr-ko-brand-core-exact&amp;amp;utm_content=go-eta-evg-ss-free-trial&amp;amp;utm_term=c-g-snowflake-e&amp;amp;_bt=579103397662&amp;amp;_bk=snowflake&amp;amp;_bm=e&amp;amp;_bn=g&amp;amp;_bg=128328467463&amp;amp;gclsrc=aw.ds&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUubkoz7BoatiURcPHbxVDF3FAWwLuPcV1hSkAOItZfeqaTMTbDpzxQaAnZXEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snowflake&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://www.databricks.com/p/ebook/the-data-lakehouse-platform-for-dummies?utm_medium=paid&amp;#43;search&amp;amp;utm_source=google&amp;amp;utm_campaign=15849074529&amp;amp;utm_adgroup=130486333845&amp;amp;utm_content=ebook&amp;amp;utm_offer=the-data-lakehouse-platform-for-dummies&amp;amp;utm_ad=587394793834&amp;amp;utm_term=databricks&amp;amp;gclid=Cj0KCQiA1sucBhDgARIsAFoytUsOVwmdjpvZBvMSSWc1Z-5P83Uc0Y8k7hBQYQjbHZIEF_5Vb0p_3fMaArshEALw_wcB&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Databricks&lt;/a&gt; 등의 업체가 분야를 선도하고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;분야에 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://dataintensive.net/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Designing Data-Intensive Applications&lt;/a&gt; 라는 책을 추천.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 탐색은 주로 &lt;strong&gt;SQL&lt;/strong&gt; 과 &lt;strong&gt;DataFrame&lt;/strong&gt; 을 활용해 수행한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt; 은 정형 데이터를 다루는 기본적인 인터페이스이며, 수십년간 사용되고 발전되어왔다. RDBMS 등의 트랜잭션 기반 데이터베이스에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pandas&lt;/strong&gt; 는 Python 생태계에서 사용되는 주된 DataFrame 이며 SQL 과 유사한 작업을 수행할 수 있다. OLAP 등의 분석 기반 환경에서 주로 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://examples.dask.org/dataframe.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DASK DataFrame&lt;/a&gt; 은 Pandas 작업을 여러개의 CPU 코어에서 분산 처리 할 수 있도록 돕는다. &lt;a class=&#34;link&#34; href=&#34;https://rapids.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RAPIDS&lt;/a&gt; 는 동일한 분산 처리 작업을 GPU 에서 수행.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-processing&#34;&gt;Data Processing&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리는 예시와 함께 설명하는 편이 좋다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SNS 플랫폼에 업로드되는 사진을 기반으로, 사진의 인기도를 예측하는 모델을 매일 학습하는 상황이라고 가정하자. 모델러는 다음과 같은 데이터를 활용하게 된다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터베이스 내 메타데이터 (업로드 시간, 제목, 장소 등)&lt;/li&gt;
&lt;li&gt;로그 데이터 기반 유저 정보 (로그인 횟수 등)&lt;/li&gt;
&lt;li&gt;별도 분류 모델 기반 사진 정보 (컨텐츠, 스타일 등)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;따라서 최종적인 모델 학습이 진행되기 전, 데이터베이스 쿼리 작업, 로그 처리 작업, 모델 예측 작업 등 많은 데이터 처리 작업이 수행되어야 하며, 이러한 &lt;strong&gt;사전 작업을 정해진 순서대로 처리&lt;/strong&gt;해야 할 필요가 생긴다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow&lt;/a&gt; 는 언급된 기능을 수행하는 Python 생태계의 기본 스케줄러 툴이다. &lt;strong&gt;DAG (Directed Acyclic Graph)&lt;/strong&gt; 라는 개념을 활용해 순차적인 작업 설정이 가능하며, 이러한 작업이란 SQL 쿼리, Python 함수 등 다양한 종류가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.prefect.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Prefect&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://dagster.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dagster&lt;/a&gt; 또한 유사한 기능을 수행하는 경쟁 제품이다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;feature-store&#34;&gt;Feature Store&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 처리 과정이 모델 학습과 병렬로 진행될 떄, 모델은 이후 학습에서 어떤 데이터가 신규로 생성되었는지, 어떤 데이터가 이미 학습에 활용되었는지 등을 파악할 필요가 발생할 수 있다 (필수적인 요소는 아님).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 경우 &lt;strong&gt;Feature Store&lt;/strong&gt; 기능을 활용한 데이터 관리가 필요해지게 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feature Store 라는 개념은 Uber 의 ML 플랫폼 &lt;strong&gt;Michalengelo&lt;/strong&gt; 를 소개하는 &lt;a class=&#34;link&#34; href=&#34;https://www.uber.com/en-KR/blog/michelangelo-machine-learning-platform/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 글&lt;/a&gt;에서 처음 등장했다. Uber 의 시스템 특성상 학습은 오프라인, 예측은 온라인으로 진행되기에 두 과정의 싱크를 맞춰줄 필요가 생겼고, 이를 해결하기 위한 수단으로 Feature Store 개념을 사용.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;tecton.ai&#34; &gt;Tecton&lt;/a&gt; 은 해당 분야에서 가장 널리 사용되는 SaaS 솔루션이며, 이외에도 &lt;a class=&#34;link&#34; href=&#34;https://feast.dev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Feast&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.featureform.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Featureform&lt;/a&gt; 등의 옵션이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;datasets&#34;&gt;Datasets&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/datasets/index&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HuggingFace Datasets&lt;/a&gt; 는 ML 학습에 특화된 8000+ 데이터셋을 제공하며, 비전, NLP 등 분야가 다양한 편이다. 호스트된 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/datasets/codeparrot/github-code&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github-Code&lt;/a&gt; 데이터를 예시로 들자면 데이터 핸들링을 돕기 위해 Aparche Parquet 형태로 스트림 할 수 있기 떄문에 1TB+ 용량의 전체 데이터를 다운로드 할 필요가 없다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;또다른 훌륭한 데이터셋의 예시로는 RedCaps 를 들 수 있다. Reddit 에서 수집된 12M 의 이미지-텍스트 페어를 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HuggingFace Datasets 와 유사한 서비스로는 &lt;a class=&#34;link&#34; href=&#34;https://www.activeloop.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Activeloop&lt;/a&gt; 이 있는데, 데이터 다운로드 없이 분석과 기타 데이터 활용이 가능하도록 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-labeling&#34;&gt;Data Labeling&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;데이터 레이블링 작업을 시작하기 전, 정말 레이블링이 필요한지를 스스로에게 물어볼 필요가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;자기지도학습 (self-supervised learning)&lt;/strong&gt; 이란 직접적인 레이블링 작업 없이 데이터의 일부분을 레이블로 활용하는 학습 방식을 뜻하며, NLP 과제에서 중요한 요소로 자리매김하고 있다. 마스킹 등의 기법을 통해 데이터의 한 부분을 예측하는 과제이며, &lt;a class=&#34;link&#34; href=&#34;https://openai.com/blog/clip/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenAI CLIP&lt;/a&gt; 과 같이 cross-modality 과제에서 (이미지-텍스트 등) 또한 활용이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;이미지 데이터 증강&lt;/strong&gt;은 비전 모델에서 사실상 필수적인 요소이다. &lt;a class=&#34;link&#34; href=&#34;https://github.com/pytorch/vision&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;torchvision&lt;/a&gt; 과 같은 라이브러리를 활용하여 간단하게 구현할 수 있으며, &lt;strong&gt;이미지의 &amp;ldquo;의미&amp;quot;를 변질시키지 않는 선에서 데이터에 변형을 주는 것&lt;/strong&gt;을 목표로 삼는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외 데이터 형태에 대한 증강 방식은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;정형 데이터의 경우 랜덤하게 선택된 셀 정보를 삭제함으로 미입수 데이터를 모방할 수 있다.&lt;/li&gt;
&lt;li&gt;텍스트의 경우 증강 기법이 상대적으로 부족한 편. 단어의 순서를 변경하거나, 부분적으로 삭제하는 방식이 존재한다.&lt;/li&gt;
&lt;li&gt;오디오 데이터는 속도를 조절하거나, 빈 오디오를 중간에 삽입하는 방식 등이 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Synthetic Data (합성 데이터)&lt;/strong&gt; 또한 고려해볼 필요가 있다. 레이블에 대한 사전 지식을 통해 기존에 존재하지 않는 데이터를 생성할 수 있으며, 적용 예시로는 영수증, 손글씨 이미지 등이 있다. 많은 공수가 필요하기 때문에 다른 방법은 없는지 충분히 검토 후 도입.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;보다 창의성을 발휘해 유저에게 레이블링 작업을 맞기는 것 또한 가능하다. 위 이미지와 같이 Google Photos 는 유저에게 이미지 레이블링 작업을 요구.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;유저의 직접적인 레이블링은 언급된 data flywheel 개념의 적용 예시이다. 유저는 모델 성능 향상에 기여하고, 이로 인해 유저의 제품 경험 또한 개선된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇듯 데이터 레이블링을 우회하는 다양한 방법이 존재하지만, 결국 &lt;strong&gt;모델링 작업을 시작하기 위해서는 어느정도의 레이블링 작업은 불가피&lt;/strong&gt;하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링이란 bounding box 와 같이 &lt;strong&gt;표준적인 형태의 주석을 기록하는 작업&lt;/strong&gt;이다. 주석의 형태보다는 레이블러가 올바른 교육을 받는 것이 가장 중요하며, &lt;strong&gt;이들이 레이블링 표준을 준수하도록 하는 것은 어렵지만 가장 핵심적인 요소&lt;/strong&gt;이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블러 고용 시 다음과 같은 옵션이 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터 레이블링을 전문적으로 수행하는 업체.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;레이블러의 &lt;strong&gt;직접적인 고용&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.mturk.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Mechanical Turk&lt;/a&gt; 와 같은 &lt;strong&gt;크라우드 소싱&lt;/strong&gt;. 레이블링 품질을 위해 가능한 피하는 편이 좋다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;레이블링 전문 업체들은 소프트웨어 개발, 인력 관리, 품질 관리 까지의 다양한 작업을 수행한다. 업체 활용이 필요하다면 데잍러를 충분히 이해한 후, 샘플 레이블 등을 통해 여러 경쟁 업체를 비교한 후 의사결정을 내리는 편이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://scale.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Scale AI&lt;/a&gt; 는 업계에서 가장 규모가 큰 데이터 레이블링 솔루션이다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://labelbox.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Labelbox&lt;/a&gt; 와 &lt;a class=&#34;link&#34; href=&#34;https://supervise.ly/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Supervisely&lt;/a&gt; 가 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://labelstud.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LabelStudio&lt;/a&gt; 는 가장 널리 알려진 오픈소스 솔루션이며, 직접 레이블링을 수행할 때 활용하게 된다. 경쟁자로는 &lt;a class=&#34;link&#34; href=&#34;https://diffgram.com/main/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Diffgram&lt;/a&gt; 이 있다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://snorkel.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Snorkel&lt;/a&gt; 은 weak supervision 기반 레이블링 툴이며, &amp;ldquo;amazing&amp;rdquo; 이라는 단어가 들어간 모든 문장을 &amp;ldquo;긍정&amp;rdquo; 카테고리로 구분하는 등의 빠른 레이블링 작업을 돕는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-versioning&#34;&gt;Data Versioning&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 버전 관리는 단계적으로 구분이 가능하다.
&lt;ul&gt;
&lt;li&gt;Level 0 : &lt;strong&gt;단순한 파일시스템 관리로, 버전 관리가 이루어 지지 않는다.&lt;/strong&gt; 모델이란 코드와 데이터가 합쳐져 만들어진 결과물이기 때문에, 데이터가 바뀌면 동일한 모델을 구현하지 못하게 된다.&lt;/li&gt;
&lt;li&gt;Level 1 : &lt;strong&gt;학습시 데이터에 대한 스냅샷을 저장&lt;/strong&gt;하는 방식. 모델에 활용된 데이터가 특정 가능하지만, 이상적인 방식이라고 보기엔 어렵다.&lt;/li&gt;
&lt;li&gt;Level 2 : &lt;strong&gt;코드 버전 관리와 같은 개념을 도입&lt;/strong&gt;. &lt;a class=&#34;link&#34; href=&#34;https://git-lfs.github.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Git-LFS&lt;/a&gt; 와 같은 툴을 사용하게되며, 적극적으로 권장되는 방식이다.&lt;/li&gt;
&lt;li&gt;Level 3 : 대용량 데이터 관리를 위한 &lt;strong&gt;특별한 솔루션&lt;/strong&gt;을 도입. 합리적인 이유 (데이터 용량이 지나치게 크거나, 데이터에 많은 규제가 붙는 경우 등) 가 없다면 불필요하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_4_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이러한 작업을 위한 툴로는 &lt;a class=&#34;link&#34; href=&#34;https://dvc.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DVC&lt;/a&gt; 가 있다. 데이터를 원격 저장소에 저장하고, 필요시 이전 버전으로 회귀하는 기능을 제공.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-5---deployment&#34;&gt;Lecture 5 - Deployment&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=W3hKjXg7fXM&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-5-deployment/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1ABdEgVHvOIBtJhfmzy5ps_dMrwFKlgwd/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배포 과정은 좋은 모델 개발에 있어 필수적인 요소이다. &lt;strong&gt;오프라인으로 모든 평가를 진행하면 모델의 작은 실수들을 놓치기 쉽고, 사용자가 정말 필요로 하는 문제 해결 능력이 부재할 수 있기 때문.&lt;/strong&gt; 이러한 요소는 모델 배포를 통해서만 검증이 가능한 경우가 많다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다른 ML 개발 단계와 같이 &lt;strong&gt;최소한의 기능만을 구현한 후, 복잡한 부분들을 순차적으로 추가&lt;/strong&gt;하는 과정을 거치는 편이 좋다. 과정은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프로토타입 설계&lt;/li&gt;
&lt;li&gt;모델/UI 분리&lt;/li&gt;
&lt;li&gt;스케일 문제 해결&lt;/li&gt;
&lt;li&gt;속도 이슈 발생 시, 엣지 디바이스 활용 검토&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;build-a-prototype-to-interact-with&#34;&gt;Build A Prototype To Interact With&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;프로토타입 설계를 위한 툴로는 최근 HuggingFace 가 인수한 &lt;a class=&#34;link&#34; href=&#34;https://gradio.app/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gradio&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://streamlit.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Streamlit&lt;/a&gt; 등이 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;좋은 프로토타입 설계를 위해서는 다음과 같은 기본적인 규칙을 지키자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;심플한 UI&lt;/strong&gt; : 프로토타입의 주된 목적은 실사용 환경에서 모델을 테스트해보고, 타인의 피드백을 얻는 것이다. Gradio, Streamlit 과 같은 앱을 활용하면 많은 코드를 쓰지 않더라도 기본적인 인터페이스 구축이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Web URL 활용&lt;/strong&gt; : URL 은 공유하기 쉬우며, 이를 기준점으로 삼아 더욱 복잡한 배포 방식을 택하면서 발생할 장단점을 생각할 수 있다. Streamlit, HuggingFace 모두 클라우드 배포 기능을 제공.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;공수 최소화&lt;/strong&gt; : 강사진은 프로토타입 설계에 하루 이상을 소비하지 않을 것을 권장.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 프로토타입은 최종 솔루션의 형태가 아니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;프론트엔드 구현에 있어 분명한 한계점이 존재한다. 완성된 형태의 서비스 제공을 위해서는 커스텀 UI 제작이 필요.&lt;/li&gt;
&lt;li&gt;스케일링 문제를 안고있다. 유저 수가 증가하게 된다면 스케일업을 위해 백엔드 구축이 필요.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;상단 장표는 일반적인 어플리케이션의 구조를 보여준다. Client 란 유저가 상호작용하는 기기, 즉 브라우저, 차량, 스마트폰 등이며, 이러한 기기는 네트워킹을 통해 서버와 소통한다. 서버는 데이터베이스와의 상호 작용을 통해 어플리케이션을 구동.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이러한 기본적인 어플리케이션 구조에 ML 모델을 배포하는 여러가지 방법이 존재한다. 언급된 프로토타입 접근법은 &lt;strong&gt;model-in-service&lt;/strong&gt; 방식에 해당하며, 웹서버가 패키징된 모델을 품고있는 경우이다 &lt;em&gt;(인스타 등 이미 성숙도가 올라간 서비스에 ML 기능을 추가하는 형태로 생각하면 됨)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 방식의 가장 큰 장점은 모델의 복잡성과 무관하게 기존의 인프라를 사용할 수 있다는 점이다. 하지만 이러한 방식에는 여러가지 단점 또한 존재한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;웹서버가 다른 언어로 작성.&lt;/strong&gt; 파이썬 기반이 아니라면, 이미 구축된 모델을 서버에 통합하는 과정이 까다로울 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;모델이 서버 코드보다 자주 업데이트 될 수 있음.&lt;/strong&gt; 어플리케이션이 이미 성숙 단계에 접어들었으나 모델이 초기 단계에 있다면, 모델 업데이트 마다 재배포 과정을 겪어야 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;웹서버에 비해 모델의 크기가 지나치게 클 수 있음.&lt;/strong&gt; 이러한 경우 모델을 직접적으로 사용하지 않더라도 전반적인 어플리케이션 사용 경험에 부정적인 영향이 미칠 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;서버 하드웨어는 ML 작업에 최적화되지 않음.&lt;/strong&gt; 이러한 서버 장비에 GPU 가 내장되어 있는 경우는 굉장히 드물다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링 속성의 차이가 발생할 수 있음.&lt;/strong&gt; 따라서 모델과 기존 어플리케이션 간 스케일링 규칙의 차등을 두어야 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;separate-your-model-from-your-ui&#34;&gt;Separate Your Model From Your UI&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;모델을 UI 에서 완전히 분리하는 방법은 크게 &lt;strong&gt;(1) Batch Prediction&lt;/strong&gt;, &lt;strong&gt;(2) Model-as-Service&lt;/strong&gt; 방식으로 나뉜다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 이란 모든 데이터 포인트에 대한 예측치를 사전에 구한 후, 결과값을 데이터베이스에 저장하는 방식&lt;/strong&gt;이다. 경우에 따라 가장 적절한 방식일 수 있는데, 인풋값이 제한된 경우 주기적으로 예측치를 구하는 것만으로 충분히 최신 정보가 반영된 예측치를 사용자에게 전달할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 방식이 적절한 예시는 초기단계의 추천 시스템, 내부 활용을 위한 마케팅 자동화 시스템 등.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주기적으로 예측값을 구하기 위해서는 데이터 처리 자동화 파이프라인 활용이 필요하다. (1) 데이터 처리, (2) 모델 로딩, (3) 예측, (4) 예측값 저장 순의 작업이 필요한데, Dagster, Airflow 등의 DAG 시스템이 처리하기에 적절한 문제이다. 유사한 ML 전용 툴인 &lt;a class=&#34;link&#34; href=&#34;https://metaflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Metaflow&lt;/a&gt; 또한 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;구현이 간단하다.&lt;/strong&gt; 이미 학습에 배치 처리 툴을 활용하고 있다면 이러한 구조를 재사용 할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링이 쉽다.&lt;/strong&gt; 데이터베이스는 기본적으로 스케일링에 최적화 되어있는 시스템이다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;대형 시스템에서 수년간 검증된 구조.&lt;/strong&gt; 이미 많은 기업들이 이와 같은 예측 파이프라인을 활용해왔고, 예상하지 못한 문제가 발생할 확률이 상대적으로 적다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치 전달이 빠름.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Batch Prediction 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;경우의 수가 많은 인풋을 처리할 수 없음.&lt;/strong&gt; 모든 경우의 수에 대한 모든 예측치를 구하는 것에는 분명한 한계가 존재한다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;예측치가 가장 최신의 정보를 반영하지 못함.&lt;/strong&gt; 이러한 정보가 매분, 매초 의미있는 변화를 가진다면, 유저가 보는 예측치는 이미 유의미한 정보를 제공하지 못할 확률이 높다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batch Job 실행 실패를 감지하기 어려움.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 란 모델을 별도의 온라인 서비스로서 운영하는 방식이다.&lt;/strong&gt; 모델은 백엔드, 또는 클라이언트에서 송출한 request 에 대해 response 를 보내는 방식으로 소통하게된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 장점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;신뢰성.&lt;/strong&gt; 모델에서 발생한 버그가 전체 웹 어플리케이션을 다운시킬 확률이 감소하게 된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;스케일링.&lt;/strong&gt; 목적에 최적화된 하드웨어를 선택하고, 알맞은 방식으로 스케일링을 적용할 수 있다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;유연성.&lt;/strong&gt; 여러 어플리케이션이 모델 인프라를 공유할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model-as-Service 의 단점&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;레이턴시.&lt;/strong&gt; 별도의 서비스인 만큼, 서버/클라이턴트가 모델을 사용할 때 시간적 비용이 발생.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;복잡한 인프라.&lt;/strong&gt; 구축/운영에 대한 새로운 비용이 발생함.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 단점들은 감안하더라도 &lt;strong&gt;model-as-service 구조는 대부분의 ML 제품 배포에 적합한 방식이다&lt;/strong&gt;. 복잡한 어플리케이션의 구조에서 모델 서비스를 개별적으로 스케일링 할 수 있다는 점은 중요하기 때문.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5주차 강의에선 이러한 모델 서비스를 구축하기 위한 부분들을 설명한다. 이는 &lt;strong&gt;(1) Rest API, (2) 디펜던시 관리, (3) 성능 최적화, (4) 수평 스케일링, (5) 롤아웃&lt;/strong&gt; 등의 개념을 포함한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Rest APIs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ML 제품의 &lt;strong&gt;Rest API&lt;/strong&gt; 란 약속된 형태의 HTTP 요청에 따라 예측값을 반환하는 형태를 칭한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인프라에 호스팅된 대안적인 프로토콜은 &lt;a class=&#34;link&#34; href=&#34;https://grpc.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gRPC&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://graphql.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GraphQL&lt;/a&gt; &lt;em&gt;(모델 서비스에 적합하지 않을 수 있음)&lt;/em&gt; 이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;아직 모델 서비스 분야에선 Rest API 문법이 통일되지 않은 상태.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google Cloud 는 key, value 페어를 가진 리스트를 인풋으로 정의&lt;/li&gt;
&lt;li&gt;Azure 는 모델 구조에 따라 변동하는 데이터 오브젝트를 다룸&lt;/li&gt;
&lt;li&gt;AWS Sagemaker 는 Google Cloud 와 유사한 형태의 인풋을 기대하지만, 세부적인 형태의 차이 존재.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dependency Management (디펜던시 관리)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;예측값은 코드, 모델 가중치, 그리고 디펜던시에 따라 결정된다.&lt;/strong&gt; 따라서 기대하는 예측값을 얻기 위해서는 웹서버에 개발 환경과 동일한 디펜던시가 세팅되어야 하지만, 이를 항상 보장하는 것은 어려운 작업이다 &lt;em&gt;(개발 환경에서 혹여나 패키지 업데이트가 이루어진다면 서버에서 동일한 업데이트를 매번 진행해야 함, 개발자가 많아지면 관리가 어려워진다)&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 디펜던시를 관리하는 방법은 크게 두가지가 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;디펜던시에 무관하게 실행 가능한, &lt;strong&gt;표준화된 모델 개발&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컨테이너 활용&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 모델 표준화&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;모델 표준화는 ONNX (Open Neural Network Exchange) 라이브러리를 활용해 이루어진다. 라이브러리는 &lt;strong&gt;환경에 무관하게 실행 가능한 ML 모델&lt;/strong&gt;을 개발할 수 있도록 돕는데, 언어, 패키지 버전 등과 무관하게 동일한 기능을 제공하는 것을 목표로 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 실사용 환경에선 많은 라이브러리들이 지나치게 빠른 속도로 업데이트되기 때문에 변환 과정에서 버그가 자주 발생하고, 이를 해결하기 위해 오히려 ONNX 를 사용하지 않는 것 보다 더 많은 작업이 발생하는 경우가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;또 torchvision 과 같은 주변 라이브러리는 아예 지원이 안되는 경우가 많다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 컨테이너&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;컨테이너를 설명하기 전, 우선 도커와 가상머신의 개념을 구분해 정리할 필요가 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;가상머신 (VM)&lt;/strong&gt; : &lt;strong&gt;라이브러리, 어플리케이션은 물론 운영체계 (OS) 까지를 하나의 패키지로 묶는 방식&lt;/strong&gt;이다. 용량은 물론 실행에 필요한 자원 소모가 큰 편.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;도커&lt;/strong&gt; : &lt;strong&gt;OS 를 적은 용량/자원으로 가상화하여, 필요한 라이브러리와 어플리케이션 만을 구동&lt;/strong&gt;하는 방식.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이렇듯 실행이 가벼운 도커는 일반적으로 구분 가능한 작업 마다 개별적으로 생성된다. 예시로 웹앱은 (1) 웹서버, (2) 데이터베이스, (3) Job 관리, (4) Worker 총 4개의 컨테이너가 함께 동작하는 방식으로 운영.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Job 관리 (Job Queue)&lt;/strong&gt; : Airflow, Rundeck 등의 Job Scheduler 에서 유지하는, 앞으로 실행할 Job 에 대한 데이터 구조.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Worker&lt;/strong&gt; : 요청한 태스크를 수행하는 자원 &lt;em&gt;(예. 주문 내역을 파싱 및 데이터베이스로 이동)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;도커 컨테이너는 &lt;strong&gt;도커 파일&lt;/strong&gt;을 통해 생성된다. 각 컨테이너는 서로 다른 도커 파일을 통해 환경을 생성하며, 클라우드나 별도 서버에 저장된 도커 허브를 통해 컨테이너를 공유하는 것 또한 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;도커는 다음과 같은 3가지 요소로 구성되어 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;클라이언트&lt;/strong&gt; : 도커 이미지 구성. 로컬 환경에서 여러 커맨드를 통해 조작이 가능하다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;도커 호스트&lt;/strong&gt; : 클라이언트에서 입력된 커맨드 실행 및 이미지/컨테이너 생성. 서버 혹은 로컬 환경 모두 구성이 가능함.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;레지스트리&lt;/strong&gt; : 여러 개의 컨테이너 저장. 도커 호스트와 직접 소통.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이와 같은 태스크 분리를 통해 노트북 등의 로컬 자원, 도커 호스트에 저장된 이미지에 등에 의해 도커 활용에 제약이 가해지지 않는다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;공개된 여러 퍼블릭 도커 허브엔 다양한 이미지가 호스팅 되어 있으며, 프라이빗 이미지를 저장할 수 있는 기능 또한 제공하고 있다. 최근엔 그 인기가 급상승해 이렇나 도커 허브 활용을 기본 전제로 하는 경우가 잦은 편이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;도커는 입문 난이도가 다소 높은 편이다. &lt;a class=&#34;link&#34; href=&#34;https://github.com/replicate/cog&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cog&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/bentoml/BentoML&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BentoML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://github.com/trussworks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Truss&lt;/a&gt; 와 같은 서비스는 이러한 과정을 간소화 해주며 지정된 모델 호스트 활용, 모델 패키징 등 다양한 기능을 제공한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance Optimization (성능 최적화)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;예측 연산을 효율화하기 위해선 &lt;strong&gt;GPU, concurrency (여러 모델 활용), model distillation (모델 간소화), quantization (파라미터 용량 제한), caching (캐싱), batching (배치 관리), GPU sharing, 관련 라이브러리들&lt;/strong&gt;을 논할 필요가 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. GPU&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;호스트 서버에 GPU 자원을 포함시키는 것에서 얻는 장점은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;학습이 이루어진 것과 같은 환경에서 예측이 이루어진다면 &lt;strong&gt;환경 관련 이슈가 발생할 염려가 없다&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;많은 트래픽을 더욱 빨리 처리할 수 있다&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 &lt;strong&gt;GPU 자원은 세팅이 보다 어렵고, 트래픽에 의한 비용폭이 크기 때문에 CPU 만을 활용한 초기 모델 서비스 또한 고려해봄직 하다&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하기 테크닉을 통해 보다 적은 비용으로 CPU 자원에서 연산 속도를 개선하는 것 또한 가능함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Concurrency&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;여러개의 CPU, 또는 CPU 코어에서 복수의 모델을 실행하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Thread Tuning&lt;/strong&gt; 과정이 필요하며, 이와 같은 테크닉을 통해 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Nw77sEAn_Js&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;로블록스&lt;/a&gt;는 일일 10억 리퀘스트에 대한 BERT 서비스를 CPU 자원만으로 해결.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. Model Distillation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;학습된 모델의 행동을 모방하는 작은 규모의 모델을 생성하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://heartbeat.comet.ml/research-guide-model-distillation-techniques-for-deep-learning-4a100801c0eb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;이 글&lt;/a&gt; 에서 관련된 테크닉을 소개하고 있으며, 직접 구현시 성능이 다소 떨어질 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;서비스 환경에서 자주 활용되지는 않지만, &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/transformers/model_doc/distilbert&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistilBERT&lt;/a&gt; 와 같은 예외 경우 또한 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4. Quantization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;모델 전체, 또는 일부분을 보다 작은 용량의 number representation 을 활용해 실행하는 방식이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대게 활용되는 representation 으로는 16-bit floating point, 8-bit integer 가 있으며, 모델 정확도에 부정적인 영향을 끼치게 된다. 속도 개선이 정확도 보다 중요하다고 판단되면 고려할 수 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PyTorch, Tensorflow 등의 패키지는 자체 quantization 라이브러리를 포함하고 있으며, Huggingface 의 사전학습 모델 활용 시 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/docs/optimum/index&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huggingface Optimum&lt;/a&gt; 또한 활용이 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습 시 quantization 과정을 감안한 &lt;strong&gt;quantization-aware training&lt;/strong&gt; 이라는 테크닉이 존재하고, 적은 용량으로 representation 변경 시 보다 개선된 정확도를 보인다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5. Caching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;자주 처리되는 인풋을 캐시에 미리 저장해둠으로 처리 속도를 개선시키는 방식. 자원 활용이 큰 연산을 수행하기 전에 인풋이 캐시에 존재하는지 먼저 확인한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;캐싱에는 다양한 방식이 존재하지만, &lt;a class=&#34;link&#34; href=&#34;https://docs.python.org/3/library/functools.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Python functools 라이브러리&lt;/a&gt;를 활용하는 것을 추천.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. Batching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;배치 처리 시 연산 속도가 개선된다는 점을 활용해 (특히 GPU 활용 시) 일정 수만큼의 인풋을 저장 후 처리하는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인풋을 모으는 기간 동안 유저가 레이턴시를 경험할 수 있기 때문에 배치 사이즈 조절이 필요하다. 레이턴시가 너무 길어진다면 이를 별도로 처리해야하며, 구현이 복잡하기 때문에 라이브러리 등을 활용.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;7. GPU Sharing&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;단일 GPU 에 여러개의 모델을 구동시키는 것 또한 가능하다. GPU sharing 기능을 지원하는 패키지 활용.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;8. 라이브러리&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyTorch, Tensorflow, NVIDIA, Ray Serve 등의 옵션이 있다. NVIDIA 쪽이 가장 좋은 성능을 보여주지만 입문장벽이 있는 편이고, &lt;a class=&#34;link&#34; href=&#34;https://docs.ray.io/en/latest/serve/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ray Serve&lt;/a&gt; 의 경우 비교적 난이도가 쉬운 편.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Horizontal Scaling (수평 스케일링)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;트래픽이 증가할 수록 단일 서버보다는 여러대의 서버에서 복제된 모델을 운영할 필요가 생긴다. 이를 &lt;strong&gt;수평 스케일링&lt;/strong&gt;이라 부르며, 한대의 서버에서 처리했을 트래픽을 여러개의 서버로 분산하는 작업을 필요로한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;각 서버엔 서비스되는 모델의 복제본이 저장 되어있으며, &lt;a class=&#34;link&#34; href=&#34;https://www.nginx.com/resources/glossary/nginx/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;nginx&lt;/a&gt; 와 같은 load balancer 라는 툴을 이용해 분산된 트래픽을 처리한다. 모델 서비스의 경우 이를 구현하는 방식으로는 크게 &lt;strong&gt;container orchestration 와 serverless&lt;/strong&gt; 가 존재한다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. Container Orchestration&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes&lt;/a&gt; 를 활용해 다수의 도커 컨테이너를 여러대의 서버에서 분산처리 할 수 있도록 돕는 방식.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;단순히 모델 배포가 목적이라면 굳이 Kubernetes 를 활용할 필요는 없다. &lt;a class=&#34;link&#34; href=&#34;https://www.kubeflow.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubeflow&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.seldon.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Seldon&lt;/a&gt; 등 관련 작업을 간소화 하는 옵션이 존재.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Serverless&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;어플리케이션을 구성하는 코드와 환경을 zip 파일, 또는 도커 컨테이너로 압축한 후 하나의 함수 (model.predict() 등) 를 통해 예측치를 연산하도록 구성.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이와 같이 패키징 된 모델은 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/lambda/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Lambda&lt;/a&gt; 와 같은 서비스를 통해 배포되며, 인프라와 관련된 모든 작업은 클라우드에서 자동적으로 처리된다 &lt;em&gt;(증가한 트래픽에 따른 스케일링 등)&lt;/em&gt;. 유저 입장에서는 제때 비용만 정산하면 됨.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;구체적인 이유로 Kubernetes 를 활용하는 것이 아니라면, Serverless 로 배포를 시작하는 편이 좋다. 단점은 다음과 같이 정리할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;배포 패키지의 사이즈 제한이 존재한다.&lt;/strong&gt; 용량이 큰 모델은 이와 같은 방식으로 배포가 어려운 편.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;트래픽 미발생으로 서버가 닫혀있는 상태에서 다시 예측치를 내기 까지의 시간 소요가 길다.&lt;/strong&gt; 이를 cold start 문제라 부르며, 초단위에서 분단위 까지의 시간을 필요로 한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;파이프라인 등 복잡한 소프트웨어 기능 구현이 어렵다.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;서버 상태 모니터링과 별도 배포 툴 적용이 어렵다.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Serverless 환경은 대체로 GPU 를 포함하지 않으며, 실행 시간에 제한을 둔다.&lt;/strong&gt; 보다 작은 규모의 &lt;a class=&#34;link&#34; href=&#34;https://www.banana.dev/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Banana&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.pipeline.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Piepeline&lt;/a&gt; 과 같은 스타트업들은 GPU 를 활용한 서버리스를 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model Rollouts (롤아웃)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;이미 배포된 상태의 모델을 업데이트하고, 관리하는 과정을 의미한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;새로운 모델을 효율적으로 배포 하기 위해서는 다음과 같은 배포 방식이 모두 가능해야 한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;점진적 배포&lt;/strong&gt; : 기존 배포 버전에서 새로운 배포 버전으로 트래픽 양을 점진적으로 증가.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;즉각적 배포&lt;/strong&gt; : 문제가 발생한 배포 버전에서 새로운 배포 버전으로 즉각적인 변경.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;배포 버전 관리&lt;/strong&gt; : 두 개의 배포 버전을 두고 트래픽 배분.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;파이프라인 배포&lt;/strong&gt; : 개발된 파이프라인 플로우를 모델과 함께 배포.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이러한 기능들은 직접 구현이 어려우며, 일반적으로 managed service 를 통해 모델 배포에 적용하게 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Managed Options&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_18.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;클라우드 3사 모두 배포 과정을 간소화하는 managed service option 기능을 제공하며, BentoML, Banana 등의 스타트업 또한 관련 기능을 제공.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;가장 인지도 있는 서비스는 &lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/sagemaker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AWS Sagemaker&lt;/a&gt; 이다. Huggingface class, SciKit-Learn model 등 일반적인 형태의 모델의 경우 적용이 쉬운 편이다. 하지만 일반적인 EC2 인스턴스에 비해 50~100% 가량 비용이 비쌈.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;move-to-the-edge&#34;&gt;Move To The Edge?&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_19.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;웹에서 벗어나 클라이언트 기기 (엣지 디바이스) 내에서 모델 예측을 구현하는 방식 또한 고려해 볼 수 있다. 인터넷 액세스가 불안정한 환경이거나, 민감한 개인정보를 다룰 경우 엣지 디바이스 활용은 필수적.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;엣지 디바이스 활용을 필수적으로 요구하는 환경이 아니라면, 모델의 정확도와 레이턴시 간 유저 경험에 더 중요한 요소를 선택해야한다. &lt;strong&gt;레이턴시를 줄일 수 있는 모든 옵션이 이미 적용되었다면, 엣지 디바이스 활용을 고려할 것&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;엣지 디바이스 inference 는 구현이 복잡하기 때문에 반드시 필요한 경우에만 적용해야 한다. 서버에서 학습된 모델 가중치를 엣지 기기에 불러온 후, 이후 모든 예측 과정을 엣지 기기에서 수행하는 방식으로 진행.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대표적인 장점은 레이턴시 감소이다. 네트워크를 사용할 필요가 없으며, 트래픽에 의한 비용이 발생하지 않는다. 이에 반한 단점은 하드웨어와 소프트웨어의 제약이다. 모델 업데이트 또한 과정이 보다 복잡해지는 문제가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Frameworks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;엣지 배포에 필요한 적절한 프레임워크는 학습 과정과 엣지 기기에 따라 달라질 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developer.nvidia.com/tensorrt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorRT&lt;/a&gt;&lt;/strong&gt; : 엣지 기기가 NVIDIA 하드웨어라면 가장 적절&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developers.google.com/ml-kit&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLKit&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://developer.apple.com/documentation/coreml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CoreML&lt;/a&gt;&lt;/strong&gt; : Android, 혹은 iPhone 을 대상으로 한다면 공식 프레임워크 검토&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/mobile/home/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyTorch Mobile&lt;/a&gt;&lt;/strong&gt; : iOS 와 Android 환경을 모두 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/lite&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TFLite&lt;/a&gt;&lt;/strong&gt; : 핸드폰과 같은 일반적인 기기가 아닌 경우 또한 TF 사용 환경을 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tensorflow.org/js&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TensorFlow JS&lt;/a&gt;&lt;/strong&gt; : 브라우저 배포 전용 프레임워크&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://tvm.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache TVM&lt;/a&gt;&lt;/strong&gt; : 라이브러리, 타깃 기기와 무관하게 활용 가능. 가능한 많은 환경을 지원하고자 한다면 적절함&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이외에도 &lt;a class=&#34;link&#34; href=&#34;https://mlir.llvm.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLIR&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://octoml.ai/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OctoML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.tinyml.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TinyML&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.modular.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Modular&lt;/a&gt; 과 같은 제품군이 존재함.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;엣지 기기의 하드웨어 제약을 뛰어넘는 용량을 가진 모델의 경우, 프레임워크와 무관하게 배포는 불가능하다고 보아야한다. 때문에 가능한 적은 용량과 연산 자원을 사용하면서 최대의 성능을 이끌어내는 모델 구조가 중요.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Quantization, Distillation 등의 기법 또한 활용 가능하나, &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MobileNets&lt;/a&gt;&lt;/strong&gt; 와 같이 엣지 기기를 사전에 염두한 모델 구조 또한 존재한다. 모델 성능이 감소하나 많은 경우 실사용에 지장이 없다. 이와 결이 유사한 모델로는 &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/huggingface/distilbert-8cf3380435b5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DistilBERT&lt;/a&gt;&lt;/strong&gt; 가 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/fsdl_5_21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mindsets&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;엣지 배포를 검토할 시 다음과 같은 사항을 고려하는 편이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;모델 구조가 아닌 엣지 기기의 환경에 집중할 것.&lt;/strong&gt; 성능이 좋은 모델 구조를 학습 후, 엣지 기기에서 구동이 어렵다면 모델링 과정을 처음부터 다시 시작해야 할 수 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;실행 가능한 모델이 구현되었다면, 계속적으로 엣지 기기를 활용할 것이 아니라 로컬 환경에서 모델을 고도화 할 것.&lt;/strong&gt; 이 경우 모델 용량 등을 Experiment Tracking Metric 으로 추가하는 것이 좋다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;모델 튜닝 과정을 추가적인 리스크로 다룰 것.&lt;/strong&gt; 관련 프레임워크는 아직 성숙하지 못했기 때문에, 작은 하이퍼파라미터 변동으로도 모델이 작동하지 않을 리스크가 존재한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;버저닝을 통한 회귀점을 구비할 것.&lt;/strong&gt; 엣지 배포의 경우 특히 모델을 작동하던 마지막 상태로 복구할 수 있는 시스템이 필요하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-6---continual-learning&#34;&gt;Lecture 6 - Continual Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=nra0Tt3a-Oc&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-6-continual-learning/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/10fDYIEELIeT3Nju001GTAxM_YYUDFMpB/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-7---foundation-models&#34;&gt;Lecture 7 - Foundation Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=Rm11UeGwGgk&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-7-foundation-models/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/17ZAj6izyYhV-SXA_UKNWjYo0adbL2E8n/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-8---ml-teams-and-project-management&#34;&gt;Lecture 8 - ML Teams and Project Management&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=a54xH6nT4Sw&amp;amp;list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-8-teams-and-pm/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1o2x8ywivp555__AEbLLI28BsiQmHobOh/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lecture-9---ethics&#34;&gt;Lecture 9 - Ethics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur&amp;amp;v=7FQpbYTqjAA&amp;amp;feature=emb_title&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YouTube&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://fullstackdeeplearning.com/course/2022/lecture-9-ethics/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lecture Notes&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1ytLW4fOSef1PkWmSsoFdWdrFG5d0oCKh/view&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>배치 관리 소프트웨어 런데크 (Rundeck)</title>
        <link>https://meme2515.github.io/mlops/rundeck/</link>
        <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
        
        <guid>https://meme2515.github.io/mlops/rundeck/</guid>
        <description>&lt;img src="https://meme2515.github.io/mlops/images/rundeck-wordmark.svg" alt="Featured image of post 배치 관리 소프트웨어 런데크 (Rundeck)" /&gt;&lt;h2 id=&#34;프로그램-사용-배경&#34;&gt;프로그램 사용 배경&lt;/h2&gt;
&lt;p&gt;업무 중 머신러닝 학습 데이터 생성을 위해 6대 로컬 PC에서 다소 리소스 인텐시브한 작업을 반복적으로, 장기간 진행할 니즈가 생겼다. 최초에는 6대 각각의 로컬 환경에서 Windows 공식 배치관리 툴인 &lt;a class=&#34;link&#34; href=&#34;https://docs.microsoft.com/en-us/windows/win32/taskschd/task-scheduler-start-page&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Task Scheduler&lt;/a&gt; 에 관련 .bat 파일을 등록할 요량이었으나 다음과 같은 이유로 별도 배치 관리 툴을 찾아보게 되었다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;6대 PC에서 개별적인 로컬 스케줄러를 관리한다는 것은 물리적인 모니터링을 필요로하기에 데이터 생성 기간동안 지나치게 많은 시간을 뺏길 것 같았다. &lt;strong&gt;빠른 대응이 가능한 중앙화된 모니터링 체계&lt;/strong&gt;가 필요했다.&lt;/li&gt;
&lt;li&gt;프로세스는 경우에 따른 작업 시간이 달라 일정기간 지속 시 재시작 가능한 &lt;strong&gt;룰 기반 배치 관리&lt;/strong&gt;가 필요했다.&lt;/li&gt;
&lt;li&gt;데이터 생성 도중 프로세스에 변동이 있을 가능성이 있었기때문에 &lt;strong&gt;프로세스 일괄 수정이 가능&lt;/strong&gt;한 툴이 필요했다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;최초 머리에 떠오른 솔루션은 &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Apache Airflow&lt;/a&gt; 였으나 그닥 익숙한 솔루션도 되지 못했고, 모니터링 환경이 Windows 10 이었기때문에 환경 세팅에 어려움이 있었다. 그렇게 구글링을 계속하며 &lt;a class=&#34;link&#34; href=&#34;https://www.ansible.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ansible&lt;/a&gt;과 같은 SSH 기반 솔루션을 생각했으나 보안상 이유로 다시 세팅에 어려움이 있었고&amp;hellip; 적합한 오픈소스 솔루션인 &lt;a class=&#34;link&#34; href=&#34;https://www.pagerduty.com/integrations/rundeck-runbook-automation/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck&lt;/a&gt;를 발견했다.&lt;/p&gt;
&lt;h2 id=&#34;rundeck-소개&#34;&gt;Rundeck 소개&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/rundeck_example.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 1. Rundeck 파이프라인 예 - 유저가 생성한 Job 들을 Node 별로 할당 및 실행, 에러 발생 등 유사시 알림 설정&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;미국의 클라우드 소프트웨어 업체인 &lt;a class=&#34;link&#34; href=&#34;https://www.pagerduty.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PagerDuty&lt;/a&gt; 사에서 개발한 작업 관리 소프트웨어이며, Physical, VM, Container, Serverless 환경에서 스크립트, API 호출 등의 작업을 스케줄링 및 관리 할 수 있다. 유학 중 룸메이트가 취업했다고 좋아하던 회사인데 좋은 프로그램을 만들고있었다.&lt;/p&gt;
&lt;p&gt;많은 유즈 케이스들이 있는데, 가장 대중적인 예시는 &lt;a class=&#34;link&#34; href=&#34;https://sre.google/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SRE (사이트 신뢰성 엔지니어링)&lt;/a&gt; 영역이다. Google 엔지니어 &lt;a class=&#34;link&#34; href=&#34;https://www.linkedin.com/in/benjamin-treynor-sloss-207120/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ben Treynor Sloss&lt;/a&gt;가 창안한 개념인데, DevOps가 개발과 운영영역 간 사일로를 줄이는 철학적 접근이라고 한다면, SRE란 operation 영역의 문제들을 엔지니어링 관점에서 해결하는 방법론이라고 정의할 수 있다. 조직의 SRE팀이 계정 및 권한 관리, 인프라 리소스 관리 등의 운영 관점의 문제들을 자동화를 통해 해결하고나면, Dev팀은 소프트웨어 개발에, Ops팀은 제품 안정화에 더욱 집중할 수 있다는 식이다 (나도 현재는 이정도로만 이해하고 있고, 관심이 있다면 &lt;a class=&#34;link&#34; href=&#34;https://www.dynatrace.com/news/blog/what-is-site-reliability-engineering/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1번&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=uTEL8Ff1Zvk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2번&lt;/a&gt; 링크에서 더욱 상세한 내용을 확인할 수 있다).&lt;/p&gt;
&lt;p&gt;Rundeck 솔루션은 이러한 SRE 관점의 운영 절차를 표준화할 수 있는 플랫폼을 제공하며, 이러한 절차들은 조직 내에서 안전하게 공유되게 된다. 나의 경우는 아직 관련 지식이 부족하며, 당장 필요한 영역은 workload automation 으로 한정되어있기 때문에 깊은 내용은 추후에 더 알아보기로 하자.&lt;/p&gt;
&lt;p&gt;핵심적으로 짚고 넘어가야 할 개념은 다음과 같다.&lt;/p&gt;
&lt;h3 id=&#34;projects&#34;&gt;Projects&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/manual/projects/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck Documentation - Projects&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rundeck 내 작업 환경의 개념이다. 한개 Rundeck 서버에 여러개의 Project를 관리할 수 있으며, 프로젝트의 개념은 사용자가 정의하기 나름이다. 팀, 인프라, 어플리케이션, 환경 등 사용 목적에 맞게 Project를 구분하게 된다.&lt;/p&gt;
&lt;h3 id=&#34;jobs&#34;&gt;Jobs&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/manual/04-jobs.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck Documentation - Jobs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;실행하고자 하는 프로세스의 묶음이다. &lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Batch_file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;윈도우 batch 파일&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow의 DAG&lt;/a&gt; 개념과 유사하다.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://meme2515.github.io/mlops/images/airflow_example.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fig 2. Airflow의 DAG 개념 예 - branch_b를 에러 케이스라고 보면 될 듯 하다&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Rundeck 내에서는 Job 단위로 스케줄러 설정이 가능하고, 개별적인 히스토리가 남게된다. 한개 Job을 생성할 때 input option을 설정하거나, 에러 핸들링 룰을 생성하는 등 부수적인 옵션이 주어지게 된다.&lt;/p&gt;
&lt;h3 id=&#34;steps&#34;&gt;Steps&lt;/h3&gt;
&lt;p&gt;CLI 커맨드, 스크립트 실행, 다른 Job 호출 등 하나의 Job을 구성하는 개별적인 태스크를 지칭하는 용어이다. 또한 개별 Step 내에서 다양한 플러그인 활용이 가능하다.&lt;/p&gt;
&lt;h3 id=&#34;nodes&#34;&gt;Nodes&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/manual/05-nodes.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rundeck Documentation - Nodes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Job이 실행되는 대상이다 (Physical, VM, Container, API, Database 등). 나의 경우에는 6대로 분할된 로컬 PC에 해당한다. 각각의 Node는 태그와 속성값을 지니게된다.&lt;/p&gt;
&lt;p&gt;Rundeck의 &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=QSY_qw9Buic&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 소개 영상&lt;/a&gt;을 확인하면 Projects -&amp;gt; Jobs -&amp;gt; Steps -&amp;gt; Nodes 순으로 계층구조 개념을 띄고있다.&lt;/p&gt;
&lt;h2 id=&#34;설치-방법-&#34;&gt;설치 방법 💻&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/administration/install/windows.html#folder-structure&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;윈도우 설치 Doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/administration/install/linux-deb.html#installing-rundeck&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ubuntu 설치 Doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/administration/install/linux-rpm.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CentOS 설치 Doc&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;내가-사용한-방법&#34;&gt;내가 사용한 방법&lt;/h2&gt;
&lt;h3 id=&#34;winrm&#34;&gt;WinRM&lt;/h3&gt;
&lt;p&gt;네트워크를 통해 원격으로 터미널을 제어하는 방법은 SSH (Secure Shell) 커맨드가 가장 익숙했고, Windows 10 부터는 OpenSSH라는 연관 툴을 기본으로 제공한다는 &lt;a class=&#34;link&#34; href=&#34;https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 가이드&lt;/a&gt;를 확인해 세팅을 시도했다. 하지만 세팅에 필요한 PowerShell이 보안상의 이유로 제한되어있어 진행이 어려웠다.&lt;/p&gt;
&lt;p&gt;이런 저런 대안을 찾아보다 Rundeck에서 제공하는 &lt;a class=&#34;link&#34; href=&#34;https://github.com/diyan/pywinrm&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;pywinrim&lt;/a&gt; 이라는 플러그인을 통해 Windows Node 설정이 가능하다는 &lt;a class=&#34;link&#34; href=&#34;https://docs.rundeck.com/docs/learning/howto/configuring-windows-nodes.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;공식 가이드&lt;/a&gt;를 확인했다. WinRM (Windows Remote Management)은 SSH의 Windows 네이티브 버전 정도로 이해가 되는데, 실제 프로토콜 방식은 굉장히 다르다고한다 (&lt;a class=&#34;link&#34; href=&#34;https://www.reddit.com/r/sysadmin/comments/nadfbs/winrm_vs_openssh/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;연관 글&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;pywinrm은 이런 WinRM 연결을 파이썬 환경에서 구현 가능하도록 하는 패키지인데, Rundeck내에서 해당 패키지를 활용한 노드 생성 기능을 구현한 듯 했다. 하지만 세팅이 생각보다 간단하지는 않았고, 나는 파이썬 스크립팅을 선호했기에 해당 패키지를 별도로 사용해 Rundeck에서는 .py 파일만 실행하는 접근법을 택했다.&lt;/p&gt;
&lt;p&gt;하단은 pywinrm 패키지 사용 예시이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; import winrm
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; s = winrm.Session(&amp;#39;windows-host.example.com&amp;#39;, auth=(&amp;#39;username&amp;#39;, &amp;#39;password&amp;#39;))
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; r = s.run_cmd(&amp;#39;ipconfig&amp;#39;, [&amp;#39;/all&amp;#39;])
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; r.status_code
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;gt;&amp;gt;&amp;gt; r.std_out
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Windows IP Configuration
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Host Name . . . . . . . . . . . . : WINDOWS-HOST
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Primary Dns Suffix  . . . . . . . :
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Node Type . . . . . . . . . . . . : Hybrid
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    IP Routing Enabled. . . . . . . . : No
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    WINS Proxy Enabled. . . . . . . . : No
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;filezilla-pscp&#34;&gt;FileZilla, PSCP&lt;/h3&gt;
&lt;p&gt;학습 데이터 생성에 필요한 초기 데이터를 6대 PC에 분할하는 작업을 위해 메인 PC에 세팅한 &lt;a class=&#34;link&#34; href=&#34;https://filezilla-project.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FileZilla&lt;/a&gt; 서버를 활용했다. 세팅 난이도도 높지 않고, 단순한 파일공유 (FTP) 프로그램으로 생각하면 될 듯 하다.&lt;/p&gt;
&lt;p&gt;일련의 과정을 통해 생성된 학습 데이터는 각각 6대 PC로 부터 실제 학습을 수행할 리눅스 서버에 &lt;a class=&#34;link&#34; href=&#34;https://documentation.help/PuTTY/pscp.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PSCP&lt;/a&gt; 커맨드를 통해 전송했다. 윈도우 환경에서 리눅스 환경으로 파일을 전송하기 위해 주로 사용되는 명령어라고 한다.&lt;/p&gt;
&lt;h2 id=&#34;결론&#34;&gt;결론&lt;/h2&gt;
&lt;p&gt;6대 PC에 스케줄링된 batch job의 성공 여부를 하나의 환경에서 모니터링 가능한 체계를 구축했다. 또한 일정시간 이상 batch job 지속 시 이를 취소하는 룰을 손쉽게 세팅할 수 있었고, 핵심 코드 또한 중심이 되는 서버 PC에서 수정이 가능하도록 했다. 언급한 3가지 요건을 어느정도 충족한 결과였다.&lt;/p&gt;
&lt;p&gt;MLOps와 어느정도 연관성이 있는지는 사실 잘 모르겠다. 리소스 인텐시브한 데이터 생성 과정에서 유지/보수가 가능한 체계를 구축했다는데 의미가 있을수는 있으나 구축하게 될 모델과 직접적인 연관성이 있는건 아니고, Rundeck 이라는 프로그램 또한 분야에서 자주 활용되는 툴은 아닌 것 같다는 인상을 받았다.&lt;/p&gt;
&lt;p&gt;다만 데이터 생성 과정을 여러대의 PC에 분산하고, 이를 모니터링 할 수 있는 체계는 생각보다 유용했고, 다시 사용할 일이 있지않을까 하는 생각이 들었다. 향후에는 조금 더 언급량이 많은 Ansible이나 Airflow같은 툴을 리눅스 기반의 환경에서 사용해보고 싶다.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
